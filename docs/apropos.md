# À propos

Fort de près de **2 ans d’expérience** dans les métiers de la data, je suis motivé par la curiosité et la rigueur que nécessitent la **statistique** et l’**IA**. Je crois à la valeur de l’exploitation raisonnée des données et des méthodes quantitatives pour répondre à des enjeux concrets — de la compréhension métier jusqu’au déploiement.

- 📍 **Basé en France**
- 💼 **Intérêts** : Banque/Assurance, Santé, Énergie, Aéro/Défense
- 🧰 **Stack** : Python, R, SQL, DAX, VBA, Git/GitHub, GitLab CI/CD

---

## Domaines d’expertise

### 1) Ingénierie & MLOps léger
- **CI/CD** pour la data science : GitHub Actions / GitLab CI, build & déploiement automatiques (apps Streamlit/Docs/Packages).
- **Tests & qualité** : tests unitaires/intégration (pytest, unittest), linting, reproductibilité (environnements verrouillés).
- **Intégration de modèles** : packaging, endpoints simples (FastAPI/Flask), suivi d’expériences et monitoring basiques.
- **Data pipeline** : ingestion, nettoyage, features, orchestration simple (scripts & cron/CI).

### 2) NLP (Traitement automatique du langage)
- **Objectifs** : classification de textes, analyse de thèmes, nettoyage & normalisation.
- **Prétraitement** : tokenisation, lemmatisation, gestion des stopwords, padding, pondération de classes.
- **Modèles** : RNN **LSTM/BiLSTM/GRU** (Keras/TensorFlow, PyTorch), embeddings (GloVe/Word2Vec), métriques `scikit-learn`.
- **Librairies** : spaCy / NLTK, TensorFlow/Keras, PyTorch, scikit-learn.

### 3) Computer Vision
- **Objectifs** : classification/segmentation, mesures et métriques par objet.
- **Outils** : **scikit-image**, OpenCV, TensorFlow/Keras, PyTorch.
- **Cas d’usage** : WSIs / imagerie médicale, démos interactives (Streamlit).

### 4) Statistiques & Machine Learning
- **Supervisé** : régressions (linéaires & non linéaires), **KNN**, **Random Forest**, **XGBoost**, réseaux de neurones.
- **Non supervisé** : **K-means**, **classification hiérarchique (CAH)**, **ACP**, **AFC**, **NMF**.
- **Séries temporelles & Panel** : données transversales, séries, **modélisation panel** (effets fixes/hasard).
- **Évaluation** : validation croisée, courbes ROC/PR, F1/Recall/Precision, interprétation locale simple.

### 5) Analyse de données & Dataviz
- **Python** : **pandas**, **NumPy**, SciPy, statsmodels ; **Matplotlib**, **Seaborn**, **Plotly**.
- **R** : **tidyverse** (`dplyr`, `readr`, `tidyr`), **ggplot2**, `plotly`, modélisation (`plm`, `broom`, `lmtest`, `sandwich`).
- **Excel** : préparation, analyses et automatisations (VBA/DAX lorsque pertinent).

---

## Langages & outils

- **Langages** : Python, R, SQL, DAX, VBA  
- **Data/ML** : pandas, NumPy, scikit-learn, TensorFlow/Keras, PyTorch, scikit-image, OpenCV  
- **Statistiques** : statsmodels (Py), `plm`/`broom`/`lmtest` (R)  
- **MLOps** : Git, GitHub/GitLab, **CI/CD**, tests, packaging, API (FastAPI/Flask)  
- **Dataviz** : Matplotlib, Seaborn, Plotly, ggplot2

---

## Certifications

- **SQL Fundamentals**  
- **Supervised & Unsupervised Learning with Python**  
- **Data Preparation & Analytics with Excel**

---

## Ma façon de travailler

1. **Cadrage** : objectifs mesurables, données disponibles, contraintes métier.  
2. **Pipeline** : collecte → qualité → features → expérimentation contrôlée.  
3. **Robustesse** : tests, traçabilité, reproductibilité, **CI/CD** pour automatiser.  
4. **Livrables** : modèle utilisable (API/app), visualisations claires, documentation actionnable.

> 🎯 **Ambition** : livrer des solutions fiables, explicables et déployables, qui créent de la valeur rapide tout en restant maintenables.

