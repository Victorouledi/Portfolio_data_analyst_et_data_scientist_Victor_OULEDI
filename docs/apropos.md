# Ã€ propos

Fort de prÃ¨s de **2 ans dâ€™expÃ©rience** dans les mÃ©tiers de la data, je suis motivÃ© par la curiositÃ© et la rigueur que nÃ©cessitent la **statistique** et lâ€™**IA**. Je crois Ã  la valeur de lâ€™exploitation raisonnÃ©e des donnÃ©es et des mÃ©thodes quantitatives pour rÃ©pondre Ã  des enjeux concrets â€” de la comprÃ©hension mÃ©tier jusquâ€™au dÃ©ploiement.

- ğŸ“ **BasÃ© en France**
- ğŸ’¼ **IntÃ©rÃªts** : Banque/Assurance, SantÃ©, Ã‰nergie, AÃ©ro/DÃ©fense
- ğŸ§° **Stack** : Python, R, SQL, DAX, VBA, Git/GitHub, GitLab CI/CD

---

## Domaines dâ€™expertise

### 1) IngÃ©nierie & MLOps lÃ©ger
- **CI/CD** pour la data science : GitHub Actions / GitLab CI, build & dÃ©ploiement automatiques (apps Streamlit/Docs/Packages).
- **Tests & qualitÃ©** : tests unitaires/intÃ©gration (pytest, unittest), linting, reproductibilitÃ© (environnements verrouillÃ©s).
- **IntÃ©gration de modÃ¨les** : packaging, endpoints simples (FastAPI/Flask), suivi dâ€™expÃ©riences et monitoring basiques.
- **Data pipeline** : ingestion, nettoyage, features, orchestration simple (scripts & cron/CI).

### 2) NLP (Traitement automatique du langage)
- **Objectifs** : classification de textes, analyse de thÃ¨mes, nettoyage & normalisation.
- **PrÃ©traitement** : tokenisation, lemmatisation, gestion des stopwords, padding, pondÃ©ration de classes.
- **ModÃ¨les** : RNN **LSTM/BiLSTM/GRU** (Keras/TensorFlow, PyTorch), embeddings (GloVe/Word2Vec), mÃ©triques `scikit-learn`.
- **Librairies** : spaCy / NLTK, TensorFlow/Keras, PyTorch, scikit-learn.

### 3) Computer Vision
- **Objectifs** : classification/segmentation, mesures et mÃ©triques par objet.
- **Outils** : **scikit-image**, OpenCV, TensorFlow/Keras, PyTorch.
- **Cas dâ€™usage** : WSIs / imagerie mÃ©dicale, dÃ©mos interactives (Streamlit).

### 4) Statistiques & Machine Learning
- **SupervisÃ©** : rÃ©gressions (linÃ©aires & non linÃ©aires), **KNN**, **Random Forest**, **XGBoost**, rÃ©seaux de neurones.
- **Non supervisÃ©** : **K-means**, **classification hiÃ©rarchique (CAH)**, **ACP**, **AFC**, **NMF**.
- **SÃ©ries temporelles & Panel** : donnÃ©es transversales, sÃ©ries, **modÃ©lisation panel** (effets fixes/hasard).
- **Ã‰valuation** : validation croisÃ©e, courbes ROC/PR, F1/Recall/Precision, interprÃ©tation locale simple.

### 5) Analyse de donnÃ©es & Dataviz
- **Python** : **pandas**, **NumPy**, SciPy, statsmodels ; **Matplotlib**, **Seaborn**, **Plotly**.
- **R** : **tidyverse** (`dplyr`, `readr`, `tidyr`), **ggplot2**, `plotly`, modÃ©lisation (`plm`, `broom`, `lmtest`, `sandwich`).
- **Excel** : prÃ©paration, analyses et automatisations (VBA/DAX lorsque pertinent).

---

## Langages & outils

- **Langages** : Python, R, SQL, DAX, VBA  
- **Data/ML** : pandas, NumPy, scikit-learn, TensorFlow/Keras, PyTorch, scikit-image, OpenCV  
- **Statistiques** : statsmodels (Py), `plm`/`broom`/`lmtest` (R)  
- **MLOps** : Git, GitHub/GitLab, **CI/CD**, tests, packaging, API (FastAPI/Flask)  
- **Dataviz** : Matplotlib, Seaborn, Plotly, ggplot2

---

## Certifications

- **SQL Fundamentals**  
- **Supervised & Unsupervised Learning with Python**  
- **Data Preparation & Analytics with Excel**

---

## Ma faÃ§on de travailler

1. **Cadrage** : objectifs mesurables, donnÃ©es disponibles, contraintes mÃ©tier.  
2. **Pipeline** : collecte â†’ qualitÃ© â†’ features â†’ expÃ©rimentation contrÃ´lÃ©e.  
3. **Robustesse** : tests, traÃ§abilitÃ©, reproductibilitÃ©, **CI/CD** pour automatiser.  
4. **Livrables** : modÃ¨le utilisable (API/app), visualisations claires, documentation actionnable.

> ğŸ¯ **Ambition** : livrer des solutions fiables, explicables et dÃ©ployables, qui crÃ©ent de la valeur rapide tout en restant maintenables.

