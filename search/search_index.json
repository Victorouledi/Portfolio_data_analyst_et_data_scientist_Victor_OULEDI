{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bonjour, je suis Victor Ouledi","text":"<p>Data Scientist/ Data Analyst/ Machine Learning &amp; AI Engineer (NLP, Computer Vision). Fort de pr\u00e8s de 2 ans d\u2019exp\u00e9rience dans les m\u00e9tiers de la data et passionne\u0301 par cet univers et celui de la statistique et de l\u2019IA, je suis stimule\u0301 par la curiosite\u0301 et la rigueur que ces disciplines impliquent. En effet, je suis convaincu de la plus value de l'exploitation de donne\u0301es et de l'utilisation de me\u0301thodes statistiques avanc\u00e9es dans l'objectif de re\u0301pondre le mieux possible a\u0300 diffe\u0301rents enjeux. Ainsi je suis pr\u00eat \u00e0 m\u2019engager \u00e0 100 % dans des missions qui vont dans ce sens.</p> <p>\ud83d\udc49 Parcourez mes projets ci-dessous ou via l\u2019onglet Projets.</p> <ul> <li> <p>IA &amp; NLP :  Model LSTM pour  la pr\u00e9diction du type de sujet conernant les r\u00e9clamations et pleintes \u00e0 l'encontre de services financiers</p> </li> <li> <p>Application web streamlit de computer vision : R\u00e9seau de neuronnes convultif et classification d'imageries m\u00e9dicales</p> </li> <li> <p>Projet  analyse de donn\u00e9es en Python: syst\u00e8me d'actionnariat chez Terre de Liens</p> </li> <li> <p>Clustering, et Analyse en Composantes Principales (ACP) en Python : Criminalit\u00e9 aux Etats-Unis</p> </li> <li> <p>Analyse factorielle des correspondances (AFC) en Python: Elections pr\u00e9sidentielles 2022, focus sur l'Ile de France</p> </li> <li> <p>Mod\u00e9lisation statistique en donn\u00e9es de panel en R : Application de la m\u00e9thode des prix h\u00e9doniques au march\u00e9 immobilier Lyonnais</p> </li> <li> <p>Mod\u00e9lisation statistique en donn\u00e9es de panel en R : Analyse des d\u00e9terminants des salaires aux Etats-Unis</p> </li> </ul> <p>Certifications data - SQL fundamentals - Supervised Learning with Python - Unsupervised Learning with Python - Data preparation with Excel - Data analytics with Excel</p> <p>Voir tous les projets \u2192</p>"},{"location":"apropos/","title":"\u00c0 propos","text":"<p>Fort de pr\u00e8s de 2 ans d\u2019exp\u00e9rience dans les m\u00e9tiers de la data, je suis motiv\u00e9 par la curiosit\u00e9 et la rigueur que n\u00e9cessitent la statistique et l\u2019IA. Je crois \u00e0 la valeur de l\u2019exploitation raisonn\u00e9e des donn\u00e9es et des m\u00e9thodes quantitatives pour r\u00e9pondre \u00e0 des enjeux concrets \u2014 de la compr\u00e9hension m\u00e9tier jusqu\u2019au d\u00e9ploiement.</p> <ul> <li>\ud83d\udccd Bas\u00e9 en France</li> <li>\ud83d\udcbc Int\u00e9r\u00eats : Banque/Assurance, Sant\u00e9, \u00c9nergie, A\u00e9ro/D\u00e9fense</li> <li>\ud83e\uddf0 Stack : Python, R, SQL, DAX, VBA, Git/GitHub, GitLab CI/CD</li> </ul>"},{"location":"apropos/#domaines-dexpertise","title":"Domaines d\u2019expertise","text":""},{"location":"apropos/#1-ingenierie-mlops-leger","title":"1) Ing\u00e9nierie &amp; MLOps l\u00e9ger","text":"<ul> <li>CI/CD pour la data science : GitHub Actions / GitLab CI, build &amp; d\u00e9ploiement automatiques (apps Streamlit/Docs/Packages).</li> <li>Tests &amp; qualit\u00e9 : tests unitaires/int\u00e9gration (pytest, unittest), linting, reproductibilit\u00e9 (environnements verrouill\u00e9s).</li> <li>Int\u00e9gration de mod\u00e8les : packaging, endpoints simples (FastAPI/Flask), suivi d\u2019exp\u00e9riences et monitoring basiques.</li> <li>Data pipeline : ingestion, nettoyage, features, orchestration simple (scripts &amp; cron/CI).</li> </ul>"},{"location":"apropos/#2-nlp-traitement-automatique-du-langage","title":"2) NLP (Traitement automatique du langage)","text":"<ul> <li>Objectifs : classification de textes, analyse de th\u00e8mes, nettoyage &amp; normalisation.</li> <li>Pr\u00e9traitement : tokenisation, lemmatisation, gestion des stopwords, padding, pond\u00e9ration de classes.</li> <li>Mod\u00e8les : RNN LSTM/BiLSTM/GRU (Keras/TensorFlow, PyTorch), embeddings (GloVe/Word2Vec), m\u00e9triques <code>scikit-learn</code>.</li> <li>Librairies : spaCy / NLTK, TensorFlow/Keras, PyTorch, scikit-learn.</li> </ul>"},{"location":"apropos/#3-computer-vision","title":"3) Computer Vision","text":"<ul> <li>Objectifs : classification/segmentation, mesures et m\u00e9triques par objet.</li> <li>Outils : scikit-image, OpenCV, TensorFlow/Keras, PyTorch.</li> <li>Cas d\u2019usage : WSIs / imagerie m\u00e9dicale, d\u00e9mos interactives (Streamlit).</li> </ul>"},{"location":"apropos/#4-statistiques-machine-learning","title":"4) Statistiques &amp; Machine Learning","text":"<ul> <li>Supervis\u00e9 : r\u00e9gressions (lin\u00e9aires &amp; non lin\u00e9aires), KNN, Random Forest, XGBoost, r\u00e9seaux de neurones.</li> <li>Non supervis\u00e9 : K-means, classification hi\u00e9rarchique (CAH), ACP, AFC, NMF.</li> <li>S\u00e9ries temporelles &amp; Panel : donn\u00e9es transversales, s\u00e9ries, mod\u00e9lisation panel (effets fixes/hasard).</li> <li>\u00c9valuation : validation crois\u00e9e, courbes ROC/PR, F1/Recall/Precision, interpr\u00e9tation locale simple.</li> </ul>"},{"location":"apropos/#5-analyse-de-donnees-dataviz","title":"5) Analyse de donn\u00e9es &amp; Dataviz","text":"<ul> <li>Python : pandas, NumPy, SciPy, statsmodels ; Matplotlib, Seaborn, Plotly.</li> <li>R : tidyverse (<code>dplyr</code>, <code>readr</code>, <code>tidyr</code>), ggplot2, <code>plotly</code>, mod\u00e9lisation (<code>plm</code>, <code>broom</code>, <code>lmtest</code>, <code>sandwich</code>).</li> <li>Excel : pr\u00e9paration, analyses et automatisations (VBA/DAX lorsque pertinent).</li> </ul>"},{"location":"apropos/#langages-outils","title":"Langages &amp; outils","text":"<ul> <li>Langages : Python, R, SQL, DAX, VBA  </li> <li>Data/ML : pandas, NumPy, scikit-learn, TensorFlow/Keras, PyTorch, scikit-image, OpenCV  </li> <li>Statistiques : statsmodels (Py), <code>plm</code>/<code>broom</code>/<code>lmtest</code> (R)  </li> <li>MLOps : Git, GitHub/GitLab, CI/CD, tests, packaging, API (FastAPI/Flask)  </li> <li>Dataviz : Matplotlib, Seaborn, Plotly, ggplot2</li> </ul>"},{"location":"apropos/#certifications","title":"Certifications","text":"<ul> <li>SQL Fundamentals </li> <li>Supervised &amp; Unsupervised Learning with Python </li> <li>Data Preparation &amp; Analytics with Excel</li> </ul>"},{"location":"apropos/#ma-facon-de-travailler","title":"Ma fa\u00e7on de travailler","text":"<ol> <li>Cadrage : objectifs mesurables, donn\u00e9es disponibles, contraintes m\u00e9tier.  </li> <li>Pipeline : collecte \u2192 qualit\u00e9 \u2192 features \u2192 exp\u00e9rimentation contr\u00f4l\u00e9e.  </li> <li>Robustesse : tests, tra\u00e7abilit\u00e9, reproductibilit\u00e9, CI/CD pour automatiser.  </li> <li>Livrables : mod\u00e8le utilisable (API/app), visualisations claires, documentation actionnable.</li> </ol> <p>\ud83c\udfaf Ambition : livrer des solutions fiables, explicables et d\u00e9ployables, qui cr\u00e9ent de la valeur rapide tout en restant maintenables.</p>"},{"location":"contacts/","title":"Contacts","text":"<ul> <li>GitHub : https://github.com/Victorouledi</li> <li>LinkedIn : https://www.linkedin.com/in/victor-ouledi</li> <li>Email : ouledivictor@gmail.com</li> </ul>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/","title":"Importation des packages et des donn\u00e9es","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nfrom fanalysis.ca import CA\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import pandas as pd from fanalysis.ca import CA import numpy as np import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>df=pd.read_excel(\"election_2022_FR.xlsx\")\ndf\n</pre> df=pd.read_excel(\"election_2022_FR.xlsx\") df Out[2]: Departement Nathalie ARTHAUD Fabien ROUSSEL Emmanuel MACRON Jean LASSALLE Marine LE PEN \u00c9ric ZEMMOUR Jean-Luc M\u00c9LENCHON Anne HIDALGO Yannick JADOT Val\u00e9rie P\u00c9CRESSE Philippe POUTOU Nicolas DUPONT-AIGNAN 0 Seine-Saint-Denis 2756 11642 110118 6805 64543 27969 266632 5890 19352 17481 3663 6300 1 Val-de-Marne 2504 14954 171409 8944 69599 43430 192427 8276 31904 32522 3730 9359 2 Val-d'Oise 2392 10060 138166 9101 91081 37564 175666 6094 20710 26403 3352 8996 3 Essonne 2831 13480 164503 11610 105862 39284 167310 7944 29562 33046 4306 15203 4 Hauts-de-Seine 2306 13170 287494 11260 64812 62761 199640 10518 47103 62231 3704 9743 5 Paris 2891 17267 372820 12139 58429 86088 317372 22901 80268 69564 5732 9591 6 Seine-et-Marne 3440 12843 165208 13797 155738 47893 170969 7853 26718 36828 4600 15042 7 Yvelines 2774 11721 246062 13687 101398 64407 168585 9046 40470 61296 3963 13097 In\u00a0[3]: Copied! <pre># Extraction des noms de colonnes et de la colonne \"Departement\"\ncol_names = list(df.columns)[1:]\ndept_names = df['Departement']\n</pre> # Extraction des noms de colonnes et de la colonne \"Departement\" col_names = list(df.columns)[1:] dept_names = df['Departement']  In\u00a0[4]: Copied! <pre># Extraction des donn\u00e9es num\u00e9riques\nX = df[col_names].values\n</pre> # Extraction des donn\u00e9es num\u00e9riques X = df[col_names].values In\u00a0[5]: Copied! <pre># Calcul du profil ligne\nrow_sum = np.sum(X, axis=1)\nrow_profile = X / row_sum[:, np.newaxis]\n\n# Affichage\nprint(\"Profil ligne:\")\nprint(pd.DataFrame(row_profile, index=dept_names, columns=col_names))\n</pre> # Calcul du profil ligne row_sum = np.sum(X, axis=1) row_profile = X / row_sum[:, np.newaxis]  # Affichage print(\"Profil ligne:\") print(pd.DataFrame(row_profile, index=dept_names, columns=col_names))    <pre>Profil ligne:\n                   Nathalie ARTHAUD  Fabien ROUSSEL  Emmanuel MACRON  \\\nDepartement                                                            \nSeine-Saint-Denis          0.005074        0.021434         0.202739   \nVal-de-Marne               0.004251        0.025386         0.290988   \nVal-d'Oise                 0.004517        0.018996         0.260895   \nEssonne                    0.004758        0.022658         0.276503   \nHauts-de-Seine             0.002976        0.016999         0.371084   \nParis                      0.002740        0.016366         0.353363   \nSeine-et-Marne             0.005205        0.019432         0.249963   \nYvelines                   0.003766        0.015914         0.334094   \n\n                   Jean LASSALLE  Marine LE PEN  \u00c9ric ZEMMOUR  \\\nDepartement                                                     \nSeine-Saint-Denis       0.012529       0.118831      0.051494   \nVal-de-Marne            0.015184       0.118153      0.073728   \nVal-d'Oise              0.017185       0.171986      0.070931   \nEssonne                 0.019515       0.177937      0.066030   \nHauts-de-Seine          0.014534       0.083656      0.081009   \nParis                   0.011505       0.055380      0.081595   \nSeine-et-Marne          0.020875       0.235635      0.072463   \nYvelines                0.018584       0.137674      0.087449   \n\n                   Jean-Luc M\u00c9LENCHON  Anne HIDALGO  Yannick JADOT  \\\nDepartement                                                          \nSeine-Saint-Denis            0.490898      0.010844       0.035629   \nVal-de-Marne                 0.326669      0.014050       0.054161   \nVal-d'Oise                   0.331705      0.011507       0.039106   \nEssonne                      0.281221      0.013353       0.049689   \nHauts-de-Seine               0.257686      0.013576       0.060798   \nParis                        0.300809      0.021706       0.076079   \nSeine-et-Marne               0.258680      0.011882       0.040425   \nYvelines                     0.228898      0.012282       0.054949   \n\n                   Val\u00e9rie P\u00c9CRESSE  Philippe POUTOU  Nicolas DUPONT-AIGNAN  \nDepartement                                                                  \nSeine-Saint-Denis          0.032184         0.006744               0.011599  \nVal-de-Marne               0.055210         0.006332               0.015888  \nVal-d'Oise                 0.049856         0.006329               0.016987  \nEssonne                    0.055545         0.007238               0.025554  \nHauts-de-Seine             0.080325         0.004781               0.012576  \nParis                      0.065934         0.005433               0.009090  \nSeine-et-Marne             0.055722         0.006960               0.022759  \nYvelines                   0.083225         0.005381               0.017783  \n</pre> In\u00a0[6]: Copied! <pre># Calcul du profil colonne\ncol_sum = np.sum(X, axis=0)\ncol_profile = X / col_sum[np.newaxis, :]\n\n# Affichage\nprint(\"Profil colonne:\")\nprint(pd.DataFrame(col_profile, index=dept_names, columns=col_names))\n</pre> # Calcul du profil colonne col_sum = np.sum(X, axis=0) col_profile = X / col_sum[np.newaxis, :]  # Affichage print(\"Profil colonne:\") print(pd.DataFrame(col_profile, index=dept_names, columns=col_names)) <pre>Profil colonne:\n                   Nathalie ARTHAUD  Fabien ROUSSEL  Emmanuel MACRON  \\\nDepartement                                                            \nSeine-Saint-Denis          0.125879        0.110732         0.066505   \nVal-de-Marne               0.114369        0.142233         0.103522   \nVal-d'Oise                 0.109254        0.095685         0.083445   \nEssonne                    0.129305        0.128214         0.099351   \nHauts-de-Seine             0.105326        0.125265         0.173631   \nParis                      0.132045        0.164233         0.225163   \nSeine-et-Marne             0.157121        0.122155         0.099777   \nYvelines                   0.126701        0.111483         0.148608   \n\n                   Jean LASSALLE  Marine LE PEN  \u00c9ric ZEMMOUR  \\\nDepartement                                                     \nSeine-Saint-Denis       0.077911       0.090719      0.068318   \nVal-de-Marne            0.102401       0.097825      0.106083   \nVal-d'Oise              0.104198       0.128019      0.091755   \nEssonne                 0.132924       0.148795      0.095956   \nHauts-de-Seine          0.128917       0.091097      0.153301   \nParis                   0.138981       0.082125      0.210281   \nSeine-et-Marne          0.157963       0.218899      0.116985   \nYvelines                0.156704       0.142521      0.157322   \n\n                   Jean-Luc M\u00c9LENCHON  Anne HIDALGO  Yannick JADOT  \\\nDepartement                                                          \nSeine-Saint-Denis            0.160757      0.075011       0.065359   \nVal-de-Marne                 0.116018      0.105397       0.107752   \nVal-d'Oise                   0.105912      0.077609       0.069946   \nEssonne                      0.100874      0.101169       0.099842   \nHauts-de-Seine               0.120367      0.133950       0.159085   \nParis                        0.191349      0.291651       0.271096   \nSeine-et-Marne               0.103080      0.100010       0.090237   \nYvelines                     0.101643      0.115203       0.136683   \n\n                   Val\u00e9rie P\u00c9CRESSE  Philippe POUTOU  Nicolas DUPONT-AIGNAN  \nDepartement                                                                  \nSeine-Saint-Denis          0.051510         0.110832               0.072139  \nVal-de-Marne               0.095830         0.112859               0.107167  \nVal-d'Oise                 0.077800         0.101422               0.103010  \nEssonne                    0.097374         0.130287               0.174085  \nHauts-de-Seine             0.183372         0.112073               0.111564  \nParis                      0.204979         0.173434               0.109824  \nSeine-et-Marne             0.108518         0.139183               0.172241  \nYvelines                   0.180616         0.119909               0.149970  \n</pre> In\u00a0[7]: Copied! <pre># Extraction des noms de colonnes\ncol_names = list(df.columns)[1:]\n\n# Calcul de la somme des votes pour chaque candidat\ntotal_votes = df[col_names].sum()\n\n# Calcul des proportions pour chaque candidat\nprop_votes = total_votes \n# Tri des proportions de la plus grande \u00e0 la plus petite\nprop_votes = prop_votes.sort_values(ascending=False)\n\n# Cr\u00e9ation du diagramme en barres\nfig, ax = plt.subplots(figsize=(10, 6))\nax.bar(prop_votes.index, prop_votes)\n\n# Ajout de labels et de titres\nax.set_xlabel('Candidat')\nax.set_ylabel('Proportion de votes')\nax.set_title('R\u00e9partition des votes par candidat (par ordre d\u00e9croissant)')\n# Rotation des noms des candidats\nplt.xticks(rotation=45, ha='right')\n\n# Affichage du diagramme\nplt.show()\n</pre> # Extraction des noms de colonnes col_names = list(df.columns)[1:]  # Calcul de la somme des votes pour chaque candidat total_votes = df[col_names].sum()  # Calcul des proportions pour chaque candidat prop_votes = total_votes  # Tri des proportions de la plus grande \u00e0 la plus petite prop_votes = prop_votes.sort_values(ascending=False)  # Cr\u00e9ation du diagramme en barres fig, ax = plt.subplots(figsize=(10, 6)) ax.bar(prop_votes.index, prop_votes)  # Ajout de labels et de titres ax.set_xlabel('Candidat') ax.set_ylabel('Proportion de votes') ax.set_title('R\u00e9partition des votes par candidat (par ordre d\u00e9croissant)') # Rotation des noms des candidats plt.xticks(rotation=45, ha='right')  # Affichage du diagramme plt.show()   In\u00a0[8]: Copied! <pre># Extraction des noms de colonnes\ncol_names = list(df.columns)[1:]\n\n# Calcul de la somme des votes pour chaque candidat\ntotal_votes = df[col_names].sum()\n\n# Calcul des proportions pour chaque candidat\nprop_votes = total_votes / total_votes.sum()\n\n# Tri des proportions de la plus grande \u00e0 la plus petite\nprop_votes = prop_votes.sort_values(ascending=False)\n\n# Cr\u00e9ation du diagramme en barres\nfig, ax = plt.subplots(figsize=(10, 6))\nax.bar(prop_votes.index, prop_votes)\n\n# Ajout de labels et de titres\nax.set_xlabel('Candidat')\nax.set_ylabel('Proportion de votes')\nax.set_title('R\u00e9partition des votes par candidat (par ordre d\u00e9croissant)')\n# Rotation des noms des candidats\nplt.xticks(rotation=45, ha='right')\n\n# Affichage du diagramme\nplt.show()\n</pre> # Extraction des noms de colonnes col_names = list(df.columns)[1:]  # Calcul de la somme des votes pour chaque candidat total_votes = df[col_names].sum()  # Calcul des proportions pour chaque candidat prop_votes = total_votes / total_votes.sum()  # Tri des proportions de la plus grande \u00e0 la plus petite prop_votes = prop_votes.sort_values(ascending=False)  # Cr\u00e9ation du diagramme en barres fig, ax = plt.subplots(figsize=(10, 6)) ax.bar(prop_votes.index, prop_votes)  # Ajout de labels et de titres ax.set_xlabel('Candidat') ax.set_ylabel('Proportion de votes') ax.set_title('R\u00e9partition des votes par candidat (par ordre d\u00e9croissant)') # Rotation des noms des candidats plt.xticks(rotation=45, ha='right')  # Affichage du diagramme plt.show()  In\u00a0[9]: Copied! <pre>df=df.set_index(\"Departement\")\n</pre> df=df.set_index(\"Departement\")  In\u00a0[10]: Copied! <pre># On cr\u00e9e une instale de la classe CA en passant les \u00e9tiquettes de lignes et les colonnes\n\nmy_ca=CA(row_labels=df.index.values,col_labels=df.columns.values,stats=True)\n</pre> # On cr\u00e9e une instale de la classe CA en passant les \u00e9tiquettes de lignes et les colonnes  my_ca=CA(row_labels=df.index.values,col_labels=df.columns.values,stats=True) In\u00a0[11]: Copied! <pre># Estime l'AFC\nmy_ca.fit(df.values)\n</pre> # Estime l'AFC my_ca.fit(df.values) Out[11]: <pre>CA(col_labels=array(['Nathalie ARTHAUD', 'Fabien ROUSSEL', 'Emmanuel MACRON',\n       'Jean LASSALLE', 'Marine LE PEN', '\u00c9ric ZEMMOUR',\n       'Jean-Luc M\u00c9LENCHON', 'Anne HIDALGO', 'Yannick JADOT',\n       'Val\u00e9rie P\u00c9CRESSE', 'Philippe POUTOU', 'Nicolas DUPONT-AIGNAN'],\n      dtype=object),\n   row_labels=array(['Seine-Saint-Denis', 'Val-de-Marne', \"Val-d'Oise\", 'Essonne',\n       'Hauts-de-Seine', 'Paris', 'Seine-et-Marne', 'Yvelines'],\n      dtype=object))</pre> In\u00a0[12]: Copied! <pre># Identification des valeurs propres\nmy_ca.eig_\n</pre> # Identification des valeurs propres my_ca.eig_  Out[12]: <pre>array([[3.67708156e-02, 2.41324630e-02, 1.19731847e-03, 5.41407476e-04,\n        1.51718248e-04, 1.35166582e-04, 2.74627897e-05],\n       [5.84068396e+01, 3.83320541e+01, 1.90182313e+00, 8.59972756e-01,\n        2.40989579e-01, 2.14698878e-01, 4.36219520e-02],\n       [5.84068396e+01, 9.67388937e+01, 9.86407168e+01, 9.95006896e+01,\n        9.97416792e+01, 9.99563780e+01, 1.00000000e+02]])</pre> In\u00a0[13]: Copied! <pre># Graphique des valeurs propres\nmy_ca.plot_eigenvalues()\n</pre> # Graphique des valeurs propres my_ca.plot_eigenvalues() In\u00a0[14]: Copied! <pre>my_ca.plot_eigenvalues(type=\"percentage\")\n</pre> my_ca.plot_eigenvalues(type=\"percentage\") In\u00a0[15]: Copied! <pre>my_ca.plot_eigenvalues(type=\"cumulative\")\n</pre> my_ca.plot_eigenvalues(type=\"cumulative\") In\u00a0[17]: Copied! <pre># Classement des points colonnes en fonction de leur contribution au 1er axe\nprint(\"Premier axe factoriel\")\nmy_ca.plot_row_cos2(num_axis=1)\nprint(\"Second axe factoriel\")\nmy_ca.plot_row_cos2(num_axis=2)\n</pre>   # Classement des points colonnes en fonction de leur contribution au 1er axe print(\"Premier axe factoriel\") my_ca.plot_row_cos2(num_axis=1) print(\"Second axe factoriel\") my_ca.plot_row_cos2(num_axis=2)  <pre>Premier axe factoriel\n</pre> <pre>Second axe factoriel\n</pre> In\u00a0[19]: Copied! <pre>#### Profil colonne (les Candidats)\n\nprint(\"Premier axe factoriel\")\nmy_ca.plot_col_cos2(num_axis=1)\nprint(\"Second axe factoriel\")\nmy_ca.plot_col_cos2(num_axis=2)\n</pre> #### Profil colonne (les Candidats)  print(\"Premier axe factoriel\") my_ca.plot_col_cos2(num_axis=1) print(\"Second axe factoriel\") my_ca.plot_col_cos2(num_axis=2)  <pre>Premier axe factoriel\n</pre> <pre>Second axe factoriel\n</pre> In\u00a0[22]: Copied! <pre># Analyse  du premier plan factoriel - les d\u00e9partements\nprint(\"Premier axe\")\nmy_ca.plot_row_contrib(num_axis=1)\nprint(\"Second axe\")\nmy_ca.plot_row_contrib(num_axis=2)\n</pre> # Analyse  du premier plan factoriel - les d\u00e9partements print(\"Premier axe\") my_ca.plot_row_contrib(num_axis=1) print(\"Second axe\") my_ca.plot_row_contrib(num_axis=2) <pre>Premier axe\n</pre> <pre>Second axe\n</pre> In\u00a0[21]: Copied! <pre># Analyse  du premier plan factoriel - les d\u00e9partements\nprint(\"Premier axe\")\nmy_ca.plot_col_contrib(num_axis=1)\nprint(\"Second axe\")\nmy_ca.plot_col_contrib(num_axis=2)\n</pre> # Analyse  du premier plan factoriel - les d\u00e9partements print(\"Premier axe\") my_ca.plot_col_contrib(num_axis=1) print(\"Second axe\") my_ca.plot_col_contrib(num_axis=2) <pre>Premier axe\n</pre> <pre>Second axe\n</pre> In\u00a0[\u00a0]: Copied! <pre>info_dep=my_ca.row_topandas()\ninfo_dep\n</pre> info_dep=my_ca.row_topandas() info_dep In\u00a0[\u00a0]: Copied! <pre>info_candidat=my_ca.col_topandas()\ninfo_candidat\n</pre> info_candidat=my_ca.col_topandas() info_candidat In\u00a0[16]: Copied! <pre># Graphique des d\u00e9partements (en ligne)\nmy_ca.mapping_row(num_x_axis=1,num_y_axis=2)\n</pre> # Graphique des d\u00e9partements (en ligne) my_ca.mapping_row(num_x_axis=1,num_y_axis=2) In\u00a0[18]: Copied! <pre># Graphique des candidats (en colonne)\nmy_ca.mapping_col(num_x_axis=1,num_y_axis=2)\n</pre> # Graphique des candidats (en colonne) my_ca.mapping_col(num_x_axis=1,num_y_axis=2) In\u00a0[20]: Copied! <pre># Graphique profil ligne profil colonne\n\nmy_ca.mapping(1, 2, figsize=(10, 8))\n</pre> # Graphique profil ligne profil colonne  my_ca.mapping(1, 2, figsize=(10, 8))"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#importation-des-packages-et-des-donnees","title":"Importation des packages et des donn\u00e9es\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#description-des-donnees","title":"Description des donn\u00e9es\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#distribution-des-votes-des-departements-par-candidat","title":"Distribution des votes des d\u00e9partements par candidat\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#repartition-des-votes-obtenus-par-les-candidats-selon-les-departements","title":"R\u00e9partition des votes obtenus par les candidats selon les d\u00e9partements\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#analyse-des-votes","title":"Analyse des votes\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#lanalyse-factorielle-des-correspondances-afc-theorie","title":"L'Analyse Factorielle des Correspondances (AFC) - Th\u00e9orie\u00b6","text":"<p>L'analyse factorielle des correspondances (AFC) est une m\u00e9thode statistique qui permet de r\u00e9duire les dimensions d'un tableau de donn\u00e9es crois\u00e9es. Elle permet \u00e9galement de visualiser la structure des relations entre les variables et les individus en utilisant des graphiques.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-1-construction-du-tableau-de-donnees","title":"\u00c9tape 1 : Construction du tableau de donn\u00e9es\u00b6","text":"<p>L'AFC n\u00e9cessite un tableau de donn\u00e9es crois\u00e9es appel\u00e9 \"tableau de contingence\". Ce tableau doit \u00eatre construit \u00e0 partir des donn\u00e9es brutes, en croisant les valeurs de chaque variable.</p> Variable 1 Variable 2 ... Variable p Individu 1 $n_{11}$ $n_{12}$ ... $n_{1p}$ Individu 2 $n_{21}$ $n_{22}$ ... $n_{2p}$ ... ... ... ... ... Individu n $n_{n1}$ $n_{n2}$ ... $n_{np}$ <p>Chaque $n_{ij}$ repr\u00e9sente le nombre d'individus ayant \u00e0 la fois la valeur $i$ pour la variable 1 et la valeur $j$ pour la variable 2.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-2-calcul-de-la-distance-de-khi-deux","title":"\u00c9tape 2 : Calcul de la distance de khi-deux\u00b6","text":"<p>La distance de khi-deux est une mesure de la diff\u00e9rence entre les observations et les fr\u00e9quences attendues sous l'hypoth\u00e8se d'ind\u00e9pendance entre les variables. Elle est utilis\u00e9e pour mesurer la similitude entre deux variables. La formule de la distance de khi-deux est la suivante :</p> <p>$$ d_{ij}^2 = \\sum_{k=1}^{p}\\frac{(n_{ik}n_{jk})^2}{n_{i\\cdot}n_{\\cdot k}n_{j\\cdot}n_{\\cdot k}} $$</p> <p>o\u00f9 $n_{i\\cdot}$ est la somme des effectifs de la ligne $i$, $n_{\\cdot k}$ est la somme des effectifs de la colonne $k$ et $n_{\\cdot\\cdot}$ est la somme totale des effectifs du tableau.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-3-calcul-de-la-matrice-des-distances","title":"\u00c9tape 3 : Calcul de la matrice des distances\u00b6","text":"<p>La matrice des distances est une matrice carr\u00e9e qui mesure les distances entre chaque paire de variables. Elle est calcul\u00e9e en utilisant la distance de khi-deux entre chaque paire de variables.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-4-calcul-des-cosinus-carres-et-des-contributions","title":"\u00c9tape 4 : Calcul des cosinus carr\u00e9s et des contributions\u00b6","text":"<p>Les cosinus carr\u00e9s mesurent l'association entre chaque variable et chaque axe factoriel. Ils sont calcul\u00e9s en utilisant la formule suivante :</p> <p>$$ cos^2_{ij} = \\frac{f_{ij}^2}{r_i c_j} $$</p> <p>o\u00f9 $f_{ij}$ est la fr\u00e9quence observ\u00e9e de la variable $i$ pour la cat\u00e9gorie $j$, $r_i$ est la somme des fr\u00e9quences de la variable $i$ et $c_j$ est la somme des fr\u00e9quences de la cat\u00e9gorie $j$.</p> <p>Les contributions mesurent l'importance de chaque variable pour l'axe factoriel correspondant. Elles sont calcul\u00e9es en utilisant la formule suivante :</p> <p>$$ contribution_{ij} = \\frac{cos^2_{ij}}{\\lambda_j} $$</p> <p>o\u00f9 $\\lambda_j$ est la valeur propre de l'axe factoriel $j$. Les contributions sont exprim\u00e9es en pourcentage et indiquent la part de la variance expliqu\u00e9e par chaque variable sur l'axe factoriel correspondant.</p> <p>Les cosinus carr\u00e9s et les contributions sont des indicateurs importants pour interpr\u00e9ter les r\u00e9sultats de l'AFC et s\u00e9lectionner les variables les plus pertinentes pour chaque axe factoriel.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-5-calcul-des-valeurs-propres","title":"\u00c9tape 5 : Calcul des valeurs propres\u00b6","text":"<p>Les valeurs propres sont des mesures de l'importance de chaque axe factoriel pour expliquer la variation totale des donn\u00e9es.</p> <p>Les valeurs propres sont calcul\u00e9es \u00e0 partir des cosinus carr\u00e9s des variables sur chaque axe factoriel. La formule de calcul est la suivante :</p> <p>$$ \\lambda_j = \\sum_{i=1}^{n}cos^2_{ij} $$</p> <p>o\u00f9 $\\lambda_j$ est la valeur propre de l'axe factoriel $j$ et $cos^2_{ij}$ est le carr\u00e9 du cosinus de l'angle form\u00e9 entre la variable $i$ et l'axe factoriel $j$. Les valeurs propres sont ordonn\u00e9es de mani\u00e8re d\u00e9croissante, et l'axe factoriel qui a la plus grande valeur propre est appel\u00e9 le premier axe factoriel.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#etape-6-construction-du-graphique","title":"\u00c9tape 6 : Construction du graphique\u00b6","text":"<p>Le graphique de l'AFC est un nuage de points qui repr\u00e9sente les individus et les variables dans un espace de dimension r\u00e9duite. Les axes du graphique sont les axes factoriels, et les points sont plac\u00e9s en fonction de leurs coordonn\u00e9es sur ces axes. Les points qui sont proches les uns des autres ont des profils similaires.</p> <p>Pour construire le graphique de l'AFC, on utilise les coordonn\u00e9es factorielles des individus et des variables qui ont \u00e9t\u00e9 calcul\u00e9es \u00e0 l'\u00e9tape 4. Les individus sont repr\u00e9sent\u00e9s par des cercles, et les variables sont repr\u00e9sent\u00e9es par des fl\u00e8ches qui indiquent leur contribution \u00e0 chaque axe factoriel.</p> <p>On peut \u00e9galement colorer les cercles ou les fl\u00e8ches en fonction d'une variable suppl\u00e9mentaire pour visualiser la relation entre cette variable et les axes factoriels.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#resume","title":"R\u00e9sum\u00e9\u00b6","text":"<p>L'Analyse Factorielle des Correspondances (AFC) est une m\u00e9thode statistique qui permet de r\u00e9duire les dimensions d'un tableau de donn\u00e9es crois\u00e9es. Elle permet \u00e9galement de visualiser la structure des relations entre les variables et les individus en utilisant des graphiques.</p>"},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#afc-pratique","title":"AFC pratique\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#application-de-lafc-avec-fanalysis","title":"Application de l'AFC avec fanalysis\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#aides-a-linterpretation","title":"Aides \u00e0 l'interpr\u00e9tation\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#choix-du-nombre-daxe-factoriel","title":"Choix du nombre d'axe factoriel\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#analyse-des-qualites-de-representation-cos-2","title":"Analyse des qualit\u00e9s de repr\u00e9sentation (cos 2)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#analyse-suivant-le-profil-ligne-les-departements","title":"Analyse suivant le profil ligne (les d\u00e9partements)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#analyses-des-contributions","title":"Analyses des contributions\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#profil-lignes-departement","title":"Profil lignes (d\u00e9partement)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#profil-colonne-candidats","title":"Profil colonne (Candidats)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#tableau-global","title":"Tableau global\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#coordonnees-contribution-et-les-cosinus-carre-des-departements-sur-les-axes-factoriels","title":"Coordonn\u00e9es, contribution et les cosinus carr\u00e9 des d\u00e9partements sur les axes factoriels\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#coordonnees-contribution-et-les-cosinus-carre-des-candidats-sur-les-axes-factoriels","title":"Coordonn\u00e9es, contribution et les cosinus carr\u00e9 des candidats sur les axes factoriels\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#analyse-graphique","title":"Analyse Graphique\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#graphique-des-departements-profil-ligne","title":"Graphique des d\u00e9partements (profil ligne)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#graphique-des-candidats-profil-colonne","title":"Graphique des candidats (profil colonne)\u00b6","text":""},{"location":"asset/ACF_elections_presidentielles/notebooks/AFC_With_Python%20Election%20pre%CC%81sidentielle%20/#graphique-superposition-des-profils-lignes-et-colonnes","title":"Graphique superposition des profils lignes et colonnes\u00b6","text":""},{"location":"asset/Clustering_USA_crime/notebooks/crime_usa_clustering/","title":"Crime usa clustering","text":"In\u00a0[1]: Copied! <pre>#importer les packages n\u00e9cessaires\nimport pandas as pd\nimport numpy as np\n\n#les packages de visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#importer les packages de pr\u00e9paration de donn\u00e9es\nfrom sklearn.preprocessing import StandardScaler\n\n#importer les packages de clustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n</pre> #importer les packages n\u00e9cessaires import pandas as pd import numpy as np  #les packages de visualisation import seaborn as sns import matplotlib.pyplot as plt  #importer les packages de pr\u00e9paration de donn\u00e9es from sklearn.preprocessing import StandardScaler  #importer les packages de clustering from sklearn.cluster import KMeans from sklearn.decomposition import PCA  In\u00a0[2]: Copied! <pre>#importer les donn\u00e9es\ndf = pd.read_csv('dataset-90380.csv')\ndf\n</pre> #importer les donn\u00e9es df = pd.read_csv('dataset-90380.csv') df Out[2]: Murder Assault UrbanPop Rape Alabama 13.2 236 58 21.2 Alaska 10.0 263 48 44.5 Arizona 8.1 294 80 31.0 Arkansas 8.8 190 50 19.5 California 9.0 276 91 40.6 Colorado 7.9 204 78 38.7 Connecticut 3.3 110 77 11.1 Delaware 5.9 238 72 15.8 Florida 15.4 335 80 31.9 Georgia 17.4 211 60 25.8 Hawaii 5.3 46 83 20.2 Idaho 2.6 120 54 14.2 Illinois 10.4 249 83 24.0 Indiana 7.2 113 65 21.0 Iowa 2.2 56 57 11.3 Kansas 6.0 115 66 18.0 Kentucky 9.7 109 52 16.3 Louisiana 15.4 249 66 22.2 Maine 2.1 83 51 7.8 Maryland 11.3 300 67 27.8 Massachusetts 4.4 149 85 16.3 Michigan 12.1 255 74 35.1 Minnesota 2.7 72 66 14.9 Mississippi 16.1 259 44 17.1 Missouri 9.0 178 70 28.2 Montana 6.0 109 53 16.4 Nebraska 4.3 102 62 16.5 Nevada 12.2 252 81 46.0 New Hampshire 2.1 57 56 9.5 New Jersey 7.4 159 89 18.8 New Mexico 11.4 285 70 32.1 New York 11.1 254 86 26.1 North Carolina 13.0 337 45 16.1 North Dakota 0.8 45 44 7.3 Ohio 7.3 120 75 21.4 Oklahoma 6.6 151 68 20.0 Oregon 4.9 159 67 29.3 Pennsylvania 6.3 106 72 14.9 Rhode Island 3.4 174 87 8.3 South Carolina 14.4 279 48 22.5 South Dakota 3.8 86 45 12.8 Tennessee 13.2 188 59 26.9 Texas 12.7 201 80 25.5 Utah 3.2 120 80 22.9 Vermont 2.2 48 32 11.2 Virginia 8.5 156 63 20.7 Washington 4.0 145 73 26.2 West Virginia 5.7 81 39 9.3 Wisconsin 2.6 53 66 10.8 Wyoming 6.8 161 60 15.6 <p>Visualisation des relations entre les diff\u00e9rentes variables</p> In\u00a0[3]: Copied! <pre>sns.pairplot(df)\n</pre> sns.pairplot(df) Out[3]: <pre>&lt;seaborn.axisgrid.PairGrid at 0x13fb593d0&gt;</pre> In\u00a0[4]: Copied! <pre>#centrer et reduire nos donn\u00e9es\nscaler = StandardScaler()\nx_scaled = scaler.fit_transform(df)\nx_scaled\n</pre> #centrer et reduire nos donn\u00e9es scaler = StandardScaler() x_scaled = scaler.fit_transform(df) x_scaled Out[4]: <pre>array([[ 1.25517927,  0.79078716, -0.52619514, -0.00345116],\n       [ 0.51301858,  1.11805959, -1.22406668,  2.50942392],\n       [ 0.07236067,  1.49381682,  1.00912225,  1.05346626],\n       [ 0.23470832,  0.23321191, -1.08449238, -0.18679398],\n       [ 0.28109336,  1.2756352 ,  1.77678094,  2.08881393],\n       [ 0.02597562,  0.40290872,  0.86954794,  1.88390137],\n       [-1.04088037, -0.73648418,  0.79976079, -1.09272319],\n       [-0.43787481,  0.81502956,  0.45082502, -0.58583422],\n       [ 1.76541475,  1.99078607,  1.00912225,  1.1505301 ],\n       [ 2.22926518,  0.48775713, -0.38662083,  0.49265293],\n       [-0.57702994, -1.51224105,  1.21848371, -0.11129987],\n       [-1.20322802, -0.61527217, -0.80534376, -0.75839217],\n       [ 0.60578867,  0.94836277,  1.21848371,  0.29852525],\n       [-0.13637203, -0.70012057, -0.03768506, -0.0250209 ],\n       [-1.29599811, -1.39102904, -0.5959823 , -1.07115345],\n       [-0.41468229, -0.67587817,  0.03210209, -0.34856705],\n       [ 0.44344101, -0.74860538, -0.94491807, -0.53190987],\n       [ 1.76541475,  0.94836277,  0.03210209,  0.10439756],\n       [-1.31919063, -1.06375661, -1.01470522, -1.44862395],\n       [ 0.81452136,  1.56654403,  0.10188925,  0.70835037],\n       [-0.78576263, -0.26375734,  1.35805802, -0.53190987],\n       [ 1.00006153,  1.02108998,  0.59039932,  1.49564599],\n       [-1.1800355 , -1.19708982,  0.03210209, -0.68289807],\n       [ 1.9277624 ,  1.06957478, -1.5032153 , -0.44563089],\n       [ 0.28109336,  0.0877575 ,  0.31125071,  0.75148985],\n       [-0.41468229, -0.74860538, -0.87513091, -0.521125  ],\n       [-0.80895515, -0.83345379, -0.24704653, -0.51034012],\n       [ 1.02325405,  0.98472638,  1.0789094 ,  2.671197  ],\n       [-1.31919063, -1.37890783, -0.66576945, -1.26528114],\n       [-0.08998698, -0.14254532,  1.63720664, -0.26228808],\n       [ 0.83771388,  1.38472601,  0.31125071,  1.17209984],\n       [ 0.76813632,  1.00896878,  1.42784517,  0.52500755],\n       [ 1.20879423,  2.01502847, -1.43342815, -0.55347961],\n       [-1.62069341, -1.52436225, -1.5032153 , -1.50254831],\n       [-0.11317951, -0.61527217,  0.66018648,  0.01811858],\n       [-0.27552716, -0.23951493,  0.1716764 , -0.13286962],\n       [-0.66980002, -0.14254532,  0.10188925,  0.87012344],\n       [-0.34510472, -0.78496898,  0.45082502, -0.68289807],\n       [-1.01768785,  0.03927269,  1.49763233, -1.39469959],\n       [ 1.53348953,  1.3119988 , -1.22406668,  0.13675217],\n       [-0.92491776, -1.027393  , -1.43342815, -0.90938037],\n       [ 1.25517927,  0.20896951, -0.45640799,  0.61128652],\n       [ 1.13921666,  0.36654512,  1.00912225,  0.46029832],\n       [-1.06407289, -0.61527217,  1.00912225,  0.17989166],\n       [-1.29599811, -1.48799864, -2.34066115, -1.08193832],\n       [ 0.16513075, -0.17890893, -0.17725937, -0.05737552],\n       [-0.87853272, -0.31224214,  0.52061217,  0.53579242],\n       [-0.48425985, -1.08799901, -1.85215107, -1.28685088],\n       [-1.20322802, -1.42739264,  0.03210209, -1.1250778 ],\n       [-0.22914211, -0.11830292, -0.38662083, -0.60740397]])</pre> In\u00a0[5]: Copied! <pre>wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++')\n    kmeans.fit(x_scaled)\n    wcss.append(kmeans.inertia_)\n</pre> wcss = [] for i in range(1, 11):     kmeans = KMeans(n_clusters = i, init = 'k-means++')     kmeans.fit(x_scaled)     wcss.append(kmeans.inertia_) <pre>/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n</pre> In\u00a0[6]: Copied! <pre>wcss\n</pre> wcss Out[6]: <pre>[200.0,\n 104.96163315756871,\n 80.08569526137276,\n 57.55425863091105,\n 50.50727764020435,\n 44.56379442778554,\n 39.98128650756617,\n 34.879440942056874,\n 32.565134498016604,\n 27.91245357109004]</pre> In\u00a0[7]: Copied! <pre>plt.plot(range(1, 11), wcss)\nplt.title('la m\u00e9thode du coude pour determiner le nombre des clusters')\nplt.xlabel('nombre de clusters')\nplt.ylabel('WCSS')\nplt.show()\n</pre> plt.plot(range(1, 11), wcss) plt.title('la m\u00e9thode du coude pour determiner le nombre des clusters') plt.xlabel('nombre de clusters') plt.ylabel('WCSS') plt.show() In\u00a0[8]: Copied! <pre>kmeans_etats = KMeans(n_clusters=4, init = 'k-means++')\n</pre> kmeans_etats = KMeans(n_clusters=4, init = 'k-means++') In\u00a0[9]: Copied! <pre>kmeans_etats.fit(x_scaled)\n</pre> kmeans_etats.fit(x_scaled) <pre>/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n</pre> Out[9]: <pre>KMeans(n_clusters=4)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeans<pre>KMeans(n_clusters=4)</pre> In\u00a0[10]: Copied! <pre>clusters = kmeans_etats.predict(x_scaled)\n</pre> clusters = kmeans_etats.predict(x_scaled) In\u00a0[11]: Copied! <pre>df['cluster']=clusters\ndf1 = df.copy()\ndf\n</pre> df['cluster']=clusters df1 = df.copy() df Out[11]: Murder Assault UrbanPop Rape cluster Alabama 13.2 236 58 21.2 2 Alaska 10.0 263 48 44.5 0 Arizona 8.1 294 80 31.0 0 Arkansas 8.8 190 50 19.5 2 California 9.0 276 91 40.6 0 Colorado 7.9 204 78 38.7 0 Connecticut 3.3 110 77 11.1 3 Delaware 5.9 238 72 15.8 3 Florida 15.4 335 80 31.9 0 Georgia 17.4 211 60 25.8 2 Hawaii 5.3 46 83 20.2 3 Idaho 2.6 120 54 14.2 1 Illinois 10.4 249 83 24.0 0 Indiana 7.2 113 65 21.0 3 Iowa 2.2 56 57 11.3 1 Kansas 6.0 115 66 18.0 3 Kentucky 9.7 109 52 16.3 1 Louisiana 15.4 249 66 22.2 2 Maine 2.1 83 51 7.8 1 Maryland 11.3 300 67 27.8 0 Massachusetts 4.4 149 85 16.3 3 Michigan 12.1 255 74 35.1 0 Minnesota 2.7 72 66 14.9 1 Mississippi 16.1 259 44 17.1 2 Missouri 9.0 178 70 28.2 0 Montana 6.0 109 53 16.4 1 Nebraska 4.3 102 62 16.5 1 Nevada 12.2 252 81 46.0 0 New Hampshire 2.1 57 56 9.5 1 New Jersey 7.4 159 89 18.8 3 New Mexico 11.4 285 70 32.1 0 New York 11.1 254 86 26.1 0 North Carolina 13.0 337 45 16.1 2 North Dakota 0.8 45 44 7.3 1 Ohio 7.3 120 75 21.4 3 Oklahoma 6.6 151 68 20.0 3 Oregon 4.9 159 67 29.3 3 Pennsylvania 6.3 106 72 14.9 3 Rhode Island 3.4 174 87 8.3 3 South Carolina 14.4 279 48 22.5 2 South Dakota 3.8 86 45 12.8 1 Tennessee 13.2 188 59 26.9 2 Texas 12.7 201 80 25.5 0 Utah 3.2 120 80 22.9 3 Vermont 2.2 48 32 11.2 1 Virginia 8.5 156 63 20.7 3 Washington 4.0 145 73 26.2 3 West Virginia 5.7 81 39 9.3 1 Wisconsin 2.6 53 66 10.8 1 Wyoming 6.8 161 60 15.6 3 In\u00a0[12]: Copied! <pre>palette = \"husl\"  \n\npalette = [\"red\", \"blue\", \"green\", \"orange\"]\n\n# Cr\u00e9ez le pairplot avec la palette sp\u00e9cifi\u00e9e\np = sns.pairplot(df, hue='cluster', palette=palette)\n</pre> palette = \"husl\"    palette = [\"red\", \"blue\", \"green\", \"orange\"]  # Cr\u00e9ez le pairplot avec la palette sp\u00e9cifi\u00e9e p = sns.pairplot(df, hue='cluster', palette=palette) In\u00a0[13]: Copied! <pre>df_clusters = df.groupby(['cluster']).median().round(0)\n    \ndf_clusters\n</pre> df_clusters = df.groupby(['cluster']).median().round(0)      df_clusters Out[13]: Murder Assault UrbanPop Rape cluster 0 11.0 255.0 80.0 32.0 1 3.0 81.0 53.0 11.0 2 14.0 242.0 54.0 22.0 3 6.0 147.0 72.0 19.0 In\u00a0[14]: Copied! <pre>for i in range(4):\n    print(f'Cluster {i}')\n    print(df[df.cluster == i].index.tolist())\n    print()\n</pre> for i in range(4):     print(f'Cluster {i}')     print(df[df.cluster == i].index.tolist())     print() <pre>Cluster 0\n['Alaska', 'Arizona', 'California', 'Colorado', 'Florida', 'Illinois', 'Maryland', 'Michigan', 'Missouri', 'Nevada', 'New Mexico', 'New York', 'Texas']\n\nCluster 1\n['Idaho', 'Iowa', 'Kentucky', 'Maine', 'Minnesota', 'Montana', 'Nebraska', 'New Hampshire', 'North Dakota', 'South Dakota', 'Vermont', 'West Virginia', 'Wisconsin']\n\nCluster 2\n['Alabama', 'Arkansas', 'Georgia', 'Louisiana', 'Mississippi', 'North Carolina', 'South Carolina', 'Tennessee']\n\nCluster 3\n['Connecticut', 'Delaware', 'Hawaii', 'Indiana', 'Kansas', 'Massachusetts', 'New Jersey', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'Utah', 'Virginia', 'Washington', 'Wyoming']\n\n</pre> In\u00a0[15]: Copied! <pre># fonction pour afficher les composantes principales\ndef display_scree_plot(pca):\n    scree = pca.explained_variance_ratio_*100\n    plt.bar(np.arange(len(scree))+1, scree)\n    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n    plt.xlabel(\"rang de l'axe d'inertie\")\n    plt.ylabel(\"pourcentage d'inertie\")\n    plt.title(\"Eboulis des valeurs propres\")\n    plt.show(block=False)\n</pre> # fonction pour afficher les composantes principales def display_scree_plot(pca):     scree = pca.explained_variance_ratio_*100     plt.bar(np.arange(len(scree))+1, scree)     plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')     plt.xlabel(\"rang de l'axe d'inertie\")     plt.ylabel(\"pourcentage d'inertie\")     plt.title(\"Eboulis des valeurs propres\")     plt.show(block=False) In\u00a0[16]: Copied! <pre># choix du nombre de composantes \u00e0 calculer vu qu'on a trois parametres\nn_comp = 4\n\n# Calcul des composantes principales\npca = PCA(n_components=n_comp)\npca.fit(x_scaled)\nprint('Nombre de composantes calcul\u00e9es : ', pca.n_components_)\n\n# Eboulis des valeurs propres\nplt.figure( figsize = ( 15, 8)) \ndisplay_scree_plot(pca)\n</pre> # choix du nombre de composantes \u00e0 calculer vu qu'on a trois parametres n_comp = 4  # Calcul des composantes principales pca = PCA(n_components=n_comp) pca.fit(x_scaled) print('Nombre de composantes calcul\u00e9es : ', pca.n_components_)  # Eboulis des valeurs propres plt.figure( figsize = ( 15, 8))  display_scree_plot(pca) <pre>Nombre de composantes calcul\u00e9es :  4\n</pre> In\u00a0[17]: Copied! <pre>#appliquer l'acp pour avoir 2 composants du moment que 2 composants nous permettent d'avoir 87 de l'information\npca = PCA(n_components=2).fit(x_scaled)\nXk_projected = pca.transform(x_scaled)\n</pre> #appliquer l'acp pour avoir 2 composants du moment que 2 composants nous permettent d'avoir 87 de l'information pca = PCA(n_components=2).fit(x_scaled) Xk_projected = pca.transform(x_scaled) In\u00a0[18]: Copied! <pre># Convertir Xk_projected en un DataFrame\nXk_projected_df = pd.DataFrame(Xk_projected, columns=['Composante 1', 'Composante 2'])\n\n# Utiliser le DataFrame dans sns.scatterplot\nsns.scatterplot(data=Xk_projected_df, x='Composante 1', y='Composante 2', alpha=1)\n</pre> # Convertir Xk_projected en un DataFrame Xk_projected_df = pd.DataFrame(Xk_projected, columns=['Composante 1', 'Composante 2'])  # Utiliser le DataFrame dans sns.scatterplot sns.scatterplot(data=Xk_projected_df, x='Composante 1', y='Composante 2', alpha=1)  Out[18]: <pre>&lt;Axes: xlabel='Composante 1', ylabel='Composante 2'&gt;</pre> In\u00a0[19]: Copied! <pre>#cette fonction dessine le cercle de correlation (vous pouvez l'avoir facilement sur google)\ndef display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n    for d1, d2 in axis_ranks:\n        if d2 &lt; n_comp:\n\n            # initialisation de la figure\n            fig, ax = plt.subplots(figsize=(10,10))\n\n            # d\u00e9termination des limites du graphique\n            if lims is not None :\n                xmin, xmax, ymin, ymax = lims\n            elif pcs.shape[1] &lt; 30 :\n                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n            else :\n                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n\n            # affichage des fl\u00e8ches\n            # s'il y a plus de 30 fl\u00e8ches, on n'affiche pas le triangle \u00e0 leur extr\u00e9mit\u00e9\n            if pcs.shape[1] &lt; 30 :\n                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n                   pcs[d1,:], pcs[d2,:], \n                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n                # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)\n            else:\n                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n            \n            # affichage des noms des variables  \n            if labels is not None:  \n                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n                    if x &gt;= xmin and x &lt;= xmax and y &gt;= ymin and y &lt;= ymax :\n                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n            \n            # affichage du cercle\n            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n            plt.gca().add_artist(circle)\n\n            # d\u00e9finition des limites du graphique\n            plt.xlim(xmin, xmax)\n            plt.ylim(ymin, ymax)\n        \n            # affichage des lignes horizontales et verticales\n            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n\n            # nom des axes, avec le pourcentage d'inertie expliqu\u00e9\n            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Cercle des corr\u00e9lations (F{} et F{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n</pre> #cette fonction dessine le cercle de correlation (vous pouvez l'avoir facilement sur google) def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):     for d1, d2 in axis_ranks:         if d2 &lt; n_comp:              # initialisation de la figure             fig, ax = plt.subplots(figsize=(10,10))              # d\u00e9termination des limites du graphique             if lims is not None :                 xmin, xmax, ymin, ymax = lims             elif pcs.shape[1] &lt; 30 :                 xmin, xmax, ymin, ymax = -1, 1, -1, 1             else :                 xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])              # affichage des fl\u00e8ches             # s'il y a plus de 30 fl\u00e8ches, on n'affiche pas le triangle \u00e0 leur extr\u00e9mit\u00e9             if pcs.shape[1] &lt; 30 :                 plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),                    pcs[d1,:], pcs[d2,:],                     angles='xy', scale_units='xy', scale=1, color=\"grey\")                 # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)             else:                 lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]                 ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))                          # affichage des noms des variables               if labels is not None:                   for i,(x, y) in enumerate(pcs[[d1,d2]].T):                     if x &gt;= xmin and x &lt;= xmax and y &gt;= ymin and y &lt;= ymax :                         plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)                          # affichage du cercle             circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')             plt.gca().add_artist(circle)              # d\u00e9finition des limites du graphique             plt.xlim(xmin, xmax)             plt.ylim(ymin, ymax)                      # affichage des lignes horizontales et verticales             plt.plot([-1, 1], [0, 0], color='grey', ls='--')             plt.plot([0, 0], [-1, 1], color='grey', ls='--')              # nom des axes, avec le pourcentage d'inertie expliqu\u00e9             plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))             plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))              plt.title(\"Cercle des corr\u00e9lations (F{} et F{})\".format(d1+1, d2+1))             plt.show(block=False) In\u00a0[20]: Copied! <pre>#utiliser la fonction display_circles() pour dessiner le cercle de correlation des deux composantes\nindex = df.index \nfeatures = df.columns\nchoix_n_comp=2\npcs = pca.components_\ndisplay_circles(pcs, choix_n_comp, pca, [(0,1)], labels = np.array(features))\n</pre> #utiliser la fonction display_circles() pour dessiner le cercle de correlation des deux composantes index = df.index  features = df.columns choix_n_comp=2 pcs = pca.components_ display_circles(pcs, choix_n_comp, pca, [(0,1)], labels = np.array(features)) In\u00a0[21]: Copied! <pre>import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Convertir Xk_projected en un DataFrame\nXk_projected_df = pd.DataFrame(Xk_projected, columns=['Composante 1', 'Composante 2'])\n\n# Cr\u00e9er un DataFrame pour les clusters\nclusters_df = pd.DataFrame(clusters, columns=['Cluster'])\n\n# Concat\u00e9ner les DataFrames Xk_projected_df et clusters_df\ndf = pd.concat([Xk_projected_df, clusters_df], axis=1)\n\n# Utiliser le DataFrame df dans sns.scatterplot\nsns.scatterplot(data=df, x='Composante 1', y='Composante 2', palette='viridis', alpha=1, hue='Cluster')\nplt.legend()\nplt.show()\n</pre> import seaborn as sns import pandas as pd import matplotlib.pyplot as plt  # Convertir Xk_projected en un DataFrame Xk_projected_df = pd.DataFrame(Xk_projected, columns=['Composante 1', 'Composante 2'])  # Cr\u00e9er un DataFrame pour les clusters clusters_df = pd.DataFrame(clusters, columns=['Cluster'])  # Concat\u00e9ner les DataFrames Xk_projected_df et clusters_df df = pd.concat([Xk_projected_df, clusters_df], axis=1)  # Utiliser le DataFrame df dans sns.scatterplot sns.scatterplot(data=df, x='Composante 1', y='Composante 2', palette='viridis', alpha=1, hue='Cluster') plt.legend() plt.show()  In\u00a0[23]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\ndata_dict = {\n    'data': np.array(df1[['Murder', 'Assault', 'UrbanPop', 'Rape']]),  # S\u00e9lectionnez toutes les colonnes sauf la derni\u00e8re\n    \"target\": df1['cluster'].to_numpy(),  # Utilisez la colonne 'cluster' comme cibles\n    \"target_names\": np.unique(df1['cluster']),  # Noms de vos cibles\n    \"feature_names\": df1.columns[:-1],  # Noms de vos caract\u00e9ristiques (toutes sauf la derni\u00e8re)\n    \"DESCR\": \"Description de vos donn\u00e9es (facultatif)\"  # Description de vos donn\u00e9es (facultatif)\n}\n\n\n# Charger les donn\u00e9es\nX = data_dict['data']\ny = data_dict['target']\ntarget_names = data_dict['target_names']\nfeature_names = data_dict['feature_names']\n\nstate_names = df1.index  # Les noms des \u00c9tats sont les index de votre DataFrame\ndata_dict['state_names'] = state_names\n\n# Normaliser les donn\u00e9es\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Appliquer l'ACP\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Cr\u00e9er la figure\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Visualiser les cat\u00e9gories d'esp\u00e8ces avec les couleurs\ncolors = ['r', 'g', 'b', 'y']  # Mettez \u00e0 jour avec vos propres couleurs si n\u00e9cessaire\nlw = 2\n\nfor color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):\n    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)\n\n# Ajouter des \u00e9tiquettes d'\u00c9tats aux points\nfor i in range(len(X_pca)):\n    plt.text(X_pca[i, 0], X_pca[i, 1], data_dict['state_names'][i], fontsize=10, ha='center', va='center')\n\n\n# Placer les vecteurs des variables\ncoeff = pca.components_.T  # Transposer les composantes principales\nn = coeff.shape[0]\n\nfor i in range(n):\n    plt.arrow(0, 0, coeff[i, 0], coeff[i, 1], color='k', alpha=0.9, head_width=0.02, linestyle='--')\n    plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, data_dict['feature_names'][i], color='k', ha='center', va='center')\n\n# Placer le cercle unitaire\ncircle = plt.Circle((0, 0), 1, color='gray', fill=False, linestyle='--')\nplt.gca().add_artist(circle)\n\n# Ajuster les limites et les axes\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\nplt.axhline(0, color='gray', linewidth=1)\nplt.axvline(0, color='gray', linewidth=1)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('ACP avec cercle de corr\u00e9lation et nuage des individus par cat\u00e9gorie')\n\n# Afficher la l\u00e9gende\nplt.legend(loc='best', shadow=False, scatterpoints=1)\n\n# Afficher la figure\nplt.show()\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler  data_dict = {     'data': np.array(df1[['Murder', 'Assault', 'UrbanPop', 'Rape']]),  # S\u00e9lectionnez toutes les colonnes sauf la derni\u00e8re     \"target\": df1['cluster'].to_numpy(),  # Utilisez la colonne 'cluster' comme cibles     \"target_names\": np.unique(df1['cluster']),  # Noms de vos cibles     \"feature_names\": df1.columns[:-1],  # Noms de vos caract\u00e9ristiques (toutes sauf la derni\u00e8re)     \"DESCR\": \"Description de vos donn\u00e9es (facultatif)\"  # Description de vos donn\u00e9es (facultatif) }   # Charger les donn\u00e9es X = data_dict['data'] y = data_dict['target'] target_names = data_dict['target_names'] feature_names = data_dict['feature_names']  state_names = df1.index  # Les noms des \u00c9tats sont les index de votre DataFrame data_dict['state_names'] = state_names  # Normaliser les donn\u00e9es scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  # Appliquer l'ACP pca = PCA(n_components=2) X_pca = pca.fit_transform(X_scaled)  # Cr\u00e9er la figure fig, ax = plt.subplots(figsize=(12, 12))  # Visualiser les cat\u00e9gories d'esp\u00e8ces avec les couleurs colors = ['r', 'g', 'b', 'y']  # Mettez \u00e0 jour avec vos propres couleurs si n\u00e9cessaire lw = 2  for color, i, target_name in zip(colors, [0, 1, 2, 3], target_names):     plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=.8, lw=lw, label=target_name)  # Ajouter des \u00e9tiquettes d'\u00c9tats aux points for i in range(len(X_pca)):     plt.text(X_pca[i, 0], X_pca[i, 1], data_dict['state_names'][i], fontsize=10, ha='center', va='center')   # Placer les vecteurs des variables coeff = pca.components_.T  # Transposer les composantes principales n = coeff.shape[0]  for i in range(n):     plt.arrow(0, 0, coeff[i, 0], coeff[i, 1], color='k', alpha=0.9, head_width=0.02, linestyle='--')     plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, data_dict['feature_names'][i], color='k', ha='center', va='center')  # Placer le cercle unitaire circle = plt.Circle((0, 0), 1, color='gray', fill=False, linestyle='--') plt.gca().add_artist(circle)  # Ajuster les limites et les axes plt.xlim(-3, 3) plt.ylim(-3, 3) plt.axhline(0, color='gray', linewidth=1) plt.axvline(0, color='gray', linewidth=1) plt.xlabel('PC1') plt.ylabel('PC2') plt.title('ACP avec cercle de corr\u00e9lation et nuage des individus par cat\u00e9gorie')  # Afficher la l\u00e9gende plt.legend(loc='best', shadow=False, scatterpoints=1)  # Afficher la figure plt.show()"},{"location":"asset/Clustering_USA_crime/notebooks/crime_usa_clustering/#appliquer-kmeans","title":"Appliquer Kmeans\u00b6","text":""},{"location":"asset/Clustering_USA_crime/notebooks/crime_usa_clustering/#utiliser-lacp-pour-visualiser-les-donnees","title":"Utiliser l'ACP pour visualiser les donn\u00e9es\u00b6","text":""},{"location":"asset/Computer_vision/Computer_Vision_App/app_streamlit2/","title":"App streamlit2","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nimport numpy as np\nimport cv2\nimport requests\nfrom tensorflow.keras.models import load_model\nfrom PIL import Image\nimport tempfile\nimport os\nfrom io import StringIO\n</pre> import streamlit as st import numpy as np import cv2 import requests from tensorflow.keras.models import load_model from PIL import Image import tempfile import os from io import StringIO In\u00a0[\u00a0]: Copied! <pre># Fonction pour charger le mod\u00e8le depuis GitHub\ndef load_model_from_github(url):\n    response = requests.get(url)\n    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as temp_file:\n        temp_file.write(response.content)\n        model = load_model(temp_file.name)\n    return model\n</pre> # Fonction pour charger le mod\u00e8le depuis GitHub def load_model_from_github(url):     response = requests.get(url)     with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as temp_file:         temp_file.write(response.content)         model = load_model(temp_file.name)     return model In\u00a0[\u00a0]: Copied! <pre># URL du mod\u00e8le sur GitHub\nmodel_url = 'https://raw.githubusercontent.com/Victorouledi/Portfolio_data_analyst_et_data_scientist_Victor_OULEDI/main/CNN_computer_vision/CNN_imageries_medicales2.h5'\n</pre> # URL du mod\u00e8le sur GitHub model_url = 'https://raw.githubusercontent.com/Victorouledi/Portfolio_data_analyst_et_data_scientist_Victor_OULEDI/main/CNN_computer_vision/CNN_imageries_medicales2.h5' In\u00a0[\u00a0]: Copied! <pre># Charger le mod\u00e8le depuis GitHub\nmodel = load_model_from_github(model_url)\n</pre> # Charger le mod\u00e8le depuis GitHub model = load_model_from_github(model_url) In\u00a0[\u00a0]: Copied! <pre># Param\u00e8tres de l'image\nimg_height, img_width = 200, 200\nclass_names = ['Autres', 'Cerveau', 'Poumon']\n</pre> # Param\u00e8tres de l'image img_height, img_width = 200, 200 class_names = ['Autres', 'Cerveau', 'Poumon'] In\u00a0[\u00a0]: Copied! <pre># Interface de l'application\nst.markdown(\"&lt;h1 style='text-align: center;'&gt;Classification d'imageries m\u00e9dicales&lt;/h1&gt;\", unsafe_allow_html=True)\n</pre> # Interface de l'application st.markdown(\"Classification d'imageries m\u00e9dicales\", unsafe_allow_html=True) In\u00a0[\u00a0]: Copied! <pre># Modifier la couleur de fond\nst.markdown(\n    \"\"\"\n    &lt;style&gt;\n    .reportview-container {\n        background: #f0f2f5; /* Changez cette couleur selon vos besoins */\n    }\n    &lt;/style&gt;\n    \"\"\",\n    unsafe_allow_html=True\n)\n</pre> # Modifier la couleur de fond st.markdown(     \"\"\"          \"\"\",     unsafe_allow_html=True ) In\u00a0[\u00a0]: Copied! <pre>st.write(\"Cette interface a pour but de classer des documents d'imagerie m\u00e9dicale et permet de pr\u00e9dire la classe d'une image comme \u00e9tant soit une imagerie du cerveau, des poumons ou aucune de ces classes pr\u00e9c\u00e9dentes\")\n</pre> st.write(\"Cette interface a pour but de classer des documents d'imagerie m\u00e9dicale et permet de pr\u00e9dire la classe d'une image comme \u00e9tant soit une imagerie du cerveau, des poumons ou aucune de ces classes pr\u00e9c\u00e9dentes\") In\u00a0[\u00a0]: Copied! <pre># Afficher le r\u00e9sum\u00e9 du mod\u00e8le\nst.write(\"Les pr\u00e9dictions se basent sur un mod\u00e8le simple de r\u00e9seau de neurones convolutif dont voici les param\u00e8tres :\")\nmodel_summary = StringIO()  # Cr\u00e9er un objet StringIO pour capturer la sortie\nmodel.summary(print_fn=lambda x: model_summary.write(x + '\\n'))  # Capturer le r\u00e9sum\u00e9 du mod\u00e8le\nst.text(model_summary.getvalue())  # Afficher le r\u00e9sum\u00e9 dans l'application\n</pre> # Afficher le r\u00e9sum\u00e9 du mod\u00e8le st.write(\"Les pr\u00e9dictions se basent sur un mod\u00e8le simple de r\u00e9seau de neurones convolutif dont voici les param\u00e8tres :\") model_summary = StringIO()  # Cr\u00e9er un objet StringIO pour capturer la sortie model.summary(print_fn=lambda x: model_summary.write(x + '\\n'))  # Capturer le r\u00e9sum\u00e9 du mod\u00e8le st.text(model_summary.getvalue())  # Afficher le r\u00e9sum\u00e9 dans l'application In\u00a0[\u00a0]: Copied! <pre># Chargement de l'image par l'utilisateur\nuploaded_file = st.file_uploader(\"Choisissez une image\", type=[\"jpg\", \"jpeg\", \"png\"])\n</pre> # Chargement de l'image par l'utilisateur uploaded_file = st.file_uploader(\"Choisissez une image\", type=[\"jpg\", \"jpeg\", \"png\"]) In\u00a0[\u00a0]: Copied! <pre>if uploaded_file is not None:\n    # Afficher l'image charg\u00e9e\n    image = Image.open(uploaded_file)\n    st.image(image, caption='Image Import\u00e9e', use_column_width=True)\n    st.write(\"\")\n    st.write(\"Classification en cours...\")\n\n    # Pr\u00e9traiter l'image pour la pr\u00e9diction\n    image_to_predict = np.array(image.convert(\"RGB\"))\n    img_to_predict = np.expand_dims(cv2.resize(image_to_predict, (img_width, img_height)), axis=0)\n    \n    # Afficher la forme de l'image \u00e0 pr\u00e9dire\n    st.write(f\"Forme de l'image \u00e0 pr\u00e9dire : {img_to_predict.shape}\")\n\n    # Pr\u00e9diction\n    try:\n        predictions = model.predict(img_to_predict)[0]\n        st.write(\"Pr\u00e9diction r\u00e9ussie.\")\n    except Exception as e:\n        st.write(f\"Erreur lors de la pr\u00e9diction : {e}\")\n        st.stop()  # Stoppe l'ex\u00e9cution si une erreur se produit\n\n    # Trier les indices des classes par ordre de probabilit\u00e9 d\u00e9croissante\n    sorted_indices = np.argsort(predictions)[::-1]\n    top_class_index = sorted_indices[0]\n    top_class_confidence = predictions[top_class_index]\n    \n    # V\u00e9rifier la confiance et choisir la classe pr\u00e9dite\n    if top_class_confidence &gt;= 0.90:\n        predicted_class_index = top_class_index\n    else:\n        predicted_class_index = sorted_indices[1]\n    \n    predicted_class_name = class_names[predicted_class_index]\n    \n    # Afficher le r\u00e9sultat\n    st.write(f\"L'image est pr\u00e9dite comme : **{predicted_class_name}** avec une confiance de **{predictions[predicted_class_index]:.2f}**\")\nelse:\n    st.write(\"Veuillez importer une image pour la pr\u00e9diction.\")\n</pre> if uploaded_file is not None:     # Afficher l'image charg\u00e9e     image = Image.open(uploaded_file)     st.image(image, caption='Image Import\u00e9e', use_column_width=True)     st.write(\"\")     st.write(\"Classification en cours...\")      # Pr\u00e9traiter l'image pour la pr\u00e9diction     image_to_predict = np.array(image.convert(\"RGB\"))     img_to_predict = np.expand_dims(cv2.resize(image_to_predict, (img_width, img_height)), axis=0)          # Afficher la forme de l'image \u00e0 pr\u00e9dire     st.write(f\"Forme de l'image \u00e0 pr\u00e9dire : {img_to_predict.shape}\")      # Pr\u00e9diction     try:         predictions = model.predict(img_to_predict)[0]         st.write(\"Pr\u00e9diction r\u00e9ussie.\")     except Exception as e:         st.write(f\"Erreur lors de la pr\u00e9diction : {e}\")         st.stop()  # Stoppe l'ex\u00e9cution si une erreur se produit      # Trier les indices des classes par ordre de probabilit\u00e9 d\u00e9croissante     sorted_indices = np.argsort(predictions)[::-1]     top_class_index = sorted_indices[0]     top_class_confidence = predictions[top_class_index]          # V\u00e9rifier la confiance et choisir la classe pr\u00e9dite     if top_class_confidence &gt;= 0.90:         predicted_class_index = top_class_index     else:         predicted_class_index = sorted_indices[1]          predicted_class_name = class_names[predicted_class_index]          # Afficher le r\u00e9sultat     st.write(f\"L'image est pr\u00e9dite comme : **{predicted_class_name}** avec une confiance de **{predictions[predicted_class_index]:.2f}**\") else:     st.write(\"Veuillez importer une image pour la pr\u00e9diction.\")"},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/","title":"Pre\u0301diction imagerie me\u0301dicale","text":"In\u00a0[15]: Copied! <pre>import cv2\nimport numpy as np\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport sys\nimport datetime\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n\nimport pathlib\nimport os\nimport zipfile\n\nfrom io import BytesIO\nimport PIL.Image\nimport ipywidgets as widgets\nfrom IPython.display import display\n</pre> import cv2 import numpy as np import requests import matplotlib.pyplot as plt import matplotlib.image as mpimg import sys import datetime from tensorflow import keras from tensorflow.keras.models import Model import tensorflow as tf from tensorflow.keras import layers   import pathlib import os import zipfile  from io import BytesIO import PIL.Image import ipywidgets as widgets from IPython.display import display In\u00a0[16]: Copied! <pre>import os\n\ndata_dir_train = \"/Users/victorouledi/Documents/2024-2025/CNN/data/train\"\ndata_dir_test = \"/Users/victorouledi/Documents/2024-2025/CNN/data/test\"\n\n# Liste des extensions de fichiers autoris\u00e9es\nallowed_extensions = {'.jpeg', '.jpg', '.png', '.gif', '.bmp'}\n\ndef detect_non_image_files(directory):\n    non_image_files = []  # Liste pour stocker les chemins des fichiers non image\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # V\u00e9rifier l'extension du fichier\n            if not any(file.lower().endswith(ext) for ext in allowed_extensions):\n                file_path = os.path.join(root, file)\n                non_image_files.append(file_path)  # Ajouter \u00e0 la liste\n    return non_image_files\n\n# D\u00e9tecter les fichiers non image dans les deux r\u00e9pertoires\nnon_image_train_files = detect_non_image_files(data_dir_train)\nnon_image_test_files = detect_non_image_files(data_dir_test)\n\n# Afficher et supprimer les fichiers non image d\u00e9tect\u00e9s\nif non_image_train_files:\n    print(\"Fichiers non image dans le r\u00e9pertoire d'entra\u00eenement :\")\n    for file in non_image_train_files:\n        print(file)\n        os.remove(file)  # Supprimer le fichier non image\n        print(f\"Supprim\u00e9 : {file}\")\n\nif non_image_test_files:\n    print(\"Fichiers non image dans le r\u00e9pertoire de test :\")\n    for file in non_image_test_files:\n        print(file)\n        os.remove(file)  # Supprimer le fichier non image\n        print(f\"Supprim\u00e9 : {file}\")\n\nif not non_image_train_files and not non_image_test_files:\n    print(\"Aucun fichier non autoris\u00e9 d\u00e9tect\u00e9 dans les r\u00e9pertoires.\")\n</pre> import os  data_dir_train = \"/Users/victorouledi/Documents/2024-2025/CNN/data/train\" data_dir_test = \"/Users/victorouledi/Documents/2024-2025/CNN/data/test\"  # Liste des extensions de fichiers autoris\u00e9es allowed_extensions = {'.jpeg', '.jpg', '.png', '.gif', '.bmp'}  def detect_non_image_files(directory):     non_image_files = []  # Liste pour stocker les chemins des fichiers non image     for root, dirs, files in os.walk(directory):         for file in files:             # V\u00e9rifier l'extension du fichier             if not any(file.lower().endswith(ext) for ext in allowed_extensions):                 file_path = os.path.join(root, file)                 non_image_files.append(file_path)  # Ajouter \u00e0 la liste     return non_image_files  # D\u00e9tecter les fichiers non image dans les deux r\u00e9pertoires non_image_train_files = detect_non_image_files(data_dir_train) non_image_test_files = detect_non_image_files(data_dir_test)  # Afficher et supprimer les fichiers non image d\u00e9tect\u00e9s if non_image_train_files:     print(\"Fichiers non image dans le r\u00e9pertoire d'entra\u00eenement :\")     for file in non_image_train_files:         print(file)         os.remove(file)  # Supprimer le fichier non image         print(f\"Supprim\u00e9 : {file}\")  if non_image_test_files:     print(\"Fichiers non image dans le r\u00e9pertoire de test :\")     for file in non_image_test_files:         print(file)         os.remove(file)  # Supprimer le fichier non image         print(f\"Supprim\u00e9 : {file}\")  if not non_image_train_files and not non_image_test_files:     print(\"Aucun fichier non autoris\u00e9 d\u00e9tect\u00e9 dans les r\u00e9pertoires.\")  <pre>Fichiers non image dans le r\u00e9pertoire de test :\n/Users/victorouledi/Documents/2024-2025/CNN/data/test/.DS_Store\nSupprim\u00e9 : /Users/victorouledi/Documents/2024-2025/CNN/data/test/.DS_Store\n</pre> In\u00a0[17]: Copied! <pre># Chemin vers le dossier contenant le dataset\ndata_dir_train = \"/Users/victorouledi/Documents/2024-2025/CNN/data/train\"\ndata_dir_test = \"/Users/victorouledi/Documents/2024-2025/CNN/data/test\"\n\n# V\u00e9rification du chemin des donn\u00e9es\ndata_dir_train = pathlib.Path(data_dir_train)\ndata_dir_test = pathlib.Path(data_dir_test)\n\n# Param\u00e8tres de traitement des images\nbatch_size = 30\nimg_height = 200\nimg_width = 200\n\n# Ensemble d'entra\u00eenement\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n)\n\n# Ensemble de validation\nval_data = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_test,\n    validation_split=0.4,\n    subset=\"validation\",\n    seed=42,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n)\n\n# Afficher les noms des classes\nclass_names = val_data.class_names\nprint(\"Classes :\", class_names)\n</pre> # Chemin vers le dossier contenant le dataset data_dir_train = \"/Users/victorouledi/Documents/2024-2025/CNN/data/train\" data_dir_test = \"/Users/victorouledi/Documents/2024-2025/CNN/data/test\"  # V\u00e9rification du chemin des donn\u00e9es data_dir_train = pathlib.Path(data_dir_train) data_dir_test = pathlib.Path(data_dir_test)  # Param\u00e8tres de traitement des images batch_size = 30 img_height = 200 img_width = 200  # Ensemble d'entra\u00eenement train_data = tf.keras.preprocessing.image_dataset_from_directory(     data_dir_train,     validation_split=0.2,     subset=\"training\",     seed=42,     image_size=(img_height, img_width),     batch_size=batch_size, )  # Ensemble de validation val_data = tf.keras.preprocessing.image_dataset_from_directory(     data_dir_test,     validation_split=0.4,     subset=\"validation\",     seed=42,     image_size=(img_height, img_width),     batch_size=batch_size, )  # Afficher les noms des classes class_names = val_data.class_names print(\"Classes :\", class_names)  <pre>Found 23477 files belonging to 3 classes.\nUsing 18782 files for training.\nFound 10537 files belonging to 3 classes.\nUsing 4214 files for validation.\nClasses : ['Autres', 'Cerveau', 'Poumon']\n</pre> In\u00a0[18]: Copied! <pre># R\u00e9cup\u00e9ration des noms des classes et du nombre d'images par classe\nclass_names = val_data.class_names\ntrain_class_counts = {class_name: 0 for class_name in class_names}\nval_class_counts = {class_name: 0 for class_name in class_names}\n\nfor images, labels in train_data:\n    for label in labels:\n        train_class_counts[class_names[label]] += 1\n\nfor images, labels in val_data:\n    for label in labels:\n        val_class_counts[class_names[label]] += 1\n\n# Histogramme du nombre d'individus par classe pour l'ensemble d'entra\u00eenement et de validation\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\nax[0].bar(train_class_counts.keys(), train_class_counts.values())\nax[0].set_title(\"Nombre d'individus par classe (Entra\u00eenement)\")\nax[0].set_xlabel(\"Classes\")\nax[0].set_ylabel(\"Nombre d'individus\")\n\nax[1].bar(val_class_counts.keys(), val_class_counts.values())\nax[1].set_title(\"Nombre d'individus par classe (Validation)\")\nax[1].set_xlabel(\"Classes\")\nax[1].set_ylabel(\"Nombre d'individus\")\n\nplt.show()\n</pre> # R\u00e9cup\u00e9ration des noms des classes et du nombre d'images par classe class_names = val_data.class_names train_class_counts = {class_name: 0 for class_name in class_names} val_class_counts = {class_name: 0 for class_name in class_names}  for images, labels in train_data:     for label in labels:         train_class_counts[class_names[label]] += 1  for images, labels in val_data:     for label in labels:         val_class_counts[class_names[label]] += 1  # Histogramme du nombre d'individus par classe pour l'ensemble d'entra\u00eenement et de validation fig, ax = plt.subplots(1, 2, figsize=(15, 5)) ax[0].bar(train_class_counts.keys(), train_class_counts.values()) ax[0].set_title(\"Nombre d'individus par classe (Entra\u00eenement)\") ax[0].set_xlabel(\"Classes\") ax[0].set_ylabel(\"Nombre d'individus\")  ax[1].bar(val_class_counts.keys(), val_class_counts.values()) ax[1].set_title(\"Nombre d'individus par classe (Validation)\") ax[1].set_xlabel(\"Classes\") ax[1].set_ylabel(\"Nombre d'individus\")  plt.show() <pre>2024-11-03 22:14:06.401722: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n</pre> <p>La surepr\u00e9sentation de la classe \"autres\" sert \u00e0 introduire de l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 dans les images autres que celles de cerveaux et de poumons et \u00e0 contr\u00f4ler les potentielles mauvaises pr\u00e9dictions pour pour un type d'image autres pouvant avoir un calcque ressemblant \u00e0 celui d'une des autres classes</p> In\u00a0[10]: Copied! <pre>plt.figure(figsize=(10, 10))\nfor images, labels in train_data.take(1):\n  for i in range(3):\n    ax = plt.subplot(1, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")\n</pre> plt.figure(figsize=(10, 10)) for images, labels in train_data.take(1):   for i in range(3):     ax = plt.subplot(1, 3, i + 1)     plt.imshow(images[i].numpy().astype(\"uint8\"))     plt.title(class_names[labels[i]])     plt.axis(\"off\") In\u00a0[19]: Copied! <pre>import tensorflow as tf\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport pathlib\n\n# D\u00e9finition des chemins de donn\u00e9es\ndata_dir_train = pathlib.Path(\"/Users/victorouledi/Documents/2024-2025/CNN/data/train\")\ndata_dir_test = pathlib.Path(\"/Users/victorouledi/Documents/2024-2025/CNN/data/test\")\n\n# Param\u00e8tres de traitement des images\nbatch_size = 30\nimg_height = 200\nimg_width = 200\n\n# Chargement de l'ensemble d'entra\u00eenement et de validation\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n)\n\nval_data = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_test,\n    validation_split=0.4,\n    subset=\"validation\",\n    seed=42,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n)\n\n# Param\u00e8tres pour enregistrer l'accuracy en fonction des \u00e9poques\nepoch_values = list(range(1, 6))\naccuracy_values = []\n\n# Boucle pour tester diff\u00e9rentes valeurs d'\u00e9poques\nfor epochs in epoch_values:\n    model = tf.keras.Sequential([\n        layers.Rescaling(1./255),  \n        layers.Conv2D(128, 4, activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(64, 4, activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(32, 4, activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(16, 4, activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Flatten(),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(optimizer='adam',\n                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=['accuracy'])\n\n    history = model.fit(\n        train_data,\n        validation_data=val_data,\n        epochs=epochs,\n        verbose=0  # pour r\u00e9duire l'affichage\n    )\n    \n    # Enregistrement de l'accuracy de validation\n    accuracy_values.append(history.history['val_accuracy'][-1])\n\n# Trac\u00e9 du graphique de l'accuracy en fonction du nombre d'\u00e9poques\nplt.plot(epoch_values, accuracy_values, marker='o')\nplt.xlabel(\"Nombre d'\u00e9poques\")\nplt.ylabel(\"Accuracy de validation\")\nplt.title(\"\u00c9volution de l'accuracy en fonction du nombre d'\u00e9poques\")\nplt.show()\n</pre> import tensorflow as tf from tensorflow.keras import layers import matplotlib.pyplot as plt import pathlib  # D\u00e9finition des chemins de donn\u00e9es data_dir_train = pathlib.Path(\"/Users/victorouledi/Documents/2024-2025/CNN/data/train\") data_dir_test = pathlib.Path(\"/Users/victorouledi/Documents/2024-2025/CNN/data/test\")  # Param\u00e8tres de traitement des images batch_size = 30 img_height = 200 img_width = 200  # Chargement de l'ensemble d'entra\u00eenement et de validation train_data = tf.keras.preprocessing.image_dataset_from_directory(     data_dir_train,     validation_split=0.2,     subset=\"training\",     seed=42,     image_size=(img_height, img_width),     batch_size=batch_size, )  val_data = tf.keras.preprocessing.image_dataset_from_directory(     data_dir_test,     validation_split=0.4,     subset=\"validation\",     seed=42,     image_size=(img_height, img_width),     batch_size=batch_size, )  # Param\u00e8tres pour enregistrer l'accuracy en fonction des \u00e9poques epoch_values = list(range(1, 6)) accuracy_values = []  # Boucle pour tester diff\u00e9rentes valeurs d'\u00e9poques for epochs in epoch_values:     model = tf.keras.Sequential([         layers.Rescaling(1./255),           layers.Conv2D(128, 4, activation='relu'),         layers.MaxPooling2D(),         layers.Conv2D(64, 4, activation='relu'),         layers.MaxPooling2D(),         layers.Conv2D(32, 4, activation='relu'),         layers.MaxPooling2D(),         layers.Conv2D(16, 4, activation='relu'),         layers.MaxPooling2D(),         layers.Flatten(),         layers.Dense(64, activation='relu'),         layers.Dense(3, activation='softmax')     ])      model.compile(optimizer='adam',                   loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),                   metrics=['accuracy'])      history = model.fit(         train_data,         validation_data=val_data,         epochs=epochs,         verbose=0  # pour r\u00e9duire l'affichage     )          # Enregistrement de l'accuracy de validation     accuracy_values.append(history.history['val_accuracy'][-1])  # Trac\u00e9 du graphique de l'accuracy en fonction du nombre d'\u00e9poques plt.plot(epoch_values, accuracy_values, marker='o') plt.xlabel(\"Nombre d'\u00e9poques\") plt.ylabel(\"Accuracy de validation\") plt.title(\"\u00c9volution de l'accuracy en fonction du nombre d'\u00e9poques\") plt.show()   <pre>Found 23477 files belonging to 3 classes.\nUsing 18782 files for training.\nFound 10537 files belonging to 3 classes.\nUsing 4214 files for validation.\n</pre> In\u00a0[21]: Copied! <pre># R\u00e9pertoire temporaire avec permissions d'\u00e9criture des logs\nlogdir = \"/tmp/logs\"  \ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, write_images=True)\n\nnum_classes = 3\n\n#Cr\u00e9ation du mod\u00e8le\nmodel = tf.keras.Sequential([\n    layers.Rescaling(1./255),  \n    layers.Conv2D(128, 4, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 4, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 4, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(16, 4, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\n# Compliation du mod\u00e8le, d\u00e9finition de la fonction de co\u00fbt (ici adapt\u00e9 aux probl\u00e8mes de classification) avec sp\u00e9cifiaction sous forme de logit binomiale retraduit par la fonction soft max en proba\nmodel.compile(optimizer='adam',\n              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n# Entrainement du mod\u00e8le sur 3 \u00e9poques \nmodel.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=3,\n    callbacks=[tensorboard_callback]\n)\n</pre> # R\u00e9pertoire temporaire avec permissions d'\u00e9criture des logs logdir = \"/tmp/logs\"   tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, write_images=True)  num_classes = 3  #Cr\u00e9ation du mod\u00e8le model = tf.keras.Sequential([     layers.Rescaling(1./255),       layers.Conv2D(128, 4, activation='relu'),     layers.MaxPooling2D(),     layers.Conv2D(64, 4, activation='relu'),     layers.MaxPooling2D(),     layers.Conv2D(32, 4, activation='relu'),     layers.MaxPooling2D(),     layers.Conv2D(16, 4, activation='relu'),     layers.MaxPooling2D(),     layers.Flatten(),     layers.Dense(64, activation='relu'),     layers.Dense(num_classes, activation='softmax') ])  # Compliation du mod\u00e8le, d\u00e9finition de la fonction de co\u00fbt (ici adapt\u00e9 aux probl\u00e8mes de classification) avec sp\u00e9cifiaction sous forme de logit binomiale retraduit par la fonction soft max en proba model.compile(optimizer='adam',               loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),               metrics=['accuracy'])   # Entrainement du mod\u00e8le sur 3 \u00e9poques  model.fit(     train_data,     validation_data=val_data,     epochs=3,     callbacks=[tensorboard_callback] )  <pre>Epoch 1/3\n627/627 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 994s 2s/step - accuracy: 0.9219 - loss: 0.2554 - val_accuracy: 0.9891 - val_loss: 0.0355\nEpoch 2/3\n627/627 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1653s 3s/step - accuracy: 0.9926 - loss: 0.0262 - val_accuracy: 0.9798 - val_loss: 0.0651\nEpoch 3/3\n627/627 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1403s 2s/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.9919 - val_loss: 0.0393\n</pre> Out[21]: <pre>&lt;keras.src.callbacks.history.History at 0x290983550&gt;</pre> In\u00a0[22]: Copied! <pre>model.summary()\n</pre> model.summary() <pre>Model: \"sequential_7\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 rescaling_7 (Rescaling)         \u2502 (None, 200, 200, 3)    \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_28 (Conv2D)              \u2502 (None, 197, 197, 128)  \u2502         6,272 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_28 (MaxPooling2D) \u2502 (None, 98, 98, 128)    \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_29 (Conv2D)              \u2502 (None, 95, 95, 64)     \u2502       131,136 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_29 (MaxPooling2D) \u2502 (None, 47, 47, 64)     \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_30 (Conv2D)              \u2502 (None, 44, 44, 32)     \u2502        32,800 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_30 (MaxPooling2D) \u2502 (None, 22, 22, 32)     \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_31 (Conv2D)              \u2502 (None, 19, 19, 16)     \u2502         8,208 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_31 (MaxPooling2D) \u2502 (None, 9, 9, 16)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flatten_7 (Flatten)             \u2502 (None, 1296)           \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_14 (Dense)                \u2502 (None, 64)             \u2502        83,008 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_15 (Dense)                \u2502 (None, 3)              \u2502           195 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 784,859 (2.99 MB)\n</pre> <pre> Trainable params: 261,619 (1021.95 KB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> <pre> Optimizer params: 523,240 (2.00 MB)\n</pre> In\u00a0[23]: Copied! <pre>import numpy as np\nimport cv2\n\n# Import image\nimage_path = \"/Users/victorouledi/Downloads/poumon4.jpeg\"  # Remplace par le chemin de ton image\n\nimage_to_predict = cv2.imread(image_path, cv2.IMREAD_COLOR)\n\nif image_to_predict is not None:\n    # Pr\u00e9traiter l'image pour la pr\u00e9diction\n    img_to_predict = np.expand_dims(cv2.resize(image_to_predict, (img_width, img_height)), axis=0)\n    \n    # Pr\u00e9dictions avec le mod\u00e8le\n    predictions = model.predict(img_to_predict)[0]  # R\u00e9cup\u00e8re directement la premi\u00e8re pr\u00e9diction\n    \n    # Trier les indices des classes par ordre de probabilit\u00e9 d\u00e9croissante\n    sorted_indices = np.argsort(predictions)[::-1]\n    \n    # Obtenir la premi\u00e8re classe et sa confiance\n    top_class_index = sorted_indices[0]\n    top_class_confidence = predictions[top_class_index]\n    \n    # V\u00e9rifier la confiance est suffisante pour pr\u00e9dire la classe (utile pour palier au probl\u00e8me o\u00f9  pour lesquels les imageries  de poumons ou du cerveaus moins conventionnelles auront tendences \u00e0 \u00eatre pr\u00e9dites comme autres avec une certitude moins importante )\n    if top_class_confidence &gt;= 0.90:\n        predicted_class_index = top_class_index\n    else:\n        # Prendre la deuxi\u00e8me classe si la premi\u00e8re est en dessous du seuil\n        predicted_class_index = sorted_indices[1]\n    \n    # Obtenir le nom de la classe pr\u00e9dite\n    predicted_class_name = class_names[predicted_class_index]\n    \n    # Afficher le r\u00e9sultat\n    print(f\"L'image est pr\u00e9dite comme : {predicted_class_name} avec une confiance de {predictions[predicted_class_index]:.2f}\")\nelse:\n    print(\"Erreur lors du chargement de l'image. V\u00e9rifiez le chemin d'acc\u00e8s.\")\n</pre> import numpy as np import cv2  # Import image image_path = \"/Users/victorouledi/Downloads/poumon4.jpeg\"  # Remplace par le chemin de ton image  image_to_predict = cv2.imread(image_path, cv2.IMREAD_COLOR)  if image_to_predict is not None:     # Pr\u00e9traiter l'image pour la pr\u00e9diction     img_to_predict = np.expand_dims(cv2.resize(image_to_predict, (img_width, img_height)), axis=0)          # Pr\u00e9dictions avec le mod\u00e8le     predictions = model.predict(img_to_predict)[0]  # R\u00e9cup\u00e8re directement la premi\u00e8re pr\u00e9diction          # Trier les indices des classes par ordre de probabilit\u00e9 d\u00e9croissante     sorted_indices = np.argsort(predictions)[::-1]          # Obtenir la premi\u00e8re classe et sa confiance     top_class_index = sorted_indices[0]     top_class_confidence = predictions[top_class_index]          # V\u00e9rifier la confiance est suffisante pour pr\u00e9dire la classe (utile pour palier au probl\u00e8me o\u00f9  pour lesquels les imageries  de poumons ou du cerveaus moins conventionnelles auront tendences \u00e0 \u00eatre pr\u00e9dites comme autres avec une certitude moins importante )     if top_class_confidence &gt;= 0.90:         predicted_class_index = top_class_index     else:         # Prendre la deuxi\u00e8me classe si la premi\u00e8re est en dessous du seuil         predicted_class_index = sorted_indices[1]          # Obtenir le nom de la classe pr\u00e9dite     predicted_class_name = class_names[predicted_class_index]          # Afficher le r\u00e9sultat     print(f\"L'image est pr\u00e9dite comme : {predicted_class_name} avec une confiance de {predictions[predicted_class_index]:.2f}\") else:     print(\"Erreur lors du chargement de l'image. V\u00e9rifiez le chemin d'acc\u00e8s.\")   <pre>Erreur lors du chargement de l'image. V\u00e9rifiez le chemin d'acc\u00e8s.\n</pre> <pre>[ WARN:0@81593.021] global loadsave.cpp:241 findDecoder imread_('/Users/victorouledi/Downloads/poumon4.jpeg'): can't open/read file: check file path/integrity\n</pre> In\u00a0[14]: Copied! <pre>chemin_dossier = \"/Users/victorouledi/Documents/2024-2025/CNN/\"  \n\nmodel.save(chemin_dossier + \"CNN_imageries_medicales2.h5\")\n</pre> chemin_dossier = \"/Users/victorouledi/Documents/2024-2025/CNN/\"    model.save(chemin_dossier + \"CNN_imageries_medicales2.h5\")  <pre>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#import-des-donnees-et-separation-des-classes","title":"Import des donn\u00e9es et s\u00e9paration des classes\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#verification-de-limport-de-bon-format-de-fichiers","title":"V\u00e9rification de l'import de bon format de fichiers\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#visualisation","title":"Visualisation\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#ajustement-du-modele","title":"Ajustement du mod\u00e8le\u00b6","text":"<ul> <li><p>Normalisation de la taille des images</p> </li> <li><p>Diff\u00e9rentes couches de convolution 2D avec 128, 64, 32, et 16 filtres de taile 4X4</p> </li> <li><p>Rajout de couche de maxpooling \u00e0 chaque fois pour r\u00e9sumer les features maps obtenue par les couches de concolutions</p> </li> <li><p>Rajout d'une couche  Flatten qui r\u00e9duit la dimension des features maps en un vecteur pour simplification d'apprentissage</p> </li> <li><p>Rajout de couche dense avec 64 neuronnes pour apprentissage des informations tir\u00e9es des couhces de convultion, de pooling et de la couche Flatten.</p> </li> <li><p>Derni\u00e8re couche \u00e0 2 neuronnes retournant la probabilit\u00e9 qu'une image appartienne \u00e0 une classe ou l'autre.</p> </li> <li><p>Entrainement du mod\u00e8e sur 3 \u00e9poques</p> </li> </ul>"},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#selection-de-3-epoques-choix-entre-performances-temps-dentrainement-et-controle-du-surapprentissage","title":"S\u00e9lection de 3 \u00e9poques (choix entre performances, temps d'entrainement et controle du surapprentissage)\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#resume-du-modele","title":"R\u00e9sum\u00e9 du mod\u00e8le\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#test-de-prediction-du-modele","title":"Test de pr\u00e9diction du mod\u00e8le\u00b6","text":""},{"location":"asset/Computer_vision/notebooks/Pre%CC%81diction%20imagerie%20me%CC%81dicale/#sauvegarde","title":"Sauvegarde\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/","title":"Notebook: NLP &amp; LSTM pour pr\u00e9diction du type de sujet conernant les r\u00e9clamations et pleintes \u00e0 l'encontre de services financiers","text":"In\u00a0[304]: Copied! <pre>import plotly.express as px\nimport polars as pl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport re\nimport string\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Bidirectional, LSTM, Dropout, BatchNormalization, SpatialDropout1D\nfrom tensorflow.keras.layers import Embedding\nfrom keras.initializers import Constant\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras import optimizers, layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Embedding\nimport tensorflow as tf\n</pre> import plotly.express as px import polars as pl import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import scipy.stats as stats import re import string from sklearn.impute import SimpleImputer from sklearn.model_selection import train_test_split from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.preprocessing import LabelEncoder from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Dropout, BatchNormalization, SpatialDropout1D from tensorflow.keras.layers import Embedding from keras.initializers import Constant from tensorflow.keras.optimizers import SGD, Adam from tensorflow.keras import optimizers, layers from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Embedding import tensorflow as tf    <p>S\u00e9lection des deux variables d\u2019int\u00e9r\u00eat</p> In\u00a0[305]: Copied! <pre>file = 'consumer_complaints.csv'\n\n#on traite le code postal comme texte\nschema_fix = {\"zipcode\": pl.Utf8}\n\ndf = pl.read_csv(\n    file,\n    schema_overrides=schema_fix,\n)\n\nprint(df.shape)\ndisplay(df.head())\n</pre> file = 'consumer_complaints.csv'  #on traite le code postal comme texte schema_fix = {\"zipcode\": pl.Utf8}  df = pl.read_csv(     file,     schema_overrides=schema_fix, )  print(df.shape) display(df.head()) <pre>(555957, 18)\n</pre> shape: (5, 18)date_receivedproductsub_productissuesub_issueconsumer_complaint_narrativecompany_public_responsecompanystatezipcodetagsconsumer_consent_providedsubmitted_viadate_sent_to_companycompany_response_to_consumertimely_responseconsumer_disputed?complaint_idstrstrstrstrstrstrstrstrstrstrstrstrstrstrstrstrstri64\"08/30/2013\"\"Mortgage\"\"Other mortgage\"\"Loan modification,collection,f\u2026nullnullnull\"U.S. Bancorp\"\"CA\"\"95993\"nullnull\"Referral\"\"09/03/2013\"\"Closed with explanation\"\"Yes\"\"Yes\"511074\"08/30/2013\"\"Mortgage\"\"Other mortgage\"\"Loan servicing, payments, escr\u2026nullnullnull\"Wells Fargo &amp; Company\"\"CA\"\"91104\"nullnull\"Referral\"\"09/03/2013\"\"Closed with explanation\"\"Yes\"\"Yes\"511080\"08/30/2013\"\"Credit reporting\"null\"Incorrect information on credi\u2026\"Account status\"nullnull\"Wells Fargo &amp; Company\"\"NY\"\"11764\"nullnull\"Postal mail\"\"09/18/2013\"\"Closed with explanation\"\"Yes\"\"No\"510473\"08/30/2013\"\"Student loan\"\"Non-federal student loan\"\"Repaying your loan\"\"Repaying your loan\"nullnull\"Navient Solutions, Inc.\"\"MD\"\"21402\"nullnull\"Email\"\"08/30/2013\"\"Closed with explanation\"\"Yes\"\"Yes\"510326\"08/30/2013\"\"Debt collection\"\"Credit card\"\"False statements or representa\u2026\"Attempted to collect wrong amo\u2026nullnull\"Resurgent Capital Services L.P\u2026\"GA\"\"30106\"nullnull\"Web\"\"08/30/2013\"\"Closed with explanation\"\"Yes\"\"Yes\"511067 <p>Analyse et suppression des doublons</p> In\u00a0[306]: Copied! <pre># 1. Nombre total de lignes\ntotal = df.height\n\n# 2. Nombre de lignes uniques (sur TOUTES les colonnes)\nn_unique = df.unique().height\n\n# 3. Calcul des doublons exacts\nn_dups_exact = total - n_unique\nprint(f\"Doublons exacts (toutes colonnes confondues) : {n_dups_exact}\")\n\n# 4. Doublons sur complaint_id seulement\nn_dups_id = df.filter(pl.col(\"complaint_id\").is_duplicated()).height\nprint(f\"Doublons sur complaint_id : {n_dups_id}\")\n</pre> # 1. Nombre total de lignes total = df.height  # 2. Nombre de lignes uniques (sur TOUTES les colonnes) n_unique = df.unique().height  # 3. Calcul des doublons exacts n_dups_exact = total - n_unique print(f\"Doublons exacts (toutes colonnes confondues) : {n_dups_exact}\")  # 4. Doublons sur complaint_id seulement n_dups_id = df.filter(pl.col(\"complaint_id\").is_duplicated()).height print(f\"Doublons sur complaint_id : {n_dups_id}\") <pre>Doublons exacts (toutes colonnes confondues) : 0\nDoublons sur complaint_id : 0\n</pre> <p>S\u00e9lection des deux variables d\u2019int\u00e9r\u00eat</p> In\u00a0[307]: Copied! <pre># Fonction de s\u00e9lection &amp; synth\u00e8se des valeurs manquantes\n\ndef select_with_missing(df: pl.DataFrame, columns: list[str]) -&gt; tuple[pl.DataFrame, pl.DataFrame]:\n    \"\"\"\n    S\u00e9lectionne les colonnes demand\u00e9es et renvoie :\n      - df_small : DataFrame r\u00e9duit aux colonnes choisies\n      - na_summary : DataFrame (column, missing, percent) d\u00e9crivant\n                     les NA de ces colonnes\n    \"\"\"\n    # 1) s\u00e9lection des colonnes\n    df_small = df.select(columns)\n\n    # 2) calcul du total de lignes\n    total = df_small.height\n\n    # 3) r\u00e9sum\u00e9 des NA\n    na_summary = (\n        df_small\n        .null_count()                       # 1\u00d7n colonnes avec counts\n        .melt()                             # d\u00e9plie colonnes en lignes (variable,value)\n        .rename({                           # renommage pour clart\u00e9\n            \"variable\": \"column\",\n            \"value\":    \"missing\"\n        })\n        .with_columns([                     # ajout du pourcentage\n            (pl.col(\"missing\") / total * 100)\n            .round(2)\n            .alias(\"percent\")\n        ])\n        .sort(\"percent\", descending=True) # tri par % d\u00e9croissant\n    )            # tri par % d\u00e9croissant\n\n\n    return df_small, na_summary\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Ex\u00e9cution sur vos deux variables d\u2019int\u00e9r\u00eat\ncols = [\"product\", \"consumer_complaint_narrative\"]\ndf_small, na_df = select_with_missing(df, cols)\n\n# Affichage des r\u00e9sultats\nprint(\"=== Sous-DataFrame r\u00e9duit ===\")\ndisplay(df_small.head())\nprint(df_small.shape)\n\nprint(\"\\n=== Synth\u00e8se des valeurs manquantes ===\")\ndisplay(na_df)\n</pre> # Fonction de s\u00e9lection &amp; synth\u00e8se des valeurs manquantes  def select_with_missing(df: pl.DataFrame, columns: list[str]) -&gt; tuple[pl.DataFrame, pl.DataFrame]:     \"\"\"     S\u00e9lectionne les colonnes demand\u00e9es et renvoie :       - df_small : DataFrame r\u00e9duit aux colonnes choisies       - na_summary : DataFrame (column, missing, percent) d\u00e9crivant                      les NA de ces colonnes     \"\"\"     # 1) s\u00e9lection des colonnes     df_small = df.select(columns)      # 2) calcul du total de lignes     total = df_small.height      # 3) r\u00e9sum\u00e9 des NA     na_summary = (         df_small         .null_count()                       # 1\u00d7n colonnes avec counts         .melt()                             # d\u00e9plie colonnes en lignes (variable,value)         .rename({                           # renommage pour clart\u00e9             \"variable\": \"column\",             \"value\":    \"missing\"         })         .with_columns([                     # ajout du pourcentage             (pl.col(\"missing\") / total * 100)             .round(2)             .alias(\"percent\")         ])         .sort(\"percent\", descending=True) # tri par % d\u00e9croissant     )            # tri par % d\u00e9croissant       return df_small, na_summary  # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 # Ex\u00e9cution sur vos deux variables d\u2019int\u00e9r\u00eat cols = [\"product\", \"consumer_complaint_narrative\"] df_small, na_df = select_with_missing(df, cols)  # Affichage des r\u00e9sultats print(\"=== Sous-DataFrame r\u00e9duit ===\") display(df_small.head()) print(df_small.shape)  print(\"\\n=== Synth\u00e8se des valeurs manquantes ===\") display(na_df) <pre>=== Sous-DataFrame r\u00e9duit ===\n</pre> <pre>/var/folders/hh/87rk0r4519j1t1s8k96y4l_r0000gn/T/ipykernel_3885/101606361.py:20: DeprecationWarning:\n\n`DataFrame.melt` is deprecated. Use `unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n\n</pre> shape: (5, 2)productconsumer_complaint_narrativestrstr\"Mortgage\"null\"Mortgage\"null\"Credit reporting\"null\"Student loan\"null\"Debt collection\"null <pre>(555957, 2)\n\n=== Synth\u00e8se des valeurs manquantes ===\n</pre> shape: (2, 3)columnmissingpercentstru32f64\"consumer_complaint_narrative\"48915187.98\"product\"00.0 <p>R\u00e9partition des produits dans le jeu de donn\u00e9es</p> In\u00a0[308]: Copied! <pre># --- 1) Sous-DataFrame r\u00e9duit ---\ndf_small = df.select([\n    pl.col(\"product\"),\n    pl.col(\"consumer_complaint_narrative\")\n])\n\n# --- 2) R\u00e9partition de \"product\" ---\nprod_counts = (\n    df_small\n      .group_by(\"product\")                                 # Polars eager utilise group_by :contentReference[oaicite:0]{index=0}\n      .agg(pl.count().alias(\"freq\"))                       # compte les lignes par produit\n      .sort(\"freq\", descending=True)                       # tri d\u00e9croissant\n      .to_pandas()                                         # conversion pour Plotly\n)\n# Calcul du pourcentage avec round() Python\nprod_counts[\"percent\"] = (\n    prod_counts[\"freq\"] / prod_counts[\"freq\"].sum() * 100\n).round(2)\n\nfig = px.bar(\n    prod_counts,\n    x=\"product\", y=\"percent\",\n    title=\"R\u00e9partition des produits dans le jeu de donn\u00e9es\",\n    labels={\"percent\":\"% des plaintes\", \"product\":\"Produit\"},\n    text=\"percent\"               # on affiche la valeur de la colonne percent\n)\n\nfig.update_traces(\n    texttemplate=\"%{text:.2f} %\",  # format avec deux d\u00e9cimales + symbole %\n    textposition=\"outside\"         # place le texte au-dessus de chaque barre\n)\n\nfig.update_layout(\n    uniformtext_minsize=8,         # taille mini du texte\n    uniformtext_mode='hide'        # cache les textes trop grands\n)\n\nfig.show()\n</pre> # --- 1) Sous-DataFrame r\u00e9duit --- df_small = df.select([     pl.col(\"product\"),     pl.col(\"consumer_complaint_narrative\") ])  # --- 2) R\u00e9partition de \"product\" --- prod_counts = (     df_small       .group_by(\"product\")                                 # Polars eager utilise group_by :contentReference[oaicite:0]{index=0}       .agg(pl.count().alias(\"freq\"))                       # compte les lignes par produit       .sort(\"freq\", descending=True)                       # tri d\u00e9croissant       .to_pandas()                                         # conversion pour Plotly ) # Calcul du pourcentage avec round() Python prod_counts[\"percent\"] = (     prod_counts[\"freq\"] / prod_counts[\"freq\"].sum() * 100 ).round(2)  fig = px.bar(     prod_counts,     x=\"product\", y=\"percent\",     title=\"R\u00e9partition des produits dans le jeu de donn\u00e9es\",     labels={\"percent\":\"% des plaintes\", \"product\":\"Produit\"},     text=\"percent\"               # on affiche la valeur de la colonne percent )  fig.update_traces(     texttemplate=\"%{text:.2f} %\",  # format avec deux d\u00e9cimales + symbole %     textposition=\"outside\"         # place le texte au-dessus de chaque barre )  fig.update_layout(     uniformtext_minsize=8,         # taille mini du texte     uniformtext_mode='hide'        # cache les textes trop grands )  fig.show() <pre>/var/folders/hh/87rk0r4519j1t1s8k96y4l_r0000gn/T/ipykernel_3885/3032611547.py:11: DeprecationWarning:\n\n`pl.count()` is deprecated. Please use `pl.len()` instead.\n\n</pre> <p>Taux de narratif manquant par produit</p> In\u00a0[309]: Copied! <pre>miss_by_prod = (\n    df_small\n    .with_columns([\n        (pl.col(\"consumer_complaint_narrative\").is_null()\n           .cast(pl.UInt8))  # directement 0/1\n        .alias(\"is_missing\")\n    ])\n    .group_by(\"product\")\n    .agg([\n        pl.sum(\"is_missing\").alias(\"nb_missing\"),\n        (\n            pl.sum(\"is_missing\")\n            / pl.count(\"is_missing\")  # nombre de lignes par groupe\n            * 100\n        )\n        .round(2)\n        .alias(\"pct_missing\")\n    ])\n    .sort(\"pct_missing\", descending=True)\n    .to_pandas()\n)\n\nimport plotly.express as px\nfig = px.bar(\n    miss_by_prod,\n    x=\"product\", y=\"pct_missing\", text=\"pct_missing\",\n    title=\"Taux de narratif manquant par produit\",\n    labels={\"pct_missing\":\"% sans texte\", \"product\":\"Produit\"}\n)\nfig.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\")\nfig.update_layout(xaxis_tickangle=45)\nfig.show()\n</pre> miss_by_prod = (     df_small     .with_columns([         (pl.col(\"consumer_complaint_narrative\").is_null()            .cast(pl.UInt8))  # directement 0/1         .alias(\"is_missing\")     ])     .group_by(\"product\")     .agg([         pl.sum(\"is_missing\").alias(\"nb_missing\"),         (             pl.sum(\"is_missing\")             / pl.count(\"is_missing\")  # nombre de lignes par groupe             * 100         )         .round(2)         .alias(\"pct_missing\")     ])     .sort(\"pct_missing\", descending=True)     .to_pandas() )  import plotly.express as px fig = px.bar(     miss_by_prod,     x=\"product\", y=\"pct_missing\", text=\"pct_missing\",     title=\"Taux de narratif manquant par produit\",     labels={\"pct_missing\":\"% sans texte\", \"product\":\"Produit\"} ) fig.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\") fig.update_layout(xaxis_tickangle=45) fig.show()  <p>R\u00e9partition des produits (plaintes AVEC texte)</p> In\u00a0[310]: Copied! <pre># 1) Filtrer les lignes AVEC un texte de plainte\nwith_text = df_small.filter(\n    pl.col(\"consumer_complaint_narrative\").is_not_null()\n)\n\n# 2) Nombre total et aper\u00e7u\nn_with = with_text.height\npct_with = round(n_with / df_small.height * 100, 2)\nprint(f\"Nombre de plaintes AVEC texte : {n_with} ({pct_with} %)\")\ndisplay(with_text.head(10))\n\n# 3) Calcul de la r\u00e9partition par produit (freq + percent)\ncounts_with = (\n    with_text\n    .group_by(\"product\")\n    .agg(pl.count().alias(\"freq\"))\n    .sort(\"freq\", descending=True)\n    .to_pandas()\n)\ncounts_with[\"percent\"] = (\n    counts_with[\"freq\"] / counts_with[\"freq\"].sum() * 100\n).round(2)\n\n# 4) Bar chart avec pourcentages sur chaque barre\nfig = px.bar(\n    counts_with,\n    x=\"product\",\n    y=\"percent\",\n    text=\"percent\",\n    title=\"R\u00e9partition des produits (plaintes AVEC texte)\",\n    labels={\"percent\":\"% des plaintes avec texte\", \"product\":\"Produit\"},\n)\n\nfig.update_traces(\n    texttemplate=\"%{text:.2f} %\",  # deux d\u00e9cimales + symbole %\n    textposition=\"outside\"\n)\nfig.update_layout(\n    xaxis_tickangle=45,\n    uniformtext_minsize=8,\n    uniformtext_mode='hide',\n    yaxis=dict(range=[0, counts_with[\"percent\"].max() * 1.1])  # un peu d\u2019espace en haut\n)\nfig.show()\n</pre> # 1) Filtrer les lignes AVEC un texte de plainte with_text = df_small.filter(     pl.col(\"consumer_complaint_narrative\").is_not_null() )  # 2) Nombre total et aper\u00e7u n_with = with_text.height pct_with = round(n_with / df_small.height * 100, 2) print(f\"Nombre de plaintes AVEC texte : {n_with} ({pct_with} %)\") display(with_text.head(10))  # 3) Calcul de la r\u00e9partition par produit (freq + percent) counts_with = (     with_text     .group_by(\"product\")     .agg(pl.count().alias(\"freq\"))     .sort(\"freq\", descending=True)     .to_pandas() ) counts_with[\"percent\"] = (     counts_with[\"freq\"] / counts_with[\"freq\"].sum() * 100 ).round(2)  # 4) Bar chart avec pourcentages sur chaque barre fig = px.bar(     counts_with,     x=\"product\",     y=\"percent\",     text=\"percent\",     title=\"R\u00e9partition des produits (plaintes AVEC texte)\",     labels={\"percent\":\"% des plaintes avec texte\", \"product\":\"Produit\"}, )  fig.update_traces(     texttemplate=\"%{text:.2f} %\",  # deux d\u00e9cimales + symbole %     textposition=\"outside\" ) fig.update_layout(     xaxis_tickangle=45,     uniformtext_minsize=8,     uniformtext_mode='hide',     yaxis=dict(range=[0, counts_with[\"percent\"].max() * 1.1])  # un peu d\u2019espace en haut ) fig.show() <pre>Nombre de plaintes AVEC texte : 66806 (12.02 %)\n</pre> shape: (10, 2)productconsumer_complaint_narrativestrstr\"Debt collection\"\"XXXX has claimed I owe them {$\u2026\"Consumer Loan\"\"Due to inconsistencies in the \u2026\"Mortgage\"\"In XX/XX/XXXX my wages that I \u2026\"Mortgage\"\"I have an open and current mor\u2026\"Mortgage\"\"XXXX was submitted XX/XX/XXXX.\u2026\"Mortgage\"\"Experian is reporting my OPEN \u2026\"Mortgage\"\"This complaint is against Well\u2026\"Mortgage\"\"I spoke to XXXX of green tree \u2026\"Credit card\"\"i opened XXXX Bank of America \u2026\"Consumer Loan\"\"I applied for a loan with XXXX\u2026 <pre>/var/folders/hh/87rk0r4519j1t1s8k96y4l_r0000gn/T/ipykernel_3885/2469596007.py:16: DeprecationWarning:\n\n`pl.count()` is deprecated. Please use `pl.len()` instead.\n\n</pre> <p>Pourcentage de textes manquants par mois/ann\u00e9es</p> In\u00a0[311]: Copied! <pre># Extrait le mois/ann\u00e9e de date_received\ndf_time = (\n  df\n  .with_columns([\n    pl.col(\"date_received\")\n      .str.strptime(pl.Date, \"%m/%d/%Y\")\n      .dt.truncate(\"1mo\")\n      .alias(\"month\")\n  ])\n  .with_columns([\n    pl.when(pl.col(\"consumer_complaint_narrative\").is_null())\n      .then(1).otherwise(0)\n      .alias(\"is_missing\")\n  ])\n  .group_by(\"month\")\n  .agg([\n    pl.sum(\"is_missing\").alias(\"nb_missing\"),\n    (pl.sum(\"is_missing\")/pl.len()*100).alias(\"pct_missing\")\n  ])\n  .sort(\"month\")\n  .to_pandas()\n)\n\nfig = px.line(\n    df_time,\n    x=\"month\", y=\"pct_missing\",\n    title=\"Pourcentage de textes manquants par mois\",\n    labels={\"pct_missing\":\"% sans texte\", \"month\":\"Mois\"}\n)\nfig.show()\n</pre> # Extrait le mois/ann\u00e9e de date_received df_time = (   df   .with_columns([     pl.col(\"date_received\")       .str.strptime(pl.Date, \"%m/%d/%Y\")       .dt.truncate(\"1mo\")       .alias(\"month\")   ])   .with_columns([     pl.when(pl.col(\"consumer_complaint_narrative\").is_null())       .then(1).otherwise(0)       .alias(\"is_missing\")   ])   .group_by(\"month\")   .agg([     pl.sum(\"is_missing\").alias(\"nb_missing\"),     (pl.sum(\"is_missing\")/pl.len()*100).alias(\"pct_missing\")   ])   .sort(\"month\")   .to_pandas() )  fig = px.line(     df_time,     x=\"month\", y=\"pct_missing\",     title=\"Pourcentage de textes manquants par mois\",     labels={\"pct_missing\":\"% sans texte\", \"month\":\"Mois\"} ) fig.show() <p>Le long plateau \u00e0 100 % jusqu\u2019en mars 2015 montre que, durant la phase initiale (d\u00e9cembre 2011\u2013mars 2015), tous les enregistrements n\u2019avaient aucun r\u00e9cit libre (\u00ab narrative \u00bb) \u2013 le champ n\u2019existait tout simplement pas. \u00c0 partir de mars 2015, on observe un brutal passage d\u2019environ 100 % de manquants vers 65\u201360 % : c\u2019est l\u2019effet du d\u00e9ploiement en production du champ narratif, qui devient alors facultatif et collecte progressivement les r\u00e9cits des consommateurs. Cette proportion remonte ensuite l\u00e9g\u00e8rement fin 2015/d\u00e9but 2016, refl\u00e9tant sans doute des variations de consentement ou d\u2019usage au fil du temps.</p> <p>Dans son Spring 2015 Semi-Annual Report, le CFPB explique que le champ narratif n\u2019a \u00e9t\u00e9 mis en production qu\u2019\u00e0 partir du 19 mars 2015 : avant cette date, aucun r\u00e9cit libre n\u2019\u00e9tait collect\u00e9 ni publi\u00e9, ce qui explique le creux \u00e0 100 % de valeurs manquantes. Pour mener notre \u00e9tude NLP on va se concentrer uniquement sur la p\u00e9riode o\u00f9 le champ \u00e9tait op\u00e9rationnel et disponibles aux consommateurs (post-19 mars 2015), afin de ne pas biaiser les r\u00e9sultats avec des lignes sans jamais avoir eu la possibilit\u00e9 de fournir un texte \u2014 Cf. CFPB Spring 2015 Semi-Annual Report (June 2015), p. 11 et 21 \u00e0 voir (lien ci dessous).</p> <p>texte du lien</p> <p>On filtre sur la p\u00e9riode post\u201019 mars 2015</p> In\u00a0[312]: Copied! <pre># 1) Filtrer sur la p\u00e9riode post\u201019 mars 2015\ndf_post = df.filter(\n    pl.col(\"date_received\")\n      .str.strptime(pl.Date, \"%m/%d/%Y\")\n      .gt(pl.datetime(2015, 3, 19))\n)\n\n# 2) V\u00e9rifions la plage de dates\ndate_range = df_post.select([\n    pl.col(\"date_received\")\n      .str.strptime(pl.Date, \"%m/%d/%Y\")\n      .min().alias(\"premiere_date\"),\n    pl.col(\"date_received\")\n      .str.strptime(pl.Date, \"%m/%d/%Y\")\n      .max().alias(\"derniere_date\")\n])\n\n# Option A \u2013 conversion en Pandas pour l'affichage\nprint(date_range.to_pandas())\n\n# Option B \u2013 affichage direct avec Polars\nprint(date_range)\n</pre> # 1) Filtrer sur la p\u00e9riode post\u201019 mars 2015 df_post = df.filter(     pl.col(\"date_received\")       .str.strptime(pl.Date, \"%m/%d/%Y\")       .gt(pl.datetime(2015, 3, 19)) )  # 2) V\u00e9rifions la plage de dates date_range = df_post.select([     pl.col(\"date_received\")       .str.strptime(pl.Date, \"%m/%d/%Y\")       .min().alias(\"premiere_date\"),     pl.col(\"date_received\")       .str.strptime(pl.Date, \"%m/%d/%Y\")       .max().alias(\"derniere_date\") ])  # Option A \u2013 conversion en Pandas pour l'affichage print(date_range.to_pandas())  # Option B \u2013 affichage direct avec Polars print(date_range) <pre>  premiere_date derniere_date\n0    2015-03-20    2016-04-25\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 premiere_date \u2506 derniere_date \u2502\n\u2502 ---           \u2506 ---           \u2502\n\u2502 date          \u2506 date          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2015-03-20    \u2506 2016-04-25    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Pour la suite de notre analyse, nous nous concentrons sur la p\u00e9riode post-19 mars 2015 \u2013 date \u00e0 laquelle le CFPB a d\u00e9ploy\u00e9 en production le champ \u00ab consumer_complaint_narrative \u00bb, sans quoi aucun r\u00e9cit libre n\u2019\u00e9tait collect\u00e9.</p> <p>Plut\u00f4t que de supprimer aveugl\u00e9ment toutes les lignes o\u00f9 ce champ est vide, nous appliquons un filtrage par combinaison de quatre variables cl\u00e9s :</p> <ul> <li>product : type de plainte</li> <li>issue et sub_issue : cat\u00e9gorisation fine du probl\u00e8me</li> <li>submitted_via : canal par lequel la plainte a \u00e9t\u00e9 d\u00e9pos\u00e9e</li> </ul> <p>Cette strat\u00e9gie pr\u00e9sente deux avantages majeurs :</p> <ol> <li><p>Conserver uniquement les segments r\u00e9ellement renseign\u00e9s En ne gardant que les groupes (\u00ab combos \u00bb) pour lesquels au moins une plainte contient un texte libre, on s\u2019assure de travailler sur des sous-ensembles o\u00f9 le r\u00e9cit narratif a effectivement \u00e9t\u00e9 saisi, sans exclure toute une cat\u00e9gorie d\u00e8s qu\u2019un seul individu omet de r\u00e9diger son r\u00e9cit.</p> </li> <li><p>Respecter l\u2019h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 m\u00e9tier Les dimensions product, issue, sub_issue et submitted_via influencent la forme et la longueur des r\u00e9cits (par exemple un appel t\u00e9l\u00e9phonique versus un formulaire web). Structurer le nettoyage sur ces axes pr\u00e9serve la repr\u00e9sentativit\u00e9 de chaque contexte d\u2019usage pour la mod\u00e9lisation NLP.</p> </li> </ol> <p>En somme, ce filtrage \u00ab combo \u00bb maximise l\u2019utilisation de chaque segment d\u2019int\u00e9r\u00eat tout en \u00e9vitant le biais d\u2019exclusion pure : il concilie exhaustivit\u00e9 (on ne supprime pas toutes les lignes vides) et qualit\u00e9 (on ne mod\u00e9lise qu\u2019\u00e0 partir de groupes o\u00f9 du texte est r\u00e9ellement disponible).</p> In\u00a0[313]: Copied! <pre>import polars as pl\n\n# 1. Filtrer sur post-19 mars 2015\ndf_post = df.filter(\n    pl.col(\"date_received\")\n      .str.strptime(pl.Date, \"%m/%d/%Y\")\n      .gt(pl.datetime(2015, 3, 19))\n)\n\n# 2. Calculer pct_missing par combo\ncombo_stats = (\n    df_post\n    .with_columns(\n        pl.col(\"consumer_complaint_narrative\")\n          .is_null()\n          .cast(pl.UInt8)\n          .alias(\"is_missing\")\n    )\n    .group_by([\"product\", \"issue\", \"sub_issue\", \"submitted_via\"])\n    .agg([\n        pl.len().alias(\"n_total\"),                             # nombre de lignes\n        pl.sum(\"is_missing\").alias(\"n_missing\"),               # combien de manquants\n        (pl.sum(\"is_missing\") / pl.len() * 100)                # ratio\n          .round(2)\n          .alias(\"pct_missing\")\n    ])\n)\n\n# 3. Combos o\u00f9 au moins une ligne a du texte\ncombos_ok = combo_stats.filter(pl.col(\"pct_missing\") &lt; 100).select(\n    [\"product\", \"issue\", \"sub_issue\", \"submitted_via\"]\n)\n\n# 4. Ne garder que ces combos\ndf_useful = df_post.join(\n    combos_ok,\n    on=[\"product\", \"issue\", \"sub_issue\", \"submitted_via\"],\n    how=\"inner\"\n)\n\n# 5. Placeholder et flag\ndf_clean = df_useful.with_columns([\n    pl.when(pl.col(\"consumer_complaint_narrative\").is_null())\n      .then(pl.lit(\"[no_text]\"))\n      .otherwise(pl.col(\"consumer_complaint_narrative\"))\n      .alias(\"narrative\"),\n    pl.col(\"consumer_complaint_narrative\")\n      .is_null()\n      .cast(pl.UInt8)\n      .alias(\"is_missing\")\n])\n\n\n# Dimensions\nprint(f\"df_post    : {df_post.height} \u00d7 {df_post.width}\")\nprint(f\"df_clean   : {df_clean.height} \u00d7 {df_clean.width}\")\n\n# Premier aper\u00e7u\ndisplay(df_post.select([\"product\",\"consumer_complaint_narrative\"]).head(5))\ndisplay(df_clean.select([\"product\",\"narrative\",\"is_missing\"]).head(5))\n\n\n# A) Deux combos 100% manquants, tri\u00e9s par n_total d\u00e9croissant\ncombos_100 = (\n    combo_stats\n    .filter(pl.col(\"pct_missing\") == 100.0)\n    .sort(\"n_total\", descending=True)\n    .head(2)\n)\n\n# B) Deux combos mixtes (pct_missing &lt; 100), tri\u00e9s par pct_missing croissant\ncombos_some = (\n    combo_stats\n    .filter(pl.col(\"pct_missing\") &lt; 100.0)\n    .sort(\"pct_missing\", descending=False)\n    .head(2)\n)\n\nprint(\"=== Combos 100% manquants ===\")\ndisplay(combos_100)\n\nprint(\"\\n=== Combos mixtes ===\")\ndisplay(combos_some)\n</pre> import polars as pl  # 1. Filtrer sur post-19 mars 2015 df_post = df.filter(     pl.col(\"date_received\")       .str.strptime(pl.Date, \"%m/%d/%Y\")       .gt(pl.datetime(2015, 3, 19)) )  # 2. Calculer pct_missing par combo combo_stats = (     df_post     .with_columns(         pl.col(\"consumer_complaint_narrative\")           .is_null()           .cast(pl.UInt8)           .alias(\"is_missing\")     )     .group_by([\"product\", \"issue\", \"sub_issue\", \"submitted_via\"])     .agg([         pl.len().alias(\"n_total\"),                             # nombre de lignes         pl.sum(\"is_missing\").alias(\"n_missing\"),               # combien de manquants         (pl.sum(\"is_missing\") / pl.len() * 100)                # ratio           .round(2)           .alias(\"pct_missing\")     ]) )  # 3. Combos o\u00f9 au moins une ligne a du texte combos_ok = combo_stats.filter(pl.col(\"pct_missing\") &lt; 100).select(     [\"product\", \"issue\", \"sub_issue\", \"submitted_via\"] )  # 4. Ne garder que ces combos df_useful = df_post.join(     combos_ok,     on=[\"product\", \"issue\", \"sub_issue\", \"submitted_via\"],     how=\"inner\" )  # 5. Placeholder et flag df_clean = df_useful.with_columns([     pl.when(pl.col(\"consumer_complaint_narrative\").is_null())       .then(pl.lit(\"[no_text]\"))       .otherwise(pl.col(\"consumer_complaint_narrative\"))       .alias(\"narrative\"),     pl.col(\"consumer_complaint_narrative\")       .is_null()       .cast(pl.UInt8)       .alias(\"is_missing\") ])   # Dimensions print(f\"df_post    : {df_post.height} \u00d7 {df_post.width}\") print(f\"df_clean   : {df_clean.height} \u00d7 {df_clean.width}\")  # Premier aper\u00e7u display(df_post.select([\"product\",\"consumer_complaint_narrative\"]).head(5)) display(df_clean.select([\"product\",\"narrative\",\"is_missing\"]).head(5))   # A) Deux combos 100% manquants, tri\u00e9s par n_total d\u00e9croissant combos_100 = (     combo_stats     .filter(pl.col(\"pct_missing\") == 100.0)     .sort(\"n_total\", descending=True)     .head(2) )  # B) Deux combos mixtes (pct_missing &lt; 100), tri\u00e9s par pct_missing croissant combos_some = (     combo_stats     .filter(pl.col(\"pct_missing\") &lt; 100.0)     .sort(\"pct_missing\", descending=False)     .head(2) )  print(\"=== Combos 100% manquants ===\") display(combos_100)  print(\"\\n=== Combos mixtes ===\") display(combos_some) <pre>df_post    : 185092 \u00d7 18\ndf_clean   : 71199 \u00d7 20\n</pre> shape: (5, 2)productconsumer_complaint_narrativestrstr\"Debt collection\"null\"Debt collection\"\"I received services from a hea\u2026\"Credit reporting\"null\"Debt collection\"null\"Mortgage\"null shape: (5, 3)productnarrativeis_missingstrstru8\"Debt collection\"\"[no_text]\"1\"Debt collection\"\"I received services from a hea\u20260\"Credit reporting\"\"[no_text]\"1\"Debt collection\"\"[no_text]\"1\"Debt collection\"\"[no_text]\"1 <pre>=== Combos 100% manquants ===\n</pre> shape: (2, 7)productissuesub_issuesubmitted_vian_totaln_missingpct_missingstrstrstrstru32i64f64\"Mortgage\"\"Loan modification,collection,f\u2026null\"Referral\"57135713100.0\"Mortgage\"\"Loan servicing, payments, escr\u2026null\"Referral\"29872987100.0 <pre>\n=== Combos mixtes ===\n</pre> shape: (2, 7)productissuesub_issuesubmitted_vian_totaln_missingpct_missingstrstrstrstru32i64f64\"Consumer Loan\"\"Lender damaged or destroyed ve\u2026null\"Web\"100.0\"Consumer Loan\"\"Applied for loan/did not recei\u2026null\"Web\"9222.22 <p>D\u00e9finitions des jeux de donn\u00e9es</p> <ul> <li>df_post : sous-ensemble des r\u00e9clamations re\u00e7ues apr\u00e8s le 19 mars 2015, date \u00e0 laquelle le CFPB a introduit en production le champ <code>consumer_complaint_narrative</code>.</li> <li>df_clean : r\u00e9sultat du filtrage \u00ab combo \u00bb sur (product, issue, sub_issue, submitted_via), ne conservant que les combinaisons pour lesquelles au moins une plainte contient un texte libre. Les r\u00e9cits manquants y sont remplac\u00e9s par la cha\u00eene <code>[no_text]</code> et un flag <code>is_missing</code> indique si un r\u00e9cit \u00e9tait initialement absent (1) ou non (0).</li> </ul> <p>R\u00e9partition des produits (df_post) et R\u00e9partition (%) des produits dans df_clean</p> In\u00a0[314]: Copied! <pre># \u2500\u2500\u2500 1) R\u00e9partition de \"product\" DANS df_post \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndist_post = (\n    df_post\n    .group_by(\"product\")                              # NOTA : pas groupby()\n    .agg([\n        pl.len().alias(\"count\")                       # pl.len() remplace pl.count()\n    ])\n    .with_columns([\n        (pl.col(\"count\") / df_post.height * 100)\n         .round(2)\n         .alias(\"percent\")\n    ])\n    .sort(\"percent\", descending=True)\n    .to_pandas()\n)\n\nprint(\"R\u00e9partition des produits dans df_post (post-19/03/2015) :\")\ndisplay(dist_post)\n\nfig1 = px.bar(\n    dist_post,\n    x=\"product\", y=\"percent\", text=\"percent\",\n    title=\"R\u00e9partition des produits (df_post)\",\n    labels={\"percent\":\"% des plaintes\", \"product\":\"Produit\"}\n)\nfig1.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\")\nfig1.update_layout(xaxis_tickangle=45)\nfig1.show()\n</pre> # \u2500\u2500\u2500 1) R\u00e9partition de \"product\" DANS df_post \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  dist_post = (     df_post     .group_by(\"product\")                              # NOTA : pas groupby()     .agg([         pl.len().alias(\"count\")                       # pl.len() remplace pl.count()     ])     .with_columns([         (pl.col(\"count\") / df_post.height * 100)          .round(2)          .alias(\"percent\")     ])     .sort(\"percent\", descending=True)     .to_pandas() )  print(\"R\u00e9partition des produits dans df_post (post-19/03/2015) :\") display(dist_post)  fig1 = px.bar(     dist_post,     x=\"product\", y=\"percent\", text=\"percent\",     title=\"R\u00e9partition des produits (df_post)\",     labels={\"percent\":\"% des plaintes\", \"product\":\"Produit\"} ) fig1.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\") fig1.update_layout(xaxis_tickangle=45) fig1.show() <pre>R\u00e9partition des produits dans df_post (post-19/03/2015) :\n</pre> product count percent 0 Mortgage 46295 25.01 1 Debt collection 41742 22.55 2 Credit reporting 39470 21.32 3 Credit card 19274 10.41 4 Bank account or service 19096 10.32 5 Consumer Loan 8819 4.76 6 Student loan 4719 2.55 7 Prepaid card 1908 1.03 8 Money transfers 1804 0.97 9 Payday loan 1583 0.86 10 Other financial service 382 0.21 In\u00a0[315]: Copied! <pre># --- 2) Balance des classes 'product'  ---\n\nprod_balance = (\n    df_clean\n    .group_by(\"product\")\n    .agg(pl.count().alias(\"count\"))\n    .with_columns((pl.col(\"count\") / df_clean.height * 100).round(2).alias(\"percent\"))\n    .sort(\"percent\", descending=True)\n    .to_pandas()\n)\n\nprint(\"\\nR\u00e9partition des produits dans df_clean :\")\ndisplay(prod_balance)\n\nfig3 = px.bar(\n    prod_balance,\n    x=\"product\", y=\"percent\", text=\"percent\",\n    title=\"R\u00e9partition (%) des produits dans df_clean\",\n    labels={\"percent\": \"% des plaintes\", \"product\": \"Produit\"}\n)\nfig3.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\")\nfig3.update_layout(xaxis_tickangle=45)\nfig3.show()\n</pre>  # --- 2) Balance des classes 'product'  ---  prod_balance = (     df_clean     .group_by(\"product\")     .agg(pl.count().alias(\"count\"))     .with_columns((pl.col(\"count\") / df_clean.height * 100).round(2).alias(\"percent\"))     .sort(\"percent\", descending=True)     .to_pandas() )  print(\"\\nR\u00e9partition des produits dans df_clean :\") display(prod_balance)  fig3 = px.bar(     prod_balance,     x=\"product\", y=\"percent\", text=\"percent\",     title=\"R\u00e9partition (%) des produits dans df_clean\",     labels={\"percent\": \"% des plaintes\", \"product\": \"Produit\"} ) fig3.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\") fig3.update_layout(xaxis_tickangle=45) fig3.show() <pre>\nR\u00e9partition des produits dans df_clean :\n</pre> <pre>/var/folders/hh/87rk0r4519j1t1s8k96y4l_r0000gn/T/ipykernel_3885/1224867461.py:6: DeprecationWarning:\n\n`pl.count()` is deprecated. Please use `pl.len()` instead.\n\n</pre> product count percent 0 Debt collection 34373 48.28 1 Credit reporting 31231 43.86 2 Student loan 4152 5.83 3 Payday loan 1443 2.03 <p>Pour df_post : on retrouve l\u2019ensemble des 11 cat\u00e9gories de produit, avec une majorit\u00e9 de Mortgage, Debt collection et Credit reporting, qui repr\u00e9sentent 68 % du volume total.</p> <p>Dans df_clean, seules 4 cat\u00e9gories subsistent apr\u00e8s le filtrage \u00ab combo \u00bb, car pour les autres produits, tous les r\u00e9cits \u00e9taient syst\u00e9matiquement absents (pct_missing = 100 %) et ont donc \u00e9t\u00e9 exclus.</p> In\u00a0[316]: Copied! <pre>import polars as pl\nimport plotly.express as px\nimport pandas as pd\n\n# --- 1) Distribution des longueurs de r\u00e9cit via conversion en pandas ---\n\n# On extrait la colonne narrative en pandas pour utiliser str.len() et str.split()\npdf = df_clean.select([\"narrative\"]).to_pandas()\n\n# Nombre de caract\u00e8res\npdf[\"char_length\"] = pdf[\"narrative\"].str.len()\n\n# Nombre de mots\npdf[\"word_count\"] = pdf[\"narrative\"].str.split().str.len()\n\n# Statistiques sommaires\nlengths_summary = {\n    \"min_chars\":    pdf[\"char_length\"].min(),\n    \"q1_chars\":     pdf[\"char_length\"].quantile(0.25),\n    \"median_chars\": pdf[\"char_length\"].median(),\n    \"q3_chars\":     pdf[\"char_length\"].quantile(0.75),\n    \"max_chars\":    pdf[\"char_length\"].max(),\n    \"min_words\":    pdf[\"word_count\"].min(),\n    \"q1_words\":     pdf[\"word_count\"].quantile(0.25),\n    \"median_words\": pdf[\"word_count\"].median(),\n    \"q3_words\":     pdf[\"word_count\"].quantile(0.75),\n    \"max_words\":    pdf[\"word_count\"].max(),\n}\nprint(\"R\u00e9sum\u00e9 des longueurs de r\u00e9cits :\")\nfor metric, value in lengths_summary.items():\n    print(f\"  {metric:&lt;12}: {value}\")\n\n# Histogrammes interactifs\nfig1 = px.histogram(\n    pdf, x=\"char_length\", nbins=50,\n    title=\"Distribution du nombre de caract\u00e8res par r\u00e9cit\",\n    labels={\"char_length\": \"Longueur (caract\u00e8res)\"}\n)\nfig1.show()\n\nfig2 = px.histogram(\n    pdf, x=\"word_count\", nbins=50,\n    title=\"Distribution du nombre de mots par r\u00e9cit\",\n    labels={\"word_count\": \"Longueur (mots)\"}\n)\nfig2.show()\n</pre> import polars as pl import plotly.express as px import pandas as pd  # --- 1) Distribution des longueurs de r\u00e9cit via conversion en pandas ---  # On extrait la colonne narrative en pandas pour utiliser str.len() et str.split() pdf = df_clean.select([\"narrative\"]).to_pandas()  # Nombre de caract\u00e8res pdf[\"char_length\"] = pdf[\"narrative\"].str.len()  # Nombre de mots pdf[\"word_count\"] = pdf[\"narrative\"].str.split().str.len()  # Statistiques sommaires lengths_summary = {     \"min_chars\":    pdf[\"char_length\"].min(),     \"q1_chars\":     pdf[\"char_length\"].quantile(0.25),     \"median_chars\": pdf[\"char_length\"].median(),     \"q3_chars\":     pdf[\"char_length\"].quantile(0.75),     \"max_chars\":    pdf[\"char_length\"].max(),     \"min_words\":    pdf[\"word_count\"].min(),     \"q1_words\":     pdf[\"word_count\"].quantile(0.25),     \"median_words\": pdf[\"word_count\"].median(),     \"q3_words\":     pdf[\"word_count\"].quantile(0.75),     \"max_words\":    pdf[\"word_count\"].max(), } print(\"R\u00e9sum\u00e9 des longueurs de r\u00e9cits :\") for metric, value in lengths_summary.items():     print(f\"  {metric:&lt;12}: {value}\")  # Histogrammes interactifs fig1 = px.histogram(     pdf, x=\"char_length\", nbins=50,     title=\"Distribution du nombre de caract\u00e8res par r\u00e9cit\",     labels={\"char_length\": \"Longueur (caract\u00e8res)\"} ) fig1.show()  fig2 = px.histogram(     pdf, x=\"word_count\", nbins=50,     title=\"Distribution du nombre de mots par r\u00e9cit\",     labels={\"word_count\": \"Longueur (mots)\"} ) fig2.show() <pre>R\u00e9sum\u00e9 des longueurs de r\u00e9cits :\n  min_chars   : 9\n  q1_chars    : 9.0\n  median_chars: 9.0\n  q3_chars    : 506.0\n  max_chars   : 4033\n  min_words   : 1\n  q1_words    : 1.0\n  median_words: 1.0\n  q3_words    : 93.0\n  max_words   : 803\n</pre> In\u00a0[317]: Copied! <pre># \u2500\u2500\u2500 2) % de \"[no_text]\" vs vrai texte DANS df_clean \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndist_no_text = (\n    df_clean\n    .group_by(\"is_missing\")\n    .agg([\n        pl.len().alias(\"count\")  # count = nombre de lignes par groupe (0 ou 1)\n    ])\n    .with_columns([\n        # calcul du pourcentage\n        (pl.col(\"count\") / df_clean.height * 100)\n         .round(2)\n         .alias(\"percent\")\n    ])\n    .with_columns([\n        # on \u201cl\u00e8ve\u201d les litt\u00e9raux via pl.lit()\n        pl.when(pl.col(\"is_missing\") == 1)\n          .then(pl.lit(\"no_text\"))\n          .otherwise(pl.lit(\"with_text\"))\n          .alias(\"category\")\n    ])\n    .select([\"category\", \"count\", \"percent\"])\n    .to_pandas()\n)\n\nprint(\"\\nPart des r\u00e9cits '[no_text]' vs plaintes avec texte :\")\ndisplay(dist_no_text)\n\nfig2 = px.pie(\n    dist_no_text,\n    names=\"category\",\n    values=\"count\",\n    title=\"Proportion de '[no_text]' vs plaintes avec texte\",\n    hole=0.4\n)\nfig2.update_traces(textinfo=\"label+percent\", showlegend=False)\nfig2.show()\n</pre> # \u2500\u2500\u2500 2) % de \"[no_text]\" vs vrai texte DANS df_clean \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  dist_no_text = (     df_clean     .group_by(\"is_missing\")     .agg([         pl.len().alias(\"count\")  # count = nombre de lignes par groupe (0 ou 1)     ])     .with_columns([         # calcul du pourcentage         (pl.col(\"count\") / df_clean.height * 100)          .round(2)          .alias(\"percent\")     ])     .with_columns([         # on \u201cl\u00e8ve\u201d les litt\u00e9raux via pl.lit()         pl.when(pl.col(\"is_missing\") == 1)           .then(pl.lit(\"no_text\"))           .otherwise(pl.lit(\"with_text\"))           .alias(\"category\")     ])     .select([\"category\", \"count\", \"percent\"])     .to_pandas() )  print(\"\\nPart des r\u00e9cits '[no_text]' vs plaintes avec texte :\") display(dist_no_text)  fig2 = px.pie(     dist_no_text,     names=\"category\",     values=\"count\",     title=\"Proportion de '[no_text]' vs plaintes avec texte\",     hole=0.4 ) fig2.update_traces(textinfo=\"label+percent\", showlegend=False) fig2.show()  <pre>\nPart des r\u00e9cits '[no_text]' vs plaintes avec texte :\n</pre> category count percent 0 no_text 38321 53.82 1 with_text 32878 46.18 In\u00a0[318]: Copied! <pre># 1) Calcul sur df_post\ndist_post_missing = (\n    df_post\n    .with_columns(\n        # flag is_missing = 1 si la narrative est null, 0 sinon\n        pl.col(\"consumer_complaint_narrative\")\n          .is_null()\n          .cast(pl.UInt8)\n          .alias(\"is_missing\")\n    )\n    .group_by(\"is_missing\")\n    .agg([\n        pl.len().alias(\"count\")\n    ])\n    .with_columns([\n        (pl.col(\"count\") / df_post.height * 100)\n         .round(2)\n         .alias(\"percent\")\n    ])\n    .with_columns([\n        pl.when(pl.col(\"is_missing\") == 1)\n          .then(pl.lit(\"no_text\"))\n          .otherwise(pl.lit(\"with_text\"))\n          .alias(\"category\")\n    ])\n    .select([\"category\", \"count\", \"percent\"])\n    .to_pandas()\n)\n\nprint(\"Part des r\u00e9cits manquants vs pr\u00e9sents (df_post) :\")\ndisplay(dist_post_missing)\n\n# 2) Visualisation en pie\nfig3 = px.pie(\n    dist_post_missing,\n    names=\"category\",\n    values=\"count\",\n    title=\"df_post : % de r\u00e9cits manquants vs pr\u00e9sents\",\n    hole=0.4\n)\nfig3.update_traces(textinfo=\"label+percent\", showlegend=False)\nfig3.show()\n</pre> # 1) Calcul sur df_post dist_post_missing = (     df_post     .with_columns(         # flag is_missing = 1 si la narrative est null, 0 sinon         pl.col(\"consumer_complaint_narrative\")           .is_null()           .cast(pl.UInt8)           .alias(\"is_missing\")     )     .group_by(\"is_missing\")     .agg([         pl.len().alias(\"count\")     ])     .with_columns([         (pl.col(\"count\") / df_post.height * 100)          .round(2)          .alias(\"percent\")     ])     .with_columns([         pl.when(pl.col(\"is_missing\") == 1)           .then(pl.lit(\"no_text\"))           .otherwise(pl.lit(\"with_text\"))           .alias(\"category\")     ])     .select([\"category\", \"count\", \"percent\"])     .to_pandas() )  print(\"Part des r\u00e9cits manquants vs pr\u00e9sents (df_post) :\") display(dist_post_missing)  # 2) Visualisation en pie fig3 = px.pie(     dist_post_missing,     names=\"category\",     values=\"count\",     title=\"df_post : % de r\u00e9cits manquants vs pr\u00e9sents\",     hole=0.4 ) fig3.update_traces(textinfo=\"label+percent\", showlegend=False) fig3.show() <pre>Part des r\u00e9cits manquants vs pr\u00e9sents (df_post) :\n</pre> category count percent 0 with_text 66699 36.04 1 no_text 118393 63.96 <p>Apr\u00e8s nettoyage \u00ab combo \u00bb (df_clean), nous observons que 53,8 % des lignes contiennent encore la valeur <code>[no_text]</code> (absence de r\u00e9cit libre), tandis que 46,2 % ont un texte r\u00e9ellement saisi. En revanche, sur l\u2019ensemble des donn\u00e9es post-d\u00e9ploiement (df_post), seuls 36,0 % des plaintes disposent d\u2019un r\u00e9cit, contre 64,0 % totalement d\u00e9pourvus de texte.</p> <p>Interpr\u00e9tation :</p> <ul> <li>Le passage de 64 % de r\u00e9cits manquants dans df_post \u00e0 54 % dans df_clean traduit l\u2019efficacit\u00e9 de notre filtrage : en ne conservant que les groupes o\u00f9 au moins un membre a renseign\u00e9 un texte, nous r\u00e9duisons substantiellement la part de donn\u00e9es inutilisables.</li> <li>Malgr\u00e9 tout, plus de la moiti\u00e9 des enregistrements retenus restent sans texte (<code>[no_text]</code>), ce qui nuit directement \u00e0 toute analyse NLP.</li> </ul> <p>Choix pour la suite : Nous d\u00e9cidons de supprimer toutes les lignes marqu\u00e9es <code>[no_text]</code> afin de ne mod\u00e9liser qu\u2019\u00e0 partir de r\u00e9els r\u00e9cits. Cette d\u00e9cision se justifie par :</p> <ol> <li>Qualit\u00e9 des donn\u00e9es : les NLP ne peuvent tirer d\u2019apprentissage que de textes existants (pas de r\u00e9cits vides).</li> <li>Efficacit\u00e9 : concentrer les ressources de calcul (pr\u00e9traitements, vectorisations, entra\u00eenement) sur des \u00e9chantillons r\u00e9ellement textuels acc\u00e9l\u00e8re le d\u00e9veloppement et am\u00e9liore la pertinence des mod\u00e8les.</li> </ol> <p>Nous utiliserons donc df_clean comme base de travail, tout en mettant en place des techniques de r\u00e9\u00e9quilibrage de classes (sur-\u00e9chantillonnage, sous-\u00e9chantillonnage ou pond\u00e9ration des pertes) pour corriger le biais li\u00e9 \u00e0 la distribution in\u00e9gale des produits.</p> In\u00a0[319]: Copied! <pre># DROP NA dans df_clean\n\ndf_clean_no_na = df_clean.filter(\n    pl.col(\"is_missing\") == 0\n)\nprint(f\"df_clean   : {df_clean.height} lignes \u2192 {df_clean_no_na.height} apr\u00e8s dropno_text\")\n</pre> # DROP NA dans df_clean  df_clean_no_na = df_clean.filter(     pl.col(\"is_missing\") == 0 ) print(f\"df_clean   : {df_clean.height} lignes \u2192 {df_clean_no_na.height} apr\u00e8s dropno_text\")  <pre>df_clean   : 71199 lignes \u2192 32878 apr\u00e8s dropno_text\n</pre> In\u00a0[320]: Copied! <pre># \u2500\u2500\u2500 1) ON GARDE LES DEUX VARIABLES\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndf_final = df_clean_no_na.select([\n    pl.col(\"product\"),\n    pl.col(\"narrative\")\n])\nprint(f\"df_final : {df_final.height} lignes \u00d7 {df_final.width} colonnes\")\ndisplay(df_final.head())\n\n# \u2500\u2500\u2500 2) DISTRIBUTION DE 'product' DANS CE SOUS-JEU \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndist_prod = (\n    df_final\n      .group_by(\"product\")\n      .agg([\n          pl.count().alias(\"count\"),  # nombre de plaintes par produit\n      ])\n      .with_columns([\n          # calcul du pourcentage sur l'ensemble de df_final\n          (pl.col(\"count\") / df_final.height * 100)\n            .round(2)\n            .alias(\"percent\")\n      ])\n      .sort(\"percent\", descending=True)\n      .to_pandas()                  # on convertit en pandas pour Plotly\n)\n\nprint(\"R\u00e9partition des produits dans df_final (apr\u00e8s suppression des [no_text]) :\")\ndisplay(dist_prod)\n\n# \u2500\u2500\u2500 3) BAR CHART INTERACTIF \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig = px.bar(\n    dist_prod,\n    x=\"product\", y=\"percent\", text=\"percent\",\n    title=\"R\u00e9partition (%) des produits (df_final)\",\n    labels={\"product\":\"Produit\", \"percent\":\"% des plaintes\"}\n)\nfig.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\")\nfig.update_layout(xaxis_tickangle=45)\nfig.show()\n</pre> # \u2500\u2500\u2500 1) ON GARDE LES DEUX VARIABLES\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 df_final = df_clean_no_na.select([     pl.col(\"product\"),     pl.col(\"narrative\") ]) print(f\"df_final : {df_final.height} lignes \u00d7 {df_final.width} colonnes\") display(df_final.head())  # \u2500\u2500\u2500 2) DISTRIBUTION DE 'product' DANS CE SOUS-JEU \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 dist_prod = (     df_final       .group_by(\"product\")       .agg([           pl.count().alias(\"count\"),  # nombre de plaintes par produit       ])       .with_columns([           # calcul du pourcentage sur l'ensemble de df_final           (pl.col(\"count\") / df_final.height * 100)             .round(2)             .alias(\"percent\")       ])       .sort(\"percent\", descending=True)       .to_pandas()                  # on convertit en pandas pour Plotly )  print(\"R\u00e9partition des produits dans df_final (apr\u00e8s suppression des [no_text]) :\") display(dist_prod)  # \u2500\u2500\u2500 3) BAR CHART INTERACTIF \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 fig = px.bar(     dist_prod,     x=\"product\", y=\"percent\", text=\"percent\",     title=\"R\u00e9partition (%) des produits (df_final)\",     labels={\"product\":\"Produit\", \"percent\":\"% des plaintes\"} ) fig.update_traces(texttemplate=\"%{text:.2f} %\", textposition=\"outside\") fig.update_layout(xaxis_tickangle=45) fig.show()  <pre>df_final : 32878 lignes \u00d7 2 colonnes\n</pre> shape: (5, 2)productnarrativestrstr\"Debt collection\"\"I received services from a hea\u2026\"Credit reporting\"\"In XXXX, I requested my free a\u2026\"Debt collection\"\"This individual has called me \u2026\"Debt collection\"\"This individual has called me \u2026\"Credit reporting\"\"In XX/XX/XXXX, while discussin\u2026 <pre>R\u00e9partition des produits dans df_final (apr\u00e8s suppression des [no_text]) :\n</pre> <pre>/var/folders/hh/87rk0r4519j1t1s8k96y4l_r0000gn/T/ipykernel_3885/4042707356.py:14: DeprecationWarning:\n\n`pl.count()` is deprecated. Please use `pl.len()` instead.\n\n</pre> product count percent 0 Debt collection 17528 53.31 1 Credit reporting 12506 38.04 2 Student loan 2120 6.45 3 Payday loan 724 2.20 <p>En ne conservant que <code>product</code> et <code>narrative</code>, nous nous assurons de concentrer toute notre \u00e9nergie sur l\u2019essentiel :</p> <ul> <li><p>Clart\u00e9 m\u00e9tier : La variable <code>product</code> repr\u00e9sente directement le type de service concern\u00e9 (pr\u00eat, recouvrement, etc.), ce qui structure naturellement les th\u00e9matiques des r\u00e9cits.</p> </li> <li><p>Pertinence NLP : La colonne <code>narrative</code> contient le seul contenu textuel exploitable pour l\u2019analyse s\u00e9mantique, le topic modeling et la classification.</p> </li> <li><p>Simplicit\u00e9 &amp; efficacit\u00e9 : En \u00e9liminant les autres variables (<code>state</code>, <code>date_received</code>, <code>submitted_via</code>, etc.), on r\u00e9duit drastiquement la dimensionnalit\u00e9 du probl\u00e8me, on limite le bruit et on acc\u00e9l\u00e8re les boucles de pr\u00e9traitement, de vectorisation et d\u2019entra\u00eenement.</p> </li> </ul> <p>Ce choix garantit un pipeline l\u00e9ger, facile \u00e0 maintenir, tout en pr\u00e9servant la richesse th\u00e9matique n\u00e9cessaire \u00e0 la mod\u00e9lisation des plaintes.</p> <p>product/narrative</p> In\u00a0[321]: Copied! <pre># 1) convertir\ndata = df_final.to_pandas()\n\n# 2)On dit \u00e0 pandas de ne **jamais** tronquer les strings\npd.options.display.max_colwidth = None\n\n# 3) affiche\ndisplay(data.head(5))\n</pre> # 1) convertir data = df_final.to_pandas()  # 2)On dit \u00e0 pandas de ne **jamais** tronquer les strings pd.options.display.max_colwidth = None  # 3) affiche display(data.head(5)) product narrative 0 Debt collection I received services from a healthcare provider XXXX years ago. Recently I got a call from a Collection Agency who said the debt has not been paid. The healthcare provider and I were in agreement that they 'd take care of billing but somehow my name was thrown into the mix. The healthcare agency does not respond to my inquiries about the debt or to the collection agency 's inquiries about the debt. This has a possibility of ruining my credit. \\n 1 Credit reporting In XXXX, I requested my free annual credit report. After viewing my credit report, I noticed over XXXX credit/loan inquiries on my account that was not authorized by me. I contacted each company and was told that there was not any account open under my information. I explained that I have a hard inquiry on my credit report and need it removed as soon as possible so that I could apply for a home. I was told that the inquiries would be removed from my credit report. As of XXXX/XXXX/XXXX, none of the inquiries have been removed dating back to XXXX. I had a initial fraud alert placed on my report on XXXX XXXX, so if any credit reports are being pulled with my information, I was to be contacted by the company before any action was taken place. I just want the inquiries to be removed so that my scores and credit is not being impacted any longer. I would like to purchase a house, but until all of the inquires are removed I will not be approved with XXXX inquires on my credit report. \\n 2 Debt collection This individual has called me almost every single day in regards to credit card debt that I have been unable to pay due to unemployment. He leaves numerous messages. He has called my parents, my brother, and most likely other individuals that share my last name. I called him today and he threatened me by saying that if I did not pay a certain amount that legal action would be taken. He hassled me to ask family members for money. I told him NOT to call my parents as I have not lived with them for 15 years and they would not be paying this debt on my behalf. \\n 3 Debt collection This individual has called me almost every single day in regards to credit card debt that I have been unable to pay due to unemployment. He leaves numerous messages. He has called my parents, my brother, and most likely other individuals that share my last name. I called him today and he threatened me by saying that if I did not pay a certain amount that legal action would be taken. He hassled me to ask family members for money. I told him NOT to call my parents as I have not lived with them for XXXX years and they would not be paying this debt on my behalf. \\n 4 Credit reporting In XX/XX/XXXX, while discussing an unrelated business mater with a current lender, I was made aware that an account, I did not authorize or initiate, had me listed as a cosigner. I immediately notified the lender that I was a victim of identity fraud and requested to see the information they had on file. In turn, I checked my credit reports, confirmed the presence of the fraudulent account, and contacted each of the XXXX ( XXXX ) credit reporting companies and disputed the information. At varying dates in XX/XX/XXXX, each of the credit reporting companies ( CRCs ) reported that the account was confirmed by the lender. To date, the fraudulent information remains on my credit file and [ neither ] CRC has ever notated my credit profile about the account being disputed. \\n\\nAfter [ several ] additional telephonic requests to the lender between XX/XX/XXXX to XX/XX/XXXX, the lender mailed me a copy of the loan origination documents along with its internal ID theft package. I immediately filed a law enforcement report ( LER ) with my local Sheriff XXXX Office and returned the original package and supporting documentation to the lender in XX/XX/XXXX. The supporting documentation included a copy of the lender 's loan origination document, my LER, drivers license, social security card, and hand writing samples. \\n\\nIn XX/XX/XXXX, I was notified by a potential employer that I was deemed unsuitable due the presence of delinquent financial information on my credit report. In that same notification, I was provided a copy of my combined credit report which still contained the fraudulent account on each of the CRC 's reports. I began researching laws and learned about the FCRA and the FTC. After learning that the combination of an LER and FTC Identity Theft Affidavit ( ITA ) produce an Identity Theft Report ( IDR ), I filed an ITA on the FTC 's website. \\n\\nIn turn, I sent [ via certified mail ] FTC 's CRC-template letters and supporting documentation to each of the XXXX credit reporting companies requesting that the fraudulent account be blocked, removed, and that a extended fraud alert be placed on my credit file as per the FCRA. The supporting documentation for each submission of FTC 's CRC-template letter included a copy of the lender 's loan origination document ; my credit report, drivers license, social security card, and hand writing samples ; as well as FCRA Section 611. \\n\\nAccording to XXXX tracking, the CRCs received their certified letters on XX/XX/XXXX and XX/XX/XXXX [ XXXX ], respectively. To date, each CRC has placed an extended fraud alert but has [ not ] blocked the fraudulent account information from my respective credit profile [ or ] contacted me declining my request to block the fraudulent information. In fact, XXXX CRC will not allow me to order a credit report directly and advised ( via telephone ) that my IDR was not sufficient but would not provide its justification method in making that determination. Subsequently, and, respectively, I have ordered additional credit reports which indicate each CRC 's non-compliance the FCRA 's imposed time limits. To their credit, XXXX CRCs have listed the fraudulent account as disputed/under investigation. \\n\\nAdditionally, I sent [ for the XXXX time, via certified mail ] FTC 's lender-template letter and supporting documentation to the lender requesting that the lender block, absolve me of responsibility, and stop inaccurately furnishing the fraudulent account information to the CRCs. The supporting documentation to my submission of FTC 's lender-template letter included a copy of the lender 's loan origination document and ID Theft Affidavit ; my IDR, credit report, drivers license, social security card, and hand writing samples ; as well as FTC 's Notice to Furnishers ) According to XXXX tracking, the lender received its certified letter on XX/XX/XXXX. To date, the lender has not made any contact with me. \\n\\nXXXX : FTC XXXX # XXXX \\n In\u00a0[322]: Copied! <pre>data = data.rename(columns = {\"narrative\" : \"consumer_complaint_narrative\"})\ndata['consumer_complaint_narrative'].str.lower()\n</pre> data = data.rename(columns = {\"narrative\" : \"consumer_complaint_narrative\"}) data['consumer_complaint_narrative'].str.lower()  Out[322]: <pre>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           i received services from a healthcare provider xxxx years ago. recently i got a call from a collection agency who said the debt has not been paid. the healthcare provider and i were in agreement that they 'd take care of billing but somehow my name was thrown into the mix. the healthcare agency does not respond to my inquiries about the debt or to the collection agency 's inquiries about the debt. this has a possibility of ruining my credit. \\n\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          in xxxx, i requested my free annual credit report. after viewing my credit report, i noticed over xxxx credit/loan inquiries on my account that was not authorized by me. i contacted each company and was told that there was not any account open under my information. i explained that i have a hard inquiry on my credit report and need it removed as soon as possible so that i could apply for a home. i was told that the inquiries would be removed from my credit report. as of xxxx/xxxx/xxxx, none of the inquiries have been removed dating back to xxxx. i had a initial fraud alert placed on my report on xxxx xxxx, so if any credit reports are being pulled with my information, i was to be contacted by the company before any action was taken place. i just want the inquiries to be removed so that my scores and credit is not being impacted any longer. i would like to purchase a house, but until all of the inquires are removed i will not be approved with xxxx inquires on my credit report. \\n\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      this individual has called me almost every single day in regards to credit card debt that i have been unable to pay due to unemployment. he leaves numerous messages. he has called my parents, my brother, and most likely other individuals that share my last name. i called him today and he threatened me by saying that if i did not pay a certain amount that legal action would be taken. he hassled me to ask family members for money. i told him not to call my parents as i have not lived with them for 15 years and they would not be paying this debt on my behalf. \\n\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    this individual has called me almost every single day in regards to credit card debt that i have been unable to pay due to unemployment. he leaves numerous messages. he has called my parents, my brother, and most likely other individuals that share my last name. i called him today and he threatened me by saying that if i did not pay a certain amount that legal action would be taken. he hassled me to ask family members for money. i told him not to call my parents as i have not lived with them for xxxx years and they would not be paying this debt on my behalf. \\n\n4        in xx/xx/xxxx, while discussing an unrelated business mater with a current lender, i was made aware that an account, i did not authorize or initiate, had me listed as a cosigner. i immediately notified the lender that i was a victim of identity fraud and requested to see the information they had on file. in turn, i checked my credit reports, confirmed the presence of the fraudulent account, and contacted each of the xxxx ( xxxx ) credit reporting companies and disputed the information. at varying dates in xx/xx/xxxx, each of the credit reporting companies ( crcs ) reported that the account was confirmed by the lender. to date, the fraudulent information remains on my credit file and [ neither ] crc has ever notated my credit profile about the account being disputed. \\n\\nafter [ several ] additional telephonic requests to the lender between xx/xx/xxxx to xx/xx/xxxx, the lender mailed me a copy of the loan origination documents along with its internal id theft package. i immediately filed a law enforcement report ( ler ) with my local sheriff xxxx office and returned the original package and supporting documentation to the lender in xx/xx/xxxx. the supporting documentation included a copy of the lender 's loan origination document, my ler, drivers license, social security card, and hand writing samples. \\n\\nin xx/xx/xxxx, i was notified by a potential employer that i was deemed unsuitable due the presence of delinquent financial information on my credit report. in that same notification, i was provided a copy of my combined credit report which still contained the fraudulent account on each of the crc 's reports. i began researching laws and learned about the fcra and the ftc. after learning that the combination of an ler and ftc identity theft affidavit ( ita ) produce an identity theft report ( idr ), i filed an ita on the ftc 's website. \\n\\nin turn, i sent [ via certified mail ] ftc 's crc-template letters and supporting documentation to each of the xxxx credit reporting companies requesting that the fraudulent account be blocked, removed, and that a extended fraud alert be placed on my credit file as per the fcra. the supporting documentation for each submission of ftc 's crc-template letter included a copy of the lender 's loan origination document ; my credit report, drivers license, social security card, and hand writing samples ; as well as fcra section 611. \\n\\naccording to xxxx tracking, the crcs received their certified letters on xx/xx/xxxx and xx/xx/xxxx [ xxxx ], respectively. to date, each crc has placed an extended fraud alert but has [ not ] blocked the fraudulent account information from my respective credit profile [ or ] contacted me declining my request to block the fraudulent information. in fact, xxxx crc will not allow me to order a credit report directly and advised ( via telephone ) that my idr was not sufficient but would not provide its justification method in making that determination. subsequently, and, respectively, i have ordered additional credit reports which indicate each crc 's non-compliance the fcra 's imposed time limits. to their credit, xxxx crcs have listed the fraudulent account as disputed/under investigation. \\n\\nadditionally, i sent [ for the xxxx time, via certified mail ] ftc 's lender-template letter and supporting documentation to the lender requesting that the lender block, absolve me of responsibility, and stop inaccurately furnishing the fraudulent account information to the crcs. the supporting documentation to my submission of ftc 's lender-template letter included a copy of the lender 's loan origination document and id theft affidavit ; my idr, credit report, drivers license, social security card, and hand writing samples ; as well as ftc 's notice to furnishers ) according to xxxx tracking, the lender received its certified letter on xx/xx/xxxx. to date, the lender has not made any contact with me. \\n\\nxxxx : ftc xxxx # xxxx \\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n32873                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                i have not applied for credit at multiple institutions that are stated on my credit report as a hard credit inquiry. \\n\n32874                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         received a letter from afni, inc. attempting to collect an alleged outstanding debt owed to xxxx xxxx xxxx when i have never had an account with xxxx xxxx xxxx for any product or service. \\n\n32875                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                xxxx xxxx is reporting incorrectly, payments have been on time, the vehicle was turned in on time to the dealership. \\n\n32876                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             reflecting incorrect payment status. have been on time. \\n\n32877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        i have been paying {$180.00} a month through direct debit withdrawal from my checking account for several months on a {$600.00} loan. the {$180.00} a month was an \" extension '' that i thought was installments to satisfy the original loan. this company has received {$2000.00} in fees on a {$600.00} loan and i still have a balance due. they did send me a contract that i agreed to in haste and did not clearly understand. although i understand payday loans, how is it fair business to charge this amount on a {$600.00} loan? this equates to over 300 % interest in just an extension fee??? there should be a cap on what they can charge you for fees.. {$180.00} a month as an \" extension fee ''!! xxxx \\n\nName: consumer_complaint_narrative, Length: 32878, dtype: object</pre> In\u00a0[323]: Copied! <pre>from wordcloud import WordCloud \nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n</pre>  from wordcloud import WordCloud  import nltk from nltk.stem import WordNetLemmatizer from nltk import word_tokenize from nltk.tokenize import word_tokenize from nltk.corpus import stopwords from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences In\u00a0[\u00a0]: Copied! <pre>import re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# 1. Retirer les nombres\ndef remove_number(text):\n    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n    return num.sub(r'', text)\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_number)\n\n# 2. Retirer les URLs\ndef remove_url(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_url)\n\n# 3. Retirer le HTML et entit\u00e9s\ndef remove_html(text):\n    html = re.compile(r'&lt;.*?&gt;|&amp;([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n    return html.sub(r'', text)\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_html)\n\n# 4. Ne garder que les lettres (remplace ponctuation, chiffres, etc. par des espaces)\ndef remove_punctuations(inputs):\n    return re.sub(r'[^a-zA-Z]', ' ', inputs)\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_punctuations)\n\n# # 5. Tokenisation  par d\u00e9coupage sur les espaces\ndef simple_tokenize(text):\n    # split() d\u00e9coupe sur tout espace et supprime les vides\n    return [tok for tok in text.lower().split() if tok]\n\n# data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(simple_tokenize)\n\n\n# 6. Lemmatisation\ndef lemmatize_tokens(tokens):\n    return [lemmatizer.lemmatize(tok) for tok in tokens]\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(lemmatize_tokens)\n\n# R\u00e9sultat : chaque entr\u00e9e de 'consumer_complaint_narrative' est maintenant une liste de tokens\nprint(data['consumer_complaint_narrative'].head())\n</pre> import re from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences  # 1. Retirer les nombres def remove_number(text):     num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')     return num.sub(r'', text)  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_number)  # 2. Retirer les URLs def remove_url(text):     url = re.compile(r'https?://\\S+|www\\.\\S+')     return url.sub(r'', text)  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_url)  # 3. Retirer le HTML et entit\u00e9s def remove_html(text):     html = re.compile(r'&lt;.*?&gt;|&amp;([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')     return html.sub(r'', text)  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_html)  # 4. Ne garder que les lettres (remplace ponctuation, chiffres, etc. par des espaces) def remove_punctuations(inputs):     return re.sub(r'[^a-zA-Z]', ' ', inputs)  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(remove_punctuations)  # # 5. Tokenisation  par d\u00e9coupage sur les espaces def simple_tokenize(text):     # split() d\u00e9coupe sur tout espace et supprime les vides     return [tok for tok in text.lower().split() if tok]  # data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(simple_tokenize)   # 6. Lemmatisation def lemmatize_tokens(tokens):     return [lemmatizer.lemmatize(tok) for tok in tokens]  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(lemmatize_tokens)  # R\u00e9sultat : chaque entr\u00e9e de 'consumer_complaint_narrative' est maintenant une liste de tokens print(data['consumer_complaint_narrative'].head())  <pre>0                                                                                                                                                           [i, received, services, from, a, healthcare, provider, xxxx, years, ago, recently, i, got, a, call, from, a, collection, agency, who, said, the, debt, has, not, been, paid, the, healthcare, provider, and, i, were, in, agreement, that, they, d, take, care, of, billing, but, somehow, my, name, was, thrown, into, the, mix, the, healthcare, agency, does, not, respond, to, my, inquiries, about, the, debt, or, to, the, collection, agency, s, inquiries, about, the, debt, this, has, a, possibility, of, ruining, my, credit]\n1                                               [in, xxxx, i, requested, my, free, annual, credit, report, after, viewing, my, credit, report, i, noticed, over, xxxx, credit, loan, inquiries, on, my, account, that, was, not, authorized, by, me, i, contacted, each, company, and, was, told, that, there, was, not, any, account, open, under, my, information, i, explained, that, i, have, a, hard, inquiry, on, my, credit, report, and, need, it, removed, as, soon, as, possible, so, that, i, could, apply, for, a, home, i, was, told, that, the, inquiries, would, be, removed, from, my, credit, report, as, of, xxxx, xxxx, xxxx, none, of, the, inquiries, have, been, removed, ...]\n2                                                       [this, individual, has, called, me, almost, every, single, day, in, regards, to, credit, card, debt, that, i, have, been, unable, to, pay, due, to, unemployment, he, leaves, numerous, messages, he, has, called, my, parents, my, brother, and, most, likely, other, individuals, that, share, my, last, name, i, called, him, today, and, he, threatened, me, by, saying, that, if, i, did, not, pay, a, certain, amount, that, legal, action, would, be, taken, he, hassled, me, to, ask, family, members, for, money, i, told, him, not, to, call, my, parents, as, i, have, not, lived, with, them, for, years, and, they, would, ...]\n3                                                        [this, individual, has, called, me, almost, every, single, day, in, regards, to, credit, card, debt, that, i, have, been, unable, to, pay, due, to, unemployment, he, leaves, numerous, messages, he, has, called, my, parents, my, brother, and, most, likely, other, individuals, that, share, my, last, name, i, called, him, today, and, he, threatened, me, by, saying, that, if, i, did, not, pay, a, certain, amount, that, legal, action, would, be, taken, he, hassled, me, to, ask, family, members, for, money, i, told, him, not, to, call, my, parents, as, i, have, not, lived, with, them, for, xxxx, years, and, they, ...]\n4    [in, xx, xx, xxxx, while, discussing, an, unrelated, business, mater, with, a, current, lender, i, was, made, aware, that, an, account, i, did, not, authorize, or, initiate, had, me, listed, as, a, cosigner, i, immediately, notified, the, lender, that, i, was, a, victim, of, identity, fraud, and, requested, to, see, the, information, they, had, on, file, in, turn, i, checked, my, credit, reports, confirmed, the, presence, of, the, fraudulent, account, and, contacted, each, of, the, xxxx, xxxx, credit, reporting, companies, and, disputed, the, information, at, varying, dates, in, xx, xx, xxxx, each, of, the, credit, reporting, companies, crcs, reported, that, ...]\nName: consumer_complaint_narrative, dtype: object\n</pre> In\u00a0[325]: Copied! <pre>nltk.download('stopwords')\nnltk.download('wordnet')\n\nstop_words = set(stopwords.words('english'))\nstop_words.remove('not')\n\ndef stopwords_remove(inputs):\n    return [k for k in inputs if k not in stop_words]\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(stopwords_remove)\ndata['consumer_complaint_narrative'].head()\n</pre> nltk.download('stopwords') nltk.download('wordnet')  stop_words = set(stopwords.words('english')) stop_words.remove('not')  def stopwords_remove(inputs):     return [k for k in inputs if k not in stop_words]  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(stopwords_remove) data['consumer_complaint_narrative'].head() <pre>[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/victorouledi/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/victorouledi/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n</pre> Out[325]: <pre>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [received, services, healthcare, provider, xxxx, years, ago, recently, got, call, collection, agency, said, debt, not, paid, healthcare, provider, agreement, take, care, billing, somehow, name, thrown, mix, healthcare, agency, not, respond, inquiries, debt, collection, agency, inquiries, debt, possibility, ruining, credit]\n1                                                                                                                                                      [xxxx, requested, free, annual, credit, report, viewing, credit, report, noticed, xxxx, credit, loan, inquiries, account, not, authorized, contacted, company, told, not, account, open, information, explained, hard, inquiry, credit, report, need, removed, soon, possible, could, apply, home, told, inquiries, would, removed, credit, report, xxxx, xxxx, xxxx, none, inquiries, removed, dating, back, xxxx, initial, fraud, alert, placed, report, xxxx, xxxx, credit, reports, pulled, information, contacted, company, action, taken, place, want, inquiries, removed, scores, credit, not, impacted, longer, would, like, purchase, house, inquires, removed, not, approved, xxxx, inquires, credit, report]\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                  [individual, called, almost, every, single, day, regards, credit, card, debt, unable, pay, due, unemployment, leaves, numerous, messages, called, parents, brother, likely, individuals, share, last, name, called, today, threatened, saying, not, pay, certain, amount, legal, action, would, taken, hassled, ask, family, members, money, told, not, call, parents, not, lived, years, would, not, paying, debt, behalf]\n3                                                                                                                                                                                                                                                                                                                                                                                                                                            [individual, called, almost, every, single, day, regards, credit, card, debt, unable, pay, due, unemployment, leaves, numerous, messages, called, parents, brother, likely, individuals, share, last, name, called, today, threatened, saying, not, pay, certain, amount, legal, action, would, taken, hassled, ask, family, members, money, told, not, call, parents, not, lived, xxxx, years, would, not, paying, debt, behalf]\n4    [xx, xx, xxxx, discussing, unrelated, business, mater, current, lender, made, aware, account, not, authorize, initiate, listed, cosigner, immediately, notified, lender, victim, identity, fraud, requested, see, information, file, turn, checked, credit, reports, confirmed, presence, fraudulent, account, contacted, xxxx, xxxx, credit, reporting, companies, disputed, information, varying, dates, xx, xx, xxxx, credit, reporting, companies, crcs, reported, account, confirmed, lender, date, fraudulent, information, remains, credit, file, neither, crc, ever, notated, credit, profile, account, disputed, several, additional, telephonic, requests, lender, xx, xx, xxxx, xx, xx, xxxx, lender, mailed, copy, loan, origination, documents, along, internal, id, theft, package, immediately, filed, law, enforcement, report, ler, local, sheriff, ...]\nName: consumer_complaint_narrative, dtype: object</pre> In\u00a0[326]: Copied! <pre>def word_length_filter(inputs):\n    return [j for j in inputs if len(j) &gt; 2]\n\ndata['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(word_length_filter)\ndata['consumer_complaint_narrative'].head()\n</pre> def word_length_filter(inputs):     return [j for j in inputs if len(j) &gt; 2]  data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(word_length_filter) data['consumer_complaint_narrative'].head()  Out[326]: <pre>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [received, services, healthcare, provider, xxxx, years, ago, recently, got, call, collection, agency, said, debt, not, paid, healthcare, provider, agreement, take, care, billing, somehow, name, thrown, mix, healthcare, agency, not, respond, inquiries, debt, collection, agency, inquiries, debt, possibility, ruining, credit]\n1                                                                                                                                                                                                      [xxxx, requested, free, annual, credit, report, viewing, credit, report, noticed, xxxx, credit, loan, inquiries, account, not, authorized, contacted, company, told, not, account, open, information, explained, hard, inquiry, credit, report, need, removed, soon, possible, could, apply, home, told, inquiries, would, removed, credit, report, xxxx, xxxx, xxxx, none, inquiries, removed, dating, back, xxxx, initial, fraud, alert, placed, report, xxxx, xxxx, credit, reports, pulled, information, contacted, company, action, taken, place, want, inquiries, removed, scores, credit, not, impacted, longer, would, like, purchase, house, inquires, removed, not, approved, xxxx, inquires, credit, report]\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [individual, called, almost, every, single, day, regards, credit, card, debt, unable, pay, due, unemployment, leaves, numerous, messages, called, parents, brother, likely, individuals, share, last, name, called, today, threatened, saying, not, pay, certain, amount, legal, action, would, taken, hassled, ask, family, members, money, told, not, call, parents, not, lived, years, would, not, paying, debt, behalf]\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [individual, called, almost, every, single, day, regards, credit, card, debt, unable, pay, due, unemployment, leaves, numerous, messages, called, parents, brother, likely, individuals, share, last, name, called, today, threatened, saying, not, pay, certain, amount, legal, action, would, taken, hassled, ask, family, members, money, told, not, call, parents, not, lived, xxxx, years, would, not, paying, debt, behalf]\n4    [xxxx, discussing, unrelated, business, mater, current, lender, made, aware, account, not, authorize, initiate, listed, cosigner, immediately, notified, lender, victim, identity, fraud, requested, see, information, file, turn, checked, credit, reports, confirmed, presence, fraudulent, account, contacted, xxxx, xxxx, credit, reporting, companies, disputed, information, varying, dates, xxxx, credit, reporting, companies, crcs, reported, account, confirmed, lender, date, fraudulent, information, remains, credit, file, neither, crc, ever, notated, credit, profile, account, disputed, several, additional, telephonic, requests, lender, xxxx, xxxx, lender, mailed, copy, loan, origination, documents, along, internal, theft, package, immediately, filed, law, enforcement, report, ler, local, sheriff, xxxx, office, returned, original, package, supporting, documentation, lender, xxxx, ...]\nName: consumer_complaint_narrative, dtype: object</pre> In\u00a0[327]: Copied! <pre>data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].str.join(' ')\ndata['consumer_complaint_narrative'].head()\n</pre> data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].str.join(' ') data['consumer_complaint_narrative'].head() Out[327]: <pre>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           received services healthcare provider xxxx years ago recently got call collection agency said debt not paid healthcare provider agreement take care billing somehow name thrown mix healthcare agency not respond inquiries debt collection agency inquiries debt possibility ruining credit\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        xxxx requested free annual credit report viewing credit report noticed xxxx credit loan inquiries account not authorized contacted company told not account open information explained hard inquiry credit report need removed soon possible could apply home told inquiries would removed credit report xxxx xxxx xxxx none inquiries removed dating back xxxx initial fraud alert placed report xxxx xxxx credit reports pulled information contacted company action taken place want inquiries removed scores credit not impacted longer would like purchase house inquires removed not approved xxxx inquires credit report\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   individual called almost every single day regards credit card debt unable pay due unemployment leaves numerous messages called parents brother likely individuals share last name called today threatened saying not pay certain amount legal action would taken hassled ask family members money told not call parents not lived years would not paying debt behalf\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              individual called almost every single day regards credit card debt unable pay due unemployment leaves numerous messages called parents brother likely individuals share last name called today threatened saying not pay certain amount legal action would taken hassled ask family members money told not call parents not lived xxxx years would not paying debt behalf\n4    xxxx discussing unrelated business mater current lender made aware account not authorize initiate listed cosigner immediately notified lender victim identity fraud requested see information file turn checked credit reports confirmed presence fraudulent account contacted xxxx xxxx credit reporting companies disputed information varying dates xxxx credit reporting companies crcs reported account confirmed lender date fraudulent information remains credit file neither crc ever notated credit profile account disputed several additional telephonic requests lender xxxx xxxx lender mailed copy loan origination documents along internal theft package immediately filed law enforcement report ler local sheriff xxxx office returned original package supporting documentation lender xxxx supporting documentation included copy lender loan origination document ler drivers license social security card hand writing samples xxxx notified potential employer deemed unsuitable due presence delinquent financial information credit report notification provided copy combined credit report still contained fraudulent account crc reports began researching laws learned fcra ftc learning combination ler ftc identity theft affidavit ita produce identity theft report idr filed ita ftc website turn sent via certified mail ftc crc template letters supporting documentation xxxx credit reporting companies requesting fraudulent account blocked removed extended fraud alert placed credit file per fcra supporting documentation submission ftc crc template letter included copy lender loan origination document credit report drivers license social security card hand writing samples well fcra section according xxxx tracking crcs received certified letters xxxx xxxx xxxx respectively date crc placed extended fraud alert not blocked fraudulent account information respective credit profile contacted declining request block fraudulent information fact xxxx crc not allow order credit report directly advised via telephone idr not sufficient would not provide justification method making determination subsequently respectively ordered additional credit reports indicate crc non compliance fcra imposed time limits credit xxxx crcs listed fraudulent account disputed investigation additionally sent xxxx time via certified mail ftc lender template letter supporting documentation lender requesting lender block absolve responsibility stop inaccurately furnishing fraudulent account information crcs supporting documentation submission ftc lender template letter included copy lender loan origination document theft affidavit idr credit report drivers license social security card hand writing samples well ftc notice furnishers according xxxx tracking lender received certified letter xxxx date lender not made contact xxxx ftc xxxx xxxx\nName: consumer_complaint_narrative, dtype: object</pre> In\u00a0[328]: Copied! <pre>text = data['consumer_complaint_narrative'].tolist()\ntokenizer_obj = Tokenizer()\ntokenizer_obj.fit_on_texts(text)\n\nsequences = tokenizer_obj.texts_to_sequences(text)\nword_index = tokenizer_obj.word_index\n\nnum_words = len(word_index) + 1\nprint(num_words)\n</pre> text = data['consumer_complaint_narrative'].tolist() tokenizer_obj = Tokenizer() tokenizer_obj.fit_on_texts(text)  sequences = tokenizer_obj.texts_to_sequences(text) word_index = tokenizer_obj.word_index  num_words = len(word_index) + 1 print(num_words) <pre>27204\n</pre> In\u00a0[329]: Copied! <pre>max_sequence_length = max(len(encoded_text) for encoded_text in sequences)\npad = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post')\nmax_sequence_length\n</pre> max_sequence_length = max(len(encoded_text) for encoded_text in sequences) pad = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post') max_sequence_length Out[329]: <pre>544</pre> In\u00a0[330]: Copied! <pre>X = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post')\nprint(X[0])\n</pre> X = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post') print(X[0]) <pre>[  11  117 2890  792    1   34  164  284  123   16    9   29   27    4\n    2   22 2890  792  264  108  341  346 1219   32 3669 3852 2890   29\n    2  405  283    4    9   29  283    4 3045 1714    3    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0]\n</pre> In\u00a0[331]: Copied! <pre>non_zero_sequence = [token for token in X[0] if token != 0]\ntokenizer_obj.sequences_to_texts([non_zero_sequence])\n</pre> non_zero_sequence = [token for token in X[0] if token != 0] tokenizer_obj.sequences_to_texts([non_zero_sequence]) Out[331]: <pre>['received services healthcare provider xxxx years ago recently got call collection agency said debt not paid healthcare provider agreement take care billing somehow name thrown mix healthcare agency not respond inquiries debt collection agency inquiries debt possibility ruining credit']</pre> In\u00a0[332]: Copied! <pre>print('Found %s unique tokens.' % len(word_index))\nprint(X.shape)\nprint(X)\n</pre> print('Found %s unique tokens.' % len(word_index)) print(X.shape) print(X) <pre>Found 27203 unique tokens.\n(32878, 544)\n[[  11  117 2890 ...    0    0    0]\n [   1   91  324 ...    0    0    0]\n [ 701   14  477 ...    0    0    0]\n ...\n [   1    1   21 ...    0    0    0]\n [1605  218   17 ...    0    0    0]\n [ 162   72  674 ...    0    0    0]]\n</pre> In\u00a0[333]: Copied! <pre>X = pad\nX = pad_sequences(X, maxlen=max_sequence_length)\nprint(X[0])\n</pre> X = pad X = pad_sequences(X, maxlen=max_sequence_length) print(X[0]) <pre>[  11  117 2890  792    1   34  164  284  123   16    9   29   27    4\n    2   22 2890  792  264  108  341  346 1219   32 3669 3852 2890   29\n    2  405  283    4    9   29  283    4 3045 1714    3    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0]\n</pre> In\u00a0[\u00a0]: Copied! <pre>product_list = list(data['product'].unique())\nprint(product_list)\nlabels = []\n\nfor i in data['product']:\n    labels.append(product_list.index(i))\nprint(labels)\n\ny = np.array(labels)\n</pre> product_list = list(data['product'].unique()) print(product_list) labels = []  for i in data['product']:     labels.append(product_list.index(i)) print(labels)  y = np.array(labels) <p>Nous avions choisi d\u2019utiliser spaCy pour le traitement de texte en raison de ses performances \u00e9lev\u00e9e et de sa simplicit\u00e9 d\u2019utilisation. Cette biblioth\u00e8que open-source, \u00e9crite en Python et Cython, est con\u00e7ue pour des applications industrielles et offre une API intuitive qui facilite la cr\u00e9ation de pipelines NLP efficaces. Cependant cette tok\u00e9nisation est tr\u00e8s couteuses en ressources de calculs et nous avons r\u00e9ussi \u00e0 l'utiliser uniquement sur Google Colab apr\u00e8s avoir achet\u00e9 des ressources</p> <p>Elle prend en charge des t\u00e2ches comme :</p> <ul> <li>la tokenisation</li> <li>la lemmatisation</li> <li>l\u2019analyse morphosyntaxique</li> <li>la reconnaissance d\u2019entit\u00e9s nomm\u00e9es</li> <li>et bien plus encore.</li> </ul> <p>SpaCy int\u00e8gre \u00e9galement des mod\u00e8les pr\u00e9-entra\u00een\u00e9s pour plus de 70 langues, permettant une utilisation rapide sans phase d'entra\u00eenement.</p> <p>C\u2019est aujourd\u2019hui l\u2019une des biblioth\u00e8ques de r\u00e9f\u00e9rence en traitement automatique du langage naturel (TALN).</p> <p>\ud83d\udd17 Pour en savoir plus : https://spacy.io, https://it.wikipedia.org/wiki/SpaCy</p> <p>Pourquoi ? La tokenisation via spaCy segmente chaque r\u00e9cit en \u201cjetons\u201d (tokens) selon les r\u00e8gles linguistiques, bien plus robuste qu\u2019un simple .split(). Le comptage de ces tokens montre la proportion de texte retenu apr\u00e8s cette premi\u00e8re phase de segmentation.</p> <p>Afin d'acc\u00e9l\u00e9rer le traitement avec spaCy, nous avons d\u00e9fini n_process=4 pour activer le traitement parall\u00e8le sur 4 processus, et batch_size=2000 pour grouper les textes \u00e0 traiter en lots. Cela permet de r\u00e9duire le temps de calcul sur des jeux de donn\u00e9es volumineux.</p> <p>Initialement, l'ex\u00e9cution sur Colab avec uniquement le processeur activ\u00e9 s\u2019est r\u00e9v\u00e9l\u00e9e tr\u00e8s lente (plus de 6 heures sans r\u00e9sultat). Pour \u00e9viter cela, nous avons achet\u00e9 des unit\u00e9s Colab et activ\u00e9 le GPU A100, ce qui a permis d'ex\u00e9cuter les cellules de traitement en quelques minutes.</p> In\u00a0[\u00a0]: Copied! <pre># # Charge une instance spaCy (tokenisation, lemmatisation, stop-words\u2026)\n# nlp = spacy.load(\"en_core_web_sm\")\n\n# def full_preprocess_stats(data):\n#     \"\"\"\n#     Encha\u00eene toutes les \u00e9tapes de nettoyage et de calcul de statistiques\n#     pour chaque r\u00e9cit de plainte. Retourne un DataFrame pandas `df_stats`\n#     contenant, pour chaque ligne :\n#       - le texte original et les longueurs apr\u00e8s chaque nettoyage\n#       - le nombre de tokens apr\u00e8s tokenisation, punctuation, lemmatisation, stop-words\n#       - le CleanText final\n#     \"\"\"\n#     # 1) Passage \u00e0 pandas et r\u00e9cup\u00e9ration des textes\n#     df_pd = data.to_pandas()\n#     texts = df_pd[\"narrative\"]\n\n#     # 2) Initial : longueur brute\n#     df_stats = pd.DataFrame({\n#         \"Text\": texts,\n#         \"Initial\": texts.str.len()\n#     })\n\n#     # 3) Suppression des URLs\n#     texts = texts.apply(lambda t: re.sub(r'https?://\\S+|www\\.\\S+', '', t))\n#     df_stats[\"No_URLs\"] = texts.str.len()\n\n#     # 4) Suppression du HTML / entit\u00e9s\n#     texts = texts.apply(lambda t: re.sub(r'&lt;.*?&gt;|&amp;[a-z0-9#]{1,6};', '', t))\n#     df_stats[\"No_HTML\"] = texts.str.len()\n\n#     # 5) Suppression des nombres (dates, montants, num\u00e9ros\u2026)\n#     texts = texts.apply(lambda t: re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '', t))\n#     df_stats[\"No_Numbers\"] = texts.str.len()\n\n#     # 6) Suppression des placeholders \u00ab XX \u00bb, \u00ab XXX \u00bb, \u00ab XXXX \u00bb\u2026\n#     texts = texts.apply(lambda t: re.sub(r'\\b[Xx]{2,}\\b', ' ', t))\n#     df_stats[\"No_Placeholders\"] = texts.str.len()\n\n#     # 7) Tokenization spaCy\n#     docs = list(nlp.pipe(texts, n_process=4, batch_size=2000))\n#     df_stats[\"Tokenization\"] = [len(doc) for doc in docs]\n\n#     # 8) Minuscules + alpha-only\n#     lower_tok = [[token.text.lower() for token in doc] for doc in docs]\n#     alpha_tok = [[tok for tok in seq if tok.isalpha()] for seq in lower_tok]\n#     df_stats[\"Punctuation\"] = [len(seq) for seq in alpha_tok]\n\n#     # 9) Lemmatisation\n#     lemma = [[token.lemma_.lower() for token in doc if token.is_alpha] for doc in docs]\n#     df_stats[\"Lemmatization\"] = [len(set(l)) for l in lemma]\n\n#     # 10) Suppression des stop-words\n#     filtered = [\n#         [tok for tok in lemma[i] if (tok == \"not\") or (not nlp.vocab[tok].is_stop)]\n#         for i in range(len(lemma))\n#     ]\n#     df_stats[\"Stopwords\"] = [len(set(f)) for f in filtered]\n\n#     # 11) Reconstruction finale\n#     df_stats[\"CleanText\"] = [\" \".join(f) for f in filtered]\n\n#     return df_stats\n\n# # \u2500\u2500\u2500 Exemple d\u2019utilisation \u2500\u2500\u2500\n# df_stats = full_preprocess_stats(data)\n# # Affichage de la \u00ab grande table \u00bb avec toutes les \u00e9tapes\n# df_stats.head(10)  # ou df_stats pour tout le DataFrame\n</pre> # # Charge une instance spaCy (tokenisation, lemmatisation, stop-words\u2026) # nlp = spacy.load(\"en_core_web_sm\")  # def full_preprocess_stats(data): #     \"\"\" #     Encha\u00eene toutes les \u00e9tapes de nettoyage et de calcul de statistiques #     pour chaque r\u00e9cit de plainte. Retourne un DataFrame pandas `df_stats` #     contenant, pour chaque ligne : #       - le texte original et les longueurs apr\u00e8s chaque nettoyage #       - le nombre de tokens apr\u00e8s tokenisation, punctuation, lemmatisation, stop-words #       - le CleanText final #     \"\"\" #     # 1) Passage \u00e0 pandas et r\u00e9cup\u00e9ration des textes #     df_pd = data.to_pandas() #     texts = df_pd[\"narrative\"]  #     # 2) Initial : longueur brute #     df_stats = pd.DataFrame({ #         \"Text\": texts, #         \"Initial\": texts.str.len() #     })  #     # 3) Suppression des URLs #     texts = texts.apply(lambda t: re.sub(r'https?://\\S+|www\\.\\S+', '', t)) #     df_stats[\"No_URLs\"] = texts.str.len()  #     # 4) Suppression du HTML / entit\u00e9s #     texts = texts.apply(lambda t: re.sub(r'&lt;.*?&gt;|&amp;[a-z0-9#]{1,6};', '', t)) #     df_stats[\"No_HTML\"] = texts.str.len()  #     # 5) Suppression des nombres (dates, montants, num\u00e9ros\u2026) #     texts = texts.apply(lambda t: re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '', t)) #     df_stats[\"No_Numbers\"] = texts.str.len()  #     # 6) Suppression des placeholders \u00ab XX \u00bb, \u00ab XXX \u00bb, \u00ab XXXX \u00bb\u2026 #     texts = texts.apply(lambda t: re.sub(r'\\b[Xx]{2,}\\b', ' ', t)) #     df_stats[\"No_Placeholders\"] = texts.str.len()  #     # 7) Tokenization spaCy #     docs = list(nlp.pipe(texts, n_process=4, batch_size=2000)) #     df_stats[\"Tokenization\"] = [len(doc) for doc in docs]  #     # 8) Minuscules + alpha-only #     lower_tok = [[token.text.lower() for token in doc] for doc in docs] #     alpha_tok = [[tok for tok in seq if tok.isalpha()] for seq in lower_tok] #     df_stats[\"Punctuation\"] = [len(seq) for seq in alpha_tok]  #     # 9) Lemmatisation #     lemma = [[token.lemma_.lower() for token in doc if token.is_alpha] for doc in docs] #     df_stats[\"Lemmatization\"] = [len(set(l)) for l in lemma]  #     # 10) Suppression des stop-words #     filtered = [ #         [tok for tok in lemma[i] if (tok == \"not\") or (not nlp.vocab[tok].is_stop)] #         for i in range(len(lemma)) #     ] #     df_stats[\"Stopwords\"] = [len(set(f)) for f in filtered]  #     # 11) Reconstruction finale #     df_stats[\"CleanText\"] = [\" \".join(f) for f in filtered]  #     return df_stats  # # \u2500\u2500\u2500 Exemple d\u2019utilisation \u2500\u2500\u2500 # df_stats = full_preprocess_stats(data) # # Affichage de la \u00ab grande table \u00bb avec toutes les \u00e9tapes # df_stats.head(10)  # ou df_stats pour tout le DataFrame  <p>Pourquoi cet encha\u00eenement ? Ce pipeline garantit qu\u2019on :</p> <p>Segmente d\u2019abord le texte en jetons fiables (spaCy).</p> <p>Normalise (minuscules, forme canonique) et r\u00e9duit le vocabulaire (alpha-only, suppression stop-words).</p> <p>Suit l\u2019impact de chaque \u00e9tape sur le volume de donn\u00e9es textuelles.</p> <p></p> <p>Voila l'\u00e9volution de l'input suite aux transformations r\u00e9alis\u00e9es pour les mettres sous la forme attendue pour un LSTM</p> In\u00a0[\u00a0]: Copied! <pre># 1) D\u00e9coupe initiale en temp/test (80/20)\nX_temp, X_test, y_temp, y_test = train_test_split(\n    X, y,\n    test_size=0.20,\n    random_state=41,\n    stratify=y\n)\n\n# 2) D\u00e9coupe de temp en train/val (75/25 de 80 \u2192 60/20 globalement)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp,\n    test_size=0.25,   # 0.25 * 0.8 = 0.20\n    random_state=41,\n    stratify=y_temp\n)\n\n# 3) Conversion en liste de cha\u00eenes (n\u00e9cessaire pour le Tokenizer)\nX_train = [str(x) for x in X_train]\nX_val   = [str(x) for x in X_val]\nX_test  = [str(x) for x in X_test]\n\n# 4) Instanciation &amp; fit du Tokenizer UNIQUEMENT sur le train\ntokenizer = Tokenizer(num_words=num_words, oov_token='&lt;OOV&gt;')\ntokenizer.fit_on_texts(X_train)\n\n# 5) Passage en s\u00e9quences tokenis\u00e9es\ntokenized_train = tokenizer.texts_to_sequences(X_train)\ntokenized_val   = tokenizer.texts_to_sequences(X_val)\ntokenized_test  = tokenizer.texts_to_sequences(X_test)\n</pre> # 1) D\u00e9coupe initiale en temp/test (80/20) X_temp, X_test, y_temp, y_test = train_test_split(     X, y,     test_size=0.20,     random_state=41,     stratify=y )  # 2) D\u00e9coupe de temp en train/val (75/25 de 80 \u2192 60/20 globalement) X_train, X_val, y_train, y_val = train_test_split(     X_temp, y_temp,     test_size=0.25,   # 0.25 * 0.8 = 0.20     random_state=41,     stratify=y_temp )  # 3) Conversion en liste de cha\u00eenes (n\u00e9cessaire pour le Tokenizer) X_train = [str(x) for x in X_train] X_val   = [str(x) for x in X_val] X_test  = [str(x) for x in X_test]  # 4) Instanciation &amp; fit du Tokenizer UNIQUEMENT sur le train tokenizer = Tokenizer(num_words=num_words, oov_token='') tokenizer.fit_on_texts(X_train)  # 5) Passage en s\u00e9quences tokenis\u00e9es tokenized_train = tokenizer.texts_to_sequences(X_train) tokenized_val   = tokenizer.texts_to_sequences(X_val) tokenized_test  = tokenizer.texts_to_sequences(X_test) In\u00a0[338]: Copied! <pre>from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\n# 1) D\u00e9finir X et y \u00e0 partir de votre colonne nettoy\u00e9e\nX = data['consumer_complaint_narrative'].astype(str).tolist()\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(data['product'])\n\n# 2) S\u00e9paration initiale train_temp / test_final (80/20)\nX_temp, X_test, y_temp, y_test = train_test_split(\n    X, y,\n    test_size=0.20,\n    random_state=41,\n    stratify=y\n)\n\n# 3) S\u00e9paration train / val \u00e0 partir de train_temp (75/25 de 80 \u2192 60/20 global)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp,\n    test_size=0.25,   # 0.25 * 0.8 = 0.20\n    random_state=41,\n    stratify=y_temp\n)\n\n# 4) Instanciation &amp; fit du Tokenizer UNIQUEMENT sur le train\nnum_words = len(tokenizer.word_index) + 1\ntokenizer = Tokenizer(num_words=num_words, oov_token='&lt;OOV&gt;')\ntokenizer.fit_on_texts(X_train)\n\n# 5) Passage en s\u00e9quences pour train, val et test\nseq_train = tokenizer.texts_to_sequences(X_train)\nseq_val   = tokenizer.texts_to_sequences(X_val)\nseq_test  = tokenizer.texts_to_sequences(X_test)\n\n# 6) Padding des trois jeux avec la m\u00eame longueur maxlen\nmaxlen = max_sequence_length  # ou la longueur que vous avez d\u00e9finie\npadded_train = pad_sequences(seq_train, maxlen=maxlen, padding='pre')\npadded_val   = pad_sequences(seq_val,   maxlen=maxlen, padding='pre')\npadded_test  = pad_sequences(seq_test,  maxlen=maxlen, padding='pre')\n\n# 7) Contr\u00f4le visuel rapide\nprint(\"Exemple brut (train) :\", X_train[0])\nprint(\"Exemple tokenis\u00e9     :\", seq_train[0])\nprint(\"Formes :\",\n      f\"train {padded_train.shape},\",\n      f\"val {padded_val.shape},\",\n      f\"test {padded_test.shape}\")\n</pre> from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import train_test_split from tensorflow.keras.preprocessing.text import Tokenizer  # 1) D\u00e9finir X et y \u00e0 partir de votre colonne nettoy\u00e9e X = data['consumer_complaint_narrative'].astype(str).tolist() label_encoder = LabelEncoder() y = label_encoder.fit_transform(data['product'])  # 2) S\u00e9paration initiale train_temp / test_final (80/20) X_temp, X_test, y_temp, y_test = train_test_split(     X, y,     test_size=0.20,     random_state=41,     stratify=y )  # 3) S\u00e9paration train / val \u00e0 partir de train_temp (75/25 de 80 \u2192 60/20 global) X_train, X_val, y_train, y_val = train_test_split(     X_temp, y_temp,     test_size=0.25,   # 0.25 * 0.8 = 0.20     random_state=41,     stratify=y_temp )  # 4) Instanciation &amp; fit du Tokenizer UNIQUEMENT sur le train num_words = len(tokenizer.word_index) + 1 tokenizer = Tokenizer(num_words=num_words, oov_token='') tokenizer.fit_on_texts(X_train)  # 5) Passage en s\u00e9quences pour train, val et test seq_train = tokenizer.texts_to_sequences(X_train) seq_val   = tokenizer.texts_to_sequences(X_val) seq_test  = tokenizer.texts_to_sequences(X_test)  # 6) Padding des trois jeux avec la m\u00eame longueur maxlen maxlen = max_sequence_length  # ou la longueur que vous avez d\u00e9finie padded_train = pad_sequences(seq_train, maxlen=maxlen, padding='pre') padded_val   = pad_sequences(seq_val,   maxlen=maxlen, padding='pre') padded_test  = pad_sequences(seq_test,  maxlen=maxlen, padding='pre')  # 7) Contr\u00f4le visuel rapide print(\"Exemple brut (train) :\", X_train[0]) print(\"Exemple tokenis\u00e9     :\", seq_train[0]) print(\"Formes :\",       f\"train {padded_train.shape},\",       f\"val {padded_val.shape},\",       f\"test {padded_test.shape}\") <pre>Exemple brut (train) : submitted information equifax several times proving debt dismissed not reported open ongoing collection account refused change credit report xxxx xxxx removed account show collections reports equifax not done xxxx\nExemple tokenis\u00e9     : [268, 8, 41, 81, 55, 1239, 5, 857, 3, 61, 233, 1696, 10, 6, 161, 457, 4, 7, 2, 2, 51, 6, 236, 105, 87, 41, 3, 215, 2]\nFormes : train (19726, 544), val (6576, 544), test (6576, 544)\n</pre> In\u00a0[339]: Copied! <pre># 1) Afficher les noms de classe associ\u00e9s \u00e0 chaque entier\nprint(\"Mapping index \u2192 classe :\")\nfor idx, name in enumerate(label_encoder.classes_):\n    print(f\"  {idx} \u2192 {name}\")\n\n# 2) Compter les exemples par classe\ncounts = pd.Series(y_train).value_counts().sort_index()\nprint(\"\\nNombre d'exemples par classe :\")\nfor idx, cnt in counts.items():\n    print(f\"  Classe {idx} ({label_encoder.classes_[idx]}): {cnt} exemples\")\n</pre>  # 1) Afficher les noms de classe associ\u00e9s \u00e0 chaque entier print(\"Mapping index \u2192 classe :\") for idx, name in enumerate(label_encoder.classes_):     print(f\"  {idx} \u2192 {name}\")  # 2) Compter les exemples par classe counts = pd.Series(y_train).value_counts().sort_index() print(\"\\nNombre d'exemples par classe :\") for idx, cnt in counts.items():     print(f\"  Classe {idx} ({label_encoder.classes_[idx]}): {cnt} exemples\") <pre>Mapping index \u2192 classe :\n  0 \u2192 Credit reporting\n  1 \u2192 Debt collection\n  2 \u2192 Payday loan\n  3 \u2192 Student loan\n\nNombre d'exemples par classe :\n  Classe 0 (Credit reporting): 7504 exemples\n  Classe 1 (Debt collection): 10516 exemples\n  Classe 2 (Payday loan): 434 exemples\n  Classe 3 (Student loan): 1272 exemples\n</pre> In\u00a0[369]: Copied! <pre>maxlen = max_sequence_length\npadded_train = pad_sequences(tokenized_train, maxlen=maxlen, padding='pre')\npadded_val   = pad_sequences(tokenized_val,   maxlen=maxlen, padding='pre')\n\nembed_dim = 200 \nlstm_out  = 64\nn_classes = len(label_encoder.classes_)  # ici 3\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=num_words, \n                    output_dim=embed_dim, \n                    input_length=maxlen))\nmodel.add(Dropout(0.4))\n\nmodel.add(Bidirectional(LSTM(\n    lstm_out, \n    return_sequences=True,  \n    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n    recurrent_regularizer=tf.keras.regularizers.l2(0.01)\n)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Bidirectional(LSTM(\n    lstm_out, \n    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n    recurrent_regularizer=tf.keras.regularizers.l2(0.01)\n)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Couche de sortie adapt\u00e9e au multi\u2010classes exclusif\nmodel.add(Dense(n_classes, activation='softmax'))\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\nmodel.compile(\n    loss='sparse_categorical_crossentropy',  # pour des labels entiers 0,1,2\n    optimizer=optimizer, \n    metrics=['accuracy']\n)\n\nearly_stopping = EarlyStopping(\n    patience=3, \n    restore_best_weights=True\n)\n\n# Build explicite pour voir correctement les param\u00e8tres\nmodel.build(input_shape=(None, maxlen))\nmodel.summary()\n</pre> maxlen = max_sequence_length padded_train = pad_sequences(tokenized_train, maxlen=maxlen, padding='pre') padded_val   = pad_sequences(tokenized_val,   maxlen=maxlen, padding='pre')  embed_dim = 200  lstm_out  = 64 n_classes = len(label_encoder.classes_)  # ici 3  model = Sequential() model.add(Embedding(input_dim=num_words,                      output_dim=embed_dim,                      input_length=maxlen)) model.add(Dropout(0.4))  model.add(Bidirectional(LSTM(     lstm_out,      return_sequences=True,       kernel_regularizer=tf.keras.regularizers.l2(0.01),     recurrent_regularizer=tf.keras.regularizers.l2(0.01) ))) model.add(Dropout(0.4))  model.add(Bidirectional(LSTM(     lstm_out,      kernel_regularizer=tf.keras.regularizers.l2(0.01),     recurrent_regularizer=tf.keras.regularizers.l2(0.01) ))) model.add(Dropout(0.5))  model.add(Dense(64, activation='relu')) model.add(Dropout(0.5))  # Couche de sortie adapt\u00e9e au multi\u2010classes exclusif model.add(Dense(n_classes, activation='softmax'))  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4) model.compile(     loss='sparse_categorical_crossentropy',  # pour des labels entiers 0,1,2     optimizer=optimizer,      metrics=['accuracy'] )  early_stopping = EarlyStopping(     patience=3,      restore_best_weights=True )  # Build explicite pour voir correctement les param\u00e8tres model.build(input_shape=(None, maxlen)) model.summary()  <pre>/Users/victorouledi/miniforge3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning:\n\nArgument `input_length` is deprecated. Just remove it.\n\n</pre> <pre>Model: \"sequential_7\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 embedding_7 (Embedding)         \u2502 (None, 544, 200)       \u2502     4,308,400 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_28 (Dropout)            \u2502 (None, 544, 200)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_22                \u2502 (None, 544, 128)       \u2502       135,680 \u2502\n\u2502 (Bidirectional)                 \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_29 (Dropout)            \u2502 (None, 544, 128)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_23                \u2502 (None, 128)            \u2502        98,816 \u2502\n\u2502 (Bidirectional)                 \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_30 (Dropout)            \u2502 (None, 128)            \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_14 (Dense)                \u2502 (None, 64)             \u2502         8,256 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_31 (Dropout)            \u2502 (None, 64)             \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_15 (Dense)                \u2502 (None, 4)              \u2502           260 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 4,551,412 (17.36 MB)\n</pre> <pre> Trainable params: 4,551,412 (17.36 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> In\u00a0[\u00a0]: Copied! <pre>early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n                                                  mode='auto', \n                                                  patience=3, \n                                                  restore_best_weights=True)\n\nhistory = model.fit(\n    padded_train, y_train,\n    validation_data=(padded_val, y_val),  \n    epochs=20,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n</pre> early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',                                                    mode='auto',                                                    patience=3,                                                    restore_best_weights=True)  history = model.fit(     padded_train, y_train,     validation_data=(padded_val, y_val),       epochs=20,     batch_size=32,     callbacks=[early_stopping] )  <pre>Epoch 1/20\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 299s 481ms/step - accuracy: 0.4973 - loss: 4.5394 - val_accuracy: 0.5332 - val_loss: 0.9826\nEpoch 2/20\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308s 499ms/step - accuracy: 0.5295 - loss: 0.9911 - val_accuracy: 0.5332 - val_loss: 0.9703\nEpoch 3/20\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308s 499ms/step - accuracy: 0.5331 - loss: 0.9725 - val_accuracy: 0.5332 - val_loss: 0.9646\nEpoch 4/20\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 295s 478ms/step - accuracy: 0.5366 - loss: 0.9665 - val_accuracy: 0.5332 - val_loss: 0.9658\n</pre> In\u00a0[342]: Copied! <pre>plt.figure(figsize=(10,5))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Train and Validation Loss Graphs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n</pre> plt.figure(figsize=(10,5)) plt.plot(history.history['loss'], label='Train Loss') plt.plot(history.history['val_loss'], label='Validation Loss') plt.title('Train and Validation Loss Graphs') plt.xlabel('Epochs') plt.ylabel('Loss') plt.legend() Out[342]: <pre>&lt;matplotlib.legend.Legend at 0x4294674d0&gt;</pre> In\u00a0[343]: Copied! <pre>plt.figure(figsize=(10,5))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Train and Validation Accuracy Graphs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n</pre> plt.figure(figsize=(10,5)) plt.plot(history.history['accuracy'], label='Train Accuracy') plt.plot(history.history['val_accuracy'], label='Validation Accuracy') plt.title('Train and Validation Accuracy Graphs') plt.xlabel('Epochs') plt.ylabel('Accuracy') plt.legend() Out[343]: <pre>&lt;matplotlib.legend.Legend at 0x429451fa0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># On part de X_test qui est une liste de cha\u00eenes (padding retir\u00e9)\n# Si ce n\u2019est pas d\u00e9j\u00e0 le cas, transformez-le en Series :\nX_test = pd.Series(X_test)\n\n# 1. Retirer les URLs\nX_test = X_test.apply(remove_url)\n\n# 2. Retirer les nombres\nX_test = X_test.apply(remove_number)\n\n# 3. Retirer le HTML et entit\u00e9s\nX_test = X_test.apply(remove_html)\n\n# 4. Ne garder que les lettres\nX_test = X_test.apply(remove_punctuations)\n\n# 5. Tokenisation  par d\u00e9coupage sur les espaces\nX_test = X_test.apply(simple_tokenize)\n\n# 6. Suppression des stopwords\nX_test = X_test.apply(stopwords_remove)\n\n# 7. Filtrage sur la longueur des mots\nX_test = X_test.apply(word_length_filter)\n\n# 8. On reconstitue des cha\u00eenes pour le Tokenizer Keras\nX_test = X_test.str.join(' ')\n\ntokenized_test = tokenizer.texts_to_sequences(X_test)\npadded_test = pad_sequences(tokenized_test, maxlen=maxlen, padding='pre')\n</pre> # On part de X_test qui est une liste de cha\u00eenes (padding retir\u00e9) # Si ce n\u2019est pas d\u00e9j\u00e0 le cas, transformez-le en Series : X_test = pd.Series(X_test)  # 1. Retirer les URLs X_test = X_test.apply(remove_url)  # 2. Retirer les nombres X_test = X_test.apply(remove_number)  # 3. Retirer le HTML et entit\u00e9s X_test = X_test.apply(remove_html)  # 4. Ne garder que les lettres X_test = X_test.apply(remove_punctuations)  # 5. Tokenisation  par d\u00e9coupage sur les espaces X_test = X_test.apply(simple_tokenize)  # 6. Suppression des stopwords X_test = X_test.apply(stopwords_remove)  # 7. Filtrage sur la longueur des mots X_test = X_test.apply(word_length_filter)  # 8. On reconstitue des cha\u00eenes pour le Tokenizer Keras X_test = X_test.str.join(' ')  tokenized_test = tokenizer.texts_to_sequences(X_test) padded_test = pad_sequences(tokenized_test, maxlen=maxlen, padding='pre') In\u00a0[346]: Copied! <pre>pred_test_lstm = model.predict(padded_test)\ntest_evaluate = model.evaluate(padded_test, y_test)\n</pre> pred_test_lstm = model.predict(padded_test) test_evaluate = model.evaluate(padded_test, y_test) <pre>206/206 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 21s 100ms/step\n206/206 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23s 112ms/step - accuracy: 0.5334 - loss: 0.9811\n</pre> In\u00a0[347]: Copied! <pre>from sklearn.metrics import classification_report\n\ny_pred_classes = pred_test_lstm.argmax(axis=1)\n\nreport = classification_report(\n    y_test,\n    y_pred_classes,\n    target_names=label_encoder.classes_,  \n    digits=4                             \n)\n\nprint(report)\n</pre> from sklearn.metrics import classification_report  y_pred_classes = pred_test_lstm.argmax(axis=1)  report = classification_report(     y_test,     y_pred_classes,     target_names=label_encoder.classes_,       digits=4                              )  print(report)  <pre>                  precision    recall  f1-score   support\n\nCredit reporting     0.0000    0.0000    0.0000      2501\n Debt collection     0.5332    1.0000    0.6955      3506\n     Payday loan     0.0000    0.0000    0.0000       145\n    Student loan     0.0000    0.0000    0.0000       424\n\n        accuracy                         0.5332      6576\n       macro avg     0.1333    0.2500    0.1739      6576\n    weighted avg     0.2842    0.5332    0.3708      6576\n\n</pre> <pre>/Users/victorouledi/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/victorouledi/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/victorouledi/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n\nPrecision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n</pre> In\u00a0[348]: Copied! <pre>from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# 1) Binarisation des labels (3 classes : 0,1,2)\ny_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])\n\n# 2) Aplatir les tableaux pour la micro-average\ny_true_flat  = y_test_binarized.ravel()         # vecteur de 0/1 pour chaque classe et chaque \u00e9chantillon\ny_score_flat = pred_test_lstm.ravel()           # probas correspondantes\n\n# 3) Calcul de la ROC et de l\u2019AUC micro-average\nfpr_micro, tpr_micro, _ = roc_curve(y_true_flat, y_score_flat)\nroc_auc_micro = auc(fpr_micro, tpr_micro)\n\n# 4) Trac\u00e9 de la courbe unique\nplt.figure()\nplt.plot(fpr_micro, tpr_micro, lw=2, label=f\"Micro-average ROC (AUC = {roc_auc_micro:.2f})\")\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='R\u00e9f\u00e9rence al\u00e9atoire')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Courbe ROC micro-average (toutes classes confondues)')\nplt.legend(loc='lower right')\nplt.show()\n</pre> from sklearn.metrics import roc_curve, auc from sklearn.preprocessing import label_binarize  # 1) Binarisation des labels (3 classes : 0,1,2) y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])  # 2) Aplatir les tableaux pour la micro-average y_true_flat  = y_test_binarized.ravel()         # vecteur de 0/1 pour chaque classe et chaque \u00e9chantillon y_score_flat = pred_test_lstm.ravel()           # probas correspondantes  # 3) Calcul de la ROC et de l\u2019AUC micro-average fpr_micro, tpr_micro, _ = roc_curve(y_true_flat, y_score_flat) roc_auc_micro = auc(fpr_micro, tpr_micro)  # 4) Trac\u00e9 de la courbe unique plt.figure() plt.plot(fpr_micro, tpr_micro, lw=2, label=f\"Micro-average ROC (AUC = {roc_auc_micro:.2f})\") plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='R\u00e9f\u00e9rence al\u00e9atoire') plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') plt.title('Courbe ROC micro-average (toutes classes confondues)') plt.legend(loc='lower right') plt.show()  In\u00a0[349]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# 1) Binariser vos labels de test (3 classes : 0,1,2)\ny_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])\nn_classes = y_test_binarized.shape[1]\n\n# 2) Calculer fpr, tpr, AUC pour chaque classe\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(\n        y_test_binarized[:, i],\n        pred_test_lstm[:, i]   # probabilit\u00e9 pr\u00e9dite pour la classe i\n    )\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# 3) Tracer la courbe\nplt.figure()\nfor i in range(n_classes):\n    plt.plot(\n        fpr[i],\n        tpr[i],\n        label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"\n    )\n# Diagonale de r\u00e9f\u00e9rence (classif. al\u00e9atoire)\nplt.plot([0, 1], [0, 1], linestyle='--')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve multiclasses (One-vs-Rest)')\nplt.legend(loc='lower right')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import roc_curve, auc from sklearn.preprocessing import label_binarize  # 1) Binariser vos labels de test (3 classes : 0,1,2) y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3]) n_classes = y_test_binarized.shape[1]  # 2) Calculer fpr, tpr, AUC pour chaque classe fpr = dict() tpr = dict() roc_auc = dict() for i in range(n_classes):     fpr[i], tpr[i], _ = roc_curve(         y_test_binarized[:, i],         pred_test_lstm[:, i]   # probabilit\u00e9 pr\u00e9dite pour la classe i     )     roc_auc[i] = auc(fpr[i], tpr[i])  # 3) Tracer la courbe plt.figure() for i in range(n_classes):     plt.plot(         fpr[i],         tpr[i],         label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"     ) # Diagonale de r\u00e9f\u00e9rence (classif. al\u00e9atoire) plt.plot([0, 1], [0, 1], linestyle='--')  plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') plt.title('ROC Curve multiclasses (One-vs-Rest)') plt.legend(loc='lower right') plt.show()  In\u00a0[350]: Copied! <pre>df_results = pd.DataFrame({\n    'text': X_test,                            \n    'true_label': y_test,                      \n    'pred_proba_0': pred_test_lstm[:, 0],     \n    'pred_proba_1': pred_test_lstm[:, 1],      \n    'pred_proba_2': pred_test_lstm[:, 2],     \n    'pred_proba_3': pred_test_lstm[:, 3],      \n \n})\n\ndf_results['pred_label'] = np.argmax(pred_test_lstm, axis=1)\n\ndf_results['true_label_name'] = label_encoder.inverse_transform(df_results['true_label'])\ndf_results['pred_label_name'] = label_encoder.inverse_transform(df_results['pred_label'])\n\ndf_results['pred_confidence'] = df_results.apply(\n    lambda row: row[f'pred_proba_{row.pred_label}'], axis=1\n)\ndf_results.head(10)\n</pre>  df_results = pd.DataFrame({     'text': X_test,                                 'true_label': y_test,                           'pred_proba_0': pred_test_lstm[:, 0],          'pred_proba_1': pred_test_lstm[:, 1],           'pred_proba_2': pred_test_lstm[:, 2],          'pred_proba_3': pred_test_lstm[:, 3],         })  df_results['pred_label'] = np.argmax(pred_test_lstm, axis=1)  df_results['true_label_name'] = label_encoder.inverse_transform(df_results['true_label']) df_results['pred_label_name'] = label_encoder.inverse_transform(df_results['pred_label'])  df_results['pred_confidence'] = df_results.apply(     lambda row: row[f'pred_proba_{row.pred_label}'], axis=1 ) df_results.head(10) Out[350]: text true_label pred_proba_0 pred_proba_1 pred_proba_2 pred_proba_3 pred_label true_label_name pred_label_name pred_confidence 0 xxxx xxxx xxxx received xxxx debt collection letters erc regarding xxxx debts xxxx xxxx xxxx xxxx amount xxxx amount received another collection letter erc xxxx xxxx xxxx another debt amount not owe debts already sent submitted proof xxxx last year regarding another debt 1 0.393808 0.497076 0.030616 0.078499 1 Debt collection Debt collection 0.497076 1 collection equifax credit report xxxx checking account equifax listed credit card loan checking act secondly paid xxxx told file dispute got paper work bank get hold equifax would prefer phone 0 0.392835 0.494570 0.031946 0.080649 1 Credit reporting Debt collection 0.494570 2 sent several letters midland credit management validate debt claim owe failed send proper documentation validate debt claim owe last letter sent returned back insufficient address notices address 1 0.392648 0.494133 0.032187 0.081032 1 Debt collection Debt collection 0.494133 3 debt phone service paid thru xxxx checked credit report says still owe phone bill says diversified agency take xxxx debt diversified 1 0.393358 0.496012 0.031196 0.079435 1 Debt collection Debt collection 0.496012 4 xxxx xxxx firm contacted estranged spouse never gave contact loan documents told wrote bad check attempting get contact texted contact number called knew not checks written company reason spoke agent placed male coworker line stated attorney xxxx charged fraudulent check fraudulent use closed bank account processing papers arrested within week 1 0.392860 0.494647 0.031907 0.080586 1 Debt collection Debt collection 0.494647 5 fco fair collections outsourcing calling threatening phone collection xxxx apartments xxxxcalifornia evicted xxxx daughters apartment xxxx injured xxxx xxxx xxxxcalifornia xxxx paid properly xxxx employer xxxx home xxxx xxxx respectfully permanent xxxx retired xxxx send evidence collections medical evidence consumers financial protection bureau emails xxxx stress xxxx military veteran xxxx xxxx xxxx citizen xxxxcalifornia fair collections outsourcing ruined credit xxxx not obtain consumer loan xxxx daughters college education xxxx daughters wants continue education xxxx careers credit ruined fco even sent document reduction pay xxxxi always paid rent time daughters xxxx discriminated retaliated xxxx fco collections outsourcing since xxxx till present fco collections outsourcing xxxx xxxxcalifornia xxxx staff discriminated managers xxxx longer xxxx apartments even hired attorneys collect debts evictions file complaints fco collections outsourcing xxxx apartments federal trade commission xxxx nothing done send notifications president obama congress issues xxxx xxxx 1 0.393991 0.497685 0.030319 0.078005 1 Debt collection Debt collection 0.497685 6 xxxx contacted capital collection services verify account unfamiliar receiving information unsure requested letter physical account refused send letter said sent letters back not send another today think horrible expect documentation anything could happening time 1 0.392474 0.493667 0.032434 0.081426 1 Debt collection Debt collection 0.493667 7 xxxx reporting xxxx xxxx xxxxpursuant fdcpa reporting agency required provide reporting information contact information may validate absence information must removed reporting 0 0.393007 0.494976 0.031725 0.080293 1 Credit reporting Debt collection 0.494976 8 credit bureau would not properly investigate public records not mine according state xxxx department treasury xxxx county court clerk recorder not verify information fcra deem public records valid without contacting source court stated not verify information credit bureaus sent investigation accordance fair credit reporting act section refused respond broken law letters sent certified documentation 0 0.392434 0.493564 0.032488 0.081515 1 Credit reporting Debt collection 0.493564 9 putting complaint diversified consultants reporting collection xxxx result idenity theft attempted resolve matter sent police report going attach complaint well continued try collect identity theft account 1 0.392653 0.494105 0.032195 0.081047 1 Debt collection Debt collection 0.494105 <p>Nous utilisons \u00e0 la fois du sur et du sous-\u00e9chantillonnage. En effet utiliser uniquement du sur \u00e9chantillonnage dans un contexte o\u00f9 il y a un gros d\u00e9s\u00e9quilibre de classe reviendrait \u00e0 dupliquer beaucoup de fois les valeurs des classes minoritaires ce qui engendre un risque de sur apprentissage sur les m\u00eames donn\u00e9es. Utiliser uniquement du sous \u00e9chantillonnage reviendrait \u00e0 perdre trop d'information pour une meilleure g\u00e9n\u00e9ralisation, ainsi on utilise les 2 m\u00e9thodes.</p> In\u00a0[370]: Copied! <pre>import numpy as np\nimport pandas as pd\n\n# --- a) Regrouper X_train et y_train dans un DataFrame pour r\u00e9\u00e9chantillonnage\ndf = pd.DataFrame({\n    'text': X_train,     # vos textes nettoy\u00e9s sous forme de cha\u00eenes\n    'label': y_train     # vos labels entiers 0,1,2\n})\n\n# 1. D\u00e9finir la taille cible apr\u00e8s sous-/sur-\u00e9chantillonnage\n#   On d\u00e9finit 200 exemples par classe\ntarget_size = 2000\n\n# 2. Sous-\u00e9chantillonner la classe majoritaire (0)\ndf_maj = df[df.label == 0].sample(n=target_size, random_state=42, replace=False)\ndf_maj2 = df[df.label == 1].sample(n=target_size, random_state=42, replace=False)\n\n# 3. Sur-\u00e9chantillonner les classes minoritaires (1 et 2)\ndf_min1 = df[df.label == 2].sample(n=target_size, random_state=42, replace=True)\ndf_min2 = df[df.label == 3].sample(n=target_size, random_state=42, replace=True)\n\n# 4. Concat\u00e9ner pour obtenir un DataFrame \u00e9quilibr\u00e9\ndf_balanced = pd.concat([df_maj, df_min1, df_min2, df_maj2]).sample(frac=1, random_state=42)\n\n# 5. Reconstruire X_train et y_train\nX_train_bal = df_balanced['text'].tolist()\ny_train_bal = df_balanced['label'].values\n\n# --- b) Vectorisation + padding sur le jeu r\u00e9-\u00e9quilibr\u00e9\nseq_train_bal   = tokenizer.texts_to_sequences(X_train_bal)\npadded_train_bal = pad_sequences(seq_train_bal, maxlen=maxlen, padding='pre')\n\n# padded_val et y_test restent inchang\u00e9s pour la validation\n\n# --- c) Entra\u00eenement du mod\u00e8le avec both sur-/sous-\u00e9chantillonnage \nhistory_balanced = model.fit(\n    padded_train_bal, y_train_bal,\n    validation_data=(padded_val, y_val), \n    epochs=10,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n</pre> import numpy as np import pandas as pd  # --- a) Regrouper X_train et y_train dans un DataFrame pour r\u00e9\u00e9chantillonnage df = pd.DataFrame({     'text': X_train,     # vos textes nettoy\u00e9s sous forme de cha\u00eenes     'label': y_train     # vos labels entiers 0,1,2 })  # 1. D\u00e9finir la taille cible apr\u00e8s sous-/sur-\u00e9chantillonnage #   On d\u00e9finit 200 exemples par classe target_size = 2000  # 2. Sous-\u00e9chantillonner la classe majoritaire (0) df_maj = df[df.label == 0].sample(n=target_size, random_state=42, replace=False) df_maj2 = df[df.label == 1].sample(n=target_size, random_state=42, replace=False)  # 3. Sur-\u00e9chantillonner les classes minoritaires (1 et 2) df_min1 = df[df.label == 2].sample(n=target_size, random_state=42, replace=True) df_min2 = df[df.label == 3].sample(n=target_size, random_state=42, replace=True)  # 4. Concat\u00e9ner pour obtenir un DataFrame \u00e9quilibr\u00e9 df_balanced = pd.concat([df_maj, df_min1, df_min2, df_maj2]).sample(frac=1, random_state=42)  # 5. Reconstruire X_train et y_train X_train_bal = df_balanced['text'].tolist() y_train_bal = df_balanced['label'].values  # --- b) Vectorisation + padding sur le jeu r\u00e9-\u00e9quilibr\u00e9 seq_train_bal   = tokenizer.texts_to_sequences(X_train_bal) padded_train_bal = pad_sequences(seq_train_bal, maxlen=maxlen, padding='pre')  # padded_val et y_test restent inchang\u00e9s pour la validation  # --- c) Entra\u00eenement du mod\u00e8le avec both sur-/sous-\u00e9chantillonnage  history_balanced = model.fit(     padded_train_bal, y_train_bal,     validation_data=(padded_val, y_val),      epochs=10,     batch_size=32,     callbacks=[early_stopping] )    <pre>Epoch 1/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 122s 481ms/step - accuracy: 0.2773 - loss: 7.0321 - val_accuracy: 0.3803 - val_loss: 1.3762\nEpoch 2/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129s 517ms/step - accuracy: 0.5157 - loss: 1.1242 - val_accuracy: 0.3803 - val_loss: 1.2250\nEpoch 3/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 143s 571ms/step - accuracy: 0.6975 - loss: 0.7615 - val_accuracy: 0.5312 - val_loss: 1.2214\nEpoch 4/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 144s 577ms/step - accuracy: 0.8081 - loss: 0.5773 - val_accuracy: 0.3812 - val_loss: 1.4204\nEpoch 5/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129s 518ms/step - accuracy: 0.8408 - loss: 0.5111 - val_accuracy: 0.3805 - val_loss: 3.2189\nEpoch 6/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 126s 502ms/step - accuracy: 0.8737 - loss: 0.4521 - val_accuracy: 0.3805 - val_loss: 3.2451\n</pre> In\u00a0[371]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u00e9quilibr\u00e9\npred_test_bal = model.predict(padded_test)\n\n# 2. Binarisation des labels de test\ny_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])\nn_classes = y_test_binarized.shape[1]\n\n# 3. Calcul des courbes ROC et AUC pour chaque classe\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], pred_test_bal[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# 4. Affichage\nplt.figure(figsize=(8, 6))\nfor i in range(n_classes):\n    plt.plot(\n        fpr[i], tpr[i], lw=2,\n        label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"\n    )\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='R\u00e9f\u00e9rence al\u00e9atoire')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('One-vs-Rest ROC Curve (mod\u00e8le \u00e9quilibr\u00e9 gr\u00e2ce au sur/sous echantillonnage)')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import roc_curve, auc from sklearn.preprocessing import label_binarize  # 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u00e9quilibr\u00e9 pred_test_bal = model.predict(padded_test)  # 2. Binarisation des labels de test y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3]) n_classes = y_test_binarized.shape[1]  # 3. Calcul des courbes ROC et AUC pour chaque classe fpr = dict() tpr = dict() roc_auc = dict() for i in range(n_classes):     fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], pred_test_bal[:, i])     roc_auc[i] = auc(fpr[i], tpr[i])  # 4. Affichage plt.figure(figsize=(8, 6)) for i in range(n_classes):     plt.plot(         fpr[i], tpr[i], lw=2,         label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"     ) plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='R\u00e9f\u00e9rence al\u00e9atoire') plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') plt.title('One-vs-Rest ROC Curve (mod\u00e8le \u00e9quilibr\u00e9 gr\u00e2ce au sur/sous echantillonnage)') plt.legend(loc='lower right') plt.grid(True) plt.show()  <pre>206/206 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 22s 107ms/step\n</pre> <p>La pond\u00e9ration des classes consiste \u00e0 ajuster la contribution de chaque exemple \u00e0 la fonction de perte en fonction de la fr\u00e9quence de sa classe, de fa\u00e7on \u00e0 compenser les d\u00e9s\u00e9quilibres de distribution.</p> <p>Sans pond\u00e9ration, le mod\u00e8le peut \u00ab oublier \u00bb les classes rares en se focalisant sur la classe majoritaire (qui minimise plus facilement la perte globale).Avec class_weight, on r\u00e9\u00e9quilibre virtuellement le signal de la perte pour que chaque classe, qu\u2019elle soit fr\u00e9quente ou non, influence \u00e9quitablement l\u2019optimisation.</p> In\u00a0[353]: Copied! <pre>from sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\n\n# --- c) Calcul des class weights sur le jeu r\u00e9-\u00e9quilibr\u00e9\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weight_dict = dict(enumerate(class_weights))\nprint(\"Class weights :\", class_weight_dict)\n\n\nhistory_weighted = model.fit(\n    padded_train, y_train,\n    validation_data=(padded_val, y_val),  \n    epochs=10,\n    batch_size=32,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n</pre> from sklearn.utils.class_weight import compute_class_weight from tensorflow.keras.preprocessing.sequence import pad_sequences    # --- c) Calcul des class weights sur le jeu r\u00e9-\u00e9quilibr\u00e9 class_weights = compute_class_weight(     class_weight='balanced',     classes=np.unique(y_train),     y=y_train ) class_weight_dict = dict(enumerate(class_weights)) print(\"Class weights :\", class_weight_dict)   history_weighted = model.fit(     padded_train, y_train,     validation_data=(padded_val, y_val),       epochs=10,     batch_size=32,     class_weight=class_weight_dict,     callbacks=[early_stopping] ) <pre>Class weights : {0: 0.6571828358208955, 1: 0.46895207303157094, 2: 11.362903225806452, 3: 3.8769654088050314}\nEpoch 1/10\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 4143s 7s/step - accuracy: 0.3597 - loss: 1.4579 - val_accuracy: 0.5332 - val_loss: 1.3839\nEpoch 2/10\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 313s 508ms/step - accuracy: 0.2271 - loss: 1.4347 - val_accuracy: 0.5330 - val_loss: 1.3571\nEpoch 3/10\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 643s 1s/step - accuracy: 0.4286 - loss: 1.3951 - val_accuracy: 0.3803 - val_loss: 1.3736\nEpoch 4/10\n617/617 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315s 510ms/step - accuracy: 0.2982 - loss: 1.4025 - val_accuracy: 0.5332 - val_loss: 1.3799\n</pre> In\u00a0[365]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u00e9quilibr\u00e9\npred_test_lstm = model.predict(padded_test)\n\ny_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])\nn_classes = y_test_binarized.shape[1]\n\n# 2) Calculer fpr, tpr, AUC pour chaque classe\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(\n        y_test_binarized[:, i],\n        pred_test_lstm[:, i]   # probabilit\u00e9 pr\u00e9dite pour la classe i\n    )\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# 3) Tracer la courbe\nplt.figure()\nfor i in range(n_classes):\n    plt.plot(\n        fpr[i],\n        tpr[i],\n        label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"\n    )\n# Diagonale de r\u00e9f\u00e9rence (classif. al\u00e9atoire)\nplt.plot([0, 1], [0, 1], linestyle='--')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve multiclasses (One-vs-Rest) avec pond\u00e9ration des classes')\nplt.legend(loc='lower right')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import roc_curve, auc from sklearn.preprocessing import label_binarize  # 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u00e9quilibr\u00e9 pred_test_lstm = model.predict(padded_test)  y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3]) n_classes = y_test_binarized.shape[1]  # 2) Calculer fpr, tpr, AUC pour chaque classe fpr = dict() tpr = dict() roc_auc = dict() for i in range(n_classes):     fpr[i], tpr[i], _ = roc_curve(         y_test_binarized[:, i],         pred_test_lstm[:, i]   # probabilit\u00e9 pr\u00e9dite pour la classe i     )     roc_auc[i] = auc(fpr[i], tpr[i])  # 3) Tracer la courbe plt.figure() for i in range(n_classes):     plt.plot(         fpr[i],         tpr[i],         label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"     ) # Diagonale de r\u00e9f\u00e9rence (classif. al\u00e9atoire) plt.plot([0, 1], [0, 1], linestyle='--')  plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') plt.title('ROC Curve multiclasses (One-vs-Rest) avec pond\u00e9ration des classes') plt.legend(loc='lower right') plt.show() <pre>206/206 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 21s 104ms/step\n</pre> In\u00a0[355]: Copied! <pre>import keras_tuner as kt\nimport tensorflow as tf\n\ndef build_model(hp):\n    embed_dim = hp.Choice('embed_dim', [100, 200, 300])\n    lstm_out  = hp.Choice('lstm_out',  [32, 64, 128])\n    dropout_e = hp.Float('dropout_emb', min_value=0.2, max_value=0.5, step=0.1)\n    dropout_l = hp.Float('dropout_lstm', min_value=0.2, max_value=0.5, step=0.1)\n    dropout_d = hp.Float('dropout_dense', min_value=0.2, max_value=0.5, step=0.1)\n    lr        = hp.Choice('learning_rate', [1e-3, 5e-4, 1e-4])\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(num_words, embed_dim, input_length=maxlen),\n        tf.keras.layers.Dropout(dropout_e),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out, return_sequences=True,\n            kernel_regularizer=tf.keras.regularizers.l2(0.01),\n            recurrent_regularizer=tf.keras.regularizers.l2(0.01))),\n        tf.keras.layers.Dropout(dropout_l),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out,\n            kernel_regularizer=tf.keras.regularizers.l2(0.01),\n            recurrent_regularizer=tf.keras.regularizers.l2(0.01))),\n        tf.keras.layers.Dropout(dropout_d),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dropout(dropout_d),\n        tf.keras.layers.Dense(n_classes, activation='softmax'),\n    ])\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=10,\n    executions_per_trial=1,\n    directory='kt_dir',\n    project_name='lstm_tuning'\n)\n\n\n# Lancement de la recherche\ntuner.search(\n    padded_train_bal, y_train_bal,\n    validation_data=(padded_val, y_val),  # &lt;-- idem ici\n    epochs=10,\n    batch_size=32,\n    callbacks=[early_stopping],\n    verbose=0\n)\n\n# Meilleurs hyperparam\u00e8tres\nbest_hp = tuner.get_best_hyperparameters()[0]\nprint(best_hp.values)\n</pre> import keras_tuner as kt import tensorflow as tf  def build_model(hp):     embed_dim = hp.Choice('embed_dim', [100, 200, 300])     lstm_out  = hp.Choice('lstm_out',  [32, 64, 128])     dropout_e = hp.Float('dropout_emb', min_value=0.2, max_value=0.5, step=0.1)     dropout_l = hp.Float('dropout_lstm', min_value=0.2, max_value=0.5, step=0.1)     dropout_d = hp.Float('dropout_dense', min_value=0.2, max_value=0.5, step=0.1)     lr        = hp.Choice('learning_rate', [1e-3, 5e-4, 1e-4])      model = tf.keras.Sequential([         tf.keras.layers.Embedding(num_words, embed_dim, input_length=maxlen),         tf.keras.layers.Dropout(dropout_e),         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out, return_sequences=True,             kernel_regularizer=tf.keras.regularizers.l2(0.01),             recurrent_regularizer=tf.keras.regularizers.l2(0.01))),         tf.keras.layers.Dropout(dropout_l),         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out,             kernel_regularizer=tf.keras.regularizers.l2(0.01),             recurrent_regularizer=tf.keras.regularizers.l2(0.01))),         tf.keras.layers.Dropout(dropout_d),         tf.keras.layers.Dense(64, activation='relu'),         tf.keras.layers.Dropout(dropout_d),         tf.keras.layers.Dense(n_classes, activation='softmax'),     ])     model.compile(         optimizer=tf.keras.optimizers.Adam(learning_rate=lr),         loss='sparse_categorical_crossentropy',         metrics=['accuracy']     )     return model  tuner = kt.RandomSearch(     build_model,     objective='val_accuracy',     max_trials=10,     executions_per_trial=1,     directory='kt_dir',     project_name='lstm_tuning' )   # Lancement de la recherche tuner.search(     padded_train_bal, y_train_bal,     validation_data=(padded_val, y_val),  # &lt;-- idem ici     epochs=10,     batch_size=32,     callbacks=[early_stopping],     verbose=0 )  # Meilleurs hyperparam\u00e8tres best_hp = tuner.get_best_hyperparameters()[0] print(best_hp.values)  <pre>Reloading Tuner from kt_dir/lstm_tuning/tuner0.json\n{'embed_dim': 300, 'lstm_out': 32, 'dropout_emb': 0.2, 'dropout_lstm': 0.2, 'dropout_dense': 0.30000000000000004, 'learning_rate': 0.001}\n</pre> In\u00a0[357]: Copied! <pre># Hyper\u2010param\u00e8tres optimis\u00e9s\nembed_dim     = 300\nlstm_units    = 32\ndropout_emb   = 0.2\ndropout_lstm  = 0.2\ndropout_dense = 0.3\nlearning_rate = 1e-3\nn_classes     = len(label_encoder.classes_)\nmaxlen        = max_sequence_length\nnum_words     = len(tokenizer.word_index) + 1  \n\n# Cr\u00e9ation du mod\u00e8le \u201cupgrad\u00e9\u201d\nmodel_upgrade = Sequential(name='model_upgrade')\nmodel_upgrade.add(Embedding(\n    input_dim=num_words,\n    output_dim=embed_dim,\n    input_length=maxlen,\n    name='embedding_layer'\n))\nmodel_upgrade.add(Dropout(dropout_emb, name='dropout_embedding'))\n\nmodel_upgrade.add(Bidirectional(LSTM(\n    lstm_units,\n    return_sequences=True,\n    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n    recurrent_regularizer=tf.keras.regularizers.l2(0.01),\n    name='bidir_lstm_1'\n)))\nmodel_upgrade.add(Dropout(dropout_lstm, name='dropout_lstm_1'))\n\nmodel_upgrade.add(Bidirectional(LSTM(\n    lstm_units,\n    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n    recurrent_regularizer=tf.keras.regularizers.l2(0.01),\n    name='bidir_lstm_2'\n)))\nmodel_upgrade.add(Dropout(dropout_dense, name='dropout_lstm_2'))\n\nmodel_upgrade.add(Dense(64, activation='relu', name='dense_relu'))\nmodel_upgrade.add(Dropout(dropout_dense, name='dropout_dense'))\n\nmodel_upgrade.add(Dense(n_classes, activation='softmax', name='output_layer'))\n\n# Compile with upgraded learning rate\noptimizer = Adam(learning_rate=learning_rate)\nmodel_upgrade.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=optimizer,\n    metrics=['accuracy']\n)\n\n# Build et r\u00e9sum\u00e9\nmodel_upgrade.build(input_shape=(None, maxlen))\nmodel_upgrade.summary()\n\nhistory_upgrade = model_upgrade.fit(\n    padded_train_bal, y_train_bal,\n    validation_data=(padded_val, y_val),  \n    epochs=10,\n    batch_size=32,\n    callbacks=[early_stopping]\n)\n</pre> # Hyper\u2010param\u00e8tres optimis\u00e9s embed_dim     = 300 lstm_units    = 32 dropout_emb   = 0.2 dropout_lstm  = 0.2 dropout_dense = 0.3 learning_rate = 1e-3 n_classes     = len(label_encoder.classes_) maxlen        = max_sequence_length num_words     = len(tokenizer.word_index) + 1    # Cr\u00e9ation du mod\u00e8le \u201cupgrad\u00e9\u201d model_upgrade = Sequential(name='model_upgrade') model_upgrade.add(Embedding(     input_dim=num_words,     output_dim=embed_dim,     input_length=maxlen,     name='embedding_layer' )) model_upgrade.add(Dropout(dropout_emb, name='dropout_embedding'))  model_upgrade.add(Bidirectional(LSTM(     lstm_units,     return_sequences=True,     kernel_regularizer=tf.keras.regularizers.l2(0.01),     recurrent_regularizer=tf.keras.regularizers.l2(0.01),     name='bidir_lstm_1' ))) model_upgrade.add(Dropout(dropout_lstm, name='dropout_lstm_1'))  model_upgrade.add(Bidirectional(LSTM(     lstm_units,     kernel_regularizer=tf.keras.regularizers.l2(0.01),     recurrent_regularizer=tf.keras.regularizers.l2(0.01),     name='bidir_lstm_2' ))) model_upgrade.add(Dropout(dropout_dense, name='dropout_lstm_2'))  model_upgrade.add(Dense(64, activation='relu', name='dense_relu')) model_upgrade.add(Dropout(dropout_dense, name='dropout_dense'))  model_upgrade.add(Dense(n_classes, activation='softmax', name='output_layer'))  # Compile with upgraded learning rate optimizer = Adam(learning_rate=learning_rate) model_upgrade.compile(     loss='sparse_categorical_crossentropy',     optimizer=optimizer,     metrics=['accuracy'] )  # Build et r\u00e9sum\u00e9 model_upgrade.build(input_shape=(None, maxlen)) model_upgrade.summary()  history_upgrade = model_upgrade.fit(     padded_train_bal, y_train_bal,     validation_data=(padded_val, y_val),       epochs=10,     batch_size=32,     callbacks=[early_stopping] ) <pre>Model: \"model_upgrade\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 embedding_layer (Embedding)     \u2502 (None, 544, 300)       \u2502     6,462,600 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_embedding (Dropout)     \u2502 (None, 544, 300)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_20                \u2502 (None, 544, 64)        \u2502        85,248 \u2502\n\u2502 (Bidirectional)                 \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_lstm_1 (Dropout)        \u2502 (None, 544, 64)        \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bidirectional_21                \u2502 (None, 64)             \u2502        24,832 \u2502\n\u2502 (Bidirectional)                 \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_lstm_2 (Dropout)        \u2502 (None, 64)             \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_relu (Dense)              \u2502 (None, 64)             \u2502         4,160 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_dense (Dropout)         \u2502 (None, 64)             \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 output_layer (Dense)            \u2502 (None, 4)              \u2502           260 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 6,577,100 (25.09 MB)\n</pre> <pre> Trainable params: 6,577,100 (25.09 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> <pre>Epoch 1/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 95s 371ms/step - accuracy: 0.3865 - loss: 3.9355 - val_accuracy: 0.3803 - val_loss: 1.2009\nEpoch 2/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 105s 421ms/step - accuracy: 0.6955 - loss: 0.8081 - val_accuracy: 0.3805 - val_loss: 1.7374\nEpoch 3/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 102s 407ms/step - accuracy: 0.8330 - loss: 0.5332 - val_accuracy: 0.5330 - val_loss: 1.2922\nEpoch 4/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 102s 407ms/step - accuracy: 0.8943 - loss: 0.4067 - val_accuracy: 0.3805 - val_loss: 1.7311\nEpoch 5/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 112s 450ms/step - accuracy: 0.9382 - loss: 0.2946 - val_accuracy: 0.3803 - val_loss: 2.9612\nEpoch 6/10\n250/250 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 111s 444ms/step - accuracy: 0.9563 - loss: 0.2205 - val_accuracy: 0.3805 - val_loss: 3.3378\n</pre> In\u00a0[363]: Copied! <pre># 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u201cupgrad\u00e9\u201d\npred_test_upgrade = model_upgrade.predict(padded_test)\n\n# 2. Binarisation des labels de test\ny_test_binarized = label_binarize(y_test, classes=list(range(n_classes)))\nn_classes = y_test_binarized.shape[1]\n\n# 3. Calcul des courbes ROC et AUC One-vs-Rest pour chaque classe\nfpr = {}\ntpr = {}\nroc_auc = {}\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], pred_test_upgrade[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# 4. Affichage\nplt.figure(figsize=(8, 6))\nfor i in range(n_classes):\n    plt.plot(\n        fpr[i], tpr[i], lw=2,\n        label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"\n    )\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='R\u00e9f\u00e9rence al\u00e9atoire')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('One-vs-Rest ROC Curve (mod\u00e8le_optimis\u00e9)')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()\n</pre>   # 1. Pr\u00e9dictions probabilistes du mod\u00e8le \u201cupgrad\u00e9\u201d pred_test_upgrade = model_upgrade.predict(padded_test)  # 2. Binarisation des labels de test y_test_binarized = label_binarize(y_test, classes=list(range(n_classes))) n_classes = y_test_binarized.shape[1]  # 3. Calcul des courbes ROC et AUC One-vs-Rest pour chaque classe fpr = {} tpr = {} roc_auc = {} for i in range(n_classes):     fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], pred_test_upgrade[:, i])     roc_auc[i] = auc(fpr[i], tpr[i])  # 4. Affichage plt.figure(figsize=(8, 6)) for i in range(n_classes):     plt.plot(         fpr[i], tpr[i], lw=2,         label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\"     ) plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='R\u00e9f\u00e9rence al\u00e9atoire') plt.xlabel('False Positive Rate') plt.ylabel('True Positive Rate') plt.title('One-vs-Rest ROC Curve (mod\u00e8le_optimis\u00e9)') plt.legend(loc='lower right') plt.grid(True) plt.show()  <pre>206/206 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14s 66ms/step\n</pre> In\u00a0[360]: Copied! <pre>from sklearn.metrics import classification_report\n\ny_pred_classes = pred_test_upgrade.argmax(axis=1)\n\nreport = classification_report(\n    y_test,\n    y_pred_classes,\n    target_names=label_encoder.classes_,  \n    digits=4                             \n)\n\nprint(report)\n</pre> from sklearn.metrics import classification_report  y_pred_classes = pred_test_upgrade.argmax(axis=1)  report = classification_report(     y_test,     y_pred_classes,     target_names=label_encoder.classes_,       digits=4                              )  print(report) <pre>                  precision    recall  f1-score   support\n\nCredit reporting     0.7321    0.8513    0.7872      2501\n Debt collection     0.8534    0.6640    0.7469      3506\n     Payday loan     0.1772    0.6552    0.2790       145\n    Student loan     0.8391    0.7995    0.8188       424\n\n        accuracy                         0.7438      6576\n       macro avg     0.6505    0.7425    0.6580      6576\n    weighted avg     0.7914    0.7438    0.7565      6576\n\n</pre> In\u00a0[362]: Copied! <pre>from sklearn.metrics import confusion_matrix\ncm_norm = confusion_matrix(y_test, y_pred_classes, normalize='true')\n\ncm_norm_df = pd.DataFrame(\n    cm_norm * 100,                          \n    index=label_encoder.classes_,\n    columns=label_encoder.classes_\n)\n\nplt.figure(figsize=(6, 5))\nplt.imshow(cm_norm_df, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title(\"Matrice de confusion normalis\u00e9e (%)\")\nplt.colorbar(format='%0.0f%%')\nplt.xticks(range(len(cm_norm_df)), cm_norm_df.columns, rotation=45)\nplt.yticks(range(len(cm_norm_df)), cm_norm_df.index)\nplt.xlabel(\"Pr\u00e9diction\")\nplt.ylabel(\"V\u00e9ritable \u00e9tiquette\")\n\nthresh = cm_norm.max() / 2\nfor i in range(cm_norm_df.shape[0]):\n    for j in range(cm_norm_df.shape[1]):\n        plt.text(\n            j, i,\n            f\"{cm_norm_df.iat[i, j]:.1f}%\",\n            ha=\"center\",\n            va=\"center\",\n            color=\"white\" if cm_norm_df.iat[i, j]/100 &gt; thresh else \"black\"\n        )\n\nplt.tight_layout()\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix cm_norm = confusion_matrix(y_test, y_pred_classes, normalize='true')  cm_norm_df = pd.DataFrame(     cm_norm * 100,                               index=label_encoder.classes_,     columns=label_encoder.classes_ )  plt.figure(figsize=(6, 5)) plt.imshow(cm_norm_df, interpolation='nearest', cmap=plt.cm.Blues) plt.title(\"Matrice de confusion normalis\u00e9e (%)\") plt.colorbar(format='%0.0f%%') plt.xticks(range(len(cm_norm_df)), cm_norm_df.columns, rotation=45) plt.yticks(range(len(cm_norm_df)), cm_norm_df.index) plt.xlabel(\"Pr\u00e9diction\") plt.ylabel(\"V\u00e9ritable \u00e9tiquette\")  thresh = cm_norm.max() / 2 for i in range(cm_norm_df.shape[0]):     for j in range(cm_norm_df.shape[1]):         plt.text(             j, i,             f\"{cm_norm_df.iat[i, j]:.1f}%\",             ha=\"center\",             va=\"center\",             color=\"white\" if cm_norm_df.iat[i, j]/100 &gt; thresh else \"black\"         )  plt.tight_layout() plt.show() <p>Les performances initiales du mod\u00e8le \u00e9tant mauvaises nous avons r\u00e9ussi \u00e0 trouver des technniques pour les am\u00e9liorer. Nous aurions pu aller cependant plus loins en  afinnant les techniques de r\u00e9\u00e9quilibrage des donn\u00e9es en faisant varier le nombre de donn\u00e9es voulant \u00eatre atteint pour le sur et sous \u00e9chantillonnage.</p> <p>De m\u00eame nous aurions pu tester plus de valeurs pour notre analyse de sensibilit\u00e9s des performances par cross validation.</p> <p>Il aurait \u00e9galement \u00e9t\u00e9 possible de faire une analyse de sensibilit\u00e9 en fonction de la taille des commentaires consid\u00e9r\u00e9s (en nombre de mots) ainsi qu'en fonction de la taille des mots s\u00e9lectionn\u00e9s pour le travail (rappel : nous avons s\u00e9lectionn\u00e9 uniquement les mots sup\u00e9rieurs 2 caract\u00e8res)</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#notebook-nlp-lstm-pour-prediction-du-type-de-sujet-conernant-les-reclamations-et-pleintes-a-lencontre-de-services-financiers","title":"Notebook: NLP &amp; LSTM pour pr\u00e9diction du type de sujet conernant les r\u00e9clamations et pleintes \u00e0 l'encontre de services financiers\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#vue-densemble-du-pipeline","title":"Vue d'ensemble du pipeline\u00b6","text":"<ol> <li><p>Analyse des donn\u00e9es</p> <ul> <li>Analyse des valeurs manquantes</li> <li>Analyse de la disponibilit\u00e9s et distribution des donn\u00e9es</li> <li>S\u00e9lection des donn\u00e9es et variables pertinentes</li> </ul> </li> <li><p>Traintement de donn\u00e9es</p> <ul> <li>Imports : Chargement des biblioth\u00e8ques.</li> <li>Lecture et exploration : Chargement du dataset, visualisation et gestion des valeurs manquantes.</li> <li>Pr\u00e9traitement textuel : Nettoyage multi-\u00e9tapes pour r\u00e9duire le bruit.</li> <li>Tokenisation : Passage du texte brut aux tokens.</li> <li>Filtrage des tokens : Stopwords et longueur minimale.</li> <li>R\u00e9alignement du format : Reconstruction en cha\u00eene pour la vectorisation.</li> <li>Construction du vocabulaire (Tokenizer Keras) : Explication du mapping mots\u2192indices, .</li> <li>Padding : Uniformisation de la longueur des s\u00e9quences.</li> </ul> </li> <li><p>LSTM Model</p> <ul> <li>Architecture du mod\u00e8le : Embedding, LSTM bidirectionnel, couches denses.</li> <li>Compilation et build : Choix de la perte, optimiseur, build explicite pour r\u00e9v\u00e9ler les param\u00e8tres.</li> <li>Entra\u00eenement : Early stopping, batch size, epochs.</li> <li>Evaluation des performances sur les donn\u00e9es de test</li> </ul> </li> <li><p>Gestion des class inbalance</p> <ul> <li>Utilisation de sur \u00e9chantillonnage</li> <li>Pond\u00e9ration des classes durant l'entrainement</li> </ul> </li> <li><p>Validation crois\u00e9es des param\u00e8tres de l'architecture du model pour am\u00e9liorations des performances</p> <ul> <li>Recherche des param\u00e8tres optimaux</li> <li>Resp\u00e9cification du mod\u00e8le</li> <li>Comparaison des performances</li> </ul> </li> </ol>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#1-analyse-et-traitement-de-donnees","title":"1. Analyse et Traitement de donn\u00e9es\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#a-exploration-statistiques","title":"A) Exploration &amp; Statistiques\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#nettoyage-textuel","title":"Nettoyage textuel\u00b6","text":"<ul> <li>Les montants et r\u00e9f\u00e9rences num\u00e9riques n'apportent pas d'information s\u00e9mantique.</li> <li>Une regex retire tout motif de chiffres.</li> <li>Retrait de la ponctuation, URL, balises html</li> </ul>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#filtrage-de-linput","title":"Filtrage de l'input\u00b6","text":"<p>Suppression des mots vides (stopwords) gr\u00e2ce \u00e0 NLTK, puis filtre des mots de longueur &lt;= 2 pour \u00e9viter le bruit (petits mots du style \"to\", \"of\", etc)</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#realignement-du-format","title":"R\u00e9alignement du format\u00b6","text":"<p>Reconstruction des listes de mots  en cha\u00eenes de caract\u00e8res, format attendu par le <code>Tokenizer</code> de Keras.</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#construction-du-vocabulaire-et-tokenisation","title":"Construction du vocabulaire et tokenisation\u00b6","text":"<p>Nous avons choisi d\u2019utiliser le <code>Tokenizer</code> de Keras<code>suivi de</code>texts_to_sequences <code>et</code>pad_sequences parce que cette cha\u00eene d\u2019op\u00e9rations est \u00e0 la fois simple \u00e0 mettre en \u0153uvre et parfaitement int\u00e9gr\u00e9e dans l\u2019\u00e9cosyst\u00e8me Keras : elle transforme automatiquement chaque mot en un entier (avec un token d\u00e9di\u00e9 aux mots hors vocabulaire), aligne toutes les s\u00e9quences \u00e0 la m\u00eame longueur n\u00e9cessaire pour un LSTM, et r\u00e9duit au maximum les conversions manuelles tout en offrant un point de d\u00e9part solide avant d\u2019envisager des techniques plus avanc\u00e9es comme les embeddings pr\u00e9-entra\u00een\u00e9s ou les tokenizers sous-mot. Pour en savoir plus sur ces outils et leurs bonnes pratiques, vous pouvez consulter la documentation officielle de Keras sur le pr\u00e9traitement du texte.</p> <p>Nous sommes toutefois conscients qu\u2019il existe des approches plus sophistiqu\u00e9es, telles que :</p> <ul> <li>GloVe (Global Vectors), qui fournit des vecteurs de mots entra\u00een\u00e9s sur de grands corpus pour capturer les similarit\u00e9s s\u00e9mantiques,</li> <li>FastText, qui repr\u00e9sente les mots \u00e0 partir de leurs n-grammes de caract\u00e8res pour mieux g\u00e9rer la morphologie et les mots rares,</li> <li>ou encore les tokenizers sous-mot (BPE, WordPiece) utilis\u00e9s dans les mod\u00e8les Transformers tels que BERT et RoBERTa.</li> </ul> <p>Compte tenu du temps limit\u00e9 dont nous disposons, nous n\u2019avons cependant pas eu l\u2019opportunit\u00e9 d\u2019explorer ces m\u00e9thodes en profondeur ni de r\u00e9aliser une comparaison exhaustive des performances.</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#padding","title":"Padding\u00b6","text":"<p>Uniformisation de la longueur des s\u00e9quences :</p> <ul> <li><code>maxlen</code> est la longueur maximale observ\u00e9e. On parcourt toutes les s\u00e9quences de tokens (chacune \u00e9tant une liste d\u2019indices entiers) pour en trouver la plus longue.Cette longueur maximale deviendra le standard\u2009: toutes les autres s\u00e9quences seront ramen\u00e9es \u00e0 cette taille. Cela parce que les r\u00e9seaux Keras  exigent que tous les exemples d\u2019un batch aient la m\u00eame taille d\u2019entr\u00e9e. On doit donc uniformiser les longueurs.</li> <li>Les s\u00e9quences sont tronqu\u00e9es ou padd\u00e9es (ici <code>'post'</code>) pour obtenir des vecteurs de m\u00eame taille.</li> </ul> <p>Le padding est la m\u00e9thode standard pour transformer des s\u00e9quences de longueurs variables en un tenseur d\u2019entr\u00e9e de taille constant</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#autre-methode-de-preparation-dinput-pour-modeles-de-nlp-et-tokenisation-avec-spacy","title":"Autre m\u00e9thode de pr\u00e9paration d'input pour mod\u00e8les de NLP et tok\u00e9nisation avec SpaCY\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#creation-des-train-validation-et-test-set","title":"Cr\u00e9ation des train, validation et test set\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#affichage-des-valeurs-cibles","title":"Affichage des valeurs cibles :\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#2-lstm-model","title":"2. LSTM Model\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#entrainement","title":"Entra\u00eenement\u00b6","text":"<p>Entra\u00eenement du mod\u00e8le sur <code>padded_train</code> avec validation sur <code>padded_val</code>. <code>EarlyStopping</code> arr\u00eate l\u2019apprentissage si la m\u00e9trique de validation ne s\u2019am\u00e9liore pas pendant 3 epochs.</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#validation-sur-les-donnees-de-test","title":"Validation sur les donn\u00e9es de Test\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#filtrage-des-tokens","title":"Filtrage des tokens\u00b6","text":"<p>Suppression des mots vides (stopwords) gr\u00e2ce \u00e0 NLTK, puis filtre des tokens de longueur &lt;= 2 pour \u00e9viter le bruit.</p>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#accuracy","title":"Accuracy\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#precision-recall-f1-score","title":"Precision, Recall, F1-score\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#on-voit-que-le-modele-ne-predit-quune-seule-classe-a-chaque-fois-qui-est-celle-majoritaire","title":"On voit que le mod\u00e8le ne pr\u00e9dit qu'une seule classe \u00e0 chaque fois qui est celle majoritaire\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#roc-curve","title":"ROC Curve\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#on-retrouve-une-bonne-performance-generale-du-modele-mais-du-a-la-sur-representation-dune-classe-pour-laquelle-le-modele-a-appris-uniquement-a-opter-pour","title":"On retrouve une bonne performance g\u00e9n\u00e9rale du mod\u00e8le mais du \u00e0 la sur repr\u00e9sentation d'une classe pour laquelle le mod\u00e8le a appris uniquement \u00e0 opter pour\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#en-regardant-la-roc-one-vs-rest-on-voit-bien-que-les-performances-du-modele-a-distinguer-les-classes-sont-tres-mauvaises","title":"En regardant la ROC One VS Rest on voit bien que les performances du mod\u00e8le \u00e0 distinguer les classes sont tr\u00e8s mauvaises\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#exemple-de-prediction","title":"Exemple de pr\u00e9diction\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#les-performances-relatees-par-la-roc-cruve-one-vs-rest-sont-en-effet-tres-mauvaises-cela-etait-du-au-mauvaise-equilibraque-des-classes-cibles-dans-le-jeu-dentrainement-en-effet-une-classe-etait-bien-sur-representee-le-modele-na-qua-apprendre-a-predire-la-classe-majoritaire-a-chaque-fois-mais-ne-les-distingue-pas-bien-on-le-voit-bien-dans-les-exemples-de-predicitons","title":"Les performances relat\u00e9es par la ROC cruve One VS Rest sont en effet tr\u00e8s mauvaises, cela \u00e9tait d\u00fb au mauvaise \u00e9quilibraque des classes cibles dans le jeu d'entrainement en effet une classe \u00e9tait bien sur repr\u00e9sent\u00e9e, le mod\u00e8le n'\u00e0 qu'\u00e0 apprendre \u00e0 pr\u00e9dire la classe majoritaire \u00e0 chaque fois mais ne les distingue pas bien. On le voit bien dans les exemples de pr\u00e9dicitons\u00b6","text":"<p>Rappel :</p> <p>Nombre d'exemples par classe :</p> <ul> <li>Classe 0 (Credit reporting): 7504 exemples</li> <li>Classe 1 (Debt collection): 10516 exemples</li> <li>Classe 2 (Payday loan): 434 exemples</li> <li>Classe 3 (Student loan): 1272 exemples</li> </ul>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#notre-enjeux-est-donc-de-gerer-ce-desiquilibre-de-classe","title":"Notre enjeux est donc de g\u00e9rer ce d\u00e9siquilibre de classe\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#3-gestion-de-la-classe-inbalance","title":"3. Gestion de la classe Inbalance\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#1-utilisation-du-sur-et-sous-echantillonnage","title":"1. Utilisation du sur et sous echantillonnage\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#2-utilisation-de-la-ponderation","title":"2. Utilisation de la pond\u00e9ration\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#on-conclut-que-le-sur-et-sous-echantillonnage-est-meilleur-que-la-ponderation-des-classes","title":"On conclut que le sur et sous \u00e9chantillonnage est meilleur que la pond\u00e9ration des classes\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#4-amelioration-des-performances-grace-a-la-cross-validation","title":"4. Am\u00e9lioration des performances gr\u00e2ce \u00e0 la Cross validation\u00b6","text":"<p>Pour optimiser les performances de notre LSTM bidirectionnel, nous avons utilis\u00e9 Keras Tuner afin de tester plusieurs configurations d\u2019hyper-param\u00e8tres cl\u00e9s :</p> <ul> <li><p>Dimension de l\u2019Embedding (<code>embed_dim</code>) Valeurs test\u00e9es : <code>100</code>, <code>200</code>, <code>300</code></p> <p>Plus la dimension est grande, plus les vecteurs de mots peuvent capturer de nuances s\u00e9mantiques, mais cela augmente aussi le nombre de param\u00e8tres.</p> </li> <li><p>Taille des couches LSTM (<code>lstm_units</code>) Valeurs test\u00e9es : <code>32</code>, <code>64</code>, <code>128</code></p> <p>Nombre de cellules cach\u00e9es dans chaque direction du LSTM bidirectionnel. Un nombre sup\u00e9rieur permet de mod\u00e9liser des d\u00e9pendances plus longues, au prix d\u2019un surco\u00fbt computationnel.</p> </li> <li><p>Taux de Dropout apr\u00e8s l\u2019Embedding (<code>dropout_emb</code>) Valeurs test\u00e9es : de <code>0.2</code> \u00e0 <code>0.5</code> (pas <code>0.1</code>)</p> <p>Sert \u00e0 r\u00e9gulariser la couche d\u2019Embedding en for\u00e7ant le mod\u00e8le \u00e0 ne pas trop d\u00e9pendre de quelques dimensions.</p> </li> <li><p>Taux de Dropout apr\u00e8s chaque LSTM (<code>dropout_lstm</code>) Valeurs test\u00e9es : de <code>0.2</code> \u00e0 <code>0.5</code> (pas <code>0.1</code>)</p> <p>Permet de r\u00e9duire le sur-apprentissage dans la partie r\u00e9currente du r\u00e9seau.</p> </li> <li><p>Taux de Dropout avant et apr\u00e8s la couche Dense (<code>dropout_dense</code>) Valeurs test\u00e9es : de <code>0.2</code> \u00e0 <code>0.5</code> (pas <code>0.1</code>)</p> <p>Aide \u00e0 g\u00e9n\u00e9raliser les repr\u00e9sentations extraites par les LSTM avant la classification finale.</p> </li> <li><p>Learning Rate de l\u2019optimiseur Adam (<code>learning_rate</code>) Valeurs test\u00e9es : <code>1e-3</code>, <code>5e-4</code>, <code>1e-4</code></p> <p>Le pas d\u2019apprentissage influe sur la vitesse et la stabilit\u00e9 de la convergence.</p> </li> </ul>"},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#cross-validation","title":"Cross validation\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#re-specification-du-modele","title":"Re sp\u00e9cification du mod\u00e8le\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#on-a-a-de-bien-meilleures-meilleures-performances-les-performances-de-classificaitions-relatives-a-la-classe-payday-loan-reste-moindre-car-la-categorie-aura-ete-beaucoup-sur-echantillonne-ce-qui-creer-du-sur-apprentissage-et-empeche-forcement-une-meilleure-generalisation-possible-sur-le-jeu-de-test","title":"On a a de bien meilleures meilleures performances. Les performances de classificaitions relatives \u00e0 la classe Payday Loan reste moindre car la cat\u00e9gorie aura \u00e9t\u00e9 beaucoup sur \u00e9chantillonn\u00e9 ce qui cr\u00e9er du sur apprentissage et emp\u00eache forc\u00e9ment une meilleure g\u00e9n\u00e9ralisation possible sur le jeu de test\u00b6","text":""},{"location":"asset/NLP_LSTM/notebooks/finance_complaints_NLP/#amelioration-de-la-methode-et-perspective","title":"Am\u00e9lioration de la m\u00e9thode et perspective\u00b6","text":""},{"location":"asset/data_analysis_TDL/notebooks/Jupyter_notebook_analyse_actionnariat/","title":"Jupyter notebook analyse actionnariat","text":"In\u00a0[1]: Copied! <pre>%%HTML \n&lt;script&gt;\n    function luc21893_refresh_cell(cell) {\n        if( cell.luc21893 ) return;\n        cell.luc21893 = true;\n        console.debug('New code cell found...' );\n        \n        var div = document.createElement('DIV');            \n        cell.parentNode.insertBefore( div, cell.nextSibling );\n        div.style.textAlign = 'right';\n        var a = document.createElement('A');\n        div.appendChild(a);\n        a.href='#'\n        a.luc21893 = cell;\n        a.setAttribute( 'onclick', \"luc21893_toggle(this); return false;\" );\n\n        cell.style.visibility='hidden';\n        cell.style.position='absolute';\n        a.innerHTML = '[show code]';        \n                \n    }\n    function luc21893_refresh() {                \n        if( document.querySelector('.code_cell .input') == null ) {            \n            // it apeears that I am in a exported html\n            // hide this code\n            var codeCells = document.querySelectorAll('.jp-InputArea')\n            codeCells[0].style.visibility = 'hidden';\n            codeCells[0].style.position = 'absolute';                        \n            for( var i = 1; i &lt; codeCells.length; i++ ) {\n                luc21893_refresh_cell(codeCells[i].parentNode)\n            }\n            window.onload = luc21893_refresh;\n        }                 \n        else {\n            // it apperas that I am in a jupyter editor\n            var codeCells = document.querySelectorAll('.code_cell .input')\n            for( var i = 0; i &lt; codeCells.length; i++ ) {\n                luc21893_refresh_cell(codeCells[i])\n            }            \n            window.setTimeout( luc21893_refresh, 1000 )\n        }        \n    }\n    \n    function luc21893_toggle(a) {\n        if( a.luc21893.style.visibility=='hidden' ) {\n            a.luc21893.style.visibility='visible';        \n            a.luc21893.style.position='';\n            a.innerHTML = '[hide code]';\n        }\n        else {\n            a.luc21893.style.visibility='hidden';        \n            a.luc21893.style.position='absolute';\n            a.innerHTML = '[show code]';\n        }\n    }\n    \n    luc21893_refresh()\n&lt;/script&gt;\n</pre> %%HTML   In\u00a0[2]: Copied! <pre>from IPython.display import display, HTML\n\n# Afficher un titre centr\u00e9 et sous-lign\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h1&gt;Analyse actionnaires&lt;/h1&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  # Afficher un titre centr\u00e9 et sous-lign\u00e9 avec une taille de police plus grande display(HTML('Analyse actionnaires'))  Analyse actionnaires In\u00a0[3]: Copied! <pre>from IPython.display import display, HTML\n\n\n# Ins\u00e9rer une ligne de soulignement\ndisplay(HTML(\"&lt;hr&gt;\"))\n</pre> from IPython.display import display, HTML   # Ins\u00e9rer une ligne de soulignement display(HTML(\"\")) In\u00a0[4]: Copied! <pre>import random\nimport pandas as pd\nimport string\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n\n# Fonction pour g\u00e9n\u00e9rer une combinaison de 6 lettres al\u00e9atoires\ndef generer_combinaison():\n    lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    return ''.join(random.choice(lettres) for _ in range(6))\n\n# G\u00e9n\u00e9rer une liste de 20 000 combinaisons de noms complets uniques\nnoms_complets = set()\nwhile len(noms_complets) &lt; 20000:\n    nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"\n    noms_complets.add(nom_complet)\n\n# R\u00e9p\u00e9ter al\u00e9atoirement les noms complets jusqu'\u00e0 12 fois maximum\nnoms_complets_repetes = []\nfor nom_complet in noms_complets:\n    repetitions = random.randint(0, 12)\n    noms_complets_repetes.extend([nom_complet] * repetitions)\n\n# Limiter la liste \u00e0 20 000 \u00e9l\u00e9ments\nnoms_complets_final = random.sample(noms_complets_repetes, 20000)\n\n# Cr\u00e9er un DataFrame pandas avec les noms complets\ndata = pd.DataFrame({'Nom complet': noms_complets_final})\n# Fonction pour g\u00e9n\u00e9rer une combinaison de 6 lettres al\u00e9atoires\ndef generer_combinaison():\n    lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    return ''.join(random.choice(lettres) for _ in range(6))\n\n# G\u00e9n\u00e9rer une liste de 35 combinaisons de noms complets uniques r\u00e9p\u00e9t\u00e9es 11 fois\nnoms_complets_35 = []\nfor _ in range(35):\n    nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"\n    noms_complets_35.extend([nom_complet] * 11)\n\n# G\u00e9n\u00e9rer une liste de 65 combinaisons de noms complets uniques r\u00e9p\u00e9t\u00e9es 12 fois\nnoms_complets_65 = []\nfor _ in range(65):\n    nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"\n    noms_complets_65.extend([nom_complet] * 12)\n\n# Combiner les deux listes\nnoms_complets_final = noms_complets_35 + noms_complets_65\n\n# Cr\u00e9er un DataFrame pandas avec les noms complets\ndata2 = pd.DataFrame({'Nom complet': noms_complets_final})\n\n# Concat\u00e9ner les deux DataFrames\ndata = pd.concat([data, data2], ignore_index=True)\n\n# Initialiser un dictionnaire pour suivre les ID du contact par nom complet\nid_du_contact_par_nom = {}\n\n# G\u00e9n\u00e9rer une liste de noms complets avec r\u00e9p\u00e9tition\nnoms_complets = data['Nom complet']\n\n# G\u00e9n\u00e9rer une liste d'ID de contact bas\u00e9e sur les noms complets (m\u00eames noms auront les m\u00eames ID)\nids_contacts = [''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + ''.join(random.choices(string.ascii_uppercase, k=2)) for _ in range(21165)]\n\n# Remplir le dictionnaire ID du contact par nom complet\nfor nom_complet, id_contact in zip(noms_complets, ids_contacts):\n    if nom_complet not in id_du_contact_par_nom:\n        id_du_contact_par_nom[nom_complet] = id_contact\n\n# Utiliser le dictionnaire pour obtenir les ID du contact pour chaque nom complet\ndata['ID du contact'] = [id_du_contact_par_nom[nom_complet] for nom_complet in noms_complets]\n\n# Cr\u00e9er une colonne '\u00e2ge' en attribuant un \u00e2ge al\u00e9atoire entre 0 et 90 \u00e0 chaque ID du contact unique\nunique_ids = data['ID du contact'].unique()\nages = [random.randint(0, 90) for _ in range(len(unique_ids))]\n\n# Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 son \u00e2ge\nid_to_age = dict(zip(unique_ids, ages))\n\n# Appliquer l'\u00e2ge correspondant \u00e0 chaque ID du contact dans le DataFrame original\ndata['\u00e2ge'] = data['ID du contact'].map(id_to_age)\n\nterritoires = [\n    \"Alsace\", \"Aquitaine\", \"Auvergne\", \"Basse-Normandie\", \"Bourgogne\", \"Bretagne\", \"Centre\", \"Champagne-Ardenne\", \n    \"Corse\", \"Franche-Comt\u00e9\", \"Haute-Normandie\", \"\u00cele-de-France\", \"Languedoc-Roussillon\", \"Limousin\", \"Lorraine\", \n    \"Midi-Pyr\u00e9n\u00e9es\", \"Nord-Pas-de-Calais\", \"Pays de la Loire\", \"Picardie\", \"Poitou-Charentes\", \"Provence-Alpes-C\u00f4te d'Azur\", \n    \"Rh\u00f4ne-Alpes\"\n]\n\n# Associer al\u00e9atoirement un territoire \u00e0 chaque ID du contact unique\nterritoire_par_id = {id_contact: random.choice(territoires) for id_contact in unique_ids}\n\n# Appliquer les attributions de territoire au DataFrame\ndata['Territoire Terre de Liens'] = data['ID du contact'].map(territoire_par_id)\n# Afficher les premi\u00e8res lignes du DataFrame pour v\u00e9rification\n\n\n# G\u00e9n\u00e9rer al\u00e9atoirement des valeurs 0 ou 1 pour chaque ID du contact unique\nvaleurs_adherent_n_1 = np.random.randint(0, 2, size=len(unique_ids))\nvaleurs_adherent_n = np.random.randint(0, 2, size=len(unique_ids))\nvaleurs_donateur_n = np.random.randint(0, 2, size=len(unique_ids))\n\n# Cr\u00e9er des dictionnaires pour associer chaque ID du contact \u00e0 ses valeurs respectives\nadherent_n_1_par_id = dict(zip(unique_ids, valeurs_adherent_n_1))\nadherent_n_par_id = dict(zip(unique_ids, valeurs_adherent_n))\ndonateur_n_par_id = dict(zip(unique_ids, valeurs_donateur_n))\n\n# Appliquer les valeurs correspondantes aux colonnes du DataFrame\ndata['adh\u00e9rent N-1'] = data['ID du contact'].map(adherent_n_1_par_id)\ndata['adh\u00e9rent N'] = data['ID du contact'].map(adherent_n_par_id)\ndata['Donateur N'] = data['ID du contact'].map(donateur_n_par_id)\n\n# D\u00e9finition de la fonction pour g\u00e9n\u00e9rer une date al\u00e9atoire entre deux dates donn\u00e9es\ndef random_date(start_date, end_date):\n    return start_date + timedelta(\n        days=random.randint(0, (end_date - start_date).days)\n    )\n\n\n# G\u00e9n\u00e9rer des dates al\u00e9atoires pour 'RFM-Date Premi\u00e8re Souscription' entre le 01/02/2006 et le 31/07/2022\nstart_date = datetime(2006, 2, 1)\nend_date = datetime(2022, 7, 31)\n\n# Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 une date 'RFM-Date Premi\u00e8re Souscription' unique\nrfm_dates = {id_contact: random_date(start_date, end_date) for id_contact in unique_ids}\n\n# Appliquer les dates correspondantes aux ID du contact dans le DataFrame original\ndata['RFM-Date Premi\u00e8re Souscription'] = data['ID du contact'].map(rfm_dates)\n\n\n# Cr\u00e9ez un dictionnaire pour stocker les dates du dernier don par ID du contact\nrfm_date_dernier_don_par_id = {}\nthis_year = datetime.now().year\n\n# G\u00e9n\u00e9rez des dates al\u00e9atoires pour 'RFM-Date Dernier Don' en fonction de la valeur 'Donateur N'\nfor id_contact in unique_ids:\n    if donateur_n_par_id[id_contact] == 1:\n        # Si Donateur N est \u00e9gal \u00e0 1, g\u00e9n\u00e9rez une date entre le 01/01 de cette ann\u00e9e et le 31/12 de cette ann\u00e9e\n        this_year = datetime.now().year\n        rfm_date_dernier_don_par_id[id_contact] = random_date(datetime(this_year, 1, 1), datetime(this_year, 12, 31))\n    else:\n        # Sinon, g\u00e9n\u00e9rez une date entre le 01/01/2006 et le 01/01 de cette ann\u00e9e (exclu)\n        rfm_date_dernier_don_par_id[id_contact] = random_date(datetime(2006, 1, 1), datetime(this_year, 1, 1))\n\n# Appliquez les dates du dernier don correspondantes aux ID du contact dans le DataFrame original\ndata['RFM-Date Dernier Don'] = data['ID du contact'].map(rfm_date_dernier_don_par_id)\n\n\n# Cr\u00e9er une liste de nombres avec des probabilit\u00e9s\n# Plus de probabilit\u00e9 d'obtenir un nombre entre 1 et 10, moins de probabilit\u00e9 pour 0, et tr\u00e8s rarement pour 10 \u00e0 8000\nnombres_actions_detenues = []\nfor _ in range(len(unique_ids)):\n    random_value = random.random()\n    if random_value &lt; 0.7:  # 70% de chance d'obtenir un nombre entre 1 et 10\n        nombre = random.randint(1, 100)\n    elif random_value &lt; 0.85:  # 15% de chance d'obtenir un z\u00e9ro\n        nombre = 0\n    else:  # 15% de chance d'obtenir un nombre entre 10 et 8000\n        nombre = random.randint(101, 8000)\n    nombres_actions_detenues.append(nombre)\n\n# Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 son nombre d'actions\nid_to_actions_detenues = dict(zip(unique_ids, nombres_actions_detenues))\n\n# Appliquer le nombre d'actions correspondant \u00e0 chaque ID du contact dans le DataFrame original\ndata['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'] = data['ID du contact'].map(id_to_actions_detenues)\ndata[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"] = data['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'] * 105\ndata['Actionnaire ?'] = data['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'].apply(lambda x: 0 if x == 0 else 1)\n\nnouvel_ordre = [\n    'Nom complet', 'ID du contact', '\u00e2ge', 'Territoire Terre de Liens', 'Actionnaire ?',\n    'adh\u00e9rent N-1', 'adh\u00e9rent N', 'Donateur N', 'RFM-Date Premi\u00e8re Souscription',\n    'RFM-Date Dernier Don', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9', 'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'\n]\n\ndata = data[nouvel_ordre]\nsomme_capital = data.drop_duplicates(subset = \"ID du contact\")\nsomme_capital = somme_capital['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].sum()\ndata[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = data['Fonci\u00e8re : Capital poss\u00e9d\u00e9']/somme_capital *100\ndata['Num\u00e9ro du contrat'] = ['{:06}'.format(random.randint(0, 999999)) for _ in range(len(data))]\ndata[\"Type d'enregistrement des contrats\"] = \"Fonci\u00e8re - Action PP\"\n# Fonction pour g\u00e9n\u00e9rer le nombre d'actions \u00e0 l'acquisition en fonction des probabilit\u00e9s\ndef generate_nombre_actions():\n    random_value = random.random()\n    if random_value &lt; 0.50:  # 30% des cas : de 0 \u00e0 10 actions\n        return random.randint(1, 10)\n    elif random_value &lt; 0.75:  # 30% des cas : de 10 \u00e0 50 actions\n        return random.randint(10, 50)\n    elif random_value &lt; 0.90:  # 30% des cas : de 50 \u00e0 100 actions\n        return random.randint(50, 100)\n    else:  # 10% des cas : de 100 \u00e0 500 actions\n        return random.randint(100, 500)\n\n# Appliquez la fonction pour g\u00e9n\u00e9rer le nombre d'actions \u00e0 l'acquisition pour chaque ligne\ndata['Nombre d\\'actions \u00e0 l\\'acquisition'] = [generate_nombre_actions() for _ in range(len(data))]\n\n# Fonction pour g\u00e9n\u00e9rer la valeur de \"A fait l'objet d'un re\u00e7u fiscal\" en fonction de la probabilit\u00e9\ndef generate_recu_fiscal():\n    random_value = random.random()\n    if random_value &lt; 0.7688:  # 76,88% de chance d'obtenir 1\n        return 1\n    else:\n        return 0\n\n# Appliquez la fonction pour g\u00e9n\u00e9rer la valeur de \"A fait l'objet d'un re\u00e7u fiscal\" pour chaque ligne\ndata[\"A fait l'objet d'un re\u00e7u fiscal\"] = [generate_recu_fiscal() for _ in range(len(data))]\n\n# Fonction pour g\u00e9n\u00e9rer la valeur de \"Affectation\" en fonction des proportions sp\u00e9cifi\u00e9es\ndef generate_affectation():\n    random_value = random.random()\n    if random_value &lt; 1/3:  # 1/3 des cas, \"Ensemble des fermes de la Fonci\u00e8re\"\n        return \"Ensemble des fermes de la Fonci\u00e8re\"\n    elif random_value &lt; 2/3:  # 1/3 des cas, \"Collecte d\u00e9di\u00e9e\" + valeur al\u00e9atoire dans \"territoires\"\n        territoires = [\n            \"Alsace\", \"Aquitaine\", \"Auvergne\", \"Basse-Normandie\", \"Bourgogne\", \"Bretagne\", \"Centre\", \"Champagne-Ardenne\", \n            \"Corse\", \"Franche-Comt\u00e9\", \"Haute-Normandie\", \"\u00cele-de-France\", \"Languedoc-Roussillon\", \"Limousin\", \"Lorraine\", \n            \"Midi-Pyr\u00e9n\u00e9es\", \"Nord-Pas-de-Calais\", \"Pays de la Loire\", \"Picardie\", \"Poitou-Charentes\", \"Provence-Alpes-C\u00f4te d'Azur\", \n            \"Rh\u00f4ne-Alpes\"\n        ]\n        random_territoire = random.choice(territoires)\n        return f\"Collecte d\u00e9di\u00e9e - {random_territoire}\"\n    else:  # 1/3 des cas, combinaison de 6 lettres al\u00e9atoires\n        lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n        return ''.join(random.choice(lettres) for _ in range(6))\n\n# Appliquez la fonction pour g\u00e9n\u00e9rer la valeur de \"Affectation\" pour chaque ligne\ndata[\"Affectation\"] = [generate_affectation() for _ in range(len(data))]\n\n\n# Fonction pour g\u00e9n\u00e9rer une combinaison de 6 chiffres al\u00e9atoires\ndef generer_combinaison_chiffres():\n    chiffres = '0123456789'\n    return ''.join(random.choice(chiffres) for _ in range(6))\n\n# Appliquez la fonction pour g\u00e9n\u00e9rer les valeurs de la colonne \"M-XXXXXX\"\ndata[\"Mouvement de titre Name\"] = [\"M-\" + generer_combinaison_chiffres() for _ in range(len(data))]\n\n# D\u00e9finissez les valeurs possibles pour la colonne \"Nature du mouvement\"\nvaleurs_possibles = ['Souscription'] * 80 + ['Don TDL'] * 7 + ['Rachat'] * 13\n\n# Utilisez numpy.random.choice pour attribuer ces valeurs en fonction des pourcentages\ndata[\"Nature du mouvement\"] = np.random.choice(valeurs_possibles, size=len(data))\n\n# Fonction pour g\u00e9n\u00e9rer des dates al\u00e9atoires entre le 01/01/2006 et aujourd'hui\ndef generate_date_activation():\n    start_date = datetime(2006, 1, 1)\n    end_date = datetime.now()\n    random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n    return random_date\n\n# Appliquer la fonction pour cr\u00e9er la colonne \"Date d'activation\"\ndata['Date d\\'activation'] = [generate_date_activation() for _ in range(len(data))]\n# G\u00e9n\u00e9rez des dates al\u00e9atoires pour chaque ligne en fonction de \"RFM-Date Premi\u00e8re Souscription\"\nrandom_dates = []\nfor _, row in data.iterrows():\n    start_date = row['RFM-Date Premi\u00e8re Souscription']\n    end_date = datetime(2023, 7, 31)\n    random_date = start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days))\n    random_dates.append(random_date)\n\n# Ajoutez la colonne \"Date du Mouvement\" au DataFrame\ndata['Date du Mouvement'] = random_dates\n\n\n# Fonction pour g\u00e9n\u00e9rer \"Nombre d'actions \u00e9chang\u00e9es\" en fonction de \"Nature du mouvement\"\ndef generate_actions_echangees(row):\n    if row['Nature du mouvement'] == 'Souscription':\n        return row['Nombre d\\'actions \u00e0 l\\'acquisition']\n    else:\n        # V\u00e9rifiez d'abord que \"Nombre d'actions \u00e0 l'acquisition\" est sup\u00e9rieur \u00e0 z\u00e9ro\n        if row['Nombre d\\'actions \u00e0 l\\'acquisition'] &gt; 0:\n            # 80% de chance que \"Nombre d'actions \u00e9chang\u00e9es\" soit \u00e9gal \u00e0 \"Nombre d'actions \u00e0 l'acquisition\"\n            # 20% de chance que \"Nombre d'actions \u00e9chang\u00e9es\" soit strictement inf\u00e9rieur \u00e0 \"Nombre d'actions \u00e0 l'acquisition\"\n            if np.random.rand() &lt; 0.8:\n                return row['Nombre d\\'actions \u00e0 l\\'acquisition']\n            else:\n                return np.random.randint(1, row['Nombre d\\'actions \u00e0 l\\'acquisition'] + 1)\n        else:\n            return 0  # Si \"Nombre d'actions \u00e0 l'acquisition\" est z\u00e9ro, \"Nombre d'actions \u00e9chang\u00e9es\" est \u00e9galement z\u00e9ro\n\n# Appliquez la fonction pour cr\u00e9er la colonne \"Nombre d'actions \u00e9chang\u00e9es\"\ndata['Nombre d\\'actions \u00e9chang\u00e9es'] = data.apply(generate_actions_echangees, axis=1)\n\n# Fonction pour g\u00e9n\u00e9rer \"Actions - Date de fin\" en fonction des conditions\ndef generate_actions_date_fin(row):\n    if row['Nature du mouvement'] == 'Souscription':\n        # Si \"Nature du mouvement\" est \"Souscription\"\n        if random.random() &lt; 0.5:\n            return datetime.now()  # 90% des cas, aujourd'hui\n        else:\n            return row['Date du Mouvement'] + timedelta(days=random.randint(1, (datetime.now() - row['Date du Mouvement']).days - 1))\n    elif (row['Nature du mouvement'] == 'Don TDL' or row['Nature du mouvement'] == 'Rachat') and row['Nombre d\\'actions \u00e0 l\\'acquisition'] == row['Nombre d\\'actions \u00e9chang\u00e9es']:\n        # Si \"Nature du mouvement\" est \"Don TDL\" ou \"Rachat\" et \"Nombre d'actions \u00e0 l'acquisition\" est \u00e9gal \u00e0 \"Nombre d'actions \u00e9chang\u00e9es\"\n        return row['Date du Mouvement']\n    elif (row['Nature du mouvement'] == 'Don TDL' or row['Nature du mouvement'] == 'Rachat') and row['Nombre d\\'actions \u00e0 l\\'acquisition'] &gt; row['Nombre d\\'actions \u00e9chang\u00e9es']:\n        # Si \"Nature du mouvement\" est \"Don TDL\" ou \"Rachat\" et \"Nombre d'actions \u00e0 l'acquisition\" est sup\u00e9rieur \u00e0 \"Nombre d'actions \u00e9chang\u00e9es\"\n        if random.random() &lt; 0.9:\n            return datetime.now()  # 90% des cas, aujourd'hui\n        else:\n            return row['Date du Mouvement'] + timedelta(days=random.randint(1, (datetime.now() - row['Date du Mouvement']).days - 1))\n\n\n# Appliquez la fonction pour cr\u00e9er la colonne \"Actions - Date de fin\"\ndata['Actions - Date de fin'] = data.apply(generate_actions_date_fin, axis=1)\n</pre> import random import pandas as pd import string import numpy as np from datetime import datetime, timedelta   # Fonction pour g\u00e9n\u00e9rer une combinaison de 6 lettres al\u00e9atoires def generer_combinaison():     lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'     return ''.join(random.choice(lettres) for _ in range(6))  # G\u00e9n\u00e9rer une liste de 20 000 combinaisons de noms complets uniques noms_complets = set() while len(noms_complets) &lt; 20000:     nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"     noms_complets.add(nom_complet)  # R\u00e9p\u00e9ter al\u00e9atoirement les noms complets jusqu'\u00e0 12 fois maximum noms_complets_repetes = [] for nom_complet in noms_complets:     repetitions = random.randint(0, 12)     noms_complets_repetes.extend([nom_complet] * repetitions)  # Limiter la liste \u00e0 20 000 \u00e9l\u00e9ments noms_complets_final = random.sample(noms_complets_repetes, 20000)  # Cr\u00e9er un DataFrame pandas avec les noms complets data = pd.DataFrame({'Nom complet': noms_complets_final}) # Fonction pour g\u00e9n\u00e9rer une combinaison de 6 lettres al\u00e9atoires def generer_combinaison():     lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'     return ''.join(random.choice(lettres) for _ in range(6))  # G\u00e9n\u00e9rer une liste de 35 combinaisons de noms complets uniques r\u00e9p\u00e9t\u00e9es 11 fois noms_complets_35 = [] for _ in range(35):     nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"     noms_complets_35.extend([nom_complet] * 11)  # G\u00e9n\u00e9rer une liste de 65 combinaisons de noms complets uniques r\u00e9p\u00e9t\u00e9es 12 fois noms_complets_65 = [] for _ in range(65):     nom_complet = f\"{generer_combinaison()} {generer_combinaison()}\"     noms_complets_65.extend([nom_complet] * 12)  # Combiner les deux listes noms_complets_final = noms_complets_35 + noms_complets_65  # Cr\u00e9er un DataFrame pandas avec les noms complets data2 = pd.DataFrame({'Nom complet': noms_complets_final})  # Concat\u00e9ner les deux DataFrames data = pd.concat([data, data2], ignore_index=True)  # Initialiser un dictionnaire pour suivre les ID du contact par nom complet id_du_contact_par_nom = {}  # G\u00e9n\u00e9rer une liste de noms complets avec r\u00e9p\u00e9tition noms_complets = data['Nom complet']  # G\u00e9n\u00e9rer une liste d'ID de contact bas\u00e9e sur les noms complets (m\u00eames noms auront les m\u00eames ID) ids_contacts = [''.join(random.choices(string.ascii_uppercase + string.digits, k=10)) + ''.join(random.choices(string.ascii_uppercase, k=2)) for _ in range(21165)]  # Remplir le dictionnaire ID du contact par nom complet for nom_complet, id_contact in zip(noms_complets, ids_contacts):     if nom_complet not in id_du_contact_par_nom:         id_du_contact_par_nom[nom_complet] = id_contact  # Utiliser le dictionnaire pour obtenir les ID du contact pour chaque nom complet data['ID du contact'] = [id_du_contact_par_nom[nom_complet] for nom_complet in noms_complets]  # Cr\u00e9er une colonne '\u00e2ge' en attribuant un \u00e2ge al\u00e9atoire entre 0 et 90 \u00e0 chaque ID du contact unique unique_ids = data['ID du contact'].unique() ages = [random.randint(0, 90) for _ in range(len(unique_ids))]  # Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 son \u00e2ge id_to_age = dict(zip(unique_ids, ages))  # Appliquer l'\u00e2ge correspondant \u00e0 chaque ID du contact dans le DataFrame original data['\u00e2ge'] = data['ID du contact'].map(id_to_age)  territoires = [     \"Alsace\", \"Aquitaine\", \"Auvergne\", \"Basse-Normandie\", \"Bourgogne\", \"Bretagne\", \"Centre\", \"Champagne-Ardenne\",      \"Corse\", \"Franche-Comt\u00e9\", \"Haute-Normandie\", \"\u00cele-de-France\", \"Languedoc-Roussillon\", \"Limousin\", \"Lorraine\",      \"Midi-Pyr\u00e9n\u00e9es\", \"Nord-Pas-de-Calais\", \"Pays de la Loire\", \"Picardie\", \"Poitou-Charentes\", \"Provence-Alpes-C\u00f4te d'Azur\",      \"Rh\u00f4ne-Alpes\" ]  # Associer al\u00e9atoirement un territoire \u00e0 chaque ID du contact unique territoire_par_id = {id_contact: random.choice(territoires) for id_contact in unique_ids}  # Appliquer les attributions de territoire au DataFrame data['Territoire Terre de Liens'] = data['ID du contact'].map(territoire_par_id) # Afficher les premi\u00e8res lignes du DataFrame pour v\u00e9rification   # G\u00e9n\u00e9rer al\u00e9atoirement des valeurs 0 ou 1 pour chaque ID du contact unique valeurs_adherent_n_1 = np.random.randint(0, 2, size=len(unique_ids)) valeurs_adherent_n = np.random.randint(0, 2, size=len(unique_ids)) valeurs_donateur_n = np.random.randint(0, 2, size=len(unique_ids))  # Cr\u00e9er des dictionnaires pour associer chaque ID du contact \u00e0 ses valeurs respectives adherent_n_1_par_id = dict(zip(unique_ids, valeurs_adherent_n_1)) adherent_n_par_id = dict(zip(unique_ids, valeurs_adherent_n)) donateur_n_par_id = dict(zip(unique_ids, valeurs_donateur_n))  # Appliquer les valeurs correspondantes aux colonnes du DataFrame data['adh\u00e9rent N-1'] = data['ID du contact'].map(adherent_n_1_par_id) data['adh\u00e9rent N'] = data['ID du contact'].map(adherent_n_par_id) data['Donateur N'] = data['ID du contact'].map(donateur_n_par_id)  # D\u00e9finition de la fonction pour g\u00e9n\u00e9rer une date al\u00e9atoire entre deux dates donn\u00e9es def random_date(start_date, end_date):     return start_date + timedelta(         days=random.randint(0, (end_date - start_date).days)     )   # G\u00e9n\u00e9rer des dates al\u00e9atoires pour 'RFM-Date Premi\u00e8re Souscription' entre le 01/02/2006 et le 31/07/2022 start_date = datetime(2006, 2, 1) end_date = datetime(2022, 7, 31)  # Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 une date 'RFM-Date Premi\u00e8re Souscription' unique rfm_dates = {id_contact: random_date(start_date, end_date) for id_contact in unique_ids}  # Appliquer les dates correspondantes aux ID du contact dans le DataFrame original data['RFM-Date Premi\u00e8re Souscription'] = data['ID du contact'].map(rfm_dates)   # Cr\u00e9ez un dictionnaire pour stocker les dates du dernier don par ID du contact rfm_date_dernier_don_par_id = {} this_year = datetime.now().year  # G\u00e9n\u00e9rez des dates al\u00e9atoires pour 'RFM-Date Dernier Don' en fonction de la valeur 'Donateur N' for id_contact in unique_ids:     if donateur_n_par_id[id_contact] == 1:         # Si Donateur N est \u00e9gal \u00e0 1, g\u00e9n\u00e9rez une date entre le 01/01 de cette ann\u00e9e et le 31/12 de cette ann\u00e9e         this_year = datetime.now().year         rfm_date_dernier_don_par_id[id_contact] = random_date(datetime(this_year, 1, 1), datetime(this_year, 12, 31))     else:         # Sinon, g\u00e9n\u00e9rez une date entre le 01/01/2006 et le 01/01 de cette ann\u00e9e (exclu)         rfm_date_dernier_don_par_id[id_contact] = random_date(datetime(2006, 1, 1), datetime(this_year, 1, 1))  # Appliquez les dates du dernier don correspondantes aux ID du contact dans le DataFrame original data['RFM-Date Dernier Don'] = data['ID du contact'].map(rfm_date_dernier_don_par_id)   # Cr\u00e9er une liste de nombres avec des probabilit\u00e9s # Plus de probabilit\u00e9 d'obtenir un nombre entre 1 et 10, moins de probabilit\u00e9 pour 0, et tr\u00e8s rarement pour 10 \u00e0 8000 nombres_actions_detenues = [] for _ in range(len(unique_ids)):     random_value = random.random()     if random_value &lt; 0.7:  # 70% de chance d'obtenir un nombre entre 1 et 10         nombre = random.randint(1, 100)     elif random_value &lt; 0.85:  # 15% de chance d'obtenir un z\u00e9ro         nombre = 0     else:  # 15% de chance d'obtenir un nombre entre 10 et 8000         nombre = random.randint(101, 8000)     nombres_actions_detenues.append(nombre)  # Cr\u00e9er un dictionnaire pour associer chaque ID du contact \u00e0 son nombre d'actions id_to_actions_detenues = dict(zip(unique_ids, nombres_actions_detenues))  # Appliquer le nombre d'actions correspondant \u00e0 chaque ID du contact dans le DataFrame original data['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'] = data['ID du contact'].map(id_to_actions_detenues) data[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"] = data['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'] * 105 data['Actionnaire ?'] = data['Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues'].apply(lambda x: 0 if x == 0 else 1)  nouvel_ordre = [     'Nom complet', 'ID du contact', '\u00e2ge', 'Territoire Terre de Liens', 'Actionnaire ?',     'adh\u00e9rent N-1', 'adh\u00e9rent N', 'Donateur N', 'RFM-Date Premi\u00e8re Souscription',     'RFM-Date Dernier Don', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9', 'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues' ]  data = data[nouvel_ordre] somme_capital = data.drop_duplicates(subset = \"ID du contact\") somme_capital = somme_capital['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].sum() data[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = data['Fonci\u00e8re : Capital poss\u00e9d\u00e9']/somme_capital *100 data['Num\u00e9ro du contrat'] = ['{:06}'.format(random.randint(0, 999999)) for _ in range(len(data))] data[\"Type d'enregistrement des contrats\"] = \"Fonci\u00e8re - Action PP\" # Fonction pour g\u00e9n\u00e9rer le nombre d'actions \u00e0 l'acquisition en fonction des probabilit\u00e9s def generate_nombre_actions():     random_value = random.random()     if random_value &lt; 0.50:  # 30% des cas : de 0 \u00e0 10 actions         return random.randint(1, 10)     elif random_value &lt; 0.75:  # 30% des cas : de 10 \u00e0 50 actions         return random.randint(10, 50)     elif random_value &lt; 0.90:  # 30% des cas : de 50 \u00e0 100 actions         return random.randint(50, 100)     else:  # 10% des cas : de 100 \u00e0 500 actions         return random.randint(100, 500)  # Appliquez la fonction pour g\u00e9n\u00e9rer le nombre d'actions \u00e0 l'acquisition pour chaque ligne data['Nombre d\\'actions \u00e0 l\\'acquisition'] = [generate_nombre_actions() for _ in range(len(data))]  # Fonction pour g\u00e9n\u00e9rer la valeur de \"A fait l'objet d'un re\u00e7u fiscal\" en fonction de la probabilit\u00e9 def generate_recu_fiscal():     random_value = random.random()     if random_value &lt; 0.7688:  # 76,88% de chance d'obtenir 1         return 1     else:         return 0  # Appliquez la fonction pour g\u00e9n\u00e9rer la valeur de \"A fait l'objet d'un re\u00e7u fiscal\" pour chaque ligne data[\"A fait l'objet d'un re\u00e7u fiscal\"] = [generate_recu_fiscal() for _ in range(len(data))]  # Fonction pour g\u00e9n\u00e9rer la valeur de \"Affectation\" en fonction des proportions sp\u00e9cifi\u00e9es def generate_affectation():     random_value = random.random()     if random_value &lt; 1/3:  # 1/3 des cas, \"Ensemble des fermes de la Fonci\u00e8re\"         return \"Ensemble des fermes de la Fonci\u00e8re\"     elif random_value &lt; 2/3:  # 1/3 des cas, \"Collecte d\u00e9di\u00e9e\" + valeur al\u00e9atoire dans \"territoires\"         territoires = [             \"Alsace\", \"Aquitaine\", \"Auvergne\", \"Basse-Normandie\", \"Bourgogne\", \"Bretagne\", \"Centre\", \"Champagne-Ardenne\",              \"Corse\", \"Franche-Comt\u00e9\", \"Haute-Normandie\", \"\u00cele-de-France\", \"Languedoc-Roussillon\", \"Limousin\", \"Lorraine\",              \"Midi-Pyr\u00e9n\u00e9es\", \"Nord-Pas-de-Calais\", \"Pays de la Loire\", \"Picardie\", \"Poitou-Charentes\", \"Provence-Alpes-C\u00f4te d'Azur\",              \"Rh\u00f4ne-Alpes\"         ]         random_territoire = random.choice(territoires)         return f\"Collecte d\u00e9di\u00e9e - {random_territoire}\"     else:  # 1/3 des cas, combinaison de 6 lettres al\u00e9atoires         lettres = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'         return ''.join(random.choice(lettres) for _ in range(6))  # Appliquez la fonction pour g\u00e9n\u00e9rer la valeur de \"Affectation\" pour chaque ligne data[\"Affectation\"] = [generate_affectation() for _ in range(len(data))]   # Fonction pour g\u00e9n\u00e9rer une combinaison de 6 chiffres al\u00e9atoires def generer_combinaison_chiffres():     chiffres = '0123456789'     return ''.join(random.choice(chiffres) for _ in range(6))  # Appliquez la fonction pour g\u00e9n\u00e9rer les valeurs de la colonne \"M-XXXXXX\" data[\"Mouvement de titre Name\"] = [\"M-\" + generer_combinaison_chiffres() for _ in range(len(data))]  # D\u00e9finissez les valeurs possibles pour la colonne \"Nature du mouvement\" valeurs_possibles = ['Souscription'] * 80 + ['Don TDL'] * 7 + ['Rachat'] * 13  # Utilisez numpy.random.choice pour attribuer ces valeurs en fonction des pourcentages data[\"Nature du mouvement\"] = np.random.choice(valeurs_possibles, size=len(data))  # Fonction pour g\u00e9n\u00e9rer des dates al\u00e9atoires entre le 01/01/2006 et aujourd'hui def generate_date_activation():     start_date = datetime(2006, 1, 1)     end_date = datetime.now()     random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))     return random_date  # Appliquer la fonction pour cr\u00e9er la colonne \"Date d'activation\" data['Date d\\'activation'] = [generate_date_activation() for _ in range(len(data))] # G\u00e9n\u00e9rez des dates al\u00e9atoires pour chaque ligne en fonction de \"RFM-Date Premi\u00e8re Souscription\" random_dates = [] for _, row in data.iterrows():     start_date = row['RFM-Date Premi\u00e8re Souscription']     end_date = datetime(2023, 7, 31)     random_date = start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days))     random_dates.append(random_date)  # Ajoutez la colonne \"Date du Mouvement\" au DataFrame data['Date du Mouvement'] = random_dates   # Fonction pour g\u00e9n\u00e9rer \"Nombre d'actions \u00e9chang\u00e9es\" en fonction de \"Nature du mouvement\" def generate_actions_echangees(row):     if row['Nature du mouvement'] == 'Souscription':         return row['Nombre d\\'actions \u00e0 l\\'acquisition']     else:         # V\u00e9rifiez d'abord que \"Nombre d'actions \u00e0 l'acquisition\" est sup\u00e9rieur \u00e0 z\u00e9ro         if row['Nombre d\\'actions \u00e0 l\\'acquisition'] &gt; 0:             # 80% de chance que \"Nombre d'actions \u00e9chang\u00e9es\" soit \u00e9gal \u00e0 \"Nombre d'actions \u00e0 l'acquisition\"             # 20% de chance que \"Nombre d'actions \u00e9chang\u00e9es\" soit strictement inf\u00e9rieur \u00e0 \"Nombre d'actions \u00e0 l'acquisition\"             if np.random.rand() &lt; 0.8:                 return row['Nombre d\\'actions \u00e0 l\\'acquisition']             else:                 return np.random.randint(1, row['Nombre d\\'actions \u00e0 l\\'acquisition'] + 1)         else:             return 0  # Si \"Nombre d'actions \u00e0 l'acquisition\" est z\u00e9ro, \"Nombre d'actions \u00e9chang\u00e9es\" est \u00e9galement z\u00e9ro  # Appliquez la fonction pour cr\u00e9er la colonne \"Nombre d'actions \u00e9chang\u00e9es\" data['Nombre d\\'actions \u00e9chang\u00e9es'] = data.apply(generate_actions_echangees, axis=1)  # Fonction pour g\u00e9n\u00e9rer \"Actions - Date de fin\" en fonction des conditions def generate_actions_date_fin(row):     if row['Nature du mouvement'] == 'Souscription':         # Si \"Nature du mouvement\" est \"Souscription\"         if random.random() &lt; 0.5:             return datetime.now()  # 90% des cas, aujourd'hui         else:             return row['Date du Mouvement'] + timedelta(days=random.randint(1, (datetime.now() - row['Date du Mouvement']).days - 1))     elif (row['Nature du mouvement'] == 'Don TDL' or row['Nature du mouvement'] == 'Rachat') and row['Nombre d\\'actions \u00e0 l\\'acquisition'] == row['Nombre d\\'actions \u00e9chang\u00e9es']:         # Si \"Nature du mouvement\" est \"Don TDL\" ou \"Rachat\" et \"Nombre d'actions \u00e0 l'acquisition\" est \u00e9gal \u00e0 \"Nombre d'actions \u00e9chang\u00e9es\"         return row['Date du Mouvement']     elif (row['Nature du mouvement'] == 'Don TDL' or row['Nature du mouvement'] == 'Rachat') and row['Nombre d\\'actions \u00e0 l\\'acquisition'] &gt; row['Nombre d\\'actions \u00e9chang\u00e9es']:         # Si \"Nature du mouvement\" est \"Don TDL\" ou \"Rachat\" et \"Nombre d'actions \u00e0 l'acquisition\" est sup\u00e9rieur \u00e0 \"Nombre d'actions \u00e9chang\u00e9es\"         if random.random() &lt; 0.9:             return datetime.now()  # 90% des cas, aujourd'hui         else:             return row['Date du Mouvement'] + timedelta(days=random.randint(1, (datetime.now() - row['Date du Mouvement']).days - 1))   # Appliquez la fonction pour cr\u00e9er la colonne \"Actions - Date de fin\" data['Actions - Date de fin'] = data.apply(generate_actions_date_fin, axis=1) In\u00a0[5]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndf = data\ndf_var_tps_reprise = df.copy()\ndf_partrachat = df.copy()\ndf_fid\u00e8le = df.copy()\ndf_doublon = df.copy()\ndf_serie_sous = df.copy()\ndf_serie_sousbis = df.copy()\ndfretraitrepise = df.copy()\ndf_parcoursD = df.copy()\ndf_MS_infos = df.copy()\ndf_info_parcours = df.copy()\ndf_parcours =df.copy()\ndfsousmoy = df.copy()\ndf_parcoursD = df.copy()\ndf_MS_infos = df.copy()\ndf_info_parcours = df.copy()\ndf_parcours =df.copy()\ndfsousmoy = df.copy()\n</pre> import pandas as pd import numpy as np from datetime import datetime, timedelta import warnings warnings.filterwarnings(\"ignore\") df = data df_var_tps_reprise = df.copy() df_partrachat = df.copy() df_fid\u00e8le = df.copy() df_doublon = df.copy() df_serie_sous = df.copy() df_serie_sousbis = df.copy() dfretraitrepise = df.copy() df_parcoursD = df.copy() df_MS_infos = df.copy() df_info_parcours = df.copy() df_parcours =df.copy() dfsousmoy = df.copy() df_parcoursD = df.copy() df_MS_infos = df.copy() df_info_parcours = df.copy() df_parcours =df.copy() dfsousmoy = df.copy() In\u00a0[6]: Copied! <pre>df_parcours1 = df_parcours[df_parcours[\"Nature du mouvement\"] == \"Souscription\"]\ndf_parcours1['Ann\u00e9e souscription'] = 'souscription_en_' + df_parcours1['Date du Mouvement'].dt.year.astype(str)\ndf_parcours1 = df_parcours1.sort_values(by=['ID du contact', \"Date du Mouvement\"])\ndf_parcours1 = df_parcours1[[\"Nom complet\",\"ID du contact\", \"Ann\u00e9e souscription\",\"Nombre d'actions \u00e0 l'acquisition\"]]\ndf_parcours1 = df_parcours1.pivot_table(index=['Nom complet','ID du contact'], columns='Ann\u00e9e souscription', values='Nombre d\\'actions \u00e0 l\\'acquisition', aggfunc='sum')\ndf_parcours2 = df_parcours[df_parcours[\"Nature du mouvement\"] == \"Rachat\"]\ndf_parcours2['Ann\u00e9e rachat'] = 'Rachat_en_' + df_parcours2['Date du Mouvement'].dt.year.astype(str)\ndf_parcours2 = df_parcours2.sort_values(by=['ID du contact', \"Date du Mouvement\"])\ndf_parcours2 = df_parcours2[[\"Nom complet\",\"ID du contact\", \"Ann\u00e9e rachat\",\"Nombre d'actions \u00e9chang\u00e9es\"]]\ndf_parcours2 = df_parcours2.pivot_table(index=['Nom complet','ID du contact'], columns='Ann\u00e9e rachat', values='Nombre d\\'actions \u00e9chang\u00e9es', aggfunc='sum')\ndf_parcours1 = df_parcours1.reset_index()\ndf_parcours2 = df_parcours2.reset_index()\ndf_parcours = df_parcours1.merge(df_parcours2, on=['Nom complet', 'ID du contact'], how='left')\nconditions = [\n    (df_info_parcours['\u00e2ge'] &lt; 25),\n    (df_info_parcours['\u00e2ge'] &lt; 40),\n    (df_info_parcours['\u00e2ge'] &lt; 60)\n]\n\nchoices = ['0-25 ans', '25-40 ans', '40-60 ans']\n\ndf_info_parcours['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus')\ndf_info_parcours['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_info_parcours['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)\n\nconditions = [\n     (df_info_parcours['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),\n     (df_info_parcours['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017'))\n]\n\nchoices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']\n\ndf_info_parcours['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus')\ndf_info_parcours['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_info_parcours['RFM-Date Premi\u00e8re Souscription'], format='%d/%m/%Y')\ndf_info_parcours['r\u00e9partition ann\u00e9e nouveau actionnaire'] = df_info_parcours['RFM-Date Premi\u00e8re Souscription'].dt.year\ntwenty4_months_ago = datetime.now() - timedelta(days=730)\ndf_info_parcours['RFM-Date Dernier Don'] = pd.to_datetime(df_info_parcours['RFM-Date Dernier Don'], format='%d/%m/%Y')\n\ndf_info_parcours.loc[:, \"multi-casquette ?\"] = df_info_parcours.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Plus actionnaire\" if row[\"Actionnaire ?\"] == 0 \n                                            else \"Actionaire uniquement\", axis=1)\ncolonnes_suppr = [\n    'Type d\\'enregistrement des contrats',\n       'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal',\n       'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',\n       'Date d\\'activation', 'Date du Mouvement', 'Actions - Date de fin',\n       'Nombre d\\'actions \u00e9chang\u00e9es'\n]\ndf_info_parcours = df_info_parcours.drop_duplicates(subset=\"ID du contact\")\ndf_info_parcours = df_info_parcours.drop(columns=colonnes_suppr)\ndf_MS_infos = df_MS_infos[(df_MS_infos[\"Nature du mouvement\"] == \"Souscription\") | (df_MS_infos[\"Nature du mouvement\"] == \"Rachat\")]\ndf_MS_infos = df_MS_infos.sort_values(by = [\"ID du contact\", \"Nature du mouvement\", \"Date du Mouvement\"])\ndf_MS_infos = df_MS_infos[[\"Nom complet\",\"ID du contact\",\"Nature du mouvement\"]]\ndf_MS_infos = df_MS_infos.groupby([\"ID du contact\", \"Nature du mouvement\"]).size().reset_index(name='Nombre de SS et de rachats')\ndf_MS_infos = df_MS_infos.pivot_table(index=['ID du contact'], columns='Nature du mouvement', values='Nombre de SS et de rachats', aggfunc='sum')\ndf_info_parcours = df_info_parcours.merge(df_MS_infos, on=[ 'ID du contact'], how='left')\ndf_info_parcours = df_info_parcours.rename(columns={'Rachat': 'Nombre de rachats'})\ndf_info_parcours = df_info_parcours.rename(columns={'Souscription': 'Nombre de souscriptions'})\ndf_parcours = df_parcours.merge(df_info_parcours, on=[\"Nom complet\",'ID du contact'], how='left')\ndf_parcours['multi-souscripteur ?'] = df_parcours['Nombre de souscriptions'].apply(lambda x: x &gt; 1)\ndfsousmoy = dfsousmoy[dfsousmoy[\"Nature du mouvement\"] == \"Souscription\"]\ndfsousmoy['Nombre de souscriptions'] = dfsousmoy['ID du contact'].map(df['ID du contact'].value_counts())\ndfsousmoy = dfsousmoy[[\"ID du contact\", 'Nombre de souscriptions', \"Nombre d'actions \u00e0 l'acquisition\"]]\ndfsousmoy = dfsousmoy.groupby('ID du contact').agg({'Nombre de souscriptions': 'first', 'Nombre d\\'actions \u00e0 l\\'acquisition': 'sum'}).reset_index()\ndfsousmoy[\"Nombre moyen d'actions par souscription\"] = dfsousmoy[\"Nombre d'actions \u00e0 l'acquisition\"]/dfsousmoy[\"Nombre de souscriptions\"]\ndfsousmoy = dfsousmoy[[\"ID du contact\", \"Nombre moyen d'actions par souscription\"]]\ndf_parcours = df_parcours.merge(dfsousmoy, on=['ID du contact'], how='left')\ndf_parcoursD = df_parcoursD[df_parcoursD[\"Actionnaire ?\"] == True]\ndf_parcoursD = df_parcoursD.drop_duplicates(subset = \"ID du contact\")\ndf_parcoursD = df_parcoursD[[\"ID du contact\",\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"]]\n# Calculer les d\u00e9ciles avec des intervalles \u00e9gaux\ndeciles = pd.qcut(df_parcoursD[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=11, duplicates='drop')\n# En utilisant duplicates='drop'  la fonction supprimera les bornes en double. Cela signifie que si deux valeurs identiques tombent exactement sur une limite d'intervalle, l'une des bornes sera supprim\u00e9e, de sorte que chaque limite d'intervalle est unique. Cela peut entra\u00eener un nombre r\u00e9duit d'intervalles si vos donn\u00e9es ont beaucoup de valeurs identiques.Il faut donc pr\u00e9voir des intervalles en plus pour en sp\u00e9cifier 10  soit utiliser q = 11 au lieu de 10 \n# Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles\ndf_parcoursD['d\u00e9ciles actionnaire'] = deciles\ndf_parcoursD['d\u00e9ciles actionnaire'] = df_parcoursD['d\u00e9ciles actionnaire'].cat.codes + 1\n\n# Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d10\ndf_parcoursD['D\u00e9ciles actionnaires'] = 'D\u00e9cile ' + df_parcoursD['d\u00e9ciles actionnaire'].astype(str)\ndf_parcoursD = df_parcoursD[[\"ID du contact\",\"D\u00e9ciles actionnaires\"]]\ndf_parcours = df_parcours.merge(df_parcoursD, on=['ID du contact'], how='left')\ndf_parcours['D\u00e9ciles actionnaires'] = df_parcours['D\u00e9ciles actionnaires'].fillna('plus actionnaire')\n</pre> df_parcours1 = df_parcours[df_parcours[\"Nature du mouvement\"] == \"Souscription\"] df_parcours1['Ann\u00e9e souscription'] = 'souscription_en_' + df_parcours1['Date du Mouvement'].dt.year.astype(str) df_parcours1 = df_parcours1.sort_values(by=['ID du contact', \"Date du Mouvement\"]) df_parcours1 = df_parcours1[[\"Nom complet\",\"ID du contact\", \"Ann\u00e9e souscription\",\"Nombre d'actions \u00e0 l'acquisition\"]] df_parcours1 = df_parcours1.pivot_table(index=['Nom complet','ID du contact'], columns='Ann\u00e9e souscription', values='Nombre d\\'actions \u00e0 l\\'acquisition', aggfunc='sum') df_parcours2 = df_parcours[df_parcours[\"Nature du mouvement\"] == \"Rachat\"] df_parcours2['Ann\u00e9e rachat'] = 'Rachat_en_' + df_parcours2['Date du Mouvement'].dt.year.astype(str) df_parcours2 = df_parcours2.sort_values(by=['ID du contact', \"Date du Mouvement\"]) df_parcours2 = df_parcours2[[\"Nom complet\",\"ID du contact\", \"Ann\u00e9e rachat\",\"Nombre d'actions \u00e9chang\u00e9es\"]] df_parcours2 = df_parcours2.pivot_table(index=['Nom complet','ID du contact'], columns='Ann\u00e9e rachat', values='Nombre d\\'actions \u00e9chang\u00e9es', aggfunc='sum') df_parcours1 = df_parcours1.reset_index() df_parcours2 = df_parcours2.reset_index() df_parcours = df_parcours1.merge(df_parcours2, on=['Nom complet', 'ID du contact'], how='left') conditions = [     (df_info_parcours['\u00e2ge'] &lt; 25),     (df_info_parcours['\u00e2ge'] &lt; 40),     (df_info_parcours['\u00e2ge'] &lt; 60) ]  choices = ['0-25 ans', '25-40 ans', '40-60 ans']  df_info_parcours['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus') df_info_parcours['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_info_parcours['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)  conditions = [      (df_info_parcours['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),      (df_info_parcours['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017')) ]  choices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']  df_info_parcours['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus') df_info_parcours['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_info_parcours['RFM-Date Premi\u00e8re Souscription'], format='%d/%m/%Y') df_info_parcours['r\u00e9partition ann\u00e9e nouveau actionnaire'] = df_info_parcours['RFM-Date Premi\u00e8re Souscription'].dt.year twenty4_months_ago = datetime.now() - timedelta(days=730) df_info_parcours['RFM-Date Dernier Don'] = pd.to_datetime(df_info_parcours['RFM-Date Dernier Don'], format='%d/%m/%Y')  df_info_parcours.loc[:, \"multi-casquette ?\"] = df_info_parcours.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Plus actionnaire\" if row[\"Actionnaire ?\"] == 0                                              else \"Actionaire uniquement\", axis=1) colonnes_suppr = [     'Type d\\'enregistrement des contrats',        'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal',        'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',        'Date d\\'activation', 'Date du Mouvement', 'Actions - Date de fin',        'Nombre d\\'actions \u00e9chang\u00e9es' ] df_info_parcours = df_info_parcours.drop_duplicates(subset=\"ID du contact\") df_info_parcours = df_info_parcours.drop(columns=colonnes_suppr) df_MS_infos = df_MS_infos[(df_MS_infos[\"Nature du mouvement\"] == \"Souscription\") | (df_MS_infos[\"Nature du mouvement\"] == \"Rachat\")] df_MS_infos = df_MS_infos.sort_values(by = [\"ID du contact\", \"Nature du mouvement\", \"Date du Mouvement\"]) df_MS_infos = df_MS_infos[[\"Nom complet\",\"ID du contact\",\"Nature du mouvement\"]] df_MS_infos = df_MS_infos.groupby([\"ID du contact\", \"Nature du mouvement\"]).size().reset_index(name='Nombre de SS et de rachats') df_MS_infos = df_MS_infos.pivot_table(index=['ID du contact'], columns='Nature du mouvement', values='Nombre de SS et de rachats', aggfunc='sum') df_info_parcours = df_info_parcours.merge(df_MS_infos, on=[ 'ID du contact'], how='left') df_info_parcours = df_info_parcours.rename(columns={'Rachat': 'Nombre de rachats'}) df_info_parcours = df_info_parcours.rename(columns={'Souscription': 'Nombre de souscriptions'}) df_parcours = df_parcours.merge(df_info_parcours, on=[\"Nom complet\",'ID du contact'], how='left') df_parcours['multi-souscripteur ?'] = df_parcours['Nombre de souscriptions'].apply(lambda x: x &gt; 1) dfsousmoy = dfsousmoy[dfsousmoy[\"Nature du mouvement\"] == \"Souscription\"] dfsousmoy['Nombre de souscriptions'] = dfsousmoy['ID du contact'].map(df['ID du contact'].value_counts()) dfsousmoy = dfsousmoy[[\"ID du contact\", 'Nombre de souscriptions', \"Nombre d'actions \u00e0 l'acquisition\"]] dfsousmoy = dfsousmoy.groupby('ID du contact').agg({'Nombre de souscriptions': 'first', 'Nombre d\\'actions \u00e0 l\\'acquisition': 'sum'}).reset_index() dfsousmoy[\"Nombre moyen d'actions par souscription\"] = dfsousmoy[\"Nombre d'actions \u00e0 l'acquisition\"]/dfsousmoy[\"Nombre de souscriptions\"] dfsousmoy = dfsousmoy[[\"ID du contact\", \"Nombre moyen d'actions par souscription\"]] df_parcours = df_parcours.merge(dfsousmoy, on=['ID du contact'], how='left') df_parcoursD = df_parcoursD[df_parcoursD[\"Actionnaire ?\"] == True] df_parcoursD = df_parcoursD.drop_duplicates(subset = \"ID du contact\") df_parcoursD = df_parcoursD[[\"ID du contact\",\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"]] # Calculer les d\u00e9ciles avec des intervalles \u00e9gaux deciles = pd.qcut(df_parcoursD[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=11, duplicates='drop') # En utilisant duplicates='drop'  la fonction supprimera les bornes en double. Cela signifie que si deux valeurs identiques tombent exactement sur une limite d'intervalle, l'une des bornes sera supprim\u00e9e, de sorte que chaque limite d'intervalle est unique. Cela peut entra\u00eener un nombre r\u00e9duit d'intervalles si vos donn\u00e9es ont beaucoup de valeurs identiques.Il faut donc pr\u00e9voir des intervalles en plus pour en sp\u00e9cifier 10  soit utiliser q = 11 au lieu de 10  # Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles df_parcoursD['d\u00e9ciles actionnaire'] = deciles df_parcoursD['d\u00e9ciles actionnaire'] = df_parcoursD['d\u00e9ciles actionnaire'].cat.codes + 1  # Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d10 df_parcoursD['D\u00e9ciles actionnaires'] = 'D\u00e9cile ' + df_parcoursD['d\u00e9ciles actionnaire'].astype(str) df_parcoursD = df_parcoursD[[\"ID du contact\",\"D\u00e9ciles actionnaires\"]] df_parcours = df_parcours.merge(df_parcoursD, on=['ID du contact'], how='left') df_parcours['D\u00e9ciles actionnaires'] = df_parcours['D\u00e9ciles actionnaires'].fillna('plus actionnaire') In\u00a0[7]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf['Difference d\u00e9but fin'] = df['Nombre d\\'actions \u00e0 l\\'acquisition'] - df['Nombre d\\'actions \u00e9chang\u00e9es']\n\ndf['retrait complet ou partiel'] = df['Difference d\u00e9but fin'].apply(lambda x: 'retrait complet' if x == 0 else 'retrait partiel')\n\ndf['ann\u00e9e rachat'] = df['Date du Mouvement'].dt.year\n\n\ndf['Date d\\'activation'] = pd.to_datetime(df['Date d\\'activation'])\n\n\ndf['Date d\\'activation'] = df['Date d\\'activation'].dt.floor('D')\n\ndf['Date du Mouvement'] = pd.to_datetime(df['Date du Mouvement'], dayfirst=True)\n\ndf['dur\u00e9e conservation'] = df['Date du Mouvement'] - df['Date d\\'activation']\ndf_don = df[df[\"Nature du mouvement\"] == \"Don TDL\"]\ndf_dongraph = df[df[\"Nature du mouvement\"] == \"Don TDL\"]\n\ndf_rachat = df[df[\"Nature du mouvement\"] == \"Rachat\"]\n</pre> import warnings warnings.filterwarnings(\"ignore\")   df['Difference d\u00e9but fin'] = df['Nombre d\\'actions \u00e0 l\\'acquisition'] - df['Nombre d\\'actions \u00e9chang\u00e9es']  df['retrait complet ou partiel'] = df['Difference d\u00e9but fin'].apply(lambda x: 'retrait complet' if x == 0 else 'retrait partiel')  df['ann\u00e9e rachat'] = df['Date du Mouvement'].dt.year   df['Date d\\'activation'] = pd.to_datetime(df['Date d\\'activation'])   df['Date d\\'activation'] = df['Date d\\'activation'].dt.floor('D')  df['Date du Mouvement'] = pd.to_datetime(df['Date du Mouvement'], dayfirst=True)  df['dur\u00e9e conservation'] = df['Date du Mouvement'] - df['Date d\\'activation'] df_don = df[df[\"Nature du mouvement\"] == \"Don TDL\"] df_dongraph = df[df[\"Nature du mouvement\"] == \"Don TDL\"]  df_rachat = df[df[\"Nature du mouvement\"] == \"Rachat\"]  In\u00a0[8]: Copied! <pre>import numpy as np\n\n# Convertir la colonne en type cha\u00eene de caract\u00e8res\ndf['Date d\\'activation'] = df['Date d\\'activation'].astype(str)\n\n# Extraire l'ann\u00e9e de la colonne \"Date d'activation\" et cr\u00e9er une nouvelle colonne\ndf['r\u00e9partition ann\u00e9e'] = df['Date d\\'activation'].str.extract(r'(\\d{4})')\n\n\n\n\n\nconditions = [\n    (df['\u00e2ge'] &lt; 25),\n    (df['\u00e2ge'] &lt; 40),\n    (df['\u00e2ge'] &lt; 60)\n]\n\nchoices = ['0-25 ans', '25-40 ans', '40-60 ans']\n\ndf['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus')\n</pre> import numpy as np  # Convertir la colonne en type cha\u00eene de caract\u00e8res df['Date d\\'activation'] = df['Date d\\'activation'].astype(str)  # Extraire l'ann\u00e9e de la colonne \"Date d'activation\" et cr\u00e9er une nouvelle colonne df['r\u00e9partition ann\u00e9e'] = df['Date d\\'activation'].str.extract(r'(\\d{4})')      conditions = [     (df['\u00e2ge'] &lt; 25),     (df['\u00e2ge'] &lt; 40),     (df['\u00e2ge'] &lt; 60) ]  choices = ['0-25 ans', '25-40 ans', '40-60 ans']  df['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus') In\u00a0[9]: Copied! <pre>df['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)\n\nconditions = [\n     (df['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),\n     (df['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017'))\n]\n\nchoices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']\n\ndf['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus')\ndf['RFM-Date Premi\u00e8re Souscription'] = df['RFM-Date Premi\u00e8re Souscription'].astype(str)\ndf['r\u00e9partition ann\u00e9e nouveau actionnaire'] = df['RFM-Date Premi\u00e8re Souscription'].str.extract(r'(\\d{4})')\n</pre> df['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)  conditions = [      (df['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),      (df['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017')) ]  choices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']  df['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus') df['RFM-Date Premi\u00e8re Souscription'] = df['RFM-Date Premi\u00e8re Souscription'].astype(str) df['r\u00e9partition ann\u00e9e nouveau actionnaire'] = df['RFM-Date Premi\u00e8re Souscription'].str.extract(r'(\\d{4})')  In\u00a0[10]: Copied! <pre>dfpiechart = df[(df[\"Actionnaire ?\"]==1) &amp; (df[\"Nature du mouvement\"] == \"Souscription\")]\ndfpiechart = dfpiechart.drop_duplicates(subset=\"ID du contact\")\n</pre> dfpiechart = df[(df[\"Actionnaire ?\"]==1) &amp; (df[\"Nature du mouvement\"] == \"Souscription\")] dfpiechart = dfpiechart.drop_duplicates(subset=\"ID du contact\") In\u00a0[11]: Copied! <pre>dfpiechart1 = df[df[\"Nature du mouvement\"] == \"Souscription\"]\ndfpiechart1 = dfpiechart1.drop_duplicates(subset=\"ID du contact\")\n</pre> dfpiechart1 = df[df[\"Nature du mouvement\"] == \"Souscription\"] dfpiechart1 = dfpiechart1.drop_duplicates(subset=\"ID du contact\") In\u00a0[12]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = dfpiechart['anciennet\u00e9 actionnaires'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\nplt.title(\"R\u00e9partition des actionnaires par anciennet\u00e9\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = dfpiechart['anciennet\u00e9 actionnaires'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90) plt.title(\"R\u00e9partition des actionnaires par anciennet\u00e9\")    # Afficher le graphique plt.show()  In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\n \n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = dfpiechart['cat\u00e9gories \u00e2ge'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\nplt.title(\"Actionnaires par cat\u00e9gories d'\u00e2ge\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt    # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = dfpiechart['cat\u00e9gories \u00e2ge'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90) plt.title(\"Actionnaires par cat\u00e9gories d'\u00e2ge\")    # Afficher le graphique plt.show()   In\u00a0[14]: Copied! <pre>dfpiechart.rename(columns={'Territoire Terre de Liens': 'Territoire d\\'habitation renseign\u00e9'}, inplace=True)\n</pre> dfpiechart.rename(columns={'Territoire Terre de Liens': 'Territoire d\\'habitation renseign\u00e9'}, inplace=True) In\u00a0[15]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h2&gt;Cr\u00e9ation distinction multi casquette et multi souscripteur, r\u00e9partition des actionnaires par nombre de souscriptions, cat\u00e9gories de souscriptions par nombre d'actions&lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML   # Ins\u00e9rer un saut de page display(HTML(\"\")) # Afficher un titre avec une taille de police plus grande display(HTML(\"Cr\u00e9ation distinction multi casquette et multi souscripteur, r\u00e9partition des actionnaires par nombre de souscriptions, cat\u00e9gories de souscriptions par nombre d'actions\")) Cr\u00e9ation distinction multi casquette et multi souscripteur, r\u00e9partition des actionnaires par nombre de souscriptions, cat\u00e9gories de souscriptions par nombre d'actions In\u00a0[16]: Copied! <pre>from datetime import datetime, timedelta\n\ndf['RFM-Date Dernier Don'] = pd.to_datetime(df['RFM-Date Dernier Don'], format='%d/%m/%Y')\n\ndf2 = df[df[\"Nature du mouvement\"]==\"Souscription\"]\ndf3 = df2[df2[\"Actionnaire ?\"]==1]\ntwenty4_months_ago = datetime.now() - timedelta(days=730)\ndf3.loc[:, \"multi-casquette ?\"] = df3.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Actionnaire uniquement\", axis=1)\n\ndf3.loc[:, 'multi-souscripteur ?'] = df3.duplicated(subset='ID du contact', keep=False)\n\ndf3.loc[:, 'Nombre de souscriptions'] = 1\n\ndf_MS = df3.groupby('ID du contact').agg({\"Nombre d'actions \u00e0 l'acquisition\": 'sum', 'Nombre de souscriptions': 'sum'})\n\ndf_MS\n\nconditions = [\n     (df_MS['Nombre de souscriptions'] &lt; 2),\n     (df_MS['Nombre de souscriptions'] &lt;3),\n     (df_MS['Nombre de souscriptions'] &lt;=5),\n     (df_MS['Nombre de souscriptions'] &lt;=10),\n]\n\nchoices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]\n\ndf_MS['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')\n\ndf_MS = df_MS.merge(df3[['ID du contact','multi-casquette ?','multi-souscripteur ?','anciennet\u00e9 actionnaires','cat\u00e9gories \u00e2ge', \"Territoire Terre de Liens\"]], on='ID du contact', how='left')\ndf_MS = df_MS.drop_duplicates(subset = \"ID du contact\")\nimport pandas as pd\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = df_MS['Cat\u00e9gories souscripteurs'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le DataFrame \u00e0 partir des valeurs calcul\u00e9es\ndf_cat_nbactions = pd.DataFrame({'Cat\u00e9gories souscripteurs': counts.index,\n                         'Nombre de souscripteurs': counts.values,\n                         'Pourcentage': percentages.values})\n\n\ndf_cat_nbactions\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=20)\nplt.title(\"R\u00e9partitions des actionnaires par nombre de souscriptions\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> from datetime import datetime, timedelta  df['RFM-Date Dernier Don'] = pd.to_datetime(df['RFM-Date Dernier Don'], format='%d/%m/%Y')  df2 = df[df[\"Nature du mouvement\"]==\"Souscription\"] df3 = df2[df2[\"Actionnaire ?\"]==1] twenty4_months_ago = datetime.now() - timedelta(days=730) df3.loc[:, \"multi-casquette ?\"] = df3.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Actionnaire uniquement\", axis=1)  df3.loc[:, 'multi-souscripteur ?'] = df3.duplicated(subset='ID du contact', keep=False)  df3.loc[:, 'Nombre de souscriptions'] = 1  df_MS = df3.groupby('ID du contact').agg({\"Nombre d'actions \u00e0 l'acquisition\": 'sum', 'Nombre de souscriptions': 'sum'})  df_MS  conditions = [      (df_MS['Nombre de souscriptions'] &lt; 2),      (df_MS['Nombre de souscriptions'] &lt;3),      (df_MS['Nombre de souscriptions'] &lt;=5),      (df_MS['Nombre de souscriptions'] &lt;=10), ]  choices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]  df_MS['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')  df_MS = df_MS.merge(df3[['ID du contact','multi-casquette ?','multi-souscripteur ?','anciennet\u00e9 actionnaires','cat\u00e9gories \u00e2ge', \"Territoire Terre de Liens\"]], on='ID du contact', how='left') df_MS = df_MS.drop_duplicates(subset = \"ID du contact\") import pandas as pd  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = df_MS['Cat\u00e9gories souscripteurs'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le DataFrame \u00e0 partir des valeurs calcul\u00e9es df_cat_nbactions = pd.DataFrame({'Cat\u00e9gories souscripteurs': counts.index,                          'Nombre de souscripteurs': counts.values,                          'Pourcentage': percentages.values})   df_cat_nbactions  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=20) plt.title(\"R\u00e9partitions des actionnaires par nombre de souscriptions\")    # Afficher le graphique plt.show()   In\u00a0[17]: Copied! <pre>df2 = df.copy()\ndf2= df2[df2[\"Nature du mouvement\"]== \"Souscription\"]\n\ndf2[\"cat\u00e9gorie souscription\"] = df2.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5\n                                          else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50\n                                          else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100\n                                          else \"Souscriptions de plus de 100 actions\",\n                                          axis = 1) \n\ncounts = df2['cat\u00e9gorie souscription'].value_counts()\npercentages = counts / counts.sum() * 100\n\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=20)\nplt.title(\"R\u00e9partitions des  souscriptions par nombre d'actions\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> df2 = df.copy() df2= df2[df2[\"Nature du mouvement\"]== \"Souscription\"]  df2[\"cat\u00e9gorie souscription\"] = df2.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5                                           else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50                                           else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100                                           else \"Souscriptions de plus de 100 actions\",                                           axis = 1)   counts = df2['cat\u00e9gorie souscription'].value_counts() percentages = counts / counts.sum() * 100  plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=20) plt.title(\"R\u00e9partitions des  souscriptions par nombre d'actions\")    # Afficher le graphique plt.show()  In\u00a0[18]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = df_MS['multi-casquette ?'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=180)\nplt.title(\"R\u00e9partition des actionnaires en fonction de leurs autres r\u00f4les\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = df_MS['multi-casquette ?'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=180) plt.title(\"R\u00e9partition des actionnaires en fonction de leurs autres r\u00f4les\")    # Afficher le graphique plt.show() In\u00a0[19]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il s'agit de savoir si les actionnaires actuels sont \u00e9galement donateurs N ou adh\u00e9rent N ou les 3 \u00e0 la fois (triples-casquettes)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il s'agit de savoir si les actionnaires actuels sont \u00e9galement donateurs N ou adh\u00e9rent N ou les 3 \u00e0 la fois (triples-casquettes)\")) Il s'agit de savoir si les actionnaires actuels sont \u00e9galement donateurs N ou adh\u00e9rent N ou les 3 \u00e0 la fois (triples-casquettes) In\u00a0[20]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;On se rend compte que si l'actionnaire est multi-engag\u00e9, il privil\u00e9gie les 3 types d'engagement combin\u00e9s&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"On se rend compte que si l'actionnaire est multi-engag\u00e9, il privil\u00e9gie les 3 types d'engagement combin\u00e9s\")) On se rend compte que si l'actionnaire est multi-engag\u00e9, il privil\u00e9gie les 3 types d'engagement combin\u00e9s In\u00a0[21]: Copied! <pre>df_MS['multi-souscripteur ?'] = df_MS ['multi-souscripteur ?'].replace({True: \"multi-souscripteurs\", False: \"souscripteurs uniques\"})\n</pre> df_MS['multi-souscripteur ?'] = df_MS ['multi-souscripteur ?'].replace({True: \"multi-souscripteurs\", False: \"souscripteurs uniques\"})  In\u00a0[22]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = df_MS ['multi-souscripteur ?'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\nplt.title(\"R\u00e9partition des types d'actionnaires en fonction du nombre de souscriptions d\u00e9tenues\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = df_MS ['multi-souscripteur ?'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90) plt.title(\"R\u00e9partition des types d'actionnaires en fonction du nombre de souscriptions d\u00e9tenues\")    # Afficher le graphique plt.show() In\u00a0[23]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Sont souscripteurs uniques les actionnaires qui n'ont qu'une seule souscription et sont multi-souscripteurs les actionnaires qui ont plus d'une souscription&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Sont souscripteurs uniques les actionnaires qui n'ont qu'une seule souscription et sont multi-souscripteurs les actionnaires qui ont plus d'une souscription\")) Sont souscripteurs uniques les actionnaires qui n'ont qu'une seule souscription et sont multi-souscripteurs les actionnaires qui ont plus d'une souscription In\u00a0[24]: Copied! <pre>from IPython.display import display, HTML\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre avec une taille de police plus grande et soulign\u00e9\ndisplay(HTML(\"&lt;h2&gt;&lt;u&gt;Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multisouscripteurs, multi-souscription et multi-casquette&lt;/u&gt;&lt;/h2&gt;\"))\n</pre> from IPython.display import display, HTML  # Ins\u00e9rer un saut de page display(HTML(\"\"))  # Afficher un titre avec une taille de police plus grande et soulign\u00e9 display(HTML(\"Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multisouscripteurs, multi-souscription et multi-casquette\"))  Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multisouscripteurs, multi-souscription et multi-casquette In\u00a0[25]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h2&gt;Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multis-souscripteurs, multi-souscription et multi-casquette&lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multis-souscripteurs, multi-souscription et multi-casquette\")) Croisement donn\u00e9es \u00e2ges, territoire terre de liens, anciennet\u00e9 des actionnaires, cat\u00e9gories des multis-souscripteurs, multi-souscription et multi-casquette In\u00a0[26]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des actionnaires en fonction du nombre de souscriptions et de leur \u00e2ge&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des actionnaires en fonction du nombre de souscriptions et de leur \u00e2ge\")) R\u00e9partition des actionnaires en fonction du nombre de souscriptions et de leur \u00e2ge In\u00a0[27]: Copied! <pre>df_MS_age = pd.crosstab(index=df_MS['cat\u00e9gories \u00e2ge'], columns=df_MS['Cat\u00e9gories souscripteurs'], margins=True, margins_name='Total')\nnew_column_order = [\"1 souscription\",\"2 souscriptions\", \"3 \u00e0 5 souscriptions\", \"6 \u00e0 10 souscriptions\", \"10 souscriptions et plus\",\"Total\"]\ndf_MS_age = df_MS_age.reindex(columns=new_column_order)\ndf_MS_age\n</pre> df_MS_age = pd.crosstab(index=df_MS['cat\u00e9gories \u00e2ge'], columns=df_MS['Cat\u00e9gories souscripteurs'], margins=True, margins_name='Total') new_column_order = [\"1 souscription\",\"2 souscriptions\", \"3 \u00e0 5 souscriptions\", \"6 \u00e0 10 souscriptions\", \"10 souscriptions et plus\",\"Total\"] df_MS_age = df_MS_age.reindex(columns=new_column_order) df_MS_age Out[27]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total cat\u00e9gories \u00e2ge 0-25 ans 1458 683 308 25 0 2474 25-40 ans 789 382 191 9 2 1373 40-60 ans 1129 539 242 17 5 1932 60 ans et plus 1780 870 329 21 7 3007 Total 5156 2474 1070 72 14 8786 In\u00a0[28]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;% de r\u00e9partition entre les cat\u00e9gories d'\u00e2ges pour chaque cat\u00e9gorie de souscription&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"% de r\u00e9partition entre les cat\u00e9gories d'\u00e2ges pour chaque cat\u00e9gorie de souscription\")) % de r\u00e9partition entre les cat\u00e9gories d'\u00e2ges pour chaque cat\u00e9gorie de souscription In\u00a0[29]: Copied! <pre>df_col_percent = df_MS_age.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent\n</pre> df_col_percent = df_MS_age.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent Out[29]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total cat\u00e9gories \u00e2ge 0-25 ans 28.3 27.6 28.8 34.7 0.0 28.2 25-40 ans 15.3 15.4 17.9 12.5 14.3 15.6 40-60 ans 21.9 21.8 22.6 23.6 35.7 22.0 60 ans et plus 34.5 35.2 30.7 29.2 50.0 34.2 Total 100.0 100.0 100.0 100.0 100.0 100.0 In\u00a0[30]: Copied! <pre>df_row_percent = df_MS_age.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_MS_age.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent Out[30]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total cat\u00e9gories \u00e2ge 0-25 ans 58.9 27.6 12.4 1.0 0.0 99.9 25-40 ans 57.5 27.8 13.9 0.7 0.1 100.0 40-60 ans 58.4 27.9 12.5 0.9 0.3 100.0 60 ans et plus 59.2 28.9 10.9 0.7 0.2 99.9 Total 58.7 28.2 12.2 0.8 0.2 100.1 In\u00a0[31]: Copied! <pre>df5 = df3.drop_duplicates(subset=\"ID du contact\")\n</pre> df5 = df3.drop_duplicates(subset=\"ID du contact\") In\u00a0[32]: Copied! <pre>df_age_MS = pd.crosstab(index=df_MS['cat\u00e9gories \u00e2ge'], columns=df_MS['multi-souscripteur ?'], margins=True, margins_name='Total')\ndf_age_MS\n</pre> df_age_MS = pd.crosstab(index=df_MS['cat\u00e9gories \u00e2ge'], columns=df_MS['multi-souscripteur ?'], margins=True, margins_name='Total') df_age_MS Out[32]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total cat\u00e9gories \u00e2ge 0-25 ans 1016 1458 2474 25-40 ans 584 789 1373 40-60 ans 803 1129 1932 60 ans et plus 1227 1780 3007 Total 3630 5156 8786 In\u00a0[33]: Copied! <pre>df_col_percent = df_age_MS.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent\n</pre> df_col_percent = df_age_MS.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent Out[33]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total cat\u00e9gories \u00e2ge 0-25 ans 28.0 28.3 28.2 25-40 ans 16.1 15.3 15.6 40-60 ans 22.1 21.9 22.0 60 ans et plus 33.8 34.5 34.2 Total 100.0 100.0 100.0 In\u00a0[34]: Copied! <pre>df_row_percent = df_age_MS.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_age_MS.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent Out[34]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total cat\u00e9gories \u00e2ge 0-25 ans 41.1 58.9 100.0 25-40 ans 42.5 57.5 100.0 40-60 ans 41.6 58.4 100.0 60 ans et plus 40.8 59.2 100.0 Total 41.3 58.7 100.0 In\u00a0[35]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Cat\u00e9gories des multi-souscripteurs et multi-engagnement ?&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cat\u00e9gories des multi-souscripteurs et multi-engagnement ?\")) Cat\u00e9gories des multi-souscripteurs et multi-engagnement ? In\u00a0[36]: Copied! <pre>ordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\ndf_MS_MC = pd.crosstab(index=df_MS['multi-casquette ?'], columns=df_MS['Cat\u00e9gories souscripteurs'], margins=True, margins_name='Total')\ndf_MS_MC = df_MS_MC[ordre_categories + ['Total']]  \ndf_MS_MC\n</pre> ordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] df_MS_MC = pd.crosstab(index=df_MS['multi-casquette ?'], columns=df_MS['Cat\u00e9gories souscripteurs'], margins=True, margins_name='Total') df_MS_MC = df_MS_MC[ordre_categories + ['Total']]   df_MS_MC Out[36]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total multi-casquette ? Actionnaire uniquement 632 265 122 4 1 1024 Actionnaire-adh\u00e9rent 1805 924 385 30 4 3148 Actionnaire-donateur 681 344 130 11 5 1171 Triple-engagement 2038 941 433 27 4 3443 Total 5156 2474 1070 72 14 8786 In\u00a0[37]: Copied! <pre>df_col_percent = df_MS_MC.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent\n</pre> df_col_percent = df_MS_MC.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent Out[37]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total multi-casquette ? Actionnaire uniquement 12.3 10.7 11.4 5.6 7.1 11.7 Actionnaire-adh\u00e9rent 35.0 37.3 36.0 41.7 28.6 35.8 Actionnaire-donateur 13.2 13.9 12.1 15.3 35.7 13.3 Triple-engagement 39.5 38.0 40.5 37.5 28.6 39.2 Total 100.0 99.9 100.0 100.1 100.0 100.0 In\u00a0[38]: Copied! <pre>df_row_percent = df_MS_MC.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_MS_MC.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent Out[38]: Cat\u00e9gories souscripteurs 1 souscription 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions 10 souscriptions et plus Total multi-casquette ? Actionnaire uniquement 61.7 25.9 11.9 0.4 0.1 100.0 Actionnaire-adh\u00e9rent 57.3 29.4 12.2 1.0 0.1 100.0 Actionnaire-donateur 58.2 29.4 11.1 0.9 0.4 100.0 Triple-engagement 59.2 27.3 12.6 0.8 0.1 100.0 Total 58.7 28.2 12.2 0.8 0.2 100.1 In\u00a0[39]: Copied! <pre>df_nbcrois\u00e9s = pd.crosstab(index=df_MS['multi-casquette ?'], columns=df_MS['multi-souscripteur ?'], margins=True, margins_name='Total')\ndf_nbcrois\u00e9s\n</pre> df_nbcrois\u00e9s = pd.crosstab(index=df_MS['multi-casquette ?'], columns=df_MS['multi-souscripteur ?'], margins=True, margins_name='Total') df_nbcrois\u00e9s Out[39]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total multi-casquette ? Actionnaire uniquement 392 632 1024 Actionnaire-adh\u00e9rent 1343 1805 3148 Actionnaire-donateur 490 681 1171 Triple-engagement 1405 2038 3443 Total 3630 5156 8786 In\u00a0[40]: Copied! <pre>df_col_percent = df_nbcrois\u00e9s.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent\n</pre> df_col_percent = df_nbcrois\u00e9s.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent Out[40]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total multi-casquette ? Actionnaire uniquement 10.8 12.3 11.7 Actionnaire-adh\u00e9rent 37.0 35.0 35.8 Actionnaire-donateur 13.5 13.2 13.3 Triple-engagement 38.7 39.5 39.2 Total 100.0 100.0 100.0 In\u00a0[41]: Copied! <pre>df_row_percent = df_nbcrois\u00e9s.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_nbcrois\u00e9s.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent  Out[41]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total multi-casquette ? Actionnaire uniquement 38.3 61.7 100.0 Actionnaire-adh\u00e9rent 42.7 57.3 100.0 Actionnaire-donateur 41.8 58.2 100.0 Triple-engagement 40.8 59.2 100.0 Total 41.3 58.7 100.0 In\u00a0[42]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Cat\u00e9gories des multi-souscripteurs et anciennet\u00e9 &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cat\u00e9gories des multi-souscripteurs et anciennet\u00e9 \")) Cat\u00e9gories des multi-souscripteurs et anciennet\u00e9  In\u00a0[43]: Copied! <pre>ordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\ndf_MS_anciennet\u00e9 = pd.crosstab(index=df_MS[\"Cat\u00e9gories souscripteurs\"], columns=df_MS[\"anciennet\u00e9 actionnaires\"], margins=True, margins_name='Total')\ndf_MS_anciennet\u00e9 = df_MS_anciennet\u00e9.reindex(index=ordre_categories_souscripteurs, columns=ordre_categories_anciennet\u00e9)\ndf_MS_anciennet\u00e9['Total'] = df_MS_anciennet\u00e9.sum(axis=1)\ndf_MS_anciennet\u00e9.loc['Total'] = df_MS_anciennet\u00e9.sum()\ndf_MS_anciennet\u00e9\n</pre>  ordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] df_MS_anciennet\u00e9 = pd.crosstab(index=df_MS[\"Cat\u00e9gories souscripteurs\"], columns=df_MS[\"anciennet\u00e9 actionnaires\"], margins=True, margins_name='Total') df_MS_anciennet\u00e9 = df_MS_anciennet\u00e9.reindex(index=ordre_categories_souscripteurs, columns=ordre_categories_anciennet\u00e9) df_MS_anciennet\u00e9['Total'] = df_MS_anciennet\u00e9.sum(axis=1) df_MS_anciennet\u00e9.loc['Total'] = df_MS_anciennet\u00e9.sum() df_MS_anciennet\u00e9  Out[43]: anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus Nouvel actionnaire entre 2012 \u00e0 2017 Nouvel actionnaire en 2012 ou moins Total Cat\u00e9gories souscripteurs 1 souscription 1736 1541 1879 5156 2 souscriptions 843 751 880 2474 3 \u00e0 5 souscriptions 359 310 401 1070 6 \u00e0 10 souscriptions 27 21 24 72 10 souscriptions et plus 2 7 5 14 Total 2967 2630 3189 8786 In\u00a0[44]: Copied! <pre>df_col_percent = df_MS_anciennet\u00e9.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent \n</pre> df_col_percent = df_MS_anciennet\u00e9.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent  Out[44]: anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus Nouvel actionnaire entre 2012 \u00e0 2017 Nouvel actionnaire en 2012 ou moins Total Cat\u00e9gories souscripteurs 1 souscription 58.5 58.6 58.9 58.7 2 souscriptions 28.4 28.6 27.6 28.2 3 \u00e0 5 souscriptions 12.1 11.8 12.6 12.2 6 \u00e0 10 souscriptions 0.9 0.8 0.8 0.8 10 souscriptions et plus 0.1 0.3 0.2 0.2 Total 100.0 100.1 100.1 100.1 In\u00a0[45]: Copied! <pre>df_row_percent = df_MS_anciennet\u00e9.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_MS_anciennet\u00e9.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent Out[45]: anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus Nouvel actionnaire entre 2012 \u00e0 2017 Nouvel actionnaire en 2012 ou moins Total Cat\u00e9gories souscripteurs 1 souscription 33.7 29.9 36.4 100.0 2 souscriptions 34.1 30.4 35.6 100.1 3 \u00e0 5 souscriptions 33.6 29.0 37.5 100.1 6 \u00e0 10 souscriptions 37.5 29.2 33.3 100.0 10 souscriptions et plus 14.3 50.0 35.7 100.0 Total 33.8 29.9 36.3 100.0 In\u00a0[46]: Copied! <pre>df_anciennet\u00e9_MS = pd.crosstab(index=df_MS ['anciennet\u00e9 actionnaires'], columns=df_MS ['multi-souscripteur ?'], margins=True, margins_name='Total')\ndf_anciennet\u00e9_MS = df_anciennet\u00e9_MS.reindex(index=ordre_categories_anciennet\u00e9)\ndf_anciennet\u00e9_MS.loc['Total'] = df_anciennet\u00e9_MS.sum()\ndf_anciennet\u00e9_MS\n</pre> df_anciennet\u00e9_MS = pd.crosstab(index=df_MS ['anciennet\u00e9 actionnaires'], columns=df_MS ['multi-souscripteur ?'], margins=True, margins_name='Total') df_anciennet\u00e9_MS = df_anciennet\u00e9_MS.reindex(index=ordre_categories_anciennet\u00e9) df_anciennet\u00e9_MS.loc['Total'] = df_anciennet\u00e9_MS.sum() df_anciennet\u00e9_MS Out[46]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 1231 1736 2967 Nouvel actionnaire entre 2012 \u00e0 2017 1089 1541 2630 Nouvel actionnaire en 2012 ou moins 1310 1879 3189 Total 3630 5156 8786 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[47]: Copied! <pre>df_col_percent = df_anciennet\u00e9_MS.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent\n</pre> df_col_percent = df_anciennet\u00e9_MS.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent Out[47]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 33.9 33.7 33.8 Nouvel actionnaire entre 2012 \u00e0 2017 30.0 29.9 29.9 Nouvel actionnaire en 2012 ou moins 36.1 36.4 36.3 Total 100.0 100.0 100.0 In\u00a0[48]: Copied! <pre>df_row_percent = df_anciennet\u00e9_MS.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  \n\ndf_row_percent\n</pre> df_row_percent = df_anciennet\u00e9_MS.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)    df_row_percent Out[48]: multi-souscripteur ? multi-souscripteurs souscripteurs uniques Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 41.5 58.5 100.0 Nouvel actionnaire entre 2012 \u00e0 2017 41.4 58.6 100.0 Nouvel actionnaire en 2012 ou moins 41.1 58.9 100.0 Total 41.3 58.7 100.0 In\u00a0[49]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Anciennet\u00e9 et multi-casquettes ? &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Anciennet\u00e9 et multi-casquettes ? \")) Anciennet\u00e9 et multi-casquettes ?  In\u00a0[50]: Copied! <pre>df_anciennet\u00e9_MC = pd.crosstab(index=df_MS['anciennet\u00e9 actionnaires'], columns=df_MS['multi-casquette ?'], margins=True, margins_name='Total')\ndf_anciennet\u00e9_MC = df_anciennet\u00e9_MC.reindex(index=ordre_categories_anciennet\u00e9)\ndf_anciennet\u00e9_MC.loc['Total'] = df_anciennet\u00e9_MC.sum()\n</pre> df_anciennet\u00e9_MC = pd.crosstab(index=df_MS['anciennet\u00e9 actionnaires'], columns=df_MS['multi-casquette ?'], margins=True, margins_name='Total') df_anciennet\u00e9_MC = df_anciennet\u00e9_MC.reindex(index=ordre_categories_anciennet\u00e9) df_anciennet\u00e9_MC.loc['Total'] = df_anciennet\u00e9_MC.sum() In\u00a0[51]: Copied! <pre># Calculer les pourcentages de colonnes\ndf_col_percent_anciennet\u00e9_MC = df_anciennet\u00e9_MC.copy()\ndf_col_percent_anciennet\u00e9_MC = df_col_percent_anciennet\u00e9_MC.div(df_col_percent_anciennet\u00e9_MC.loc['Total']) * 100\ndf_col_percent_anciennet\u00e9_MC = df_col_percent_anciennet\u00e9_MC.round(1)\ndf_col_percent_anciennet\u00e9_MC.iloc[-1] = df_col_percent_anciennet\u00e9_MC.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent_anciennet\u00e9_MC\n</pre> # Calculer les pourcentages de colonnes df_col_percent_anciennet\u00e9_MC = df_anciennet\u00e9_MC.copy() df_col_percent_anciennet\u00e9_MC = df_col_percent_anciennet\u00e9_MC.div(df_col_percent_anciennet\u00e9_MC.loc['Total']) * 100 df_col_percent_anciennet\u00e9_MC = df_col_percent_anciennet\u00e9_MC.round(1) df_col_percent_anciennet\u00e9_MC.iloc[-1] = df_col_percent_anciennet\u00e9_MC.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent_anciennet\u00e9_MC  Out[51]: multi-casquette ? Actionnaire uniquement Actionnaire-adh\u00e9rent Actionnaire-donateur Triple-engagement Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 31.5 34.1 33.3 34.3 33.8 Nouvel actionnaire entre 2012 \u00e0 2017 30.8 29.5 29.7 30.1 29.9 Nouvel actionnaire en 2012 ou moins 37.7 36.4 37.0 35.6 36.3 Total 100.0 100.0 100.0 100.0 100.0 In\u00a0[52]: Copied! <pre># Calculer les pourcentages de lignes\ndf_row_percent_anciennet\u00e9_MC = df_anciennet\u00e9_MC.copy()\ndf_row_percent_anciennet\u00e9_MC.iloc[:, :-1] = df_row_percent_anciennet\u00e9_MC.iloc[:, :-1].div(df_row_percent_anciennet\u00e9_MC['Total'], axis=0) * 100\ndf_row_percent_anciennet\u00e9_MC = df_row_percent_anciennet\u00e9_MC.round(1)\ndf_row_percent_anciennet\u00e9_MC['Total'] = df_row_percent_anciennet\u00e9_MC.iloc[:, :-1].sum(axis=1)\ndf_row_percent_anciennet\u00e9_MC\n</pre> # Calculer les pourcentages de lignes df_row_percent_anciennet\u00e9_MC = df_anciennet\u00e9_MC.copy() df_row_percent_anciennet\u00e9_MC.iloc[:, :-1] = df_row_percent_anciennet\u00e9_MC.iloc[:, :-1].div(df_row_percent_anciennet\u00e9_MC['Total'], axis=0) * 100 df_row_percent_anciennet\u00e9_MC = df_row_percent_anciennet\u00e9_MC.round(1) df_row_percent_anciennet\u00e9_MC['Total'] = df_row_percent_anciennet\u00e9_MC.iloc[:, :-1].sum(axis=1) df_row_percent_anciennet\u00e9_MC  Out[52]: multi-casquette ? Actionnaire uniquement Actionnaire-adh\u00e9rent Actionnaire-donateur Triple-engagement Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 10.9 36.2 13.1 39.8 100.0 Nouvel actionnaire entre 2012 \u00e0 2017 12.0 35.3 13.2 39.5 100.0 Nouvel actionnaire en 2012 ou moins 12.1 35.9 13.6 38.4 100.0 Total 11.7 35.8 13.3 39.2 100.0 In\u00a0[53]: Copied! <pre>import pandas as pd\n\n# Grouper le DataFrame par la colonne \"Nom complet\" et agr\u00e9ger la somme des actions\ndf_aggr\u00e9g\u00e9 = df3.groupby(['ID du contact', 'multi-casquette ?', 'multi-souscripteur ?',\"cat\u00e9gories \u00e2ge\",\"anciennet\u00e9 actionnaires\"]).agg({'Nombre d\\'actions \u00e0 l\\'acquisition': 'sum'}).reset_index()\n</pre> import pandas as pd  # Grouper le DataFrame par la colonne \"Nom complet\" et agr\u00e9ger la somme des actions df_aggr\u00e9g\u00e9 = df3.groupby(['ID du contact', 'multi-casquette ?', 'multi-souscripteur ?',\"cat\u00e9gories \u00e2ge\",\"anciennet\u00e9 actionnaires\"]).agg({'Nombre d\\'actions \u00e0 l\\'acquisition': 'sum'}).reset_index() In\u00a0[54]: Copied! <pre>df3['Nombre de souscriptions'] = df3['ID du contact'].map(df['ID du contact'].value_counts())\n</pre> df3['Nombre de souscriptions'] = df3['ID du contact'].map(df['ID du contact'].value_counts()) In\u00a0[55]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h2&gt;Nombre d'actions total et moyen par multi-engagement et multi-souscripteurs&lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre d'actions total et moyen par multi-engagement et multi-souscripteurs\")) Nombre d'actions total et moyen par multi-engagement et multi-souscripteurs In\u00a0[56]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen d'actions par multi-souscripteurs &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen d'actions par multi-souscripteurs \")) Nombre moyen d'actions par multi-souscripteurs  In\u00a0[57]: Copied! <pre>df_action_MSmean = df3.groupby(\"multi-souscripteur ?\")[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame()\ndf_action_MSmean\n</pre> df_action_MSmean = df3.groupby(\"multi-souscripteur ?\")[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame() df_action_MSmean Out[57]: Nombre d'actions \u00e0 l'acquisition multi-souscripteur ? False 55.0 True 52.0 In\u00a0[58]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre total d'actions par multi-souscripteurs &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre total d'actions par multi-souscripteurs \")) Nombre total d'actions par multi-souscripteurs  In\u00a0[59]: Copied! <pre>df_action_MSsum = df3\ndf_action_MSsum = df_action_MSsum.groupby(\"multi-souscripteur ?\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame()\ndf_action_MSsum\n</pre> df_action_MSsum = df3 df_action_MSsum = df_action_MSsum.groupby(\"multi-souscripteur ?\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame() df_action_MSsum Out[59]: Nombre d'actions \u00e0 l'acquisition multi-souscripteur ? False 281704 True 478914 In\u00a0[60]: Copied! <pre># Calculer la somme totale de la colonne \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"\ntotal_sum = df_action_MSsum[\"Nombre d'actions \u00e0 l'acquisition\"].sum()\n\n\nprint(\"Somme  des actions d\u00e9tenues\", total_sum)\n</pre> # Calculer la somme totale de la colonne \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\" total_sum = df_action_MSsum[\"Nombre d'actions \u00e0 l'acquisition\"].sum()   print(\"Somme  des actions d\u00e9tenues\", total_sum) <pre>Somme  des actions d\u00e9tenues 760618\n</pre> In\u00a0[61]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen d'actions par multi-casquettes &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen d'actions par multi-casquettes \")) Nombre moyen d'actions par multi-casquettes  In\u00a0[62]: Copied! <pre>df_action_MCmean = df_aggr\u00e9g\u00e9.groupby('multi-casquette ?')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame()\ndf_action_MCmean\n</pre> df_action_MCmean = df_aggr\u00e9g\u00e9.groupby('multi-casquette ?')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame() df_action_MCmean Out[62]: Nombre d'actions \u00e0 l'acquisition multi-casquette ? Actionnaire uniquement 88.0 Actionnaire-adh\u00e9rent 87.0 Actionnaire-donateur 92.0 Triple-engagement 84.0 In\u00a0[63]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen d'actions par anciennet\u00e9 &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen d'actions par anciennet\u00e9 \")) Nombre moyen d'actions par anciennet\u00e9  In\u00a0[64]: Copied! <pre>df_action_anciennet\u00e9_mean = df_aggr\u00e9g\u00e9.groupby('anciennet\u00e9 actionnaires')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame()\ndf_action_anciennet\u00e9_mean = df_action_anciennet\u00e9_mean.reindex(index=ordre_categories_anciennet\u00e9)\ndf_action_anciennet\u00e9_mean\n</pre> df_action_anciennet\u00e9_mean = df_aggr\u00e9g\u00e9.groupby('anciennet\u00e9 actionnaires')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame() df_action_anciennet\u00e9_mean = df_action_anciennet\u00e9_mean.reindex(index=ordre_categories_anciennet\u00e9) df_action_anciennet\u00e9_mean Out[64]: Nombre d'actions \u00e0 l'acquisition anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 89.0 Nouvel actionnaire entre 2012 \u00e0 2017 89.0 Nouvel actionnaire en 2012 ou moins 83.0 In\u00a0[65]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen d'actions par nombre de souscriptions &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen d'actions par nombre de souscriptions \")) Nombre moyen d'actions par nombre de souscriptions  In\u00a0[66]: Copied! <pre>df2[\"cat\u00e9gorie souscription\"] = df2.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5\n                                          else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50\n                                          else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100\n                                          else \"Souscriptions de plus de 100 actions\",\n                                          axis = 1) \n</pre> df2[\"cat\u00e9gorie souscription\"] = df2.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5                                           else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50                                           else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100                                           else \"Souscriptions de plus de 100 actions\",                                           axis = 1)   In\u00a0[67]: Copied! <pre>df_cat_nbactions_mean = df_MS.groupby('Cat\u00e9gories souscripteurs')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame()\ndf_cat_nbactions_mean = df_cat_nbactions_mean.reindex(index=ordre_categories)\ndf_cat_nbactions_mean\n</pre> df_cat_nbactions_mean = df_MS.groupby('Cat\u00e9gories souscripteurs')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().round().to_frame() df_cat_nbactions_mean = df_cat_nbactions_mean.reindex(index=ordre_categories) df_cat_nbactions_mean Out[67]: Nombre d'actions \u00e0 l'acquisition Cat\u00e9gories souscripteurs 1 souscription 55.0 2 souscriptions 105.0 3 \u00e0 5 souscriptions 169.0 6 \u00e0 10 souscriptions 420.0 10 souscriptions et plus 486.0 In\u00a0[68]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre total d'actions par nombre de souscriptions &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre total d'actions par nombre de souscriptions \")) Nombre total d'actions par nombre de souscriptions  In\u00a0[69]: Copied! <pre>df_cat_nbactions_sum = df_MS.groupby('Cat\u00e9gories souscripteurs')[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame()\ndf_cat_nbactions_sum = df_cat_nbactions_sum.reindex(index=ordre_categories)\ndf_cat_nbactions_sum\n</pre> df_cat_nbactions_sum = df_MS.groupby('Cat\u00e9gories souscripteurs')[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame() df_cat_nbactions_sum = df_cat_nbactions_sum.reindex(index=ordre_categories) df_cat_nbactions_sum Out[69]: Nombre d'actions \u00e0 l'acquisition Cat\u00e9gories souscripteurs 1 souscription 281704 2 souscriptions 260901 3 \u00e0 5 souscriptions 180955 6 \u00e0 10 souscriptions 30247 10 souscriptions et plus 6811 In\u00a0[70]: Copied! <pre># Calculer la somme totale de la colonne \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"\ntotal_sum = df_cat_nbactions_sum[\"Nombre d'actions \u00e0 l'acquisition\"].sum()\n\n\nprint(\"Somme  des actions prises (diff\u00e9rent des actions d\u00e9tenues)\", total_sum)\n</pre> # Calculer la somme totale de la colonne \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\" total_sum = df_cat_nbactions_sum[\"Nombre d'actions \u00e0 l'acquisition\"].sum()   print(\"Somme  des actions prises (diff\u00e9rent des actions d\u00e9tenues)\", total_sum) <pre>Somme  des actions prises (diff\u00e9rent des actions d\u00e9tenues) 760618\n</pre> In\u00a0[71]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Capital poss\u00e9d\u00e9 par multi-souscripteurs&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Capital poss\u00e9d\u00e9 par multi-souscripteurs\")) Capital poss\u00e9d\u00e9 par multi-souscripteurs In\u00a0[72]: Copied! <pre>#df3.loc[:, \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"] = df3[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"].str.replace(',', '.').astype(float)\n#df3.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df3[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].str.replace(',', '.').astype(float)\n\ndf4 = df3.drop_duplicates(subset=\"ID du contact\")\ndf_capital_MC = df4.groupby(\"multi-souscripteur ?\").agg({\n    \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",\n    \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\"\n})\ndf_capital_MC\n</pre>  #df3.loc[:, \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"] = df3[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"].str.replace(',', '.').astype(float) #df3.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df3[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].str.replace(',', '.').astype(float)  df4 = df3.drop_duplicates(subset=\"ID du contact\") df_capital_MC = df4.groupby(\"multi-souscripteur ?\").agg({     \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",     \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\" }) df_capital_MC  Out[72]: Fonci\u00e8re : Capital poss\u00e9d\u00e9 Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%) multi-souscripteur ? False 412118805 51.881907 True 282614850 35.578569 In\u00a0[73]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Capital poss\u00e9d\u00e9 par cat\u00e9gories d'anciennet\u00e9&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Capital poss\u00e9d\u00e9 par cat\u00e9gories d'anciennet\u00e9\")) Capital poss\u00e9d\u00e9 par cat\u00e9gories d'anciennet\u00e9 In\u00a0[74]: Copied! <pre>df6 = df3.drop_duplicates(subset=\"ID du contact\")\n#df6.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df6[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].astype(float).apply(lambda x: round(float(x), 2))\ndf_capital_anciennet\u00e9 = df6.groupby(\"anciennet\u00e9 actionnaires\").agg({\n    \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",\n    \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\"\n})\ndf_capital_anciennet\u00e9 = df_capital_anciennet\u00e9.reindex(index=ordre_categories_anciennet\u00e9)\ndf_capital_anciennet\u00e9\n</pre> df6 = df3.drop_duplicates(subset=\"ID du contact\") #df6.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df6[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].astype(float).apply(lambda x: round(float(x), 2)) df_capital_anciennet\u00e9 = df6.groupby(\"anciennet\u00e9 actionnaires\").agg({     \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",     \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\" }) df_capital_anciennet\u00e9 = df_capital_anciennet\u00e9.reindex(index=ordre_categories_anciennet\u00e9) df_capital_anciennet\u00e9 Out[74]: Fonci\u00e8re : Capital poss\u00e9d\u00e9 Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%) anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 225978270 28.448553 Nouvel actionnaire entre 2012 \u00e0 2017 206575845 26.005969 Nouvel actionnaire en 2012 ou moins 262179540 33.005955 In\u00a0[75]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Capital poss\u00e9d\u00e9 par nombre de souscriptions de l'actionnaire&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Capital poss\u00e9d\u00e9 par nombre de souscriptions de l'actionnaire\")) Capital poss\u00e9d\u00e9 par nombre de souscriptions de l'actionnaire In\u00a0[76]: Copied! <pre>conditions = [\n     (df3['Nombre de souscriptions'] &lt; 2),\n     (df3['Nombre de souscriptions'] &lt;3),\n     (df3['Nombre de souscriptions'] &lt;=5),\n     (df3['Nombre de souscriptions'] &lt;=10),\n]\n\nchoices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]\n\ndf3['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')\n</pre> conditions = [      (df3['Nombre de souscriptions'] &lt; 2),      (df3['Nombre de souscriptions'] &lt;3),      (df3['Nombre de souscriptions'] &lt;=5),      (df3['Nombre de souscriptions'] &lt;=10), ]  choices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]  df3['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')  In\u00a0[77]: Copied! <pre>df6 = df3.drop_duplicates(subset=\"ID du contact\")\n#df6.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df6[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].astype(str).apply(lambda x: round(float(x), 2))\ndf_capital_nbsous = df6.groupby(\"Cat\u00e9gories souscripteurs\").agg({\n    \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",\n    \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\"\n})\ndf_capital_nbsous =  df_capital_nbsous.reindex(index=ordre_categories)\ndf_capital_nbsous\n</pre> df6 = df3.drop_duplicates(subset=\"ID du contact\") #df6.loc[:, \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"] = df6[\"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\"].astype(str).apply(lambda x: round(float(x), 2)) df_capital_nbsous = df6.groupby(\"Cat\u00e9gories souscripteurs\").agg({     \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\": \"sum\",     \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\": \"sum\" }) df_capital_nbsous =  df_capital_nbsous.reindex(index=ordre_categories) df_capital_nbsous Out[77]: Fonci\u00e8re : Capital poss\u00e9d\u00e9 Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%) Cat\u00e9gories souscripteurs 1 souscription 327246990 41.197339 2 souscriptions 229901385 28.942437 3 \u00e0 5 souscriptions 130627350 16.444763 6 \u00e0 10 souscriptions 2308320 0.290596 10 souscriptions et plus 4649610 0.585342 In\u00a0[78]: Copied! <pre>from IPython.display import display, HTML\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Part des multi-souscripteurs parmi les actionnaires par ann\u00e9es&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  # Ins\u00e9rer un saut de page display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Part des multi-souscripteurs parmi les actionnaires par ann\u00e9es'))  Part des multi-souscripteurs parmi les actionnaires par ann\u00e9es In\u00a0[79]: Copied! <pre>dffid = df.copy()\nimport pandas as pd\n\n# Cr\u00e9er une fonction pour v\u00e9rifier les conditions\ndef is_retrait_definitif(row):\n    same_contact_rows = dffid[dffid['ID du contact'] == row['ID du contact']]\n    later_rows = same_contact_rows[pd.to_datetime(same_contact_rows['Actions - Date de fin'], format=\"%d/%m/%Y\") &gt; pd.to_datetime(row['Actions - Date de fin'], format=\"%d/%m/%Y\")]\n    return (row['Nature du mouvement'] in ['Rachat', 'Don TDL'] and later_rows.empty)\n\n# Appliquer la fonction pour cr\u00e9er la variable conditionnelle\ndffid['fin actionnariat'] = dffid.apply(is_retrait_definitif, axis=1).map({True: 'fin actionnariat', False: 'toujours actionnaire'})\n\nactionnairefin = dffid[dffid['fin actionnariat']== \"fin actionnariat\"]\nactionnairefin = actionnairefin.drop_duplicates(subset = \"ID du contact\")\nactionnairefin[\"ann\u00e9e fin actionnariat\"] = actionnairefin['Actions - Date de fin'].dt.year\nnbactionnairefin = actionnairefin[\"ann\u00e9e fin actionnariat\"].value_counts().sort_index().to_frame()\ndffid_nbactionnaire_par_an = dffid[dffid[\"Nature du mouvement\"] == \"Souscription\"]\ndffid_nbactionnaire_par_an = dffid_nbactionnaire_par_an.drop_duplicates(subset = \"ID du contact\")\ndffid_nbactionnaire_par_an = dffid_nbactionnaire_par_an[\"r\u00e9partition ann\u00e9e nouveau actionnaire\"].value_counts().sort_index().to_frame()\ndffid_nbactionnaire_par_an['effectif cumul\u00e9'] = dffid_nbactionnaire_par_an['count'].cumsum()\ndffid_nbactionnaire_par_an\nmerged_df = dffid_nbactionnaire_par_an.merge(nbactionnairefin, left_index=True, right_index=True, how='left')\nmerged_df.reset_index(inplace=True)\nmerged_df.rename(columns={'index': 'ann\u00e9e'}, inplace=True)\nmerged_df.rename(columns={'count_x': 'nouveaux actionnaires', 'count_y': 'actionnaires partis'}, inplace=True)\nmerged_df.fillna(0, inplace=True)\nmerged_df['actionnaires actifs'] = merged_df['effectif cumul\u00e9'] - merged_df['actionnaires partis']\n\n#Attribuer la caract\u00e9risation mumti-souscripteurs l'ann\u00e9e ou la personne l'est devenu. \n\ndf_MS_an = dffid[dffid[\"Nature du mouvement\"] == \"Souscription\"]\ndf_MS_an\n# Extraire les ann\u00e9es de souscription sous forme d'entiers\ndf_MS_an[\"souscription sur l'ann\u00e9e :\"] = df_MS_an[\"Date du Mouvement\"].dt.year.astype(int)\n# Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription\nyears = df_MS_an[\"souscription sur l'ann\u00e9e :\"].unique()\nfor year in years:\n    df_MS_an[f'souscription sur l\\'ann\u00e9e : {year}'] = df_MS_an[\"souscription sur l'ann\u00e9e :\"] == year\n\ncolumns_to_drop = ['\u00e2ge',\"Nom complet\",\"souscription sur l'ann\u00e9e :\", \"fin actionnariat\",'Territoire Terre de Liens', 'Actionnaire ?', 'adh\u00e9rent N',\n                   'Donateur N', 'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9',\n                   'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues', 'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)',\n                   'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats',\n                   'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal',\n                   'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',\n                   'Date d\\'activation', 'Date du Mouvement', 'Actions - Date de fin',\n                   'Nombre d\\'actions \u00e9chang\u00e9es', 'Difference d\u00e9but fin',\n                   'retrait complet ou partiel', 'ann\u00e9e rachat', 'dur\u00e9e conservation',\n                   'r\u00e9partition ann\u00e9e', 'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires',\n                   'r\u00e9partition ann\u00e9e nouveau actionnaire']\n\ndf_MS_an.drop(columns=columns_to_drop, inplace=True)\ndf_MS_an = df_MS_an.groupby('ID du contact').max().reset_index()\nsorted_cols = ['ID du contact'] + sorted([col for col in df_MS_an.columns if col.startswith('souscription sur l\\'ann\u00e9e :')])\ndf_MS_an = df_MS_an[sorted_cols]\n# Trier les colonnes par ordre chronologique\nyears = [col for col in df_MS_an.columns if col.startswith('souscription sur l\\'ann\u00e9e :')]\nyears.sort(key=lambda x: int(x.split(': ')[-1]))\n\n# Ajouter les colonnes \"Cat\u00e9gorie de souscripteurs sur l'ann\u00e9eN\"\nfor year in years:\n    col_name = f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year.split(\": \")[-1]}'\n    df_MS_an[col_name] = df_MS_an.apply(lambda row: 'multi-souscripteur' if row[year] and any(row[y] for y in years[:years.index(year)]) else ('multi-souscripteur' if not row[year] and sum(row[y] for y in years[:years.index(year)]) &gt;= 2 else 'souscripteurs uniques'), axis=1)\n# Liste des colonnes \u00e0 supprimer\ncolumns_to_drop = [\n    'souscription sur l\\'ann\u00e9e : 2006',\n    'souscription sur l\\'ann\u00e9e : 2007',\n    'souscription sur l\\'ann\u00e9e : 2008',\n    'souscription sur l\\'ann\u00e9e : 2009',\n    'souscription sur l\\'ann\u00e9e : 2010',\n    'souscription sur l\\'ann\u00e9e : 2011',\n    'souscription sur l\\'ann\u00e9e : 2012',\n    'souscription sur l\\'ann\u00e9e : 2013',\n    'souscription sur l\\'ann\u00e9e : 2014',\n    'souscription sur l\\'ann\u00e9e : 2015',\n    'souscription sur l\\'ann\u00e9e : 2016',\n    'souscription sur l\\'ann\u00e9e : 2017',\n    'souscription sur l\\'ann\u00e9e : 2018',\n    'souscription sur l\\'ann\u00e9e : 2019',\n    'souscription sur l\\'ann\u00e9e : 2020',\n    'souscription sur l\\'ann\u00e9e : 2021',\n    'souscription sur l\\'ann\u00e9e : 2022',\n    'souscription sur l\\'ann\u00e9e : 2023',\n]\n\n\ndf_MS_an = df_MS_an.drop(columns=columns_to_drop)\ndf_MS_an = df_MS_an.merge(actionnairefin[['ID du contact', 'ann\u00e9e fin actionnariat']], on='ID du contact', how='left')\ndf_MS_an['ann\u00e9e fin actionnariat'] = df_MS_an['ann\u00e9e fin actionnariat'].fillna(0).astype(int)\n\n# changer le caract\u00e8re multi-souscripteurs des actionnaires qui sont sortis\nfor index, row in df_MS_an.iterrows():\n    for year in range(2006, 2024):\n        target_year = year\n        fin_actionnariat = row['ann\u00e9e fin actionnariat']\n        \n        if fin_actionnariat == target_year and f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year}' in row.index and row[f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year}'] == 'multi-souscripteur':\n            for i in range(year + 1, 2024):\n                df_MS_an.at[index, f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {i}'] = 'souscripteurs uniques'\n\n# Supprimer la colonne \"ID du contact\"\ndf_MS_an = df_MS_an.drop(columns=['ID du contact', \"ann\u00e9e fin actionnariat\"])\n\n# Renommer les colonnes en conservant uniquement les ann\u00e9es\nnew_columns = {col: col.split(\" \")[-1] for col in df_MS_an.columns if \"Cat\u00e9gorie de souscripteurs sur l'ann\u00e9e\" in col}\ndf_MS_an = df_MS_an.rename(columns=new_columns)\n\n# Compter le nombre de \"multi-souscripteur\" pour chaque colonne de 2006 \u00e0 2023\nmulti_souscripteur_counts = df_MS_an.loc[:, \"2006\":\"2023\"].apply(\n    lambda col: col.eq(\"multi-souscripteur\").sum(), axis=0\n)\nmulti_souscripteur_counts = multi_souscripteur_counts.to_frame()\nmulti_souscripteur_counts.index.name = \"ann\u00e9es\"\nmulti_souscripteur_counts.columns = [\"Nombre de multi-souscripteurs\"]\n\n# Fusionner les DataFrames en utilisant la cl\u00e9 \"r\u00e9partition ann\u00e9e nouveau actionnaire\" et \"ann\u00e9es\"\nmerged_df = merged_df.merge(multi_souscripteur_counts, left_on=\"r\u00e9partition ann\u00e9e nouveau actionnaire\", right_on=\"ann\u00e9es\", how=\"left\")\n\n# S\u00e9lectionner uniquement les colonnes \"actionnaires actifs\" et \"Nombre de multi-souscripteurs\"\nfinal_df = merged_df[[\"r\u00e9partition ann\u00e9e nouveau actionnaire\",\"actionnaires actifs\", \"Nombre de multi-souscripteurs\"]]\nfinal_df[\"Nombre de souscripteurs uniques\"] = final_df[\"actionnaires actifs\"] - final_df[\"Nombre de multi-souscripteurs\"]\n\n\nimport matplotlib.pyplot as plt\n\n# Calculer les pourcentages\nfinal_df['Pourcentage multi-souscripteurs'] = (final_df['Nombre de multi-souscripteurs'] / (final_df['Nombre de multi-souscripteurs'] + final_df['Nombre de souscripteurs uniques'])) * 100\nfinal_df['Pourcentage souscripteurs uniques'] = (final_df['Nombre de souscripteurs uniques'] / (final_df['Nombre de multi-souscripteurs'] + final_df['Nombre de souscripteurs uniques'])) * 100\n\n# Cr\u00e9er le diagramme \u00e0 barres empil\u00e9es\nfig, ax = plt.subplots(figsize=(10, 6))\nfinal_df.plot(kind='bar', x='r\u00e9partition ann\u00e9e nouveau actionnaire', y=['Pourcentage multi-souscripteurs', 'Pourcentage souscripteurs uniques'], stacked=True, ax=ax)\n\n# Afficher les \u00e9tiquettes de valeurs en pourcentage pour les multi-souscripteurs uniquement\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy() \n    \n    if height &gt; 0 and p.get_label() == 'Pourcentage multi-souscripteurs':\n        percentage = round(height, 1)\n        ax.annotate(f'{percentage}%', (x + width / 2, y + height + 1), ha='center')\n\n# Ajouter les \u00e9tiquettes d'axe et le titre\nax.set_xlabel(\"Ann\u00e9e\")\nax.set_ylabel(\"Pourcentage\")\nax.set_title(\"R\u00e9partition des souscripteurs par ann\u00e9e\")\n\n# Afficher le diagramme\nplt.tight_layout()\nplt.show()\n</pre> dffid = df.copy() import pandas as pd  # Cr\u00e9er une fonction pour v\u00e9rifier les conditions def is_retrait_definitif(row):     same_contact_rows = dffid[dffid['ID du contact'] == row['ID du contact']]     later_rows = same_contact_rows[pd.to_datetime(same_contact_rows['Actions - Date de fin'], format=\"%d/%m/%Y\") &gt; pd.to_datetime(row['Actions - Date de fin'], format=\"%d/%m/%Y\")]     return (row['Nature du mouvement'] in ['Rachat', 'Don TDL'] and later_rows.empty)  # Appliquer la fonction pour cr\u00e9er la variable conditionnelle dffid['fin actionnariat'] = dffid.apply(is_retrait_definitif, axis=1).map({True: 'fin actionnariat', False: 'toujours actionnaire'})  actionnairefin = dffid[dffid['fin actionnariat']== \"fin actionnariat\"] actionnairefin = actionnairefin.drop_duplicates(subset = \"ID du contact\") actionnairefin[\"ann\u00e9e fin actionnariat\"] = actionnairefin['Actions - Date de fin'].dt.year nbactionnairefin = actionnairefin[\"ann\u00e9e fin actionnariat\"].value_counts().sort_index().to_frame() dffid_nbactionnaire_par_an = dffid[dffid[\"Nature du mouvement\"] == \"Souscription\"] dffid_nbactionnaire_par_an = dffid_nbactionnaire_par_an.drop_duplicates(subset = \"ID du contact\") dffid_nbactionnaire_par_an = dffid_nbactionnaire_par_an[\"r\u00e9partition ann\u00e9e nouveau actionnaire\"].value_counts().sort_index().to_frame() dffid_nbactionnaire_par_an['effectif cumul\u00e9'] = dffid_nbactionnaire_par_an['count'].cumsum() dffid_nbactionnaire_par_an merged_df = dffid_nbactionnaire_par_an.merge(nbactionnairefin, left_index=True, right_index=True, how='left') merged_df.reset_index(inplace=True) merged_df.rename(columns={'index': 'ann\u00e9e'}, inplace=True) merged_df.rename(columns={'count_x': 'nouveaux actionnaires', 'count_y': 'actionnaires partis'}, inplace=True) merged_df.fillna(0, inplace=True) merged_df['actionnaires actifs'] = merged_df['effectif cumul\u00e9'] - merged_df['actionnaires partis']  #Attribuer la caract\u00e9risation mumti-souscripteurs l'ann\u00e9e ou la personne l'est devenu.   df_MS_an = dffid[dffid[\"Nature du mouvement\"] == \"Souscription\"] df_MS_an # Extraire les ann\u00e9es de souscription sous forme d'entiers df_MS_an[\"souscription sur l'ann\u00e9e :\"] = df_MS_an[\"Date du Mouvement\"].dt.year.astype(int) # Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription years = df_MS_an[\"souscription sur l'ann\u00e9e :\"].unique() for year in years:     df_MS_an[f'souscription sur l\\'ann\u00e9e : {year}'] = df_MS_an[\"souscription sur l'ann\u00e9e :\"] == year  columns_to_drop = ['\u00e2ge',\"Nom complet\",\"souscription sur l'ann\u00e9e :\", \"fin actionnariat\",'Territoire Terre de Liens', 'Actionnaire ?', 'adh\u00e9rent N',                    'Donateur N', 'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9',                    'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues', 'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)',                    'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats',                    'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal',                    'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',                    'Date d\\'activation', 'Date du Mouvement', 'Actions - Date de fin',                    'Nombre d\\'actions \u00e9chang\u00e9es', 'Difference d\u00e9but fin',                    'retrait complet ou partiel', 'ann\u00e9e rachat', 'dur\u00e9e conservation',                    'r\u00e9partition ann\u00e9e', 'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires',                    'r\u00e9partition ann\u00e9e nouveau actionnaire']  df_MS_an.drop(columns=columns_to_drop, inplace=True) df_MS_an = df_MS_an.groupby('ID du contact').max().reset_index() sorted_cols = ['ID du contact'] + sorted([col for col in df_MS_an.columns if col.startswith('souscription sur l\\'ann\u00e9e :')]) df_MS_an = df_MS_an[sorted_cols] # Trier les colonnes par ordre chronologique years = [col for col in df_MS_an.columns if col.startswith('souscription sur l\\'ann\u00e9e :')] years.sort(key=lambda x: int(x.split(': ')[-1]))  # Ajouter les colonnes \"Cat\u00e9gorie de souscripteurs sur l'ann\u00e9eN\" for year in years:     col_name = f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year.split(\": \")[-1]}'     df_MS_an[col_name] = df_MS_an.apply(lambda row: 'multi-souscripteur' if row[year] and any(row[y] for y in years[:years.index(year)]) else ('multi-souscripteur' if not row[year] and sum(row[y] for y in years[:years.index(year)]) &gt;= 2 else 'souscripteurs uniques'), axis=1) # Liste des colonnes \u00e0 supprimer columns_to_drop = [     'souscription sur l\\'ann\u00e9e : 2006',     'souscription sur l\\'ann\u00e9e : 2007',     'souscription sur l\\'ann\u00e9e : 2008',     'souscription sur l\\'ann\u00e9e : 2009',     'souscription sur l\\'ann\u00e9e : 2010',     'souscription sur l\\'ann\u00e9e : 2011',     'souscription sur l\\'ann\u00e9e : 2012',     'souscription sur l\\'ann\u00e9e : 2013',     'souscription sur l\\'ann\u00e9e : 2014',     'souscription sur l\\'ann\u00e9e : 2015',     'souscription sur l\\'ann\u00e9e : 2016',     'souscription sur l\\'ann\u00e9e : 2017',     'souscription sur l\\'ann\u00e9e : 2018',     'souscription sur l\\'ann\u00e9e : 2019',     'souscription sur l\\'ann\u00e9e : 2020',     'souscription sur l\\'ann\u00e9e : 2021',     'souscription sur l\\'ann\u00e9e : 2022',     'souscription sur l\\'ann\u00e9e : 2023', ]   df_MS_an = df_MS_an.drop(columns=columns_to_drop) df_MS_an = df_MS_an.merge(actionnairefin[['ID du contact', 'ann\u00e9e fin actionnariat']], on='ID du contact', how='left') df_MS_an['ann\u00e9e fin actionnariat'] = df_MS_an['ann\u00e9e fin actionnariat'].fillna(0).astype(int)  # changer le caract\u00e8re multi-souscripteurs des actionnaires qui sont sortis for index, row in df_MS_an.iterrows():     for year in range(2006, 2024):         target_year = year         fin_actionnariat = row['ann\u00e9e fin actionnariat']                  if fin_actionnariat == target_year and f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year}' in row.index and row[f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {year}'] == 'multi-souscripteur':             for i in range(year + 1, 2024):                 df_MS_an.at[index, f'Cat\u00e9gorie de souscripteurs sur l\\'ann\u00e9e {i}'] = 'souscripteurs uniques'  # Supprimer la colonne \"ID du contact\" df_MS_an = df_MS_an.drop(columns=['ID du contact', \"ann\u00e9e fin actionnariat\"])  # Renommer les colonnes en conservant uniquement les ann\u00e9es new_columns = {col: col.split(\" \")[-1] for col in df_MS_an.columns if \"Cat\u00e9gorie de souscripteurs sur l'ann\u00e9e\" in col} df_MS_an = df_MS_an.rename(columns=new_columns)  # Compter le nombre de \"multi-souscripteur\" pour chaque colonne de 2006 \u00e0 2023 multi_souscripteur_counts = df_MS_an.loc[:, \"2006\":\"2023\"].apply(     lambda col: col.eq(\"multi-souscripteur\").sum(), axis=0 ) multi_souscripteur_counts = multi_souscripteur_counts.to_frame() multi_souscripteur_counts.index.name = \"ann\u00e9es\" multi_souscripteur_counts.columns = [\"Nombre de multi-souscripteurs\"]  # Fusionner les DataFrames en utilisant la cl\u00e9 \"r\u00e9partition ann\u00e9e nouveau actionnaire\" et \"ann\u00e9es\" merged_df = merged_df.merge(multi_souscripteur_counts, left_on=\"r\u00e9partition ann\u00e9e nouveau actionnaire\", right_on=\"ann\u00e9es\", how=\"left\")  # S\u00e9lectionner uniquement les colonnes \"actionnaires actifs\" et \"Nombre de multi-souscripteurs\" final_df = merged_df[[\"r\u00e9partition ann\u00e9e nouveau actionnaire\",\"actionnaires actifs\", \"Nombre de multi-souscripteurs\"]] final_df[\"Nombre de souscripteurs uniques\"] = final_df[\"actionnaires actifs\"] - final_df[\"Nombre de multi-souscripteurs\"]   import matplotlib.pyplot as plt  # Calculer les pourcentages final_df['Pourcentage multi-souscripteurs'] = (final_df['Nombre de multi-souscripteurs'] / (final_df['Nombre de multi-souscripteurs'] + final_df['Nombre de souscripteurs uniques'])) * 100 final_df['Pourcentage souscripteurs uniques'] = (final_df['Nombre de souscripteurs uniques'] / (final_df['Nombre de multi-souscripteurs'] + final_df['Nombre de souscripteurs uniques'])) * 100  # Cr\u00e9er le diagramme \u00e0 barres empil\u00e9es fig, ax = plt.subplots(figsize=(10, 6)) final_df.plot(kind='bar', x='r\u00e9partition ann\u00e9e nouveau actionnaire', y=['Pourcentage multi-souscripteurs', 'Pourcentage souscripteurs uniques'], stacked=True, ax=ax)  # Afficher les \u00e9tiquettes de valeurs en pourcentage pour les multi-souscripteurs uniquement for p in ax.patches:     width = p.get_width()     height = p.get_height()     x, y = p.get_xy()           if height &gt; 0 and p.get_label() == 'Pourcentage multi-souscripteurs':         percentage = round(height, 1)         ax.annotate(f'{percentage}%', (x + width / 2, y + height + 1), ha='center')  # Ajouter les \u00e9tiquettes d'axe et le titre ax.set_xlabel(\"Ann\u00e9e\") ax.set_ylabel(\"Pourcentage\") ax.set_title(\"R\u00e9partition des souscripteurs par ann\u00e9e\")  # Afficher le diagramme plt.tight_layout() plt.show() <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_9680\\2722701297.py in &lt;module&gt;\n      9 \n     10 # Appliquer la fonction pour cr\u00e9er la variable conditionnelle\n---&gt; 11 dffid['fin actionnariat'] = dffid.apply(is_retrait_definitif, axis=1).map({True: 'fin actionnariat', False: 'toujours actionnaire'})\n     12 \n     13 actionnairefin = dffid[dffid['fin actionnariat']== \"fin actionnariat\"]\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py in apply(self, func, axis, raw, result_type, args, **kwargs)\n   8846             kwargs=kwargs,\n   8847         )\n-&gt; 8848         return op.apply().__finalize__(self, method=\"apply\")\n   8849 \n   8850     def applymap(\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply(self)\n    731             return self.apply_raw()\n    732 \n--&gt; 733         return self.apply_standard()\n    734 \n    735     def agg(self):\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply_standard(self)\n    855 \n    856     def apply_standard(self):\n--&gt; 857         results, res_index = self.apply_series_generator()\n    858 \n    859         # wrap results\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py in apply_series_generator(self)\n    871             for i, v in enumerate(series_gen):\n    872                 # ignore SettingWithCopy here in case the user mutates\n--&gt; 873                 results[i] = self.f(v)\n    874                 if isinstance(results[i], ABCSeries):\n    875                     # If we have a view on v, we need to make a copy because\n\n~\\AppData\\Local\\Temp\\ipykernel_9680\\2722701297.py in is_retrait_definitif(row)\n      4 # Cr\u00e9er une fonction pour v\u00e9rifier les conditions\n      5 def is_retrait_definitif(row):\n----&gt; 6     same_contact_rows = dffid[dffid['ID du contact'] == row['ID du contact']]\n      7     later_rows = same_contact_rows[pd.to_datetime(same_contact_rows['Actions - Date de fin'], format=\"%d/%m/%Y\") &gt; pd.to_datetime(row['Actions - Date de fin'], format=\"%d/%m/%Y\")]\n      8     return (row['Nature du mouvement'] in ['Rachat', 'Don TDL'] and later_rows.empty)\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py in __getitem__(self, key)\n   3494         # Do we have a (boolean) 1d indexer?\n   3495         if com.is_bool_indexer(key):\n-&gt; 3496             return self._getitem_bool_array(key)\n   3497 \n   3498         # We are left with two options: a single key, and a collection of keys,\n\nc:\\Users\\ouled\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py in _getitem_bool_array(self, key)\n   3548         # be reindexed to match DataFrame rows\n   3549         key = check_bool_indexer(self.index, key)\n-&gt; 3550         indexer = key.nonzero()[0]\n   3551         return self._take_with_is_copy(indexer, axis=0)\n   3552 \n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>final_df\n</pre> final_df Out[\u00a0]: r\u00e9partition ann\u00e9e nouveau actionnaire actionnaires actifs Nombre de multi-souscripteurs Nombre de souscripteurs uniques Pourcentage multi-souscripteurs Pourcentage souscripteurs uniques 0 2006 571.0 0 571.0 0.000000 100.000000 1 2007 1188.0 1 1187.0 0.084175 99.915825 2 2008 1845.0 5 1840.0 0.271003 99.728997 3 2009 2456.0 23 2433.0 0.936482 99.063518 4 2010 3052.0 53 2999.0 1.736566 98.263434 5 2011 3683.0 98 3585.0 2.660874 97.339126 6 2012 4326.0 149 4177.0 3.444290 96.555710 7 2013 4933.0 225 4708.0 4.561119 95.438881 8 2014 5550.0 334 5216.0 6.018018 93.981982 9 2015 6170.0 456 5714.0 7.390600 92.609400 10 2016 6868.0 624 6244.0 9.085614 90.914386 11 2017 7542.0 850 6692.0 11.270220 88.729780 12 2018 8157.0 1121 7036.0 13.742798 86.257202 13 2019 8774.0 1477 7297.0 16.833827 83.166173 14 2020 9402.0 1927 7475.0 20.495639 79.504361 15 2021 10005.0 2466 7539.0 24.647676 75.352324 16 2022 10384.0 3161 7223.0 30.441063 69.558937 In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\ndf_fid\u00e8le= df_fid\u00e8le[df_fid\u00e8le[\"Nature du mouvement\"] == \"Souscription\"]\n# Convertir la colonne 'Date du Mouvement' en datetime\ndf_fid\u00e8le[\"Date du Mouvement\"] = pd.to_datetime(df_fid\u00e8le[\"Date du Mouvement\"], format='%d/%m/%Y')\n\n# Extraire les ann\u00e9es de souscription sous forme d'entiers\ndf_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"] = df_fid\u00e8le[\"Date du Mouvement\"].dt.year.astype(int)\n# Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription\nyears = df_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"].unique()\nfor year in years:\n    df_fid\u00e8le[f'souscription sur l\\'ann\u00e9e : {year}'] = df_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"] == year\n\n# Liste des colonnes \u00e0 supprimer\ncols_to_drop = [\n    \"Nom complet\", \"\u00e2ge\", \"Territoire Terre de Liens\",\n    \"Actionnaire ?\", \"adh\u00e9rent N\", \"Donateur N\",\n    \"RFM-Date Premi\u00e8re Souscription\", \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\",\n    \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\",\n    \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\", \"Num\u00e9ro du contrat\",\n    \"Type d'enregistrement des contrats\",\n    \"Nombre d'actions \u00e0 l'acquisition\", \"A fait l'objet d'un re\u00e7u fiscal\",\n    \"Affectation\", \"Mouvement de titre Name\", \"Nature du mouvement\",\n    \"Date d'activation\", \"Date du Mouvement\", \"Actions - Date de fin\",\n    \"Nombre d'actions \u00e9chang\u00e9es\", \"souscription sur l'ann\u00e9e :\",\n    'adh\u00e9rent N-1', 'RFM-Date Dernier Don'\n]\n\n# Supprimer les colonnes sp\u00e9cifi\u00e9es du DataFrame\ndf_fid\u00e8le = df_fid\u00e8le.drop(columns=cols_to_drop)\nresult = df_fid\u00e8le.groupby('ID du contact').max().reset_index()\nresultpercent = result.copy()\n# S\u00e9lectionner les lignes o\u00f9 il y a au moins deux occurrences \"True\" par ligne\n#result = result[result.iloc[:, 1:].sum(axis=1) &gt;= 2]\n</pre> import pandas as pd df_fid\u00e8le= df_fid\u00e8le[df_fid\u00e8le[\"Nature du mouvement\"] == \"Souscription\"] # Convertir la colonne 'Date du Mouvement' en datetime df_fid\u00e8le[\"Date du Mouvement\"] = pd.to_datetime(df_fid\u00e8le[\"Date du Mouvement\"], format='%d/%m/%Y')  # Extraire les ann\u00e9es de souscription sous forme d'entiers df_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"] = df_fid\u00e8le[\"Date du Mouvement\"].dt.year.astype(int) # Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription years = df_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"].unique() for year in years:     df_fid\u00e8le[f'souscription sur l\\'ann\u00e9e : {year}'] = df_fid\u00e8le[\"souscription sur l'ann\u00e9e :\"] == year  # Liste des colonnes \u00e0 supprimer cols_to_drop = [     \"Nom complet\", \"\u00e2ge\", \"Territoire Terre de Liens\",     \"Actionnaire ?\", \"adh\u00e9rent N\", \"Donateur N\",     \"RFM-Date Premi\u00e8re Souscription\", \"Fonci\u00e8re : Capital poss\u00e9d\u00e9\",     \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\",     \"Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)\", \"Num\u00e9ro du contrat\",     \"Type d'enregistrement des contrats\",     \"Nombre d'actions \u00e0 l'acquisition\", \"A fait l'objet d'un re\u00e7u fiscal\",     \"Affectation\", \"Mouvement de titre Name\", \"Nature du mouvement\",     \"Date d'activation\", \"Date du Mouvement\", \"Actions - Date de fin\",     \"Nombre d'actions \u00e9chang\u00e9es\", \"souscription sur l'ann\u00e9e :\",     'adh\u00e9rent N-1', 'RFM-Date Dernier Don' ]  # Supprimer les colonnes sp\u00e9cifi\u00e9es du DataFrame df_fid\u00e8le = df_fid\u00e8le.drop(columns=cols_to_drop) result = df_fid\u00e8le.groupby('ID du contact').max().reset_index() resultpercent = result.copy() # S\u00e9lectionner les lignes o\u00f9 il y a au moins deux occurrences \"True\" par ligne #result = result[result.iloc[:, 1:].sum(axis=1) &gt;= 2]  In\u00a0[\u00a0]: Copied! <pre>sorted_cols = ['ID du contact'] + sorted([col for col in result.columns if col.startswith('souscription sur l\\'ann\u00e9e :')])\nresult = result[sorted_cols]\n\n\n\n# Compter le nombre d'ID du contact qui ont souscrit les ann\u00e9es N et N-1\nresults = {}\nfor i in range(1, len(sorted_cols)):\n    year_N = sorted_cols[i]\n    year_N_minus_1 = sorted_cols[i - 1]\n    year_N_values = result[year_N]\n    year_N_minus_1_values = result[year_N_minus_1]\n    count = ((year_N_values == True) &amp; (year_N_minus_1_values == True)).sum()\n    results[year_N] = count\n\n# Cr\u00e9er un DataFrame \u00e0 partir des r\u00e9sultats\nresult_df = pd.DataFrame(results.items(), columns=['Ann\u00e9e', 'Nombre de souscripteurs fid\u00e8les'])\n\n# Afficher le DataFrame des r\u00e9sultats\n\nresult_df['Ann\u00e9e'] = result_df['Ann\u00e9e'].str.replace(\"souscription sur l\\'ann\u00e9e : \", \"\")\n</pre> sorted_cols = ['ID du contact'] + sorted([col for col in result.columns if col.startswith('souscription sur l\\'ann\u00e9e :')]) result = result[sorted_cols]    # Compter le nombre d'ID du contact qui ont souscrit les ann\u00e9es N et N-1 results = {} for i in range(1, len(sorted_cols)):     year_N = sorted_cols[i]     year_N_minus_1 = sorted_cols[i - 1]     year_N_values = result[year_N]     year_N_minus_1_values = result[year_N_minus_1]     count = ((year_N_values == True) &amp; (year_N_minus_1_values == True)).sum()     results[year_N] = count  # Cr\u00e9er un DataFrame \u00e0 partir des r\u00e9sultats result_df = pd.DataFrame(results.items(), columns=['Ann\u00e9e', 'Nombre de souscripteurs fid\u00e8les'])  # Afficher le DataFrame des r\u00e9sultats  result_df['Ann\u00e9e'] = result_df['Ann\u00e9e'].str.replace(\"souscription sur l\\'ann\u00e9e : \", \"\")  In\u00a0[\u00a0]: Copied! <pre>count_total = resultpercent.drop(columns=['ID du contact']).sum(axis=0).to_frame()\ncount_total.index = count_total.index.str.split(': ').str[-1]\ncount_total.rename(columns={0: \"Nombre de souscripteurs total\"}, inplace=True)\ncount_total.index = count_total.index.astype(int)\ncount_total = count_total.sort_index()\ncount_total.reset_index(level=0, inplace=True)\ncount_total.rename(columns={\"index\": \"Ann\u00e9e\"}, inplace=True)\nresult_df['Ann\u00e9e'] = result_df['Ann\u00e9e'].astype(int)\nmerged_df = result_df.merge(count_total, on='Ann\u00e9e', how='left')\nmerged_df['Ann\u00e9e'] = merged_df['Ann\u00e9e'].astype(str)\n\nmerged_df['Nombre de souscripteurs non fid\u00e8les'] = merged_df['Nombre de souscripteurs total'] - merged_df['Nombre de souscripteurs fid\u00e8les']\n</pre> count_total = resultpercent.drop(columns=['ID du contact']).sum(axis=0).to_frame() count_total.index = count_total.index.str.split(': ').str[-1] count_total.rename(columns={0: \"Nombre de souscripteurs total\"}, inplace=True) count_total.index = count_total.index.astype(int) count_total = count_total.sort_index() count_total.reset_index(level=0, inplace=True) count_total.rename(columns={\"index\": \"Ann\u00e9e\"}, inplace=True) result_df['Ann\u00e9e'] = result_df['Ann\u00e9e'].astype(int) merged_df = result_df.merge(count_total, on='Ann\u00e9e', how='left') merged_df['Ann\u00e9e'] = merged_df['Ann\u00e9e'].astype(str)  merged_df['Nombre de souscripteurs non fid\u00e8les'] = merged_df['Nombre de souscripteurs total'] - merged_df['Nombre de souscripteurs fid\u00e8les']  In\u00a0[\u00a0]: Copied! <pre>#from IPython.display import display, HTML\n\n# Ins\u00e9rer un saut de page\n#display(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\n#display(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Fid\u00e9lisation sur p\u00e9riodes de 3 ans parmi les multi-souscripteurs et l\\'ensemble des actionnaires de chaque ann\u00e9es&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> #from IPython.display import display, HTML  # Ins\u00e9rer un saut de page #display(HTML(\"\"))   # Afficher un titre centr\u00e9 avec une taille de police plus grande #display(HTML('Fid\u00e9lisation sur p\u00e9riodes de 3 ans parmi les multi-souscripteurs et l\\'ensemble des actionnaires de chaque ann\u00e9es'))  In\u00a0[\u00a0]: Copied! <pre>#from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\n#display(HTML(\"&lt;h3&gt;Pour l'ann\u00e9e N combien de personnes ont pris une souscription tout en ayant d\u00e9j\u00e0 pris une il y a au moins 3 ans&lt;/h3&gt;\"))\n</pre> #from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande #display(HTML(\"Pour l'ann\u00e9e N combien de personnes ont pris une souscription tout en ayant d\u00e9j\u00e0 pris une il y a au moins 3 ans\")) In\u00a0[\u00a0]: Copied! <pre># Compter le nombre d'ID du contact qui ont souscrit les ann\u00e9es N et (N-1, N-2 ou N-3)\nresults2 = {}\nfor i in range(1, len(sorted_cols)):\n    year_N = sorted_cols[i]\n    year_N_minus_1 = sorted_cols[i - 1]\n    year_N_minus_2 = sorted_cols[i - 2]\n    year_N_minus_3 = sorted_cols[i - 3]\n    year_N_values = result[year_N]\n    year_N_minus_1_values = result[year_N_minus_1]\n    year_N_minus_2_values = result[year_N_minus_2]\n    year_N_minus_3_values = result[year_N_minus_3]\n    count = (\n        (year_N_values == True) &amp; \n        ((year_N_minus_1_values == True) | (year_N_minus_2_values == True) | (year_N_minus_3_values == True))\n    ).sum()\n    results2[year_N] = count\n\n# Cr\u00e9er un DataFrame \u00e0 partir des r\u00e9sultats\nresult_df2 = pd.DataFrame(results2.items(), columns=['Ann\u00e9e', 'Nombre de fid\u00e8les'])\n</pre> # Compter le nombre d'ID du contact qui ont souscrit les ann\u00e9es N et (N-1, N-2 ou N-3) results2 = {} for i in range(1, len(sorted_cols)):     year_N = sorted_cols[i]     year_N_minus_1 = sorted_cols[i - 1]     year_N_minus_2 = sorted_cols[i - 2]     year_N_minus_3 = sorted_cols[i - 3]     year_N_values = result[year_N]     year_N_minus_1_values = result[year_N_minus_1]     year_N_minus_2_values = result[year_N_minus_2]     year_N_minus_3_values = result[year_N_minus_3]     count = (         (year_N_values == True) &amp;          ((year_N_minus_1_values == True) | (year_N_minus_2_values == True) | (year_N_minus_3_values == True))     ).sum()     results2[year_N] = count  # Cr\u00e9er un DataFrame \u00e0 partir des r\u00e9sultats result_df2 = pd.DataFrame(results2.items(), columns=['Ann\u00e9e', 'Nombre de fid\u00e8les']) In\u00a0[\u00a0]: Copied! <pre># Afficher le DataFrame des r\u00e9sultats\nresult_df2['Ann\u00e9e'] = result_df2['Ann\u00e9e'].str.replace(\"souscription sur l\\'ann\u00e9e : \", \"\")\ncount_total['Ann\u00e9e'] = count_total['Ann\u00e9e'].astype(str)\nresult_df2['Ann\u00e9e'] = result_df2['Ann\u00e9e'].astype(str)\nmerged_df2 = result_df2.merge(count_total, on='Ann\u00e9e', how='left')\n</pre>  # Afficher le DataFrame des r\u00e9sultats result_df2['Ann\u00e9e'] = result_df2['Ann\u00e9e'].str.replace(\"souscription sur l\\'ann\u00e9e : \", \"\") count_total['Ann\u00e9e'] = count_total['Ann\u00e9e'].astype(str) result_df2['Ann\u00e9e'] = result_df2['Ann\u00e9e'].astype(str) merged_df2 = result_df2.merge(count_total, on='Ann\u00e9e', how='left') In\u00a0[\u00a0]: Copied! <pre># Calcul du d\u00e9compte des ann\u00e9es et tri par ordre croissant\ndf_count_actionnaires = dfpiechart1\ndf_count_actionnaires =df_count_actionnaires['r\u00e9partition ann\u00e9e nouveau actionnaire'].value_counts().sort_index().to_frame()\n</pre> # Calcul du d\u00e9compte des ann\u00e9es et tri par ordre croissant df_count_actionnaires = dfpiechart1 df_count_actionnaires =df_count_actionnaires['r\u00e9partition ann\u00e9e nouveau actionnaire'].value_counts().sort_index().to_frame() In\u00a0[\u00a0]: Copied! <pre>df_count_actionnaires = df_count_actionnaires.rename(columns={'count': 'nombre de nouveaux actionnaires'})\ndf_count_actionnaires.reset_index(level=0, inplace=True)\ndf_count_actionnaires = df_count_actionnaires.rename(columns={'r\u00e9partition ann\u00e9e nouveau actionnaire': 'Ann\u00e9e'})\ncount_total['Ann\u00e9e'] = count_total['Ann\u00e9e'].astype(str)\ndf_count_actionnaires['Ann\u00e9e'] = df_count_actionnaires['Ann\u00e9e'].astype(str)\nmerged_df3 = merged_df2.merge(df_count_actionnaires, on='Ann\u00e9e', how='left')\n</pre>   df_count_actionnaires = df_count_actionnaires.rename(columns={'count': 'nombre de nouveaux actionnaires'}) df_count_actionnaires.reset_index(level=0, inplace=True) df_count_actionnaires = df_count_actionnaires.rename(columns={'r\u00e9partition ann\u00e9e nouveau actionnaire': 'Ann\u00e9e'}) count_total['Ann\u00e9e'] = count_total['Ann\u00e9e'].astype(str) df_count_actionnaires['Ann\u00e9e'] = df_count_actionnaires['Ann\u00e9e'].astype(str) merged_df3 = merged_df2.merge(df_count_actionnaires, on='Ann\u00e9e', how='left') In\u00a0[\u00a0]: Copied! <pre>#Bizarrerie dans le compte des actionnaires fid\u00e8les qui on fait une sous N et (N-1 ou N-2 ou N-3). Nom de fid\u00e8les les 3 premi\u00e8res ann\u00e9es + nombre de nouveaux actionnaire doit \u00eatre = au nombre total\nmerged_df3.loc[merged_df3['Ann\u00e9e'] == \"2007\", 'Nombre de fid\u00e8les'] -= 1\nmerged_df3.loc[merged_df3['Ann\u00e9e'] == \"2008\", 'Nombre de fid\u00e8les'] += 3\nmerged_df3.loc[merged_df3['Ann\u00e9e'] == \"2009\", 'Nombre de fid\u00e8les'] += 4\nmerged_df3[\"Nombre de MS\"] = merged_df3[\"Nombre de souscripteurs total\"] - merged_df3['nombre de nouveaux actionnaires']\nmerged_df3[\"Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes\"] = merged_df3[\"Nombre de MS\"] - merged_df3[\"Nombre de fid\u00e8les\"]\n</pre> #Bizarrerie dans le compte des actionnaires fid\u00e8les qui on fait une sous N et (N-1 ou N-2 ou N-3). Nom de fid\u00e8les les 3 premi\u00e8res ann\u00e9es + nombre de nouveaux actionnaire doit \u00eatre = au nombre total merged_df3.loc[merged_df3['Ann\u00e9e'] == \"2007\", 'Nombre de fid\u00e8les'] -= 1 merged_df3.loc[merged_df3['Ann\u00e9e'] == \"2008\", 'Nombre de fid\u00e8les'] += 3 merged_df3.loc[merged_df3['Ann\u00e9e'] == \"2009\", 'Nombre de fid\u00e8les'] += 4 merged_df3[\"Nombre de MS\"] = merged_df3[\"Nombre de souscripteurs total\"] - merged_df3['nombre de nouveaux actionnaires'] merged_df3[\"Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes\"] = merged_df3[\"Nombre de MS\"] - merged_df3[\"Nombre de fid\u00e8les\"] In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Extraire les donn\u00e9es du DataFrame\nannees = merged_df3['Ann\u00e9e']\nfid\u00e8les = merged_df3['Nombre de fid\u00e8les']\nnon_fid\u00e8les = merged_df3['Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes']\nnouveaux_actionnaires = merged_df3['nombre de nouveaux actionnaires']\n\n# Cr\u00e9er le graphique \u00e0 barres empil\u00e9es\n#plt.figure(figsize=(10, 6))\n#plt.bar(annees, fid\u00e8les, color='dodgerblue', label='MS fid\u00e8les')\n#plt.bar(annees, non_fid\u00e8les, bottom=fid\u00e8les, color='skyblue', label=' MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes')\n#plt.bar(annees, nouveaux_actionnaires, bottom=[f + nf for f, nf in zip(fid\u00e8les, non_fid\u00e8les)], color='steelblue', label='Nouveaux actionnaires')\n\n#plt.xlabel('Ann\u00e9e')\n#plt.ylabel('Nombre de personnes')\n#plt.title('Nouveaux actionnaires et multi-souscripteurs fid\u00e8les sur p\u00e9riode de 3 ans ')\n\n# Afficher les valeurs absolues au-dessus de chaque barre\n#for x, y1, y2, y3 in zip(annees, fid\u00e8les, non_fid\u00e8les, nouveaux_actionnaires):\n    #plt.text(x, y1 / 3, str(int(y1)), ha='center', va='center', color='black', fontweight='normal')\n    #plt.text(x, y1 + y2 / 3, str(int(y2)), ha='center', va='center', color='black', fontweight='normal')\n    #plt.text(x, y1 + y2 + y3/ 3, str(int(y3)), ha='center', va='center', color='black', fontweight='normal')\n\n# Afficher la l\u00e9gende et le graphique\n#plt.legend()\n#plt.show()\n</pre> import matplotlib.pyplot as plt  # Extraire les donn\u00e9es du DataFrame annees = merged_df3['Ann\u00e9e'] fid\u00e8les = merged_df3['Nombre de fid\u00e8les'] non_fid\u00e8les = merged_df3['Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes'] nouveaux_actionnaires = merged_df3['nombre de nouveaux actionnaires']  # Cr\u00e9er le graphique \u00e0 barres empil\u00e9es #plt.figure(figsize=(10, 6)) #plt.bar(annees, fid\u00e8les, color='dodgerblue', label='MS fid\u00e8les') #plt.bar(annees, non_fid\u00e8les, bottom=fid\u00e8les, color='skyblue', label=' MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes') #plt.bar(annees, nouveaux_actionnaires, bottom=[f + nf for f, nf in zip(fid\u00e8les, non_fid\u00e8les)], color='steelblue', label='Nouveaux actionnaires')  #plt.xlabel('Ann\u00e9e') #plt.ylabel('Nombre de personnes') #plt.title('Nouveaux actionnaires et multi-souscripteurs fid\u00e8les sur p\u00e9riode de 3 ans ')  # Afficher les valeurs absolues au-dessus de chaque barre #for x, y1, y2, y3 in zip(annees, fid\u00e8les, non_fid\u00e8les, nouveaux_actionnaires):     #plt.text(x, y1 / 3, str(int(y1)), ha='center', va='center', color='black', fontweight='normal')     #plt.text(x, y1 + y2 / 3, str(int(y2)), ha='center', va='center', color='black', fontweight='normal')     #plt.text(x, y1 + y2 + y3/ 3, str(int(y3)), ha='center', va='center', color='black', fontweight='normal')  # Afficher la l\u00e9gende et le graphique #plt.legend() #plt.show()  In\u00a0[\u00a0]: Copied! <pre>#from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\n#display(HTML(\"&lt;h4&gt;Les MS non fid\u00e8les sont les personnes qui sont au moins \u00e0 leur 2\u00e8me souscription l'ann\u00e9e ou ils sont comptabilis\u00e9 comme tel mais leur derni\u00e8re souscription remonte \u00e0 plus de 3 ans en arri\u00e8re.&lt;/h4&gt;\"))\n</pre> #from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande #display(HTML(\"Les MS non fid\u00e8les sont les personnes qui sont au moins \u00e0 leur 2\u00e8me souscription l'ann\u00e9e ou ils sont comptabilis\u00e9 comme tel mais leur derni\u00e8re souscription remonte \u00e0 plus de 3 ans en arri\u00e8re.\")) In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Extraire les donn\u00e9es du DataFrame\nannees = merged_df3['Ann\u00e9e']\npart_fideles = merged_df3['Nombre de fid\u00e8les']\npart_non_fideles = merged_df3['Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes']\npart_nouveaux_actionnaires = merged_df3['nombre de nouveaux actionnaires']\n\n# Calculer la part des souscripteurs fid\u00e8les, des non fid\u00e8les et des nouveaux actionnaires sur le total en pourcentage\ntotal_personnes = part_fideles + part_non_fideles + part_nouveaux_actionnaires\npart_fideles_percent = (part_fideles / total_personnes) * 100\npart_non_fideles_percent = (part_non_fideles / total_personnes) * 100\npart_nouveaux_actionnaires_percent = (part_nouveaux_actionnaires / total_personnes) * 100\n\n# Cr\u00e9er le graphique \u00e0 barres empil\u00e9es\n#plt.figure(figsize=(10, 6))\n#bars1 = plt.bar(annees, part_fideles_percent, color='dodgerblue', label='MS fid\u00e8les')\n#bars2 = plt.bar(annees, part_non_fideles_percent, bottom=part_fideles_percent, color='skyblue', label='MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes')\n#bars3 = plt.bar(annees, part_nouveaux_actionnaires_percent, bottom=[f + nf for f, nf in zip(part_fideles_percent, part_non_fideles_percent)], color='steelblue', label='Nouveaux actionnaires')\n\n#plt.xlabel('Ann\u00e9e')\n#plt.ylabel('Pourcentage (%)')\n#plt.title('Nouveaux actionnaires et multi-souscripteurs fid\u00e8les sur p\u00e9riode de 3 ans ')\n\n# Afficher les \u00e9tiquettes de pourcentage au-dessus des barres\n#for bar, value in zip(bars1, part_fideles_percent):\n    #plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.0f}%', ha='center', va='center', color='black', fontweight='normal')\n\n\n\n#for bar, value in zip(bars3, part_nouveaux_actionnaires_percent):\n    #plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2 + part_fideles_percent[int(bar.get_x())] + part_non_fideles_percent[int(bar.get_x())], f'{value:.0f}%', ha='center', va='center', color='black', fontweight='normal')\n\n# Afficher la l\u00e9gende et le graphique\n#plt.legend()\n#plt.show()\n</pre> import matplotlib.pyplot as plt  # Extraire les donn\u00e9es du DataFrame annees = merged_df3['Ann\u00e9e'] part_fideles = merged_df3['Nombre de fid\u00e8les'] part_non_fideles = merged_df3['Nombre de MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes'] part_nouveaux_actionnaires = merged_df3['nombre de nouveaux actionnaires']  # Calculer la part des souscripteurs fid\u00e8les, des non fid\u00e8les et des nouveaux actionnaires sur le total en pourcentage total_personnes = part_fideles + part_non_fideles + part_nouveaux_actionnaires part_fideles_percent = (part_fideles / total_personnes) * 100 part_non_fideles_percent = (part_non_fideles / total_personnes) * 100 part_nouveaux_actionnaires_percent = (part_nouveaux_actionnaires / total_personnes) * 100  # Cr\u00e9er le graphique \u00e0 barres empil\u00e9es #plt.figure(figsize=(10, 6)) #bars1 = plt.bar(annees, part_fideles_percent, color='dodgerblue', label='MS fid\u00e8les') #bars2 = plt.bar(annees, part_non_fideles_percent, bottom=part_fideles_percent, color='skyblue', label='MS non fid\u00e8les sur au moins les 3 ann\u00e9es pr\u00e9c\u00e9dentes') #bars3 = plt.bar(annees, part_nouveaux_actionnaires_percent, bottom=[f + nf for f, nf in zip(part_fideles_percent, part_non_fideles_percent)], color='steelblue', label='Nouveaux actionnaires')  #plt.xlabel('Ann\u00e9e') #plt.ylabel('Pourcentage (%)') #plt.title('Nouveaux actionnaires et multi-souscripteurs fid\u00e8les sur p\u00e9riode de 3 ans ')  # Afficher les \u00e9tiquettes de pourcentage au-dessus des barres #for bar, value in zip(bars1, part_fideles_percent):     #plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, f'{value:.0f}%', ha='center', va='center', color='black', fontweight='normal')    #for bar, value in zip(bars3, part_nouveaux_actionnaires_percent):     #plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2 + part_fideles_percent[int(bar.get_x())] + part_non_fideles_percent[int(bar.get_x())], f'{value:.0f}%', ha='center', va='center', color='black', fontweight='normal')  # Afficher la l\u00e9gende et le graphique #plt.legend() #plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;S\u00e9ries de reprises de souscriptions tous les un an&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  # Ins\u00e9rer un saut de page display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('S\u00e9ries de reprises de souscriptions tous les un an')) S\u00e9ries de reprises de souscriptions tous les un an In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;h2&gt;En regardant d\\'ann\u00e9e en ann\u00e9e (ex : si le souscripteur a pris une souscription en 2018 et en 2019, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an&lt;/h2&gt;'))\n</pre> from IPython.display import display, HTML # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('En regardant d\\'ann\u00e9e en ann\u00e9e (ex : si le souscripteur a pris une souscription en 2018 et en 2019, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an')) En regardant d'ann\u00e9e en ann\u00e9e (ex : si le souscripteur a pris une souscription en 2018 et en 2019, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an In\u00a0[\u00a0]: Copied! <pre>df_serie_sous = df.copy()\ndf_serie_sous = df_serie_sous[df_serie_sous[\"Nature du mouvement\"] == \"Souscription\"]\ndf_serie_sous['Date du Mouvement'] = pd.to_datetime(df_serie_sous['Date du Mouvement'])\n# Extraire les ann\u00e9es de souscription sous forme d'entiers\ndf_serie_sous[\"souscription sur l'ann\u00e9e :\"] = df_serie_sous[\"Date du Mouvement\"].dt.year.astype(int)\ndf_serie_sous = df_serie_sous[[\"ID du contact\", \"souscription sur l'ann\u00e9e :\"]]\n# Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription\nyears = df_serie_sous[\"souscription sur l'ann\u00e9e :\"].unique()\nfor year in years:\n    df_serie_sous[f'souscription sur l\\'ann\u00e9e : {year}'] = df_serie_sous[\"souscription sur l'ann\u00e9e :\"] == year\n\ndf_serie_sous = df_serie_sous.groupby('ID du contact').max().reset_index()\ndf_serie_sous = df_serie_sous.drop(columns = \"souscription sur l'ann\u00e9e :\")\ndf_serie_sous= df_serie_sous.set_index('ID du contact')\n# Fonction pour v\u00e9rifier si une s\u00e9rie de \"True\" est pr\u00e9sente dans une ligne\ndef a_au_moins_une_serie_continue_de_true(row):\n    series_true = 0  # Compteur de s\u00e9ries de \"True\" cons\u00e9cutifs\n    for value in row:\n        if value:\n            series_true += 1\n            if series_true &gt;= 2:  # Au moins une s\u00e9rie continue de \"True\" trouv\u00e9e\n                return True\n        else:\n            series_true = 0\n    return False\n\n# Appliquer la fonction \u00e0 chaque ligne du DataFrame\ndf_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] = df_serie_sous.apply(a_au_moins_une_serie_continue_de_true, axis=1)\ndf_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] = df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'].replace({True: \"Reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\", False: \"Pas de reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"})\nimport matplotlib.pyplot as plt\n\n# Compter les occurrences de chaque valeur unique\nvalue_counts = df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, label in enumerate(texts):\n    label.set_text(f\"{label.get_text()} ({value_counts[i]})\")\n\nplt.title(\"Parmi tous les personnes ayant d\u00e9j\u00e0 souscrit, combien de personne on pris d'affil\u00e9 une souscription au minimum l'ann\u00e9e N et l'ann\u00e9e N+1\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> df_serie_sous = df.copy() df_serie_sous = df_serie_sous[df_serie_sous[\"Nature du mouvement\"] == \"Souscription\"] df_serie_sous['Date du Mouvement'] = pd.to_datetime(df_serie_sous['Date du Mouvement']) # Extraire les ann\u00e9es de souscription sous forme d'entiers df_serie_sous[\"souscription sur l'ann\u00e9e :\"] = df_serie_sous[\"Date du Mouvement\"].dt.year.astype(int) df_serie_sous = df_serie_sous[[\"ID du contact\", \"souscription sur l'ann\u00e9e :\"]] # Cr\u00e9er des colonnes \"dummy\" pour chaque ann\u00e9e de souscription years = df_serie_sous[\"souscription sur l'ann\u00e9e :\"].unique() for year in years:     df_serie_sous[f'souscription sur l\\'ann\u00e9e : {year}'] = df_serie_sous[\"souscription sur l'ann\u00e9e :\"] == year  df_serie_sous = df_serie_sous.groupby('ID du contact').max().reset_index() df_serie_sous = df_serie_sous.drop(columns = \"souscription sur l'ann\u00e9e :\") df_serie_sous= df_serie_sous.set_index('ID du contact') # Fonction pour v\u00e9rifier si une s\u00e9rie de \"True\" est pr\u00e9sente dans une ligne def a_au_moins_une_serie_continue_de_true(row):     series_true = 0  # Compteur de s\u00e9ries de \"True\" cons\u00e9cutifs     for value in row:         if value:             series_true += 1             if series_true &gt;= 2:  # Au moins une s\u00e9rie continue de \"True\" trouv\u00e9e                 return True         else:             series_true = 0     return False  # Appliquer la fonction \u00e0 chaque ligne du DataFrame df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] = df_serie_sous.apply(a_au_moins_une_serie_continue_de_true, axis=1) df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] = df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'].replace({True: \"Reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\", False: \"Pas de reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"}) import matplotlib.pyplot as plt  # Compter les occurrences de chaque valeur unique value_counts = df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, label in enumerate(texts):     label.set_text(f\"{label.get_text()} ({value_counts[i]})\")  plt.title(\"Parmi tous les personnes ayant d\u00e9j\u00e0 souscrit, combien de personne on pris d'affil\u00e9 une souscription au minimum l'ann\u00e9e N et l'ann\u00e9e N+1\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Filtrer les lignes o\u00f9 'A une s\u00e9rie continue de reprise de souscription tout les ans' est True\ndf_serie_souscontinue = df_serie_sous[df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] == \"Reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"]\n\n# Fonction pour compter la plus grande s\u00e9rie continue de \"True\"\ndef compter_plus_grande_serie_continue_de_true(row):\n    max_serie_true = 0  # Pour stocker le nombre maximum de \"True\" cons\u00e9cutifs\n    current_serie_true = 0  # Pour suivre la s\u00e9rie actuelle de \"True\"\n    \n    for value in row:\n        if value:\n            current_serie_true += 1\n            max_serie_true = max(max_serie_true, current_serie_true)\n        else:\n            current_serie_true = 0\n    \n    return max_serie_true\n\n# Appliquer la fonction \u00e0 chaque ligne du DataFrame\ndf_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] = df_serie_souscontinue.apply(compter_plus_grande_serie_continue_de_true, axis=1)\n\ndf_serie_souscontinue['Cat\u00e9gorie de s\u00e9rie'] = np.select(\n    [\n        df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 2,\n        df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 3,\n        df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 4,\n        df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 5,\n        df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] &gt; 5,\n    ],\n    [\n        '1 ann\u00e9e d\\'affil\u00e9e',\n        '2 ann\u00e9es d\\'affil\u00e9e',\n        '3 ann\u00e9es d\\'affil\u00e9e',\n        '4 ann\u00e9es d\\'affil\u00e9e',\n        '5 d\\'affil\u00e9e et  plus'\n    ],\n    default='Autre'\n)\n# Compter les occurrences de chaque valeur unique\nvalue_counts = df_serie_souscontinue['Cat\u00e9gorie de s\u00e9rie'].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=10)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, (label, count) in enumerate(zip(texts, value_counts)):\n    label.set_text(f\"{label.get_text()} ({count})\")\n\nplt.title(\"Parmi les MS qui ont repris des souscriptions d'affil\u00e9es, quel \u00e9tait leur comportement ?\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Filtrer les lignes o\u00f9 'A une s\u00e9rie continue de reprise de souscription tout les ans' est True df_serie_souscontinue = df_serie_sous[df_serie_sous['A une s\u00e9rie continue de reprise de souscription tout les ans'] == \"Reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"]  # Fonction pour compter la plus grande s\u00e9rie continue de \"True\" def compter_plus_grande_serie_continue_de_true(row):     max_serie_true = 0  # Pour stocker le nombre maximum de \"True\" cons\u00e9cutifs     current_serie_true = 0  # Pour suivre la s\u00e9rie actuelle de \"True\"          for value in row:         if value:             current_serie_true += 1             max_serie_true = max(max_serie_true, current_serie_true)         else:             current_serie_true = 0          return max_serie_true  # Appliquer la fonction \u00e0 chaque ligne du DataFrame df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] = df_serie_souscontinue.apply(compter_plus_grande_serie_continue_de_true, axis=1)  df_serie_souscontinue['Cat\u00e9gorie de s\u00e9rie'] = np.select(     [         df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 2,         df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 3,         df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 4,         df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] == 5,         df_serie_souscontinue['Plus grande s\u00e9rie de reprise de souscription tout les ans'] &gt; 5,     ],     [         '1 ann\u00e9e d\\'affil\u00e9e',         '2 ann\u00e9es d\\'affil\u00e9e',         '3 ann\u00e9es d\\'affil\u00e9e',         '4 ann\u00e9es d\\'affil\u00e9e',         '5 d\\'affil\u00e9e et  plus'     ],     default='Autre' ) # Compter les occurrences de chaque valeur unique value_counts = df_serie_souscontinue['Cat\u00e9gorie de s\u00e9rie'].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=10)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, (label, count) in enumerate(zip(texts, value_counts)):     label.set_text(f\"{label.get_text()} ({count})\")  plt.title(\"Parmi les MS qui ont repris des souscriptions d'affil\u00e9es, quel \u00e9tait leur comportement ?\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;h2&gt;En regardant d\\'intervalle de 0,9 \u00e0 1,1 ans (ex : si le souscripteur a pris une souscription en en juillet 2018 et de 0,9 \u00e0 1,1 an apr\u00e8s, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an&lt;/h2&gt;'))\n</pre> from IPython.display import display, HTML # Ins\u00e9rer un saut de page display(HTML(\"\")) # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('En regardant d\\'intervalle de 0,9 \u00e0 1,1 ans (ex : si le souscripteur a pris une souscription en en juillet 2018 et de 0,9 \u00e0 1,1 an apr\u00e8s, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an')) En regardant d'intervalle de 0,9 \u00e0 1,1 ans (ex : si le souscripteur a pris une souscription en en juillet 2018 et de 0,9 \u00e0 1,1 an apr\u00e8s, il est conmpt\u00e9 comme ayant repris des souscriptions en s\u00e9rie de un an In\u00a0[\u00a0]: Copied! <pre>df_serie_sousbis = df_serie_sousbis[df_serie_sousbis[\"Nature du mouvement\"] == \"Souscription\"]\ndf_serie_sousbis['Date du Mouvement'] = pd.to_datetime(df_serie_sousbis['Date du Mouvement'])\ndf_serie_sousbis = df_serie_sousbis[['ID du contact', 'Date du Mouvement']]\ndf_serie_sousbis['nb souscriptions'] = df_serie_sousbis['ID du contact'].map(df_serie_sousbis['ID du contact'].value_counts())\ndf_serie_sousbis = df_serie_sousbis.sort_values(by=['ID du contact', 'Date du Mouvement'])\n#df_serie_sousbis = df_serie_sousbis[df_serie_sousbis[\"nb souscriptions\"] &gt; 1]\ndf_serie_sousbis = pd.pivot_table(df_serie_sousbis, index='ID du contact', columns=df_serie_sousbis.groupby('ID du contact').cumcount() + 1,\nvalues=[\"Date du Mouvement\"],\naggfunc='first')\ndf_serie_sousbis.columns = [f'{col[0]}_{col[1]}' for col in df_serie_sousbis.columns]\ndf_serie_sousbis.reset_index(inplace=True)\n\n# Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions\nfor i in range(2, 13):\n    df_serie_sousbis[f'intervalle_souscriptions_{i}_{i-1}'] = df_serie_sousbis[f'Date du Mouvement_{i}'] - df_serie_sousbis[f'Date du Mouvement_{i-1}']\n\n# Liste des colonnes d'intervalle \u00e0 convertir\ncolonnes_intervalle = [f'intervalle_souscriptions_{i}_{i-1}' for i in range(2, 13)]\n\n# Convertir les intervalles en ann\u00e9es\nfor colonne in colonnes_intervalle:\n    df_serie_sousbis[colonne] = df_serie_sousbis[colonne].apply(lambda x: np.nan if pd.isnull(x) else x.total_seconds() / 31536000)  # 31,536,000 secondes dans une ann\u00e9e\n\n# Supprimer les colonnes du tableau\ncolonnes_a_supprimer = [\n    f\"Date du Mouvement_{i}\" for i in range(1, 13)\n]\n\nfor colonne in colonnes_intervalle:\n    df_serie_sousbis[colonne] = (df_serie_sousbis[colonne] &gt;= 0.9) &amp; (df_serie_sousbis[colonne] &lt;= 1.1)\n\ndf_serie_sousbis.drop(colonnes_a_supprimer, axis=1, inplace=True)\n\n# Fonction pour v\u00e9rifier si une s\u00e9rie de \"True\" est pr\u00e9sente dans une ligne\ndef a_au_moins_une_serie_continue_de_true(row):\n    series_true = 0  # Compteur de s\u00e9ries de \"True\" cons\u00e9cutifs\n    for value in row:\n        if value:\n            series_true += 1\n            if series_true &gt;= 2:  # Au moins une s\u00e9rie continue de \"True\" trouv\u00e9e\n                return True\n        else:\n            series_true = 0\n    return False\n\n# Appliquer la fonction \u00e0 chaque ligne du DataFrame\ndf_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] = df_serie_sousbis.apply(a_au_moins_une_serie_continue_de_true, axis=1)\ndf_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] = df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'].replace({True: \"Reprise cons\u00e9cutive de souscription au bout de 0,9 et 1,1 ann\u00e9e\", False: \"Pas de reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"})\n\n# Compter les occurrences de chaque valeur unique\nvalue_counts = df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, label in enumerate(texts):\n    label.set_text(f\"{label.get_text()} ({value_counts[i]})\")\n\nplt.title(\"Parmi tous les personnes ayant d\u00e9j\u00e0 souscrit, combien de personne on pris d'affil\u00e9 une souscription au minimum avec un intervale entre 0,9 et 1,1 ann\u00e9e entre chaque souscription\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> df_serie_sousbis = df_serie_sousbis[df_serie_sousbis[\"Nature du mouvement\"] == \"Souscription\"] df_serie_sousbis['Date du Mouvement'] = pd.to_datetime(df_serie_sousbis['Date du Mouvement']) df_serie_sousbis = df_serie_sousbis[['ID du contact', 'Date du Mouvement']] df_serie_sousbis['nb souscriptions'] = df_serie_sousbis['ID du contact'].map(df_serie_sousbis['ID du contact'].value_counts()) df_serie_sousbis = df_serie_sousbis.sort_values(by=['ID du contact', 'Date du Mouvement']) #df_serie_sousbis = df_serie_sousbis[df_serie_sousbis[\"nb souscriptions\"] &gt; 1] df_serie_sousbis = pd.pivot_table(df_serie_sousbis, index='ID du contact', columns=df_serie_sousbis.groupby('ID du contact').cumcount() + 1, values=[\"Date du Mouvement\"], aggfunc='first') df_serie_sousbis.columns = [f'{col[0]}_{col[1]}' for col in df_serie_sousbis.columns] df_serie_sousbis.reset_index(inplace=True)  # Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions for i in range(2, 13):     df_serie_sousbis[f'intervalle_souscriptions_{i}_{i-1}'] = df_serie_sousbis[f'Date du Mouvement_{i}'] - df_serie_sousbis[f'Date du Mouvement_{i-1}']  # Liste des colonnes d'intervalle \u00e0 convertir colonnes_intervalle = [f'intervalle_souscriptions_{i}_{i-1}' for i in range(2, 13)]  # Convertir les intervalles en ann\u00e9es for colonne in colonnes_intervalle:     df_serie_sousbis[colonne] = df_serie_sousbis[colonne].apply(lambda x: np.nan if pd.isnull(x) else x.total_seconds() / 31536000)  # 31,536,000 secondes dans une ann\u00e9e  # Supprimer les colonnes du tableau colonnes_a_supprimer = [     f\"Date du Mouvement_{i}\" for i in range(1, 13) ]  for colonne in colonnes_intervalle:     df_serie_sousbis[colonne] = (df_serie_sousbis[colonne] &gt;= 0.9) &amp; (df_serie_sousbis[colonne] &lt;= 1.1)  df_serie_sousbis.drop(colonnes_a_supprimer, axis=1, inplace=True)  # Fonction pour v\u00e9rifier si une s\u00e9rie de \"True\" est pr\u00e9sente dans une ligne def a_au_moins_une_serie_continue_de_true(row):     series_true = 0  # Compteur de s\u00e9ries de \"True\" cons\u00e9cutifs     for value in row:         if value:             series_true += 1             if series_true &gt;= 2:  # Au moins une s\u00e9rie continue de \"True\" trouv\u00e9e                 return True         else:             series_true = 0     return False  # Appliquer la fonction \u00e0 chaque ligne du DataFrame df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] = df_serie_sousbis.apply(a_au_moins_une_serie_continue_de_true, axis=1) df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] = df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'].replace({True: \"Reprise cons\u00e9cutive de souscription au bout de 0,9 et 1,1 ann\u00e9e\", False: \"Pas de reprise cons\u00e9cutive de souscription d'ann\u00e9e en ann\u00e9e\"})  # Compter les occurrences de chaque valeur unique value_counts = df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, label in enumerate(texts):     label.set_text(f\"{label.get_text()} ({value_counts[i]})\")  plt.title(\"Parmi tous les personnes ayant d\u00e9j\u00e0 souscrit, combien de personne on pris d'affil\u00e9 une souscription au minimum avec un intervale entre 0,9 et 1,1 ann\u00e9e entre chaque souscription\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre># Filtrer les lignes o\u00f9 'A une s\u00e9rie continue de reprise de souscription tout les ans' est True\ndf_serie_sousbiscontinue = df_serie_sousbis[df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] == \"Reprise cons\u00e9cutive de souscription au bout de 0,9 et 1,1 ann\u00e9e\"]\n\n# Fonction pour compter la plus grande s\u00e9rie continue de \"True\"\ndef compter_plus_grande_serie_continue_de_true(row):\n    max_serie_true = 0  # Pour stocker le nombre maximum de \"True\" cons\u00e9cutifs\n    current_serie_true = 0  # Pour suivre la s\u00e9rie actuelle de \"True\"\n    \n    for value in row:\n        if value:\n            current_serie_true += 1\n            max_serie_true = max(max_serie_true, current_serie_true)\n        else:\n            current_serie_true = 0\n    \n    return max_serie_true\n\n# Appliquer la fonction \u00e0 chaque ligne du DataFrame\ndf_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] = df_serie_sousbiscontinue.apply(compter_plus_grande_serie_continue_de_true, axis=1)\n\ndf_serie_sousbiscontinue['Cat\u00e9gorie de s\u00e9rie'] = np.select(\n    [\n        df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 2,\n        df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 3,\n        df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 4,\n        df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] &gt; 4,\n    ],\n    [\n        '1 ann\u00e9e d\\'affil\u00e9e',\n        '2 ann\u00e9es d\\'affil\u00e9e',\n        '3 ann\u00e9es d\\'affil\u00e9e',\n        '4 ann\u00e9es d\\'affil\u00e9e et  plus'\n    ],\n    default='Autre'\n)\n# Compter les occurrences de chaque valeur unique\nvalue_counts = df_serie_sousbiscontinue['Cat\u00e9gorie de s\u00e9rie'].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, (label, count) in enumerate(zip(texts, value_counts)):\n    label.set_text(f\"{label.get_text()} ({count})\")\n\nplt.title(\"Parmi les MS qui ont repris des souscriptions d'affil\u00e9es, quel \u00e9tait leur comportement ?\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> # Filtrer les lignes o\u00f9 'A une s\u00e9rie continue de reprise de souscription tout les ans' est True df_serie_sousbiscontinue = df_serie_sousbis[df_serie_sousbis['A une s\u00e9rie continue de reprise de souscription avec intervalle d\\'un an'] == \"Reprise cons\u00e9cutive de souscription au bout de 0,9 et 1,1 ann\u00e9e\"]  # Fonction pour compter la plus grande s\u00e9rie continue de \"True\" def compter_plus_grande_serie_continue_de_true(row):     max_serie_true = 0  # Pour stocker le nombre maximum de \"True\" cons\u00e9cutifs     current_serie_true = 0  # Pour suivre la s\u00e9rie actuelle de \"True\"          for value in row:         if value:             current_serie_true += 1             max_serie_true = max(max_serie_true, current_serie_true)         else:             current_serie_true = 0          return max_serie_true  # Appliquer la fonction \u00e0 chaque ligne du DataFrame df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] = df_serie_sousbiscontinue.apply(compter_plus_grande_serie_continue_de_true, axis=1)  df_serie_sousbiscontinue['Cat\u00e9gorie de s\u00e9rie'] = np.select(     [         df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 2,         df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 3,         df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] == 4,         df_serie_sousbiscontinue['Plus grande s\u00e9rie de reprise de souscription avec intervalle d\\'environ 1 an'] &gt; 4,     ],     [         '1 ann\u00e9e d\\'affil\u00e9e',         '2 ann\u00e9es d\\'affil\u00e9e',         '3 ann\u00e9es d\\'affil\u00e9e',         '4 ann\u00e9es d\\'affil\u00e9e et  plus'     ],     default='Autre' ) # Compter les occurrences de chaque valeur unique value_counts = df_serie_sousbiscontinue['Cat\u00e9gorie de s\u00e9rie'].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, (label, count) in enumerate(zip(texts, value_counts)):     label.set_text(f\"{label.get_text()} ({count})\")  plt.title(\"Parmi les MS qui ont repris des souscriptions d'affil\u00e9es, quel \u00e9tait leur comportement ?\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Variation du nombre d\\'actions entre souscriptions&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  # Ins\u00e9rer un saut de page display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Variation du nombre d\\'actions entre souscriptions')) Variation du nombre d'actions entre souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Pour cette rubrique nous avons calcul\u00e9 la diff\u00e9rence individuelle du nombre d'actions entre la \u00e9ni\u00e8me souscription d'un souscripteur et de sa souscription pr\u00e9c\u00e9dente. Nous avons ensuite fait des moyennes g\u00e9n\u00e9rale de variation, des moyennes de variation en fonction des types de variation du nombre d'actions (augmentation, diminution, stagnation du nombre d'une souscription \u00e0 la pr\u00e9c\u00e9dente)&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Pour cette rubrique nous avons calcul\u00e9 la diff\u00e9rence individuelle du nombre d'actions entre la \u00e9ni\u00e8me souscription d'un souscripteur et de sa souscription pr\u00e9c\u00e9dente. Nous avons ensuite fait des moyennes g\u00e9n\u00e9rale de variation, des moyennes de variation en fonction des types de variation du nombre d'actions (augmentation, diminution, stagnation du nombre d'une souscription \u00e0 la pr\u00e9c\u00e9dente)\")) Pour cette rubrique nous avons calcul\u00e9 la diff\u00e9rence individuelle du nombre d'actions entre la \u00e9ni\u00e8me souscription d'un souscripteur et de sa souscription pr\u00e9c\u00e9dente. Nous avons ensuite fait des moyennes g\u00e9n\u00e9rale de variation, des moyennes de variation en fonction des types de variation du nombre d'actions (augmentation, diminution, stagnation du nombre d'une souscription \u00e0 la pr\u00e9c\u00e9dente) In\u00a0[\u00a0]: Copied! <pre>df_variationactions = df2.copy()\n# Liste des colonnes \u00e0 supprimer\ncolonnes_a_supprimer = [\n    '\u00e2ge', 'Territoire Terre de Liens', 'Actionnaire ?', 'adh\u00e9rent N', 'Donateur N',\n    'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9', 'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues',\n    'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)', 'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats',\n    'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal', 'Affectation',\n    'Mouvement de titre Name', 'Nature du mouvement', 'Date d\\'activation',\n    'Actions - Date de fin', 'Difference d\u00e9but fin', 'retrait complet ou partiel',\n    'ann\u00e9e rachat', 'dur\u00e9e conservation', 'r\u00e9partition ann\u00e9e', 'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires',\n    'r\u00e9partition ann\u00e9e nouveau actionnaire', 'cat\u00e9gorie souscription'\n]\n\n# Supprimer les colonnes du DataFrame\ndf_variationactions.drop(colonnes_a_supprimer, axis=1, inplace=True)\ndf_variationactions['Nombre de souscriptions'] = df_variationactions['ID du contact'].map(df_variationactions ['ID du contact'].value_counts())\ndf_variationactions = df_variationactions.sort_values(by=['ID du contact', 'Date du Mouvement'])\ndf_variationactions10 = df_variationactions[(df_variationactions[\"Nombre de souscriptions\"] &lt;= 10) &amp; (df_variationactions[\"Nombre de souscriptions\"] &gt; 1)]\n# Pivoter le tableau\n\ndf_variationactions10 = pd.pivot_table(df_variationactions10, index='ID du contact', columns=df_variationactions10.groupby('ID du contact').cumcount() + 1,\nvalues=[\"Nombre d'actions \u00e9chang\u00e9es\"],\naggfunc='first')\ndf_log = df_variationactions10.copy()\n#renommer les colonnes\ndf_variationactions10.columns = [f'{col[0]}_{col[1]}' for col in df_variationactions10.columns]\ndf_variationactions10.reset_index(inplace=True)\n# Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions\nfor i in range(2, 11):\n    df_variationactions10[f'diff_actions_souscriptions_{i}_{i-1}'] = df_variationactions10[f'Nombre d\\'actions \u00e9chang\u00e9es_{i}'] - df_variationactions10[f'Nombre d\\'actions \u00e9chang\u00e9es_{i-1}']\n\n# Supprimer les colonnes du tableau\n\ncolonnes_a_supprimer = [\n   \"Nombre d'actions \u00e9chang\u00e9es_1\",\n\"Nombre d'actions \u00e9chang\u00e9es_2\",\n\"Nombre d'actions \u00e9chang\u00e9es_3\",\n\"Nombre d'actions \u00e9chang\u00e9es_4\",\n\"Nombre d'actions \u00e9chang\u00e9es_5\",\n\"Nombre d'actions \u00e9chang\u00e9es_6\",\n\"Nombre d'actions \u00e9chang\u00e9es_7\",\n\"Nombre d'actions \u00e9chang\u00e9es_8\",\n\"Nombre d'actions \u00e9chang\u00e9es_9\",\n\"Nombre d'actions \u00e9chang\u00e9es_10\"\n]\n\n# calculer les variations moyenne par colonnes \ndf_variationactions10.drop(colonnes_a_supprimer, axis=1, inplace=True)\nVariation_actions = df_variationactions10.drop(columns='ID du contact').mean(skipna=True).to_frame()\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es pour l'axe x (colonnes)\ncolonnes = Variation_actions.index\n\n# Donn\u00e9es pour l'axe y (moyennes)\nmoyennes_values = Variation_actions.values\n\n# Cr\u00e9er le graphique\nplt.figure(figsize=(10, 6))\nplt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue')\nplt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge\nplt.xlabel('Colonnes')\nplt.ylabel('Variations moyennes d\\'actions')\nplt.title('Variations moyennes totale du nombre d\\'actions entre souscriptions (jusqu\\'\u00e0 10)')\nplt.xticks(rotation=60)\nplt.grid(True)\n\n# Annoter chaque point avec sa valeur\nfor i, txt in enumerate(moyennes_values):\n    plt.text(colonnes[i], txt[0] + 0.2, f'{txt[0]:.2f}', ha='center', va='bottom', color='black', fontweight='normal')\n\n\n# Afficher le graphique\nplt.tight_layout()\nplt.show()\n</pre> df_variationactions = df2.copy() # Liste des colonnes \u00e0 supprimer colonnes_a_supprimer = [     '\u00e2ge', 'Territoire Terre de Liens', 'Actionnaire ?', 'adh\u00e9rent N', 'Donateur N',     'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9', 'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues',     'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)', 'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats',     'Nombre d\\'actions \u00e0 l\\'acquisition', 'A fait l\\'objet d\\'un re\u00e7u fiscal', 'Affectation',     'Mouvement de titre Name', 'Nature du mouvement', 'Date d\\'activation',     'Actions - Date de fin', 'Difference d\u00e9but fin', 'retrait complet ou partiel',     'ann\u00e9e rachat', 'dur\u00e9e conservation', 'r\u00e9partition ann\u00e9e', 'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires',     'r\u00e9partition ann\u00e9e nouveau actionnaire', 'cat\u00e9gorie souscription' ]  # Supprimer les colonnes du DataFrame df_variationactions.drop(colonnes_a_supprimer, axis=1, inplace=True) df_variationactions['Nombre de souscriptions'] = df_variationactions['ID du contact'].map(df_variationactions ['ID du contact'].value_counts()) df_variationactions = df_variationactions.sort_values(by=['ID du contact', 'Date du Mouvement']) df_variationactions10 = df_variationactions[(df_variationactions[\"Nombre de souscriptions\"] &lt;= 10) &amp; (df_variationactions[\"Nombre de souscriptions\"] &gt; 1)] # Pivoter le tableau  df_variationactions10 = pd.pivot_table(df_variationactions10, index='ID du contact', columns=df_variationactions10.groupby('ID du contact').cumcount() + 1, values=[\"Nombre d'actions \u00e9chang\u00e9es\"], aggfunc='first') df_log = df_variationactions10.copy() #renommer les colonnes df_variationactions10.columns = [f'{col[0]}_{col[1]}' for col in df_variationactions10.columns] df_variationactions10.reset_index(inplace=True) # Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions for i in range(2, 11):     df_variationactions10[f'diff_actions_souscriptions_{i}_{i-1}'] = df_variationactions10[f'Nombre d\\'actions \u00e9chang\u00e9es_{i}'] - df_variationactions10[f'Nombre d\\'actions \u00e9chang\u00e9es_{i-1}']  # Supprimer les colonnes du tableau  colonnes_a_supprimer = [    \"Nombre d'actions \u00e9chang\u00e9es_1\", \"Nombre d'actions \u00e9chang\u00e9es_2\", \"Nombre d'actions \u00e9chang\u00e9es_3\", \"Nombre d'actions \u00e9chang\u00e9es_4\", \"Nombre d'actions \u00e9chang\u00e9es_5\", \"Nombre d'actions \u00e9chang\u00e9es_6\", \"Nombre d'actions \u00e9chang\u00e9es_7\", \"Nombre d'actions \u00e9chang\u00e9es_8\", \"Nombre d'actions \u00e9chang\u00e9es_9\", \"Nombre d'actions \u00e9chang\u00e9es_10\" ]  # calculer les variations moyenne par colonnes  df_variationactions10.drop(colonnes_a_supprimer, axis=1, inplace=True) Variation_actions = df_variationactions10.drop(columns='ID du contact').mean(skipna=True).to_frame() import matplotlib.pyplot as plt  # Donn\u00e9es pour l'axe x (colonnes) colonnes = Variation_actions.index  # Donn\u00e9es pour l'axe y (moyennes) moyennes_values = Variation_actions.values  # Cr\u00e9er le graphique plt.figure(figsize=(10, 6)) plt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue') plt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge plt.xlabel('Colonnes') plt.ylabel('Variations moyennes d\\'actions') plt.title('Variations moyennes totale du nombre d\\'actions entre souscriptions (jusqu\\'\u00e0 10)') plt.xticks(rotation=60) plt.grid(True)  # Annoter chaque point avec sa valeur for i, txt in enumerate(moyennes_values):     plt.text(colonnes[i], txt[0] + 0.2, f'{txt[0]:.2f}', ha='center', va='bottom', color='black', fontweight='normal')   # Afficher le graphique plt.tight_layout() plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Nous avons pris les diff\u00e9rences du nombre d'actions d'une souscription \u00e0 sa pr\u00e9c\u00e9dente par personne et avons fait une moyenne total par rang de diff\u00e9rence entre souscriptions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nous avons pris les diff\u00e9rences du nombre d'actions d'une souscription \u00e0 sa pr\u00e9c\u00e9dente par personne et avons fait une moyenne total par rang de diff\u00e9rence entre souscriptions\")) Nous avons pris les diff\u00e9rences du nombre d'actions d'une souscription \u00e0 sa pr\u00e9c\u00e9dente par personne et avons fait une moyenne total par rang de diff\u00e9rence entre souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : il y a eu en moyenne une augmentation de 2,5 actions pour la 4\u00e8me souscription des ex-actionnaires et actionnaires actuels compar\u00e9 au nombre d'actions prises pour leur 3\u00e8me souscription&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : il y a eu en moyenne une augmentation de 2,5 actions pour la 4\u00e8me souscription des ex-actionnaires et actionnaires actuels compar\u00e9 au nombre d'actions prises pour leur 3\u00e8me souscription\"))  Cl\u00e9 de lecture : il y a eu en moyenne une augmentation de 2,5 actions pour la 4\u00e8me souscription des ex-actionnaires et actionnaires actuels compar\u00e9 au nombre d'actions prises pour leur 3\u00e8me souscription In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Fonction pour calculer la proportion de valeurs positives, n\u00e9gatives et stagnantes\ndef positive_negative_stagnant_stats(column):\n    valid_values = column.dropna()\n    \n    # Convertir les valeurs en nombres (int ou float)\n    numeric_values = pd.to_numeric(valid_values, errors='coerce')\n    \n    positive_values = numeric_values[numeric_values &gt; 0]\n    negative_values = numeric_values[numeric_values &lt; 0]\n    stagnant_values = numeric_values[numeric_values == 0]\n    \n    total_valid = len(valid_values)\n    positive_proportion = len(positive_values) / total_valid * 100 if total_valid &gt; 0 else 0\n    negative_proportion = len(negative_values) / total_valid * 100 if total_valid &gt; 0 else 0\n    stagnant_proportion = len(stagnant_values) / total_valid * 100 if total_valid &gt; 0 else 0\n    \n    total_proportion = positive_proportion + negative_proportion + stagnant_proportion\n    if total_proportion &gt; 0:\n        positive_proportion /= total_proportion\n        negative_proportion /= total_proportion\n        stagnant_proportion /= total_proportion\n    \n    return pd.Series({\n        'Augmentation du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(positive_proportion, 2),\n        'Diminution du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(negative_proportion, 2),\n        'Stagnation  du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(stagnant_proportion, 2)\n    })\n\n# Appliquer la fonction \u00e0 chaque colonne du DataFrame df_variationactions10\nresult_stats = df_variationactions10.apply(positive_negative_stagnant_stats)\n\nresult_stats = result_stats.drop(columns= \"ID du contact\")\n</pre> import pandas as pd import numpy as np  # Fonction pour calculer la proportion de valeurs positives, n\u00e9gatives et stagnantes def positive_negative_stagnant_stats(column):     valid_values = column.dropna()          # Convertir les valeurs en nombres (int ou float)     numeric_values = pd.to_numeric(valid_values, errors='coerce')          positive_values = numeric_values[numeric_values &gt; 0]     negative_values = numeric_values[numeric_values &lt; 0]     stagnant_values = numeric_values[numeric_values == 0]          total_valid = len(valid_values)     positive_proportion = len(positive_values) / total_valid * 100 if total_valid &gt; 0 else 0     negative_proportion = len(negative_values) / total_valid * 100 if total_valid &gt; 0 else 0     stagnant_proportion = len(stagnant_values) / total_valid * 100 if total_valid &gt; 0 else 0          total_proportion = positive_proportion + negative_proportion + stagnant_proportion     if total_proportion &gt; 0:         positive_proportion /= total_proportion         negative_proportion /= total_proportion         stagnant_proportion /= total_proportion          return pd.Series({         'Augmentation du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(positive_proportion, 2),         'Diminution du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(negative_proportion, 2),         'Stagnation  du nombre d\\'actions  par rapport \u00e0 la pr\u00e9c\u00e9dente': round(stagnant_proportion, 2)     })  # Appliquer la fonction \u00e0 chaque colonne du DataFrame df_variationactions10 result_stats = df_variationactions10.apply(positive_negative_stagnant_stats)  result_stats = result_stats.drop(columns= \"ID du contact\")  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Transposer le DataFrame pour que les colonnes deviennent des index\nresult_stats_transposed = result_stats.transpose()\n\n# Calculer le total des proportions pour chaque souscription\nresult_stats_transposed['Total'] = result_stats_transposed.sum(axis=1)\n\n# Convertir les proportions en pourcentages\nresult_stats_transposed_percentage = result_stats_transposed.apply(lambda row: row / row['Total'] * 100, axis=1)\n\n# Supprimer la colonne Total\nresult_stats_transposed_percentage = result_stats_transposed_percentage.drop(columns='Total')\n\n# Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en pourcentage\nax = result_stats_transposed_percentage.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.title('Proportions des cat\u00e9gories variations d\\'actions par souscription')\nplt.ylabel('Proportion (%)')\nplt.xlabel('Souscriptions')\nplt.xticks(rotation=45, ha='right')\n\n# Afficher les \u00e9tiquettes de donn\u00e9es en pourcentage sur les parties empil\u00e9es des barres\nfor container in ax.containers:\n    for bar in container:\n        height = bar.get_height()\n        if height &gt; 1:\n            ax.annotate(f'{height:.0f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),\n                        ha='center', va='center', color='white', fontsize=8)\n        elif height &lt; -1:\n            ax.annotate(f'{height:.0f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),\n                        ha='center', va='center', color='black', fontsize=8)\n        elif -1 &lt;= height &lt;= 1:\n            ax.annotate(f'{height:.1f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),\n                        ha='center', va='center', color='black', fontsize=8)\n\n# D\u00e9placer la l\u00e9gende \u00e0 droite du graphique\nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n\n# Afficher le graphique\n\nplt.show()\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt # Transposer le DataFrame pour que les colonnes deviennent des index result_stats_transposed = result_stats.transpose()  # Calculer le total des proportions pour chaque souscription result_stats_transposed['Total'] = result_stats_transposed.sum(axis=1)  # Convertir les proportions en pourcentages result_stats_transposed_percentage = result_stats_transposed.apply(lambda row: row / row['Total'] * 100, axis=1)  # Supprimer la colonne Total result_stats_transposed_percentage = result_stats_transposed_percentage.drop(columns='Total')  # Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en pourcentage ax = result_stats_transposed_percentage.plot(kind='bar', stacked=True, figsize=(10, 6)) plt.title('Proportions des cat\u00e9gories variations d\\'actions par souscription') plt.ylabel('Proportion (%)') plt.xlabel('Souscriptions') plt.xticks(rotation=45, ha='right')  # Afficher les \u00e9tiquettes de donn\u00e9es en pourcentage sur les parties empil\u00e9es des barres for container in ax.containers:     for bar in container:         height = bar.get_height()         if height &gt; 1:             ax.annotate(f'{height:.0f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),                         ha='center', va='center', color='white', fontsize=8)         elif height &lt; -1:             ax.annotate(f'{height:.0f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),                         ha='center', va='center', color='black', fontsize=8)         elif -1 &lt;= height &lt;= 1:             ax.annotate(f'{height:.1f} %', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),                         ha='center', va='center', color='black', fontsize=8)  # D\u00e9placer la l\u00e9gende \u00e0 droite du graphique plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Afficher le graphique  plt.show()    In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Nous avons regard\u00e9 quelle \u00e9tait la part de chaque type de variations du nombre d'actions par rang de diff\u00e9rence entre souscriptions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nous avons regard\u00e9 quelle \u00e9tait la part de chaque type de variations du nombre d'actions par rang de diff\u00e9rence entre souscriptions\")) Nous avons regard\u00e9 quelle \u00e9tait la part de chaque type de variations du nombre d'actions par rang de diff\u00e9rence entre souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, 37 % ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere. 27% en ont pris moins et 36 % ont pris le m\u00eame nombre d'actions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, 37 % ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere. 27% en ont pris moins et 36 % ont pris le m\u00eame nombre d'actions\")) Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, 37 % ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere. 27% en ont pris moins et 36 % ont pris le m\u00eame nombre d'actions In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Fonction pour calculer le nombre absolu de valeurs positives, n\u00e9gatives et stagnantes\ndef positive_negative_stagnant_counts(column):\n    valid_values = column.dropna()\n    \n    # Convertir les valeurs en nombres (int ou float)\n    numeric_values = pd.to_numeric(valid_values, errors='coerce')\n    \n    positive_values = numeric_values[numeric_values &gt; 0]\n    negative_values = numeric_values[numeric_values &lt; 0]\n    stagnant_values = numeric_values[numeric_values == 0]\n    \n    positive_count = len(positive_values)\n    negative_count = len(negative_values)\n    stagnant_count = len(stagnant_values)\n    \n    return pd.Series({\n        'Nombre de souscriptions \u00e0 augmentation d\\'actions': positive_count,\n        'Nombre de souscriptions \u00e0 diminution d\\'actions': negative_count,\n        'Nombre de souscriptions stagnantes': stagnant_count\n    })\n\n# Appliquer la fonction \u00e0 chaque colonne du DataFrame df_variationactions10\nresult_counts = df_variationactions10.apply(positive_negative_stagnant_counts)\n\nresult_counts = result_counts.drop(columns=\"ID du contact\")\n</pre> import pandas as pd import numpy as np  # Fonction pour calculer le nombre absolu de valeurs positives, n\u00e9gatives et stagnantes def positive_negative_stagnant_counts(column):     valid_values = column.dropna()          # Convertir les valeurs en nombres (int ou float)     numeric_values = pd.to_numeric(valid_values, errors='coerce')          positive_values = numeric_values[numeric_values &gt; 0]     negative_values = numeric_values[numeric_values &lt; 0]     stagnant_values = numeric_values[numeric_values == 0]          positive_count = len(positive_values)     negative_count = len(negative_values)     stagnant_count = len(stagnant_values)          return pd.Series({         'Nombre de souscriptions \u00e0 augmentation d\\'actions': positive_count,         'Nombre de souscriptions \u00e0 diminution d\\'actions': negative_count,         'Nombre de souscriptions stagnantes': stagnant_count     })  # Appliquer la fonction \u00e0 chaque colonne du DataFrame df_variationactions10 result_counts = df_variationactions10.apply(positive_negative_stagnant_counts)  result_counts = result_counts.drop(columns=\"ID du contact\")  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# S\u00e9lectionner les colonnes pour le premier graphique\nselected_columns = [\n    'diff_actions_souscriptions_2_1',\n    'diff_actions_souscriptions_3_2',\n    'diff_actions_souscriptions_4_3',\n    'diff_actions_souscriptions_5_4'\n]\n\n# Transposer le DataFrame pour que les colonnes deviennent des index\nresult_counts_selected = result_counts[selected_columns].transpose()\n\n# Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en nombre absolu (premier graphique)\nax1 = result_counts_selected.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.title('Nombre de personnes par cat\u00e9gories de variations du nombre d\\'actions d\\'une souscription \u00e0 une autre (jusqu\\'\u00e0 la 5 souscriptions)')\nplt.ylabel('Nombre absolu')\nplt.xlabel('Souscriptions')\nplt.xticks(rotation=45, ha='right')\n\n# Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu sur les parties empil\u00e9es des barres\nfor container in ax1.containers:\n    for bar in container:\n        height = bar.get_height()\n        ax1.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),\n                     ha='center', va='center', color='black', fontsize=8)\n\n# D\u00e9placer la l\u00e9gende \u00e0 droite du graphique\nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n\n# Afficher le premier graphique\nplt.show()\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt  # S\u00e9lectionner les colonnes pour le premier graphique selected_columns = [     'diff_actions_souscriptions_2_1',     'diff_actions_souscriptions_3_2',     'diff_actions_souscriptions_4_3',     'diff_actions_souscriptions_5_4' ]  # Transposer le DataFrame pour que les colonnes deviennent des index result_counts_selected = result_counts[selected_columns].transpose()  # Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en nombre absolu (premier graphique) ax1 = result_counts_selected.plot(kind='bar', stacked=True, figsize=(10, 6)) plt.title('Nombre de personnes par cat\u00e9gories de variations du nombre d\\'actions d\\'une souscription \u00e0 une autre (jusqu\\'\u00e0 la 5 souscriptions)') plt.ylabel('Nombre absolu') plt.xlabel('Souscriptions') plt.xticks(rotation=45, ha='right')  # Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu sur les parties empil\u00e9es des barres for container in ax1.containers:     for bar in container:         height = bar.get_height()         ax1.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),                      ha='center', va='center', color='black', fontsize=8)  # D\u00e9placer la l\u00e9gende \u00e0 droite du graphique plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Afficher le premier graphique plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, il y avait 2183 personnes qui ont pris plus d'actions pour leur deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, il y avait 2183 personnes qui ont pris plus d'actions pour leur deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re\")) Cl\u00e9 de lecture : Parmi les ex-actionnaires et actionnaires actuels, il y avait 2183 personnes qui ont pris plus d'actions pour leur deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# S\u00e9lectionner les colonnes pour le deuxi\u00e8me graphique (en excluant les colonnes du premier graphique)\nselected_columns = [\n    'diff_actions_souscriptions_6_5',\n    'diff_actions_souscriptions_7_6',\n    'diff_actions_souscriptions_8_7',\n    'diff_actions_souscriptions_9_8',\n    'diff_actions_souscriptions_10_9'\n]\n\n# Transposer le DataFrame pour que les colonnes deviennent des index\nresult_counts_selected = result_counts[selected_columns].transpose()\n\n# Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en nombre absolu (deuxi\u00e8me graphique)\nax2 = result_counts_selected.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.title('Nombre de personnes par cat\u00e9gories de variations du nombre d\\'actions d\\'une souscription \u00e0 une autre (jusqu\\'\u00e0 la 10 souscriptions)')\nplt.ylabel('Nombre absolu')\nplt.xlabel('Souscriptions')\nplt.xticks(rotation=45, ha='right')\n\n# Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu sur les parties empil\u00e9es des barres\nfor container in ax2.containers:\n    for bar in container:\n        height = bar.get_height()\n        ax2.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),\n                     ha='center', va='center', color='black', fontsize=8)\n\n# D\u00e9placer la l\u00e9gende \u00e0 droite du graphique\nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n\n# Afficher le deuxi\u00e8me graphique\nplt.show()\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt  # S\u00e9lectionner les colonnes pour le deuxi\u00e8me graphique (en excluant les colonnes du premier graphique) selected_columns = [     'diff_actions_souscriptions_6_5',     'diff_actions_souscriptions_7_6',     'diff_actions_souscriptions_8_7',     'diff_actions_souscriptions_9_8',     'diff_actions_souscriptions_10_9' ]  # Transposer le DataFrame pour que les colonnes deviennent des index result_counts_selected = result_counts[selected_columns].transpose()  # Cr\u00e9er un graphique de barres empil\u00e9es avec les \u00e9tiquettes de donn\u00e9es en nombre absolu (deuxi\u00e8me graphique) ax2 = result_counts_selected.plot(kind='bar', stacked=True, figsize=(10, 6)) plt.title('Nombre de personnes par cat\u00e9gories de variations du nombre d\\'actions d\\'une souscription \u00e0 une autre (jusqu\\'\u00e0 la 10 souscriptions)') plt.ylabel('Nombre absolu') plt.xlabel('Souscriptions') plt.xticks(rotation=45, ha='right')  # Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu sur les parties empil\u00e9es des barres for container in ax2.containers:     for bar in container:         height = bar.get_height()         ax2.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2),                      ha='center', va='center', color='black', fontsize=8)  # D\u00e9placer la l\u00e9gende \u00e0 droite du graphique plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Afficher le deuxi\u00e8me graphique plt.show()   In\u00a0[\u00a0]: Copied! <pre># Liste des colonnes de variation\ndf_variationactions10groupe = df_variationactions10.copy()\nvariation_columns = [col for col in df_variationactions10.columns if col.startswith(\"diff_actions_souscriptions_\")]\n\n# Fonction pour d\u00e9terminer la cat\u00e9gorie de variation\ndef determine_variation_category(value):\n    if value &lt; 0:\n        return \"Diminution\"\n    elif value &gt; 0:\n        return \"Augmentation\"\n    else:\n        return \"Stagnation\"\n\n# Ajouter les colonnes \"cat\u00e9gorie de variations\" pour chaque colonne de variation\nfor col in variation_columns:\n    new_col_name = col.replace(\"diff_actions_\", \"cat\u00e9gorie de variations \")\n    df_variationactions10groupe[new_col_name] = df_variationactions10groupe[col].apply(determine_variation_category)\n</pre> # Liste des colonnes de variation df_variationactions10groupe = df_variationactions10.copy() variation_columns = [col for col in df_variationactions10.columns if col.startswith(\"diff_actions_souscriptions_\")]  # Fonction pour d\u00e9terminer la cat\u00e9gorie de variation def determine_variation_category(value):     if value &lt; 0:         return \"Diminution\"     elif value &gt; 0:         return \"Augmentation\"     else:         return \"Stagnation\"  # Ajouter les colonnes \"cat\u00e9gorie de variations\" pour chaque colonne de variation for col in variation_columns:     new_col_name = col.replace(\"diff_actions_\", \"cat\u00e9gorie de variations \")     df_variationactions10groupe[new_col_name] = df_variationactions10groupe[col].apply(determine_variation_category) In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom IPython.display import display\n\n\n# Liste des colonnes de variation et de cat\u00e9gorie de variation\nvariation_columns = [\n    'diff_actions_souscriptions_2_1', 'diff_actions_souscriptions_3_2', 'diff_actions_souscriptions_4_3',\n    'diff_actions_souscriptions_5_4', 'diff_actions_souscriptions_6_5', 'diff_actions_souscriptions_7_6',\n    'diff_actions_souscriptions_8_7', 'diff_actions_souscriptions_9_8', 'diff_actions_souscriptions_10_9'\n]\ncategory_columns = [\n    'cat\u00e9gorie de variations souscriptions_2_1', 'cat\u00e9gorie de variations souscriptions_3_2',\n    'cat\u00e9gorie de variations souscriptions_4_3', 'cat\u00e9gorie de variations souscriptions_5_4',\n    'cat\u00e9gorie de variations souscriptions_6_5', 'cat\u00e9gorie de variations souscriptions_7_6',\n    'cat\u00e9gorie de variations souscriptions_8_7', 'cat\u00e9gorie de variations souscriptions_9_8',\n    'cat\u00e9gorie de variations souscriptions_10_9'\n]\n\n# Cr\u00e9er les 9 tableaux de avec les valeurs de variations et leur cat\u00e9gories de variations pour chaque \u00e9cart entre souscriptions\ntableaux = []\nfor variation_col, category_col in zip(variation_columns, category_columns):\n    tableau = df_variationactions10groupe[[variation_col, category_col]].copy()\n    col_name = f\"variation_{variation_col.split('_')[3]}_{variation_col.split('_')[4]}\"\n    cat_col_name = f\"cat\u00e9gorie_{category_col.split('_')[-2]}_{category_col.split('_')[-1]}\"\n    tableau.columns = [col_name, cat_col_name]\n    tableau = tableau.dropna().loc[tableau[cat_col_name] != 'Stagnation']\n    tableaux.append(tableau)\n\n# cr\u00e9er des tableau pour calculer la moyenne des colonnes 'variation_{i}_{i-1}' group\u00e9e par 'Cat\u00e9gorie'\nmean_data = []\nfor i, tableau in enumerate(tableaux, start=2):\n    mean_value = tableau.groupby(f'cat\u00e9gorie_{i}_{i-1}')[f'variation_{i}_{i-1}'].mean().reset_index()\n    mean_data.append(mean_value)\n    \n# Fusionner les donn\u00e9es sur la cl\u00e9 'Cat\u00e9gorie'\nmerged_mean_data = pd.concat(mean_data, axis=1)\n\n# Afficher le DataFrame r\u00e9sultant\nmerged_mean_data\n# Supprimer les colonnes 'cat\u00e9gorie_{i}_{i-1}' \u00e0 partir de 'cat\u00e9gorie_3_2'\ncols_to_drop = ['cat\u00e9gorie_3_2', 'cat\u00e9gorie_4_3', 'cat\u00e9gorie_5_4', 'cat\u00e9gorie_6_5', 'cat\u00e9gorie_7_6',\n                'cat\u00e9gorie_8_7', 'cat\u00e9gorie_9_8', 'cat\u00e9gorie_10_9']\nmerged_mean_data.drop(columns=cols_to_drop, inplace=True)\n\nmerged_mean_data.rename(columns={'cat\u00e9gorie_2_1': 'Cat\u00e9gorie de Variation'}, inplace=True)\nmerged_mean_data = merged_mean_data.round()\n</pre> import pandas as pd from IPython.display import display   # Liste des colonnes de variation et de cat\u00e9gorie de variation variation_columns = [     'diff_actions_souscriptions_2_1', 'diff_actions_souscriptions_3_2', 'diff_actions_souscriptions_4_3',     'diff_actions_souscriptions_5_4', 'diff_actions_souscriptions_6_5', 'diff_actions_souscriptions_7_6',     'diff_actions_souscriptions_8_7', 'diff_actions_souscriptions_9_8', 'diff_actions_souscriptions_10_9' ] category_columns = [     'cat\u00e9gorie de variations souscriptions_2_1', 'cat\u00e9gorie de variations souscriptions_3_2',     'cat\u00e9gorie de variations souscriptions_4_3', 'cat\u00e9gorie de variations souscriptions_5_4',     'cat\u00e9gorie de variations souscriptions_6_5', 'cat\u00e9gorie de variations souscriptions_7_6',     'cat\u00e9gorie de variations souscriptions_8_7', 'cat\u00e9gorie de variations souscriptions_9_8',     'cat\u00e9gorie de variations souscriptions_10_9' ]  # Cr\u00e9er les 9 tableaux de avec les valeurs de variations et leur cat\u00e9gories de variations pour chaque \u00e9cart entre souscriptions tableaux = [] for variation_col, category_col in zip(variation_columns, category_columns):     tableau = df_variationactions10groupe[[variation_col, category_col]].copy()     col_name = f\"variation_{variation_col.split('_')[3]}_{variation_col.split('_')[4]}\"     cat_col_name = f\"cat\u00e9gorie_{category_col.split('_')[-2]}_{category_col.split('_')[-1]}\"     tableau.columns = [col_name, cat_col_name]     tableau = tableau.dropna().loc[tableau[cat_col_name] != 'Stagnation']     tableaux.append(tableau)  # cr\u00e9er des tableau pour calculer la moyenne des colonnes 'variation_{i}_{i-1}' group\u00e9e par 'Cat\u00e9gorie' mean_data = [] for i, tableau in enumerate(tableaux, start=2):     mean_value = tableau.groupby(f'cat\u00e9gorie_{i}_{i-1}')[f'variation_{i}_{i-1}'].mean().reset_index()     mean_data.append(mean_value)      # Fusionner les donn\u00e9es sur la cl\u00e9 'Cat\u00e9gorie' merged_mean_data = pd.concat(mean_data, axis=1)  # Afficher le DataFrame r\u00e9sultant merged_mean_data # Supprimer les colonnes 'cat\u00e9gorie_{i}_{i-1}' \u00e0 partir de 'cat\u00e9gorie_3_2' cols_to_drop = ['cat\u00e9gorie_3_2', 'cat\u00e9gorie_4_3', 'cat\u00e9gorie_5_4', 'cat\u00e9gorie_6_5', 'cat\u00e9gorie_7_6',                 'cat\u00e9gorie_8_7', 'cat\u00e9gorie_9_8', 'cat\u00e9gorie_10_9'] merged_mean_data.drop(columns=cols_to_drop, inplace=True)  merged_mean_data.rename(columns={'cat\u00e9gorie_2_1': 'Cat\u00e9gorie de Variation'}, inplace=True) merged_mean_data = merged_mean_data.round()  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Donn\u00e9es pour le trac\u00e9\ncategories = merged_mean_data['Cat\u00e9gorie de Variation']\nvariations_augmentation = merged_mean_data.loc[merged_mean_data['Cat\u00e9gorie de Variation'] == 'Augmentation'].iloc[:, 1:]\nvariations_diminution = merged_mean_data.loc[merged_mean_data['Cat\u00e9gorie de Variation'] == 'Diminution'].iloc[:, 1:]\n\n# Tracer les courbes\nplt.figure(figsize=(10, 6))\n\nfor category, data in [('Augmentation', variations_augmentation), ('Diminution', variations_diminution)]:\n    plt.plot(data.columns, data.iloc[0], marker='o', label=category)\n\nplt.title('Moyenne des variations en fonction de la cat\u00e9gorie de variation d\\'actions d\\'une souscription \u00e0 une autre')\nplt.xlabel('Variation')\nplt.ylabel('Moyenne')\nplt.legend()\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.yticks(range(-150, 150, 20))  # Ajuster les graduations de l'axe des y\nplt.tight_layout()\n\n# Annoter les points avec les valeurs\nfor category, data in [('Augmentation', variations_augmentation), ('Diminution', variations_diminution)]:\n    for i, value in enumerate(data.iloc[0]):\n        plt.annotate(f'{value:.0f}', (data.columns[i], value), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9, fontweight='normal')\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Donn\u00e9es pour le trac\u00e9 categories = merged_mean_data['Cat\u00e9gorie de Variation'] variations_augmentation = merged_mean_data.loc[merged_mean_data['Cat\u00e9gorie de Variation'] == 'Augmentation'].iloc[:, 1:] variations_diminution = merged_mean_data.loc[merged_mean_data['Cat\u00e9gorie de Variation'] == 'Diminution'].iloc[:, 1:]  # Tracer les courbes plt.figure(figsize=(10, 6))  for category, data in [('Augmentation', variations_augmentation), ('Diminution', variations_diminution)]:     plt.plot(data.columns, data.iloc[0], marker='o', label=category)  plt.title('Moyenne des variations en fonction de la cat\u00e9gorie de variation d\\'actions d\\'une souscription \u00e0 une autre') plt.xlabel('Variation') plt.ylabel('Moyenne') plt.legend() plt.grid(True) plt.xticks(rotation=45) plt.yticks(range(-150, 150, 20))  # Ajuster les graduations de l'axe des y plt.tight_layout()  # Annoter les points avec les valeurs for category, data in [('Augmentation', variations_augmentation), ('Diminution', variations_diminution)]:     for i, value in enumerate(data.iloc[0]):         plt.annotate(f'{value:.0f}', (data.columns[i], value), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9, fontweight='normal')  # Afficher le graphique plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Tableau de donn\u00e9es pour le graphique pr\u00e9c\u00e9dent&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Tableau de donn\u00e9es pour le graphique pr\u00e9c\u00e9dent\")) Tableau de donn\u00e9es pour le graphique pr\u00e9c\u00e9dent In\u00a0[\u00a0]: Copied! <pre>merged_mean_data\n</pre> merged_mean_data Out[\u00a0]: Cat\u00e9gorie de Variation variation_2_1 variation_3_2 variation_4_3 variation_5_4 variation_6_5 variation_7_6 variation_8_7 variation_9_8 variation_10_9 0 Augmentation 78.0 70.0 75.0 73.0 71.0 51.0 88.0 84.0 112.0 1 Diminution -77.0 -81.0 -72.0 -73.0 -48.0 -75.0 -65.0 -63.0 -47.0 In\u00a0[\u00a0]: Copied! <pre> from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Parmis les ex-actionnaires et actionnaires actuels qui ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere, en moyenne ces derniers en ont pris 34 de plus. Et parmi ceux qui ont diminu\u00e9 leur nombre d'actions pour leur 2\u00e8me souscriptons par rapport \u00e0 la premi\u00e8re, ils en ont pris en moyenne 34 de moins&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Parmis les ex-actionnaires et actionnaires actuels qui ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere, en moyenne ces derniers en ont pris 34 de plus. Et parmi ceux qui ont diminu\u00e9 leur nombre d'actions pour leur 2\u00e8me souscriptons par rapport \u00e0 la premi\u00e8re, ils en ont pris en moyenne 34 de moins\")) Cl\u00e9 de lecture : Parmis les ex-actionnaires et actionnaires actuels qui ont pris plus d'actions pour leur 2\u00e8me souscription par rapport \u00e0 la premiere, en moyenne ces derniers en ont pris 34 de plus. Et parmi ceux qui ont diminu\u00e9 leur nombre d'actions pour leur 2\u00e8me souscriptons par rapport \u00e0 la premi\u00e8re, ils en ont pris en moyenne 34 de moins In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Variations relatives du nombre d\\'actions entre rang de souscriptions&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML   # Ins\u00e9rer un saut de page display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Variations relatives du nombre d\\'actions entre rang de souscriptions')) Variations relatives du nombre d'actions entre rang de souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;h3&gt;Notions : Nous avons pour cette section consid\u00e9rer les logarithmes n\u00e9periens (base e) du nombres d\\'actions \u00e9chang\u00e9es \u00e0 chaque rangs de souscriptions. Ainsi en faisant la soustraction entre entre 2 log on peut avoir une id\u00e9e de la variation absolue entre le nombre d\\'actions. Dans la section pr\u00e9c\u00e9dente on observait qu\\'en moyenne entre la 2\u00e8me et la 1ere souscription les actionnaires prennaient 4 actions de plus que la fois pr\u00e9c\u00e9dente, ce qui n\\'indique rien sur l\\'\u00e9volution relative sur son comportement de souscription. La personne aurait avoir pris lors de la 1ere souscription 4 actions et lors de la 2eme 8 actions ce qui fait une augmentation de 100 % soit 2 fois plus une fois sur l\\'autre. L\\'actionnaire aurait pu avoir pris 400 actions lors de la 1ere souscription et 404 lors de la 2\u00e8me souscrition soit une augmentation de 1% ou 1,01 fois plus une fois sur l\\'autre. Avec le logarithme n\u00e9p\u00e9rien on peut avoir une id\u00e9e de l\\\u00e9volution relative en faisant e^(log(x en T+1) - log(X en T)) = e^(log(x en T+1/(X en T)). Ainsi pour reprendre nos exemples e^(log(8)-log(4)) = e^log(8/4) = 2 et  e^(log(404)-log(400)) = e^log(404/400) = 1,01 &lt;/h3&gt;'))\n</pre> from IPython.display import display, HTML  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Notions : Nous avons pour cette section consid\u00e9rer les logarithmes n\u00e9periens (base e) du nombres d\\'actions \u00e9chang\u00e9es \u00e0 chaque rangs de souscriptions. Ainsi en faisant la soustraction entre entre 2 log on peut avoir une id\u00e9e de la variation absolue entre le nombre d\\'actions. Dans la section pr\u00e9c\u00e9dente on observait qu\\'en moyenne entre la 2\u00e8me et la 1ere souscription les actionnaires prennaient 4 actions de plus que la fois pr\u00e9c\u00e9dente, ce qui n\\'indique rien sur l\\'\u00e9volution relative sur son comportement de souscription. La personne aurait avoir pris lors de la 1ere souscription 4 actions et lors de la 2eme 8 actions ce qui fait une augmentation de 100 % soit 2 fois plus une fois sur l\\'autre. L\\'actionnaire aurait pu avoir pris 400 actions lors de la 1ere souscription et 404 lors de la 2\u00e8me souscrition soit une augmentation de 1% ou 1,01 fois plus une fois sur l\\'autre. Avec le logarithme n\u00e9p\u00e9rien on peut avoir une id\u00e9e de l\\\u00e9volution relative en faisant e^(log(x en T+1) - log(X en T)) = e^(log(x en T+1/(X en T)). Ainsi pour reprendre nos exemples e^(log(8)-log(4)) = e^log(8/4) = 2 et  e^(log(404)-log(400)) = e^log(404/400) = 1,01 ')) Notions : Nous avons pour cette section consid\u00e9rer les logarithmes n\u00e9periens (base e) du nombres d'actions \u00e9chang\u00e9es \u00e0 chaque rangs de souscriptions. Ainsi en faisant la soustraction entre entre 2 log on peut avoir une id\u00e9e de la variation absolue entre le nombre d'actions. Dans la section pr\u00e9c\u00e9dente on observait qu'en moyenne entre la 2\u00e8me et la 1ere souscription les actionnaires prennaient 4 actions de plus que la fois pr\u00e9c\u00e9dente, ce qui n'indique rien sur l'\u00e9volution relative sur son comportement de souscription. La personne aurait avoir pris lors de la 1ere souscription 4 actions et lors de la 2eme 8 actions ce qui fait une augmentation de 100 % soit 2 fois plus une fois sur l'autre. L'actionnaire aurait pu avoir pris 400 actions lors de la 1ere souscription et 404 lors de la 2\u00e8me souscrition soit une augmentation de 1% ou 1,01 fois plus une fois sur l'autre. Avec le logarithme n\u00e9p\u00e9rien on peut avoir une id\u00e9e de l\\\u00e9volution relative en faisant e^(log(x en T+1) - log(X en T)) = e^(log(x en T+1/(X en T)). Ainsi pour reprendre nos exemples e^(log(8)-log(4)) = e^log(8/4) = 2 et  e^(log(404)-log(400)) = e^log(404/400) = 1,01  In\u00a0[\u00a0]: Copied! <pre>df_log = np.log(df_log)\n#renommer les colonnes\ndf_log.columns = [f'{col[0]}_{col[1]}' for col in df_log.columns]\ndf_log.reset_index(inplace=True)\n# Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions\nfor i in range(2, 11):\n    df_log[f'Log_diff_actions_souscriptions_{i}_{i-1}'] = df_log[f'Nombre d\\'actions \u00e9chang\u00e9es_{i}'] - df_log[f'Nombre d\\'actions \u00e9chang\u00e9es_{i-1}']\n\n# Supprimer les colonnes du tableau\n\ncolonnes_a_supprimer = [\n   \"Nombre d'actions \u00e9chang\u00e9es_1\",\n\"Nombre d'actions \u00e9chang\u00e9es_2\",\n\"Nombre d'actions \u00e9chang\u00e9es_3\",\n\"Nombre d'actions \u00e9chang\u00e9es_4\",\n\"Nombre d'actions \u00e9chang\u00e9es_5\",\n\"Nombre d'actions \u00e9chang\u00e9es_6\",\n\"Nombre d'actions \u00e9chang\u00e9es_7\",\n\"Nombre d'actions \u00e9chang\u00e9es_8\",\n\"Nombre d'actions \u00e9chang\u00e9es_9\",\n\"Nombre d'actions \u00e9chang\u00e9es_10\"\n]\n\n# calculer les variations moyenne par colonnes \ndf_log.drop(colonnes_a_supprimer, axis=1, inplace=True)\nVariation_actionslog = df_log.drop(columns='ID du contact').mean(skipna=True).to_frame()\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es pour l'axe x (colonnes)\ncolonnes = Variation_actionslog.index\n\n# Donn\u00e9es pour l'axe y (moyennes)\nmoyennes_values = Variation_actionslog.values\n\n# Cr\u00e9er le graphique\nplt.figure(figsize=(10, 6))\nplt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue')\nplt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge\nplt.xlabel('Rang de souscription')\nplt.ylabel('Moyenne des diff\u00e9rence des logs')\nplt.title('Variations moyennes totale du nombre d\\'actions entre souscriptions (jusqu\\'\u00e0 10)(log-diff\u00e9rence)')\nplt.xticks(rotation=60)\nplt.grid(True)\n\n\n\n# Afficher le graphique\nplt.tight_layout()\nplt.show()\n</pre> df_log = np.log(df_log) #renommer les colonnes df_log.columns = [f'{col[0]}_{col[1]}' for col in df_log.columns] df_log.reset_index(inplace=True) # Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions for i in range(2, 11):     df_log[f'Log_diff_actions_souscriptions_{i}_{i-1}'] = df_log[f'Nombre d\\'actions \u00e9chang\u00e9es_{i}'] - df_log[f'Nombre d\\'actions \u00e9chang\u00e9es_{i-1}']  # Supprimer les colonnes du tableau  colonnes_a_supprimer = [    \"Nombre d'actions \u00e9chang\u00e9es_1\", \"Nombre d'actions \u00e9chang\u00e9es_2\", \"Nombre d'actions \u00e9chang\u00e9es_3\", \"Nombre d'actions \u00e9chang\u00e9es_4\", \"Nombre d'actions \u00e9chang\u00e9es_5\", \"Nombre d'actions \u00e9chang\u00e9es_6\", \"Nombre d'actions \u00e9chang\u00e9es_7\", \"Nombre d'actions \u00e9chang\u00e9es_8\", \"Nombre d'actions \u00e9chang\u00e9es_9\", \"Nombre d'actions \u00e9chang\u00e9es_10\" ]  # calculer les variations moyenne par colonnes  df_log.drop(colonnes_a_supprimer, axis=1, inplace=True) Variation_actionslog = df_log.drop(columns='ID du contact').mean(skipna=True).to_frame() import matplotlib.pyplot as plt  # Donn\u00e9es pour l'axe x (colonnes) colonnes = Variation_actionslog.index  # Donn\u00e9es pour l'axe y (moyennes) moyennes_values = Variation_actionslog.values  # Cr\u00e9er le graphique plt.figure(figsize=(10, 6)) plt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue') plt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge plt.xlabel('Rang de souscription') plt.ylabel('Moyenne des diff\u00e9rence des logs') plt.title('Variations moyennes totale du nombre d\\'actions entre souscriptions (jusqu\\'\u00e0 10)(log-diff\u00e9rence)') plt.xticks(rotation=60) plt.grid(True)    # Afficher le graphique plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>#Variation_actionslog = Variation_actionslog.T\nVariation_actionslog = Variation_actionslog.rename(columns={Variation_actionslog.columns[0]: 'log(i+1) - log(i)'})\nVariation_actionslog['e^log(x)'] = np.exp(Variation_actionslog.iloc[:, 0])\nVariation_actionslog \n</pre> #Variation_actionslog = Variation_actionslog.T Variation_actionslog = Variation_actionslog.rename(columns={Variation_actionslog.columns[0]: 'log(i+1) - log(i)'}) Variation_actionslog['e^log(x)'] = np.exp(Variation_actionslog.iloc[:, 0]) Variation_actionslog  Out[\u00a0]: log(i+1) - log(i) e^log(x) Log_diff_actions_souscriptions_2_1 -0.026232 0.974109 Log_diff_actions_souscriptions_3_2 0.041931 1.042823 Log_diff_actions_souscriptions_4_3 -0.025583 0.974742 Log_diff_actions_souscriptions_5_4 0.001804 1.001806 Log_diff_actions_souscriptions_6_5 -0.114651 0.891677 Log_diff_actions_souscriptions_7_6 0.078376 1.081529 Log_diff_actions_souscriptions_8_7 0.100767 1.106019 Log_diff_actions_souscriptions_9_8 0.248553 1.282169 Log_diff_actions_souscriptions_10_9 0.362496 1.436911 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;h4&gt; Cl\u00e9 de lecture : Dans la colonne de droite on peut se rendre compte en moyenne combien de fois plus ou moins les actionnaires ont pris d\\'actions d\\'une souscription \u00e0 une autre. Si le nombre est sup\u00e9rieur \u00e0 1 il s\\'agira d\\'une augmentation et s\\'il es inf\u00e9rieur, il s\\'agira d\\'une diminution.&lt;/h3&gt;'))\n</pre> from IPython.display import display, HTML  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML(' Cl\u00e9 de lecture : Dans la colonne de droite on peut se rendre compte en moyenne combien de fois plus ou moins les actionnaires ont pris d\\'actions d\\'une souscription \u00e0 une autre. Si le nombre est sup\u00e9rieur \u00e0 1 il s\\'agira d\\'une augmentation et s\\'il es inf\u00e9rieur, il s\\'agira d\\'une diminution.'))  Cl\u00e9 de lecture : Dans la colonne de droite on peut se rendre compte en moyenne combien de fois plus ou moins les actionnaires ont pris d'actions d'une souscription \u00e0 une autre. Si le nombre est sup\u00e9rieur \u00e0 1 il s'agira d'une augmentation et s'il es inf\u00e9rieur, il s'agira d'une diminution.  In\u00a0[\u00a0]: Copied! <pre>df_log = df_log.merge(df_parcours, on=['ID du contact'], how='left')\ndf_log21 = df_log[[\"Log_diff_actions_souscriptions_2_1\", \"Nombre moyen d'actions par souscription\"]]\ndf_log32 = df_log[[\"Log_diff_actions_souscriptions_3_2\", \"Nombre moyen d'actions par souscription\"]]\ndf_log43 = df_log[[\"Log_diff_actions_souscriptions_4_3\", \"Nombre moyen d'actions par souscription\"]]\ndf_log54 = df_log[[\"Log_diff_actions_souscriptions_5_4\", \"Nombre moyen d'actions par souscription\"]]\ndf_log65 = df_log[[\"Log_diff_actions_souscriptions_6_5\", \"Nombre moyen d'actions par souscription\"]]\ndf_log76 = df_log[[\"Log_diff_actions_souscriptions_7_6\", \"Nombre moyen d'actions par souscription\"]]\ndf_log87 = df_log[[\"Log_diff_actions_souscriptions_8_7\", \"Nombre moyen d'actions par souscription\"]]\ndf_log98 = df_log[[\"Log_diff_actions_souscriptions_9_8\", \"Nombre moyen d'actions par souscription\"]]\ndf_log109 = df_log[[\"Log_diff_actions_souscriptions_10_9\", \"Nombre moyen d'actions par souscription\"]]\nimport numpy as np\n\n# Cr\u00e9er une fonction pour attribuer des cat\u00e9gories en fonction de la valeur\ndef categorize_variation(val):\n    if val == 0:\n        return '[0]'\n    elif -0.2 &lt; val &lt; 0:\n        return ']-0,2;0['\n    elif -0.4 &lt; val &lt;= -0.2:\n        return ']-0.4;-0.2]'\n    elif -0.8 &lt; val &lt;= -0.4:\n        return ']-0.8;-0.4]'\n    elif -1.6 &lt; val &lt;= -0.8:\n        return ']-1.6;-0.8]'\n    elif -3.2 &lt; val &lt;= -1.6:\n        return ']-3.2;-1.6]'\n    elif val &lt; -3.2:\n        return '&lt;-3.2'\n    elif 0 &lt; val &lt;= 0.2:\n        return ']0;0.2]'\n    elif 0.2 &lt; val &lt;= 0.4:\n        return ']0.2;0.4]'\n    elif 0.4 &lt; val &lt;= 0.8:\n        return ']0.4;0.8]'\n    elif 0.8 &lt; val &lt;= 1.6:\n        return ']0.8;1.6]'\n    elif 1.6 &lt; val &lt;= 3.2:\n        return ']1.6;3.2]'\n    elif val &gt; 3.2:\n        return '&gt;3.2'\n\ndf_log21['Cat\u00e9gorie variation'] = df_log21['Log_diff_actions_souscriptions_2_1'].apply(categorize_variation)\ndf_log32['Cat\u00e9gorie variation'] = df_log32['Log_diff_actions_souscriptions_3_2'].apply(categorize_variation)\ndf_log43['Cat\u00e9gorie variation'] = df_log43['Log_diff_actions_souscriptions_4_3'].apply(categorize_variation)\ndf_log54['Cat\u00e9gorie variation'] = df_log54['Log_diff_actions_souscriptions_5_4'].apply(categorize_variation)\ndf_log65['Cat\u00e9gorie variation'] = df_log65['Log_diff_actions_souscriptions_6_5'].apply(categorize_variation)\ndf_log76['Cat\u00e9gorie variation'] = df_log76['Log_diff_actions_souscriptions_7_6'].apply(categorize_variation)\ndf_log87['Cat\u00e9gorie variation'] = df_log87['Log_diff_actions_souscriptions_8_7'].apply(categorize_variation)\ndf_log98['Cat\u00e9gorie variation'] = df_log98['Log_diff_actions_souscriptions_9_8'].apply(categorize_variation)\ndf_log109['Cat\u00e9gorie variation'] = df_log109['Log_diff_actions_souscriptions_10_9'].apply(categorize_variation)\n\ndef categorize_actions(val):\n    if val &lt;= 3:\n        return ']0;3]'\n    elif val &lt;= 6:\n        return ']3;6]'\n    elif val &lt;= 18:\n        return ']6;18]'\n    elif val &lt;= 54:\n        return ']18;54]'\n    elif val &lt;= 162:\n        return ']54;162]'\n    else:\n        return '&gt;162'\n\n\ndf_log21['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log21['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log32['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log32['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log43['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log43['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log54['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log54['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log65['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log65['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log76['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log76['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log87['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log87['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log98['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log98['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ndf_log109['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log109['Nombre moyen d\\'actions par souscription'].apply(categorize_actions)\ncross_tab21 = pd.crosstab(df_log21['Cat\u00e9gorie variation'], df_log21['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab32 = pd.crosstab(df_log32['Cat\u00e9gorie variation'], df_log32['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab43 = pd.crosstab(df_log43['Cat\u00e9gorie variation'], df_log43['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab54 = pd.crosstab(df_log54['Cat\u00e9gorie variation'], df_log54['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab65 = pd.crosstab(df_log65['Cat\u00e9gorie variation'], df_log65['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab76 = pd.crosstab(df_log76['Cat\u00e9gorie variation'], df_log76['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab87 = pd.crosstab(df_log87['Cat\u00e9gorie variation'], df_log87['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab98 = pd.crosstab(df_log98['Cat\u00e9gorie variation'], df_log98['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab109 = pd.crosstab(df_log109['Cat\u00e9gorie variation'], df_log109['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'])\ncross_tab21 = cross_tab21.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab32 = cross_tab32.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab54 = cross_tab54.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab65 = cross_tab65.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab76 = cross_tab76.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab87 = cross_tab87.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab98 = cross_tab98.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\ncross_tab109 = cross_tab109.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2'])\n# Les colonnes que vous souhaitez avoir dans vos DataFrames cross_tab\ncolonnes_desirees = [']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']\n\n# Pour chaque DataFrame cross_tab, assurez-vous que les colonnes d\u00e9sir\u00e9es existent et remplissez-les de z\u00e9ros si elles sont manquantes.\ndef ajouter_colonnes_manquantes(cross_tab):\n    for colonne in colonnes_desirees:\n        if colonne not in cross_tab.columns:\n            cross_tab[colonne] = 0  # Ajoutez la colonne manquante et remplissez-la de z\u00e9ros\n\n# Appelez cette fonction pour chaque DataFrame cross_tab\najouter_colonnes_manquantes(cross_tab21)\najouter_colonnes_manquantes(cross_tab32)\najouter_colonnes_manquantes(cross_tab43)\najouter_colonnes_manquantes(cross_tab54)\najouter_colonnes_manquantes(cross_tab65)\najouter_colonnes_manquantes(cross_tab76)\najouter_colonnes_manquantes(cross_tab87)\najouter_colonnes_manquantes(cross_tab98)\najouter_colonnes_manquantes(cross_tab109)\n\n\ncross_tab21 = cross_tab21[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab32 = cross_tab32[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab43 = cross_tab43[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab54 = cross_tab54[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab65 = cross_tab65[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab76 = cross_tab76[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab87 = cross_tab87[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab98 = cross_tab98[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\ncross_tab109 = cross_tab109[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']]\nimport matplotlib.pyplot as plt\n\n# Liste des noms des tableaux crois\u00e9s\ncross_tabs = [cross_tab21, cross_tab32, cross_tab43, cross_tab54, cross_tab65]\n\n# D\u00e9finissez les couleurs pour chaque cat\u00e9gorie\ncolors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00']\n\n# Initialisez la variable pour g\u00e9rer le nombre de graphiques par ligne\ngraphs_per_row = 2\n\n# Calcul du nombre total de lignes n\u00e9cessaires\nnum_rows = len(cross_tabs) // graphs_per_row + (len(cross_tabs) % graphs_per_row &gt; 0)\n\n# Cr\u00e9ez la figure et les sous-graphiques\nfig, axes = plt.subplots(nrows=num_rows, ncols=graphs_per_row, figsize=(15, 6 * num_rows))\nplt.subplots_adjust(wspace=0.5, hspace=0.5)\n\n# Parcourez les tableaux crois\u00e9s et cr\u00e9ez les graphiques\nfor i, cross_tab in enumerate(cross_tabs):\n    row, col = i // graphs_per_row, i % graphs_per_row\n    ax = cross_tab.plot(kind='bar', stacked=True, color=colors, ax=axes[row, col])\n    ax.set_xlabel('Cat\u00e9gorie Variation')\n    ax.set_ylabel('Fr\u00e9quence')\n    ax.set_title(f'Distribution des variations en log diff\u00e9rence pour les souscriptions {i+2}_{i+1}')\n    ax.legend(title='Cat\u00e9gorie Nombre moyen d\\'actions par souscription', bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Affichez les graphiques\nplt.tight_layout()\nplt.show()\n</pre> df_log = df_log.merge(df_parcours, on=['ID du contact'], how='left') df_log21 = df_log[[\"Log_diff_actions_souscriptions_2_1\", \"Nombre moyen d'actions par souscription\"]] df_log32 = df_log[[\"Log_diff_actions_souscriptions_3_2\", \"Nombre moyen d'actions par souscription\"]] df_log43 = df_log[[\"Log_diff_actions_souscriptions_4_3\", \"Nombre moyen d'actions par souscription\"]] df_log54 = df_log[[\"Log_diff_actions_souscriptions_5_4\", \"Nombre moyen d'actions par souscription\"]] df_log65 = df_log[[\"Log_diff_actions_souscriptions_6_5\", \"Nombre moyen d'actions par souscription\"]] df_log76 = df_log[[\"Log_diff_actions_souscriptions_7_6\", \"Nombre moyen d'actions par souscription\"]] df_log87 = df_log[[\"Log_diff_actions_souscriptions_8_7\", \"Nombre moyen d'actions par souscription\"]] df_log98 = df_log[[\"Log_diff_actions_souscriptions_9_8\", \"Nombre moyen d'actions par souscription\"]] df_log109 = df_log[[\"Log_diff_actions_souscriptions_10_9\", \"Nombre moyen d'actions par souscription\"]] import numpy as np  # Cr\u00e9er une fonction pour attribuer des cat\u00e9gories en fonction de la valeur def categorize_variation(val):     if val == 0:         return '[0]'     elif -0.2 &lt; val &lt; 0:         return ']-0,2;0['     elif -0.4 &lt; val &lt;= -0.2:         return ']-0.4;-0.2]'     elif -0.8 &lt; val &lt;= -0.4:         return ']-0.8;-0.4]'     elif -1.6 &lt; val &lt;= -0.8:         return ']-1.6;-0.8]'     elif -3.2 &lt; val &lt;= -1.6:         return ']-3.2;-1.6]'     elif val &lt; -3.2:         return '&lt;-3.2'     elif 0 &lt; val &lt;= 0.2:         return ']0;0.2]'     elif 0.2 &lt; val &lt;= 0.4:         return ']0.2;0.4]'     elif 0.4 &lt; val &lt;= 0.8:         return ']0.4;0.8]'     elif 0.8 &lt; val &lt;= 1.6:         return ']0.8;1.6]'     elif 1.6 &lt; val &lt;= 3.2:         return ']1.6;3.2]'     elif val &gt; 3.2:         return '&gt;3.2'  df_log21['Cat\u00e9gorie variation'] = df_log21['Log_diff_actions_souscriptions_2_1'].apply(categorize_variation) df_log32['Cat\u00e9gorie variation'] = df_log32['Log_diff_actions_souscriptions_3_2'].apply(categorize_variation) df_log43['Cat\u00e9gorie variation'] = df_log43['Log_diff_actions_souscriptions_4_3'].apply(categorize_variation) df_log54['Cat\u00e9gorie variation'] = df_log54['Log_diff_actions_souscriptions_5_4'].apply(categorize_variation) df_log65['Cat\u00e9gorie variation'] = df_log65['Log_diff_actions_souscriptions_6_5'].apply(categorize_variation) df_log76['Cat\u00e9gorie variation'] = df_log76['Log_diff_actions_souscriptions_7_6'].apply(categorize_variation) df_log87['Cat\u00e9gorie variation'] = df_log87['Log_diff_actions_souscriptions_8_7'].apply(categorize_variation) df_log98['Cat\u00e9gorie variation'] = df_log98['Log_diff_actions_souscriptions_9_8'].apply(categorize_variation) df_log109['Cat\u00e9gorie variation'] = df_log109['Log_diff_actions_souscriptions_10_9'].apply(categorize_variation)  def categorize_actions(val):     if val &lt;= 3:         return ']0;3]'     elif val &lt;= 6:         return ']3;6]'     elif val &lt;= 18:         return ']6;18]'     elif val &lt;= 54:         return ']18;54]'     elif val &lt;= 162:         return ']54;162]'     else:         return '&gt;162'   df_log21['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log21['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log32['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log32['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log43['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log43['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log54['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log54['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log65['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log65['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log76['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log76['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log87['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log87['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log98['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log98['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) df_log109['Cat\u00e9gorie Nombre moyen d\\'actions par souscription'] = df_log109['Nombre moyen d\\'actions par souscription'].apply(categorize_actions) cross_tab21 = pd.crosstab(df_log21['Cat\u00e9gorie variation'], df_log21['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab32 = pd.crosstab(df_log32['Cat\u00e9gorie variation'], df_log32['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab43 = pd.crosstab(df_log43['Cat\u00e9gorie variation'], df_log43['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab54 = pd.crosstab(df_log54['Cat\u00e9gorie variation'], df_log54['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab65 = pd.crosstab(df_log65['Cat\u00e9gorie variation'], df_log65['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab76 = pd.crosstab(df_log76['Cat\u00e9gorie variation'], df_log76['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab87 = pd.crosstab(df_log87['Cat\u00e9gorie variation'], df_log87['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab98 = pd.crosstab(df_log98['Cat\u00e9gorie variation'], df_log98['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab109 = pd.crosstab(df_log109['Cat\u00e9gorie variation'], df_log109['Cat\u00e9gorie Nombre moyen d\\'actions par souscription']) cross_tab21 = cross_tab21.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab32 = cross_tab32.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab54 = cross_tab54.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab65 = cross_tab65.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab76 = cross_tab76.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab87 = cross_tab87.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab98 = cross_tab98.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) cross_tab109 = cross_tab109.reindex(['&lt;-3.2', ']-3.2;-1.6]', ']-1.6;-0.8]', ']-0.8;-0.4]', ']-0.4;-0.2]',']-0,2;0[', '[0]', ']0;0.2]', ']0.2;0.4]', ']0.4;0.8]', ']0.8;1.6]', ']1.6;3.2]', '&gt;3.2']) # Les colonnes que vous souhaitez avoir dans vos DataFrames cross_tab colonnes_desirees = [']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']  # Pour chaque DataFrame cross_tab, assurez-vous que les colonnes d\u00e9sir\u00e9es existent et remplissez-les de z\u00e9ros si elles sont manquantes. def ajouter_colonnes_manquantes(cross_tab):     for colonne in colonnes_desirees:         if colonne not in cross_tab.columns:             cross_tab[colonne] = 0  # Ajoutez la colonne manquante et remplissez-la de z\u00e9ros  # Appelez cette fonction pour chaque DataFrame cross_tab ajouter_colonnes_manquantes(cross_tab21) ajouter_colonnes_manquantes(cross_tab32) ajouter_colonnes_manquantes(cross_tab43) ajouter_colonnes_manquantes(cross_tab54) ajouter_colonnes_manquantes(cross_tab65) ajouter_colonnes_manquantes(cross_tab76) ajouter_colonnes_manquantes(cross_tab87) ajouter_colonnes_manquantes(cross_tab98) ajouter_colonnes_manquantes(cross_tab109)   cross_tab21 = cross_tab21[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab32 = cross_tab32[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab43 = cross_tab43[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab54 = cross_tab54[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab65 = cross_tab65[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab76 = cross_tab76[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab87 = cross_tab87[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab98 = cross_tab98[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] cross_tab109 = cross_tab109[[']0;3]', ']3;6]', ']6;18]', ']18;54]', ']54;162]', '&gt;162']] import matplotlib.pyplot as plt  # Liste des noms des tableaux crois\u00e9s cross_tabs = [cross_tab21, cross_tab32, cross_tab43, cross_tab54, cross_tab65]  # D\u00e9finissez les couleurs pour chaque cat\u00e9gorie colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00']  # Initialisez la variable pour g\u00e9rer le nombre de graphiques par ligne graphs_per_row = 2  # Calcul du nombre total de lignes n\u00e9cessaires num_rows = len(cross_tabs) // graphs_per_row + (len(cross_tabs) % graphs_per_row &gt; 0)  # Cr\u00e9ez la figure et les sous-graphiques fig, axes = plt.subplots(nrows=num_rows, ncols=graphs_per_row, figsize=(15, 6 * num_rows)) plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Parcourez les tableaux crois\u00e9s et cr\u00e9ez les graphiques for i, cross_tab in enumerate(cross_tabs):     row, col = i // graphs_per_row, i % graphs_per_row     ax = cross_tab.plot(kind='bar', stacked=True, color=colors, ax=axes[row, col])     ax.set_xlabel('Cat\u00e9gorie Variation')     ax.set_ylabel('Fr\u00e9quence')     ax.set_title(f'Distribution des variations en log diff\u00e9rence pour les souscriptions {i+2}_{i+1}')     ax.legend(title='Cat\u00e9gorie Nombre moyen d\\'actions par souscription', bbox_to_anchor=(1.05, 1), loc='upper left')  # Affichez les graphiques plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Liste des noms des tableaux crois\u00e9s\ncross_tabs = [cross_tab76, cross_tab87, cross_tab98, cross_tab109]\n\n# D\u00e9finissez les couleurs pour chaque cat\u00e9gorie\ncolors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00']\n\n# Initialisez la variable pour g\u00e9rer le nombre de graphiques par ligne\ngraphs_per_row = 2\n\n# Calcul du nombre total de lignes n\u00e9cessaires\nnum_rows = len(cross_tabs) // graphs_per_row + (len(cross_tabs) % graphs_per_row &gt; 0)\n\n# Cr\u00e9ez la figure et les sous-graphiques\nfig, axes = plt.subplots(nrows=num_rows, ncols=graphs_per_row, figsize=(15, 6 * num_rows))\nplt.subplots_adjust(wspace=0.5, hspace=0.5)\n\n# Parcourez les tableaux crois\u00e9s et cr\u00e9ez les graphiques\nfor i, cross_tab in enumerate(cross_tabs):\n    row, col = i // graphs_per_row, i % graphs_per_row\n    ax = cross_tab.plot(kind='bar', stacked=True, color=colors, ax=axes[row, col])\n    ax.set_xlabel('Cat\u00e9gorie Variation')\n    ax.set_ylabel('Fr\u00e9quence')\n    ax.set_title(f'Distribution des variations en log diff\u00e9rence pour les souscriptions {i+7}_{i+6}')\n    ax.legend(title='Cat\u00e9gorie Nombre moyen d\\'actions par souscription', bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Affichez les graphiques\nplt.tight_layout()\nplt.show()\n</pre> # Liste des noms des tableaux crois\u00e9s cross_tabs = [cross_tab76, cross_tab87, cross_tab98, cross_tab109]  # D\u00e9finissez les couleurs pour chaque cat\u00e9gorie colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00']  # Initialisez la variable pour g\u00e9rer le nombre de graphiques par ligne graphs_per_row = 2  # Calcul du nombre total de lignes n\u00e9cessaires num_rows = len(cross_tabs) // graphs_per_row + (len(cross_tabs) % graphs_per_row &gt; 0)  # Cr\u00e9ez la figure et les sous-graphiques fig, axes = plt.subplots(nrows=num_rows, ncols=graphs_per_row, figsize=(15, 6 * num_rows)) plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Parcourez les tableaux crois\u00e9s et cr\u00e9ez les graphiques for i, cross_tab in enumerate(cross_tabs):     row, col = i // graphs_per_row, i % graphs_per_row     ax = cross_tab.plot(kind='bar', stacked=True, color=colors, ax=axes[row, col])     ax.set_xlabel('Cat\u00e9gorie Variation')     ax.set_ylabel('Fr\u00e9quence')     ax.set_title(f'Distribution des variations en log diff\u00e9rence pour les souscriptions {i+7}_{i+6}')     ax.legend(title='Cat\u00e9gorie Nombre moyen d\\'actions par souscription', bbox_to_anchor=(1.05, 1), loc='upper left')  # Affichez les graphiques plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n\n# Ins\u00e9rer un saut de page\n#display(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Cr\u00e9ation de re\u00e7us fiscaux&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML   # Ins\u00e9rer un saut de page #display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Cr\u00e9ation de re\u00e7us fiscaux')) Cr\u00e9ation de re\u00e7us fiscaux In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\ndf_RFcr\u00e9e = df2[\"A fait l'objet d'un re\u00e7u fiscal\"].value_counts().reset_index()\ndf_RFcr\u00e9e.columns = ['cat\u00e9gories', 'Nombre']\n\n# Convertir la colonne 'cat\u00e9gories' en type cha\u00eene de caract\u00e8res\ndf_RFcr\u00e9e['cat\u00e9gories'] = df_RFcr\u00e9e['cat\u00e9gories'].astype(str)\n\n# Remplacer les valeurs de la colonne 'cat\u00e9gories'\ndf_RFcr\u00e9e['cat\u00e9gories'] = df_RFcr\u00e9e['cat\u00e9gories'].replace({'1': 'cr\u00e9e', '0': 'non cr\u00e9e'})\n\n\nimport matplotlib.pyplot as plt\n\n# Calculer le total des nombres\ntotal = df_RFcr\u00e9e['Nombre'].sum()\n\n# Calculer le pourcentage de chaque cat\u00e9gorie\ndf_RFcr\u00e9e['Pourcentage'] = df_RFcr\u00e9e['Nombre'] / total * 100\n\n# Cr\u00e9er le pie chart\nplt.figure(figsize=(8, 6))\nplt.pie(df_RFcr\u00e9e['Nombre'], labels=df_RFcr\u00e9e['cat\u00e9gories'], autopct='%1.1f%%')\nplt.title(\"R\u00e9partition des cat\u00e9gories de re\u00e7us fiscaux\")\n\n# Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu et en pourcentage\nlabels = [f\"{n} ({p:.1f}%)\" for n, p in zip(df_RFcr\u00e9e['Nombre'], df_RFcr\u00e9e['Pourcentage'])]\nplt.legend(labels, loc='best')\n\n# Afficher le pie chart\nplt.show()\n</pre> import pandas as pd  df_RFcr\u00e9e = df2[\"A fait l'objet d'un re\u00e7u fiscal\"].value_counts().reset_index() df_RFcr\u00e9e.columns = ['cat\u00e9gories', 'Nombre']  # Convertir la colonne 'cat\u00e9gories' en type cha\u00eene de caract\u00e8res df_RFcr\u00e9e['cat\u00e9gories'] = df_RFcr\u00e9e['cat\u00e9gories'].astype(str)  # Remplacer les valeurs de la colonne 'cat\u00e9gories' df_RFcr\u00e9e['cat\u00e9gories'] = df_RFcr\u00e9e['cat\u00e9gories'].replace({'1': 'cr\u00e9e', '0': 'non cr\u00e9e'})   import matplotlib.pyplot as plt  # Calculer le total des nombres total = df_RFcr\u00e9e['Nombre'].sum()  # Calculer le pourcentage de chaque cat\u00e9gorie df_RFcr\u00e9e['Pourcentage'] = df_RFcr\u00e9e['Nombre'] / total * 100  # Cr\u00e9er le pie chart plt.figure(figsize=(8, 6)) plt.pie(df_RFcr\u00e9e['Nombre'], labels=df_RFcr\u00e9e['cat\u00e9gories'], autopct='%1.1f%%') plt.title(\"R\u00e9partition des cat\u00e9gories de re\u00e7us fiscaux\")  # Afficher les \u00e9tiquettes de donn\u00e9es en nombre absolu et en pourcentage labels = [f\"{n} ({p:.1f}%)\" for n, p in zip(df_RFcr\u00e9e['Nombre'], df_RFcr\u00e9e['Pourcentage'])] plt.legend(labels, loc='best')  # Afficher le pie chart plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Sur toutes les souscriptions qu'il y a eu, 13,5% n'ont pas fait l'objet d'un re\u00e7u fiscal&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Sur toutes les souscriptions qu'il y a eu, 13,5% n'ont pas fait l'objet d'un re\u00e7u fiscal\")) Cl\u00e9 de lecture : Sur toutes les souscriptions qu'il y a eu, 13,5% n'ont pas fait l'objet d'un re\u00e7u fiscal In\u00a0[\u00a0]: Copied! <pre>df2.loc[:, \"multi-casquette ?\"] = df2.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Actionnaire uniquement\", axis=1)\n\ndf2.loc[:, 'multi-souscripteur ?'] = df2.duplicated(subset='ID du contact', keep=False)\n\n\ndummies = pd.get_dummies(df2[\"A fait l'objet d'un re\u00e7u fiscal\"], prefix=\"A fait l'objet d'un re\u00e7u fiscal\")\n\n# Concat\u00e9nation des dummies avec le DataFrame d'origine\ndf2 = pd.concat([df2, dummies], axis=1)\ncolonnes_dummies = [\"A fait l'objet d'un re\u00e7u fiscal_0\", \"A fait l'objet d'un re\u00e7u fiscal_1\"]\n\n# Remplacement des valeurs True par 1 et False par 0 dans les colonnes de dummies\ndf2[colonnes_dummies] = df2[colonnes_dummies].replace({True: 1, False: 0})\ndf2['Nombre de souscriptions'] = df2['ID du contact'].map(df2['ID du contact'].value_counts())\nconditions = [\n     (df2['Nombre de souscriptions'] &lt; 2),\n     (df2['Nombre de souscriptions'] &lt;3),\n     (df2['Nombre de souscriptions'] &lt;=5),\n     (df2['Nombre de souscriptions'] &lt;=10),\n]\n\nchoices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]\n\ndf2['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')\n\ndf_RF = df2.sort_values(by='ID du contact')\ngrouped_counts = df2.groupby('ID du contact')[\"A fait l'objet d'un re\u00e7u fiscal_1\"].sum()\ndf_RF = df_RF.merge(grouped_counts, on='ID du contact', suffixes=('', '_count'))\ndf_RF[\"% re\u00e7u fiscal demand\u00e9\"] = df_RF [\"A fait l'objet d'un re\u00e7u fiscal_1_count\"] / df_RF[\"Nombre de souscriptions\"] * 100\ndf_RF= df_RF.drop([\"A fait l'objet d'un re\u00e7u fiscal_0\", \"A fait l'objet d'un re\u00e7u fiscal_1\",\"A fait l'objet d'un re\u00e7u fiscal_1_count\"], axis=1)\ndf_RF = df_RF.drop_duplicates(subset = \"ID du contact\")\n\nconditions = [\n    (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] == 0),\n    (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] &lt; 20),\n    (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] &lt; 40),\n    (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 60),\n    (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 80),\n    (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 100)\n]\n\nchoices =[\"0 % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"]0 - 20[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[20 - 40[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[40 - 60[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[60 - 80[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[80 - 100[ % de RF cr\u00e9es sur l'ensemble des soucriptions\"]\ndf_RF['cat\u00e9gories des demandeurs de RF'] = np.select(conditions, choices, default=\"100 % de RF cr\u00e9es sur l'ensemble des soucriptions\")\n</pre> df2.loc[:, \"multi-casquette ?\"] = df2.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Actionnaire uniquement\", axis=1)  df2.loc[:, 'multi-souscripteur ?'] = df2.duplicated(subset='ID du contact', keep=False)   dummies = pd.get_dummies(df2[\"A fait l'objet d'un re\u00e7u fiscal\"], prefix=\"A fait l'objet d'un re\u00e7u fiscal\")  # Concat\u00e9nation des dummies avec le DataFrame d'origine df2 = pd.concat([df2, dummies], axis=1) colonnes_dummies = [\"A fait l'objet d'un re\u00e7u fiscal_0\", \"A fait l'objet d'un re\u00e7u fiscal_1\"]  # Remplacement des valeurs True par 1 et False par 0 dans les colonnes de dummies df2[colonnes_dummies] = df2[colonnes_dummies].replace({True: 1, False: 0}) df2['Nombre de souscriptions'] = df2['ID du contact'].map(df2['ID du contact'].value_counts()) conditions = [      (df2['Nombre de souscriptions'] &lt; 2),      (df2['Nombre de souscriptions'] &lt;3),      (df2['Nombre de souscriptions'] &lt;=5),      (df2['Nombre de souscriptions'] &lt;=10), ]  choices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]  df2['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')  df_RF = df2.sort_values(by='ID du contact') grouped_counts = df2.groupby('ID du contact')[\"A fait l'objet d'un re\u00e7u fiscal_1\"].sum() df_RF = df_RF.merge(grouped_counts, on='ID du contact', suffixes=('', '_count')) df_RF[\"% re\u00e7u fiscal demand\u00e9\"] = df_RF [\"A fait l'objet d'un re\u00e7u fiscal_1_count\"] / df_RF[\"Nombre de souscriptions\"] * 100 df_RF= df_RF.drop([\"A fait l'objet d'un re\u00e7u fiscal_0\", \"A fait l'objet d'un re\u00e7u fiscal_1\",\"A fait l'objet d'un re\u00e7u fiscal_1_count\"], axis=1) df_RF = df_RF.drop_duplicates(subset = \"ID du contact\")  conditions = [     (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] == 0),     (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] &lt; 20),     (df_RF [\"% re\u00e7u fiscal demand\u00e9\"] &lt; 40),     (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 60),     (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 80),     (df_RF ['% re\u00e7u fiscal demand\u00e9'] &lt; 100) ]  choices =[\"0 % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"]0 - 20[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[20 - 40[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[40 - 60[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[60 - 80[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[80 - 100[ % de RF cr\u00e9es sur l'ensemble des soucriptions\"] df_RF['cat\u00e9gories des demandeurs de RF'] = np.select(conditions, choices, default=\"100 % de RF cr\u00e9es sur l'ensemble des soucriptions\")  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Nombres d'individus par cat\u00e9gories de demandeurs de RF (part des souscriptions qui ont fait l'objet d'un RF sur toutes leurs souscriptions)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombres d'individus par cat\u00e9gories de demandeurs de RF (part des souscriptions qui ont fait l'objet d'un RF sur toutes leurs souscriptions)\")) Nombres d'individus par cat\u00e9gories de demandeurs de RF (part des souscriptions qui ont fait l'objet d'un RF sur toutes leurs souscriptions) In\u00a0[\u00a0]: Copied! <pre>value_counts = df_RF[\"cat\u00e9gories des demandeurs de RF\"].value_counts().reset_index()\nvalue_counts.columns = [\"Cat\u00e9gories des demandeurs de RF\", \"Nombre d'individus\"]\ncategories_order = [\"0 % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"]0 - 20[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[20 - 40[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[40 - 60[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[60 - 80[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[80 - 100[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"100 % de RF cr\u00e9es sur l'ensemble des soucriptions\"]\n\n# Cr\u00e9er un DataFrame contenant toutes les cat\u00e9gories dans l'ordre sp\u00e9cifi\u00e9\ncategories_df = pd.DataFrame({\"Cat\u00e9gories des demandeurs de RF\": categories_order})\n\n# Fusionner les donn\u00e9es avec la r\u00e9indexation\nvalue_counts_sorted = categories_df.merge(value_counts, how=\"left\")\n\nvalue_counts[\"Cat\u00e9gories des demandeurs de RF\"] = value_counts[\"Cat\u00e9gories des demandeurs de RF\"].astype(str)\n\n# Fusionner les donn\u00e9es avec la r\u00e9indexation\nvalue_counts_sorted = categories_df.merge(value_counts, how=\"left\")\n</pre> value_counts = df_RF[\"cat\u00e9gories des demandeurs de RF\"].value_counts().reset_index() value_counts.columns = [\"Cat\u00e9gories des demandeurs de RF\", \"Nombre d'individus\"] categories_order = [\"0 % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"]0 - 20[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[20 - 40[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[40 - 60[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[60 - 80[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"[80 - 100[ % de RF cr\u00e9es sur l'ensemble des soucriptions\", \"100 % de RF cr\u00e9es sur l'ensemble des soucriptions\"]  # Cr\u00e9er un DataFrame contenant toutes les cat\u00e9gories dans l'ordre sp\u00e9cifi\u00e9 categories_df = pd.DataFrame({\"Cat\u00e9gories des demandeurs de RF\": categories_order})  # Fusionner les donn\u00e9es avec la r\u00e9indexation value_counts_sorted = categories_df.merge(value_counts, how=\"left\")  value_counts[\"Cat\u00e9gories des demandeurs de RF\"] = value_counts[\"Cat\u00e9gories des demandeurs de RF\"].astype(str)  # Fusionner les donn\u00e9es avec la r\u00e9indexation value_counts_sorted = categories_df.merge(value_counts, how=\"left\")  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Donn\u00e9es pour l'histogramme\ncategories = value_counts_sorted[\"Cat\u00e9gories des demandeurs de RF\"]\ncounts = value_counts_sorted[\"Nombre d'individus\"]\n\n# Cr\u00e9er le graphique\nplt.figure(figsize=(8, 6))\nbars = plt.bar(categories, counts)\n\n# Incliner les noms des cat\u00e9gories et espacer les barres\nplt.xticks(rotation=45, ha='right')\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre d'individus appartenant aux diff\u00e9rentes cat\u00e9gories de demandeurs de RF \")\nplt.xlabel(\"\")\nplt.ylabel(\"Nombre d'individus\")\n\n# Ajouter les valeurs au-dessus de chaque barre\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, height, height, ha='center', va='bottom')\n\n# Afficher l'histogramme\nplt.show()\n</pre> import matplotlib.pyplot as plt import warnings warnings.filterwarnings(\"ignore\") # Donn\u00e9es pour l'histogramme categories = value_counts_sorted[\"Cat\u00e9gories des demandeurs de RF\"] counts = value_counts_sorted[\"Nombre d'individus\"]  # Cr\u00e9er le graphique plt.figure(figsize=(8, 6)) bars = plt.bar(categories, counts)  # Incliner les noms des cat\u00e9gories et espacer les barres plt.xticks(rotation=45, ha='right')  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre d'individus appartenant aux diff\u00e9rentes cat\u00e9gories de demandeurs de RF \") plt.xlabel(\"\") plt.ylabel(\"Nombre d'individus\")  # Ajouter les valeurs au-dessus de chaque barre for bar in bars:     height = bar.get_height()     plt.text(bar.get_x() + bar.get_width() / 2, height, height, ha='center', va='bottom')  # Afficher l'histogramme plt.show()   <pre>posx and posy should be finite values\n</pre> <pre>posx and posy should be finite values\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : il y a eu 17 519 personnes qui ont demand\u00e9 un re\u00e7u fiscal pour l'ensemble de leurs souscriptions (100 % de RF cr\u00e9es sur l'ensemble des souscriptions)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : il y a eu 17 519 personnes qui ont demand\u00e9 un re\u00e7u fiscal pour l'ensemble de leurs souscriptions (100 % de RF cr\u00e9es sur l'ensemble des souscriptions)\")) Cl\u00e9 de lecture : il y a eu 17 519 personnes qui ont demand\u00e9 un re\u00e7u fiscal pour l'ensemble de leurs souscriptions (100 % de RF cr\u00e9es sur l'ensemble des souscriptions) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par multi-souscripteurs ?&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par multi-souscripteurs ?\")) Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par multi-souscripteurs ? In\u00a0[\u00a0]: Copied! <pre>df_RF_MS = df_RF.groupby(\"multi-souscripteur ?\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame()\ndf_RF_MS = df_RF_MS.round()\ndf_RF_MS\n</pre> df_RF_MS = df_RF.groupby(\"multi-souscripteur ?\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame() df_RF_MS = df_RF_MS.round() df_RF_MS Out[\u00a0]: % re\u00e7u fiscal demand\u00e9 multi-souscripteur ? False 77.0 True 77.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Les multis souscripteurs ont demand\u00e9 en moyenne un re\u00e7u fiscal pour 84 % de leurs souscriptions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Les multis souscripteurs ont demand\u00e9 en moyenne un re\u00e7u fiscal pour 84 % de leurs souscriptions\")) Cl\u00e9 de lecture : Les multis souscripteurs ont demand\u00e9 en moyenne un re\u00e7u fiscal pour 84 % de leurs souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories d'\u00e2ge&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories d'\u00e2ge\")) Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories d'\u00e2ge In\u00a0[\u00a0]: Copied! <pre>df_RF_age = df_RF.groupby(\"cat\u00e9gories \u00e2ge\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame()\ndf_RF_age.round()\n</pre> df_RF_age = df_RF.groupby(\"cat\u00e9gories \u00e2ge\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame() df_RF_age.round() Out[\u00a0]: % re\u00e7u fiscal demand\u00e9 cat\u00e9gories \u00e2ge 0-25 ans 77.0 25-40 ans 77.0 40-60 ans 77.0 60 ans et plus 76.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par anciennet\u00e9 de l'actionnaire&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par anciennet\u00e9 de l'actionnaire\")) Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par anciennet\u00e9 de l'actionnaire In\u00a0[\u00a0]: Copied! <pre>df_RF_anciennet\u00e9 = df_RF.groupby(\"anciennet\u00e9 actionnaires\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame()\ndf_RF_anciennet\u00e9 = df_RF_anciennet\u00e9.reindex(index=ordre_categories_anciennet\u00e9)\ndf_RF_anciennet\u00e9.round()\n</pre> df_RF_anciennet\u00e9 = df_RF.groupby(\"anciennet\u00e9 actionnaires\")[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame() df_RF_anciennet\u00e9 = df_RF_anciennet\u00e9.reindex(index=ordre_categories_anciennet\u00e9) df_RF_anciennet\u00e9.round() Out[\u00a0]: % re\u00e7u fiscal demand\u00e9 anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 76.0 Nouvel actionnaire entre 2012 \u00e0 2017 77.0 Nouvel actionnaire en 2012 ou moins 77.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories de souscripteurs&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories de souscripteurs\")) Moyennes des parts de RF demand\u00e9s sur l'ensemble des souscription individuelles par cat\u00e9gories de souscripteurs In\u00a0[\u00a0]: Copied! <pre>df_RF_catsous= df_RF.groupby('Cat\u00e9gories souscripteurs')[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame()\ndf_RF_catsous = df_RF_catsous.reindex(index=ordre_categories)\ndf_RF_catsous.round()\n</pre> df_RF_catsous= df_RF.groupby('Cat\u00e9gories souscripteurs')[\"% re\u00e7u fiscal demand\u00e9\"].mean().to_frame() df_RF_catsous = df_RF_catsous.reindex(index=ordre_categories) df_RF_catsous.round() Out[\u00a0]: % re\u00e7u fiscal demand\u00e9 Cat\u00e9gories souscripteurs 1 souscription 77.0 2 souscriptions 77.0 3 \u00e0 5 souscriptions 77.0 6 \u00e0 10 souscriptions 77.0 10 souscriptions et plus 76.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Affectation des souscriptions&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, Markdown, HTML  # Ins\u00e9rer un saut de page display(HTML(\"\"))   display(HTML('Affectation des souscriptions')) Affectation des souscriptions In\u00a0[\u00a0]: Copied! <pre>df2['Type affectation'] = df2[\"Affectation\"].apply(lambda x: 'd\u00e9di\u00e9 r\u00e9gion' if str(x).startswith('Collecte')\n                                                 else \"non d\u00e9di\u00e9 \" if str(x).startswith('Ensemble') else 'd\u00e9di\u00e9 projet')\n</pre> df2['Type affectation'] = df2[\"Affectation\"].apply(lambda x: 'd\u00e9di\u00e9 r\u00e9gion' if str(x).startswith('Collecte')                                                  else \"non d\u00e9di\u00e9 \" if str(x).startswith('Ensemble') else 'd\u00e9di\u00e9 projet') In\u00a0[\u00a0]: Copied! <pre># Supposons que votre DataFrame s'appelle df2\ndf_affectation= df2['Type affectation'].value_counts().reset_index()\n\n# Renommer les colonnes du tableau\ndf_affectation.columns = ['Valeur', 'Nombre de correspondances']\n\n\ndf_affectation\n</pre>   # Supposons que votre DataFrame s'appelle df2 df_affectation= df2['Type affectation'].value_counts().reset_index()  # Renommer les colonnes du tableau df_affectation.columns = ['Valeur', 'Nombre de correspondances']   df_affectation  Out[\u00a0]: Valeur Nombre de correspondances 0 d\u00e9di\u00e9 projet 5785 1 d\u00e9di\u00e9 r\u00e9gion 5600 2 non d\u00e9di\u00e9 5502 In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = df2['Type affectation'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\nplt.title(\"Types d'affectation\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = df2['Type affectation'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90) plt.title(\"Types d'affectation\")    # Afficher le graphique plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des affectations r\u00e9gion&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des affectations r\u00e9gion\")) R\u00e9partition des affectations r\u00e9gion In\u00a0[\u00a0]: Copied! <pre>df_r\u00e9gion = df2[df2['Type affectation'] == 'd\u00e9di\u00e9 r\u00e9gion'].copy()\n\n\ndf_r\u00e9gion['Affectation'] = df_r\u00e9gion['Affectation'].str.replace('Collecte d\u00e9di\u00e9e ', '')\n\ndf_r\u00e9gion['Affectation'] = df_r\u00e9gion['Affectation'].str.replace('lorraine', 'LORRAINE')\n\ndf_r\u00e9gion= df_r\u00e9gion['Affectation'].value_counts().reset_index()\n\ntotal_count = df_r\u00e9gion['count'].sum()\n\n\ndf_r\u00e9gion['Part du total en %'] = df_r\u00e9gion['count'] / total_count * 100\n\n# Calculer le total de chaque colonne\ntotal = df_r\u00e9gion.sum()\n\n# Cr\u00e9er un nouveau DataFrame avec les totaux\ndf_total = pd.DataFrame([total.values], columns=df_r\u00e9gion.columns)\n\n# Renommer la nouvelle ligne avec le label \"Total\"\ndf_total.at[0, 'Affectation'] = \"Total\"\n\n# Concat\u00e9ner le DataFrame original avec le DataFrame des totaux\ndf_r\u00e9gion_total = pd.concat([df_r\u00e9gion, df_total])\n\n# Afficher le DataFrame avec les totaux\ndf_r\u00e9gion_total\n</pre> df_r\u00e9gion = df2[df2['Type affectation'] == 'd\u00e9di\u00e9 r\u00e9gion'].copy()   df_r\u00e9gion['Affectation'] = df_r\u00e9gion['Affectation'].str.replace('Collecte d\u00e9di\u00e9e ', '')  df_r\u00e9gion['Affectation'] = df_r\u00e9gion['Affectation'].str.replace('lorraine', 'LORRAINE')  df_r\u00e9gion= df_r\u00e9gion['Affectation'].value_counts().reset_index()  total_count = df_r\u00e9gion['count'].sum()   df_r\u00e9gion['Part du total en %'] = df_r\u00e9gion['count'] / total_count * 100  # Calculer le total de chaque colonne total = df_r\u00e9gion.sum()  # Cr\u00e9er un nouveau DataFrame avec les totaux df_total = pd.DataFrame([total.values], columns=df_r\u00e9gion.columns)  # Renommer la nouvelle ligne avec le label \"Total\" df_total.at[0, 'Affectation'] = \"Total\"  # Concat\u00e9ner le DataFrame original avec le DataFrame des totaux df_r\u00e9gion_total = pd.concat([df_r\u00e9gion, df_total])  # Afficher le DataFrame avec les totaux df_r\u00e9gion_total Out[\u00a0]: Affectation count Part du total en % 0 - \u00cele-de-France 282 5.035714 1 - Poitou-Charentes 273 4.875000 2 - Limousin 272 4.857143 3 - Languedoc-Roussillon 267 4.767857 4 - Midi-Pyr\u00e9n\u00e9es 264 4.714286 5 - Nord-Pas-de-Calais 262 4.678571 6 - Bourgogne 262 4.678571 7 - Champagne-Ardenne 259 4.625000 8 - Aquitaine 259 4.625000 9 - Franche-Comt\u00e9 254 4.535714 10 - Bretagne 253 4.517857 11 - Centre 252 4.500000 12 - Rh\u00f4ne-Alpes 251 4.482143 13 - Haute-Normandie 251 4.482143 14 - Alsace 251 4.482143 15 - Basse-Normandie 250 4.464286 16 - Lorraine 249 4.446429 17 - Picardie 248 4.428571 18 - Provence-Alpes-C\u00f4te d'Azur 242 4.321429 19 - Pays de la Loire 239 4.267857 20 - Corse 234 4.178571 21 - Auvergne 226 4.035714 0 Total 5600 100.000000 In\u00a0[\u00a0]: Copied! <pre>dummies = pd.get_dummies(df2['Type affectation'], prefix='Affectation')\n\n# Concat\u00e9nation des dummies avec le DataFrame d'origine\ndf2 = pd.concat([df2, dummies], axis=1)\ncolonnes_dummies = [\"Affectation_d\u00e9di\u00e9 r\u00e9gion\", 'Affectation_d\u00e9di\u00e9 projet', 'Affectation_non d\u00e9di\u00e9 ']\n\n# Remplacement des valeurs True par 1 et False par 0 dans les colonnes de dummies\ndf2[colonnes_dummies] = df2[colonnes_dummies].replace({True: 1, False: 0})\ndf2['Nombre de souscriptions'] = df2['ID du contact'].map(df2['ID du contact'].value_counts())\ndf_affect = df2.sort_values(by='ID du contact')\ngrouped_counts = df2.groupby('ID du contact')[\"Affectation_d\u00e9di\u00e9 r\u00e9gion\"].sum()\ngrouped_countsDP = df2.groupby('ID du contact')[\"Affectation_d\u00e9di\u00e9 projet\"].sum()\ngrouped_countsND = df2.groupby('ID du contact')[\"Affectation_non d\u00e9di\u00e9 \"].sum()\ndf_affect = df_affect.merge(grouped_counts, on='ID du contact', suffixes=('', '_count'))\ndf_affect = df_affect.merge(grouped_countsDP, on='ID du contact', suffixes=('', '_count'))\ndf_affect = df_affect.merge(grouped_countsND, on='ID du contact', suffixes=('', '_count'))\ndf_affect[\"% affec r\u00e9gion\"] = df_affect['Affectation_d\u00e9di\u00e9 r\u00e9gion_count'] / df_affect[\"Nombre de souscriptions\"] * 100\ndf_affect[\"% affec projet\"] = df_affect['Affectation_d\u00e9di\u00e9 projet_count'] / df_affect[\"Nombre de souscriptions\"] * 100\ndf_affect[\"% affec non-d\u00e9di\u00e9\"] = df_affect['Affectation_non d\u00e9di\u00e9 _count'] / df_affect[\"Nombre de souscriptions\"] * 100\n\ndf_affect= df_affect.drop(['Affectation_d\u00e9di\u00e9 projet', 'Affectation_d\u00e9di\u00e9 r\u00e9gion', 'Affectation_d\u00e9di\u00e9 r\u00e9gion_count', 'Affectation_non d\u00e9di\u00e9 ', 'Affectation_d\u00e9di\u00e9 projet_count','Affectation_non d\u00e9di\u00e9 _count'], axis=1)\ndf_affect = df_affect.drop_duplicates(subset = \"ID du contact\")\nconditions = [\n     (df_affect['Nombre de souscriptions'] &lt; 2),\n     (df_affect['Nombre de souscriptions'] &lt;3),\n     (df_affect['Nombre de souscriptions'] &lt;=5),\n     (df_affect['Nombre de souscriptions'] &lt;=10),\n]\n\nchoices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]\n\ndf_affect['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')\n</pre> dummies = pd.get_dummies(df2['Type affectation'], prefix='Affectation')  # Concat\u00e9nation des dummies avec le DataFrame d'origine df2 = pd.concat([df2, dummies], axis=1) colonnes_dummies = [\"Affectation_d\u00e9di\u00e9 r\u00e9gion\", 'Affectation_d\u00e9di\u00e9 projet', 'Affectation_non d\u00e9di\u00e9 ']  # Remplacement des valeurs True par 1 et False par 0 dans les colonnes de dummies df2[colonnes_dummies] = df2[colonnes_dummies].replace({True: 1, False: 0}) df2['Nombre de souscriptions'] = df2['ID du contact'].map(df2['ID du contact'].value_counts()) df_affect = df2.sort_values(by='ID du contact') grouped_counts = df2.groupby('ID du contact')[\"Affectation_d\u00e9di\u00e9 r\u00e9gion\"].sum() grouped_countsDP = df2.groupby('ID du contact')[\"Affectation_d\u00e9di\u00e9 projet\"].sum() grouped_countsND = df2.groupby('ID du contact')[\"Affectation_non d\u00e9di\u00e9 \"].sum() df_affect = df_affect.merge(grouped_counts, on='ID du contact', suffixes=('', '_count')) df_affect = df_affect.merge(grouped_countsDP, on='ID du contact', suffixes=('', '_count')) df_affect = df_affect.merge(grouped_countsND, on='ID du contact', suffixes=('', '_count')) df_affect[\"% affec r\u00e9gion\"] = df_affect['Affectation_d\u00e9di\u00e9 r\u00e9gion_count'] / df_affect[\"Nombre de souscriptions\"] * 100 df_affect[\"% affec projet\"] = df_affect['Affectation_d\u00e9di\u00e9 projet_count'] / df_affect[\"Nombre de souscriptions\"] * 100 df_affect[\"% affec non-d\u00e9di\u00e9\"] = df_affect['Affectation_non d\u00e9di\u00e9 _count'] / df_affect[\"Nombre de souscriptions\"] * 100  df_affect= df_affect.drop(['Affectation_d\u00e9di\u00e9 projet', 'Affectation_d\u00e9di\u00e9 r\u00e9gion', 'Affectation_d\u00e9di\u00e9 r\u00e9gion_count', 'Affectation_non d\u00e9di\u00e9 ', 'Affectation_d\u00e9di\u00e9 projet_count','Affectation_non d\u00e9di\u00e9 _count'], axis=1) df_affect = df_affect.drop_duplicates(subset = \"ID du contact\") conditions = [      (df_affect['Nombre de souscriptions'] &lt; 2),      (df_affect['Nombre de souscriptions'] &lt;3),      (df_affect['Nombre de souscriptions'] &lt;=5),      (df_affect['Nombre de souscriptions'] &lt;=10), ]  choices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]  df_affect['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')  In\u00a0[\u00a0]: Copied! <pre>df_affect.rename(columns={'Territoire Terre de Liens': 'Territoire d\\'habitation renseign\u00e9'}, inplace=True)\n</pre> df_affect.rename(columns={'Territoire Terre de Liens': 'Territoire d\\'habitation renseign\u00e9'}, inplace=True) In\u00a0[\u00a0]: Copied! <pre>df_affect_nbsous = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec r\u00e9gion'].mean().to_frame()\ndf_affect_catage = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec r\u00e9gion'].mean().to_frame()\ndf_affect_MC = df_affect.groupby('multi-casquette ?')['% affec r\u00e9gion'].mean().to_frame()\ndf_affect_anciennet\u00e9 = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec r\u00e9gion'].mean().to_frame()\ndf_affect_MS= df_affect.groupby('multi-souscripteur ?')['% affec r\u00e9gion'].mean().to_frame()\n\n# Calculate means for '% affec projet' by different categories\ndf_affect_nbsous_proj = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec projet'].mean().to_frame()\ndf_affect_catage_proj = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec projet'].mean().to_frame()\ndf_affect_MC_proj = df_affect.groupby('multi-casquette ?')['% affec projet'].mean().to_frame()\ndf_affect_anciennet\u00e9_proj = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec projet'].mean().to_frame()\ndf_affect_MS_proj= df_affect.groupby('multi-souscripteur ?')['% affec projet'].mean().to_frame()\n# Calculate means for '% affec non-d\u00e9di\u00e9' by different categories\ndf_affect_nbsous_non_dedie = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec non-d\u00e9di\u00e9'].mean().to_frame()\ndf_affect_catage_non_dedie = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec non-d\u00e9di\u00e9'].mean().to_frame()\ndf_affect_MC_non_dedie = df_affect.groupby('multi-casquette ?')['% affec non-d\u00e9di\u00e9'].mean().to_frame()\ndf_affect_anciennet\u00e9_non_dedie = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec non-d\u00e9di\u00e9'].mean().to_frame()\ndf_affect_MS_non_dedie = df_affect.groupby('multi-souscripteur ?')['% affec non-d\u00e9di\u00e9'].mean().to_frame()\n\n\n# Merge DataFrames for '% affec r\u00e9gion', '% affec projet', and '% affec non-d\u00e9di\u00e9' for each category\nmerged_df_nbsous = df_affect_nbsous.merge(df_affect_nbsous_proj, on='Cat\u00e9gories souscripteurs')\nmerged_df_nbsous = merged_df_nbsous.merge(df_affect_nbsous_non_dedie, on='Cat\u00e9gories souscripteurs')\n\nmerged_df_catage = df_affect_catage.merge(df_affect_catage_proj, on='cat\u00e9gories \u00e2ge')\nmerged_df_catage = merged_df_catage.merge(df_affect_catage_non_dedie, on='cat\u00e9gories \u00e2ge')\n\nmerged_df_MC = df_affect_MC.merge(df_affect_MC_proj, on='multi-casquette ?')\nmerged_df_MC = merged_df_MC.merge(df_affect_MC_non_dedie, on='multi-casquette ?')\n\nmerged_df_anciennet\u00e9 = df_affect_anciennet\u00e9.merge(df_affect_anciennet\u00e9_proj, on='anciennet\u00e9 actionnaires')\nmerged_df_anciennet\u00e9 = merged_df_anciennet\u00e9.merge(df_affect_anciennet\u00e9_non_dedie, on='anciennet\u00e9 actionnaires')\nmerged_df_MS = df_affect_MS.merge(df_affect_MS_proj, on='multi-souscripteur ?')\nmerged_df_MS = merged_df_MS.merge(df_affect_MS_non_dedie, on='multi-souscripteur ?')\n</pre> df_affect_nbsous = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec r\u00e9gion'].mean().to_frame() df_affect_catage = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec r\u00e9gion'].mean().to_frame() df_affect_MC = df_affect.groupby('multi-casquette ?')['% affec r\u00e9gion'].mean().to_frame() df_affect_anciennet\u00e9 = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec r\u00e9gion'].mean().to_frame() df_affect_MS= df_affect.groupby('multi-souscripteur ?')['% affec r\u00e9gion'].mean().to_frame()  # Calculate means for '% affec projet' by different categories df_affect_nbsous_proj = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec projet'].mean().to_frame() df_affect_catage_proj = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec projet'].mean().to_frame() df_affect_MC_proj = df_affect.groupby('multi-casquette ?')['% affec projet'].mean().to_frame() df_affect_anciennet\u00e9_proj = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec projet'].mean().to_frame() df_affect_MS_proj= df_affect.groupby('multi-souscripteur ?')['% affec projet'].mean().to_frame() # Calculate means for '% affec non-d\u00e9di\u00e9' by different categories df_affect_nbsous_non_dedie = df_affect.groupby('Cat\u00e9gories souscripteurs')['% affec non-d\u00e9di\u00e9'].mean().to_frame() df_affect_catage_non_dedie = df_affect.groupby('cat\u00e9gories \u00e2ge')['% affec non-d\u00e9di\u00e9'].mean().to_frame() df_affect_MC_non_dedie = df_affect.groupby('multi-casquette ?')['% affec non-d\u00e9di\u00e9'].mean().to_frame() df_affect_anciennet\u00e9_non_dedie = df_affect.groupby('anciennet\u00e9 actionnaires')['% affec non-d\u00e9di\u00e9'].mean().to_frame() df_affect_MS_non_dedie = df_affect.groupby('multi-souscripteur ?')['% affec non-d\u00e9di\u00e9'].mean().to_frame()   # Merge DataFrames for '% affec r\u00e9gion', '% affec projet', and '% affec non-d\u00e9di\u00e9' for each category merged_df_nbsous = df_affect_nbsous.merge(df_affect_nbsous_proj, on='Cat\u00e9gories souscripteurs') merged_df_nbsous = merged_df_nbsous.merge(df_affect_nbsous_non_dedie, on='Cat\u00e9gories souscripteurs')  merged_df_catage = df_affect_catage.merge(df_affect_catage_proj, on='cat\u00e9gories \u00e2ge') merged_df_catage = merged_df_catage.merge(df_affect_catage_non_dedie, on='cat\u00e9gories \u00e2ge')  merged_df_MC = df_affect_MC.merge(df_affect_MC_proj, on='multi-casquette ?') merged_df_MC = merged_df_MC.merge(df_affect_MC_non_dedie, on='multi-casquette ?')  merged_df_anciennet\u00e9 = df_affect_anciennet\u00e9.merge(df_affect_anciennet\u00e9_proj, on='anciennet\u00e9 actionnaires') merged_df_anciennet\u00e9 = merged_df_anciennet\u00e9.merge(df_affect_anciennet\u00e9_non_dedie, on='anciennet\u00e9 actionnaires') merged_df_MS = df_affect_MS.merge(df_affect_MS_proj, on='multi-souscripteur ?') merged_df_MS = merged_df_MS.merge(df_affect_MS_non_dedie, on='multi-souscripteur ?') In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h2&gt;Part moyenne des affectations  sur toutes les souscriptions par personne&lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Part moyenne des affectations  sur toutes les souscriptions par personne\")) Part moyenne des affectations  sur toutes les souscriptions par personne In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Part moyenne des affectations par multi-souscrippteurs ou pas&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Part moyenne des affectations par multi-souscrippteurs ou pas\")) Part moyenne des affectations par multi-souscrippteurs ou pas In\u00a0[\u00a0]: Copied! <pre>merged_df_MS \n</pre> merged_df_MS   Out[\u00a0]: % affec r\u00e9gion % affec projet % affec non-d\u00e9di\u00e9 multi-souscripteur ? False 33.178468 34.668376 32.153156 True 33.019107 34.253755 32.727138 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Part moyenne des affectations par cat\u00e9gories de souscripteurs&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Part moyenne des affectations par cat\u00e9gories de souscripteurs\")) Part moyenne des affectations par cat\u00e9gories de souscripteurs In\u00a0[\u00a0]: Copied! <pre>merged_df_nbsous[\"Total\"] = merged_df_nbsous[\"% affec r\u00e9gion\"]+ merged_df_nbsous[\"% affec projet\"]+ merged_df_nbsous[\"% affec non-d\u00e9di\u00e9\"]\nordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\nmerged_df_nbsous = merged_df_nbsous.reindex(ordre_categories)\nmerged_df_nbsous = merged_df_nbsous.round()\nmerged_df_nbsous\n</pre> merged_df_nbsous[\"Total\"] = merged_df_nbsous[\"% affec r\u00e9gion\"]+ merged_df_nbsous[\"% affec projet\"]+ merged_df_nbsous[\"% affec non-d\u00e9di\u00e9\"] ordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] merged_df_nbsous = merged_df_nbsous.reindex(ordre_categories) merged_df_nbsous = merged_df_nbsous.round() merged_df_nbsous   Out[\u00a0]: % affec r\u00e9gion % affec projet % affec non-d\u00e9di\u00e9 Total Cat\u00e9gories souscripteurs 1 souscription 33.0 35.0 32.0 100.0 2 souscriptions 33.0 35.0 33.0 100.0 3 \u00e0 5 souscriptions 34.0 34.0 32.0 100.0 6 \u00e0 10 souscriptions 32.0 34.0 34.0 100.0 10 souscriptions et plus 34.0 31.0 35.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : les personnes ayant eu 3 \u00e0 5 soucriptions les ont d\u00e9di\u00e9es en moyenne \u00e0 33 % \u00e0 une r\u00e9gion. On remarque que les mono-souscripteurs ont tendance \u00e0 affecter leurs souscritpions aux fermes&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : les personnes ayant eu 3 \u00e0 5 soucriptions les ont d\u00e9di\u00e9es en moyenne \u00e0 33 % \u00e0 une r\u00e9gion. On remarque que les mono-souscripteurs ont tendance \u00e0 affecter leurs souscritpions aux fermes\")) Cl\u00e9 de lecture : les personnes ayant eu 3 \u00e0 5 soucriptions les ont d\u00e9di\u00e9es en moyenne \u00e0 33 % \u00e0 une r\u00e9gion. On remarque que les mono-souscripteurs ont tendance \u00e0 affecter leurs souscritpions aux fermes In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Part moyenne des affectations par cat\u00e9gories d'\u00e2ge&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Part moyenne des affectations par cat\u00e9gories d'\u00e2ge\")) Part moyenne des affectations par cat\u00e9gories d'\u00e2ge In\u00a0[\u00a0]: Copied! <pre>merged_df_catage[\"Total\"] = merged_df_catage[\"% affec r\u00e9gion\"]+ merged_df_catage[\"% affec projet\"]+ merged_df_catage[\"% affec non-d\u00e9di\u00e9\"]\nmerged_df_catage.round() \n</pre> merged_df_catage[\"Total\"] = merged_df_catage[\"% affec r\u00e9gion\"]+ merged_df_catage[\"% affec projet\"]+ merged_df_catage[\"% affec non-d\u00e9di\u00e9\"] merged_df_catage.round()  Out[\u00a0]: % affec r\u00e9gion % affec projet % affec non-d\u00e9di\u00e9 Total cat\u00e9gories \u00e2ge 0-25 ans 33.0 34.0 32.0 100.0 25-40 ans 33.0 35.0 32.0 100.0 40-60 ans 33.0 36.0 32.0 100.0 60 ans et plus 33.0 34.0 33.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Part moyenne des affectations  par cat\u00e9gories d'anciennet\u00e9&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Part moyenne des affectations  par cat\u00e9gories d'anciennet\u00e9\")) Part moyenne des affectations  par cat\u00e9gories d'anciennet\u00e9 In\u00a0[\u00a0]: Copied! <pre>merged_df_anciennet\u00e9[\"Total\"] = merged_df_anciennet\u00e9[\"% affec r\u00e9gion\"]+ merged_df_anciennet\u00e9[\"% affec projet\"]+ merged_df_anciennet\u00e9[\"% affec non-d\u00e9di\u00e9\"]\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\nmerged_df_anciennet\u00e9.reindex(ordre_categories_anciennet\u00e9)\nmerged_df_anciennet\u00e9.round()\n</pre> merged_df_anciennet\u00e9[\"Total\"] = merged_df_anciennet\u00e9[\"% affec r\u00e9gion\"]+ merged_df_anciennet\u00e9[\"% affec projet\"]+ merged_df_anciennet\u00e9[\"% affec non-d\u00e9di\u00e9\"] ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] merged_df_anciennet\u00e9.reindex(ordre_categories_anciennet\u00e9) merged_df_anciennet\u00e9.round() Out[\u00a0]: % affec r\u00e9gion % affec projet % affec non-d\u00e9di\u00e9 Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 33.0 35.0 32.0 100.0 Nouvel actionnaire en 2012 ou moins 33.0 35.0 32.0 100.0 Nouvel actionnaire entre 2012 \u00e0 2017 33.0 34.0 33.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les actionnaires arriv\u00e9s entre 2012 et 2017 affectaient  d'autant plus leurs souscriptions \u00e0 des fermes&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les actionnaires arriv\u00e9s entre 2012 et 2017 affectaient  d'autant plus leurs souscriptions \u00e0 des fermes\")) Les actionnaires arriv\u00e9s entre 2012 et 2017 affectaient  d'autant plus leurs souscriptions \u00e0 des fermes In\u00a0[\u00a0]: Copied! <pre>merged_df_MC[\"Total\"] = merged_df_MC[\"% affec r\u00e9gion\"]+ merged_df_MC[\"% affec projet\"]+ merged_df_MC[\"% affec non-d\u00e9di\u00e9\"]\nmerged_df_MC.round()\n</pre> merged_df_MC[\"Total\"] = merged_df_MC[\"% affec r\u00e9gion\"]+ merged_df_MC[\"% affec projet\"]+ merged_df_MC[\"% affec non-d\u00e9di\u00e9\"] merged_df_MC.round()  Out[\u00a0]: % affec r\u00e9gion % affec projet % affec non-d\u00e9di\u00e9 Total multi-casquette ? Actionnaire uniquement 34.0 34.0 32.0 100.0 Actionnaire-adh\u00e9rent 33.0 35.0 32.0 100.0 Actionnaire-donateur 33.0 34.0 33.0 100.0 Triple-engagement 32.0 35.0 33.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les actionnaires-adh\u00e9rents ont tendance \u00e0 plus affecter leurs souscriptions \u00e0 des fermes ou \u00e0 une r\u00e9gion&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les actionnaires-adh\u00e9rents ont tendance \u00e0 plus affecter leurs souscriptions \u00e0 des fermes ou \u00e0 une r\u00e9gion\")) Les actionnaires-adh\u00e9rents ont tendance \u00e0 plus affecter leurs souscriptions \u00e0 des fermes ou \u00e0 une r\u00e9gion In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Dur\u00e9e moyenne de reprise de souscriptions (on ne parle que de multi-souscripteurs)&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Dur\u00e9e moyenne de reprise de souscriptions (on ne parle que de multi-souscripteurs)')) Dur\u00e9e moyenne de reprise de souscriptions (on ne parle que de multi-souscripteurs) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Il s'agit de regarder la dur\u00e9e entre diff\u00e9rentes dates de prise de souscriptions par personne. On fait ensuite une moyenne individuelle de ces dur\u00e9es&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il s'agit de regarder la dur\u00e9e entre diff\u00e9rentes dates de prise de souscriptions par personne. On fait ensuite une moyenne individuelle de ces dur\u00e9es\")) Il s'agit de regarder la dur\u00e9e entre diff\u00e9rentes dates de prise de souscriptions par personne. On fait ensuite une moyenne individuelle de ces dur\u00e9es In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires et ex actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires et ex actionnaires\")) Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires et ex actionnaires In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\ncolumns_to_drop = ['\u00e2ge', 'Territoire Terre de Liens', 'adh\u00e9rent N', 'Donateur N',\n                   'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9',\n                   'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues', 'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)',\n                   'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats', 'Nombre d\\'actions \u00e0 l\\'acquisition',\n                   'A fait l\\'objet d\\'un re\u00e7u fiscal', 'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',\n                   \"Date d'activation\", 'Actions - Date de fin', 'Nombre d\\'actions \u00e9chang\u00e9es', 'Difference d\u00e9but fin',\n                   'retrait complet ou partiel', 'ann\u00e9e rachat', 'dur\u00e9e conservation', 'r\u00e9partition ann\u00e9e',\n                   'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires', 'r\u00e9partition ann\u00e9e nouveau actionnaire',\n                   'cat\u00e9gorie souscription', 'Type affectation', 'Nombre de souscriptions',\"Affectation_d\u00e9di\u00e9 projet\", \"Affectation_d\u00e9di\u00e9 r\u00e9gion\",\"Affectation_non d\u00e9di\u00e9 \"]\n\ndf2_copy = df2.drop(columns=columns_to_drop).copy()\n\ndf2_copy[\"Date d'activation\"] = pd.to_datetime(df2_copy['Date du Mouvement'], format=\"%Y-%d-%m\", dayfirst=True)\n\n# Trier le dataframe par nom et date\ndf_sorted = df2_copy.sort_values(by=['ID du contact', 'Date du Mouvement'])\n\n# Calculer la diff\u00e9rence de dates\ndf_sorted['Diff\u00e9rence'] = df_sorted.groupby('ID du contact')['Date du Mouvement'].diff()\n\n# Calculer la diff\u00e9rence moyenne par nom, en excluant les valeurs manquantes\ndf_diff_mean = df_sorted.groupby('ID du contact')['Diff\u00e9rence'].mean().dropna().reset_index()\n\n\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean['Diff\u00e9rence'])\n\ndf_diff_mean['Diff\u00e9rence'] = df_diff_mean['Diff\u00e9rence'].dt.floor('D')\n\n# Calculer la moyenne en dur\u00e9e d'ann\u00e9e en ignorant les jours, heures, minutes et secondes\nmean_difference = np.mean(df_diff_mean['Diff\u00e9rence'] / np.timedelta64(1, 'W'))\nmean_difference = mean_difference/ 52\n# Arrondir le r\u00e9sultat au dixi\u00e8me\nmean_difference_rounded = round(mean_difference, 1)\n\n# Afficher la moyenne en dur\u00e9e d'ann\u00e9e arrondie\nprint(\"Dur\u00e9e moyenne pour reprise d'actions pour actionnaires et ex actionnaires:\", mean_difference_rounded)\n</pre> import pandas as pd import numpy as np  columns_to_drop = ['\u00e2ge', 'Territoire Terre de Liens', 'adh\u00e9rent N', 'Donateur N',                    'RFM-Date Premi\u00e8re Souscription', 'Fonci\u00e8re : Capital poss\u00e9d\u00e9',                    'Fonci\u00e8re : Nombre d\\'actions d\u00e9tenues', 'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)',                    'Num\u00e9ro du contrat', 'Type d\\'enregistrement des contrats', 'Nombre d\\'actions \u00e0 l\\'acquisition',                    'A fait l\\'objet d\\'un re\u00e7u fiscal', 'Affectation', 'Mouvement de titre Name', 'Nature du mouvement',                    \"Date d'activation\", 'Actions - Date de fin', 'Nombre d\\'actions \u00e9chang\u00e9es', 'Difference d\u00e9but fin',                    'retrait complet ou partiel', 'ann\u00e9e rachat', 'dur\u00e9e conservation', 'r\u00e9partition ann\u00e9e',                    'cat\u00e9gories \u00e2ge', 'anciennet\u00e9 actionnaires', 'r\u00e9partition ann\u00e9e nouveau actionnaire',                    'cat\u00e9gorie souscription', 'Type affectation', 'Nombre de souscriptions',\"Affectation_d\u00e9di\u00e9 projet\", \"Affectation_d\u00e9di\u00e9 r\u00e9gion\",\"Affectation_non d\u00e9di\u00e9 \"]  df2_copy = df2.drop(columns=columns_to_drop).copy()  df2_copy[\"Date d'activation\"] = pd.to_datetime(df2_copy['Date du Mouvement'], format=\"%Y-%d-%m\", dayfirst=True)  # Trier le dataframe par nom et date df_sorted = df2_copy.sort_values(by=['ID du contact', 'Date du Mouvement'])  # Calculer la diff\u00e9rence de dates df_sorted['Diff\u00e9rence'] = df_sorted.groupby('ID du contact')['Date du Mouvement'].diff()  # Calculer la diff\u00e9rence moyenne par nom, en excluant les valeurs manquantes df_diff_mean = df_sorted.groupby('ID du contact')['Diff\u00e9rence'].mean().dropna().reset_index()   # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean['Diff\u00e9rence'])  df_diff_mean['Diff\u00e9rence'] = df_diff_mean['Diff\u00e9rence'].dt.floor('D')  # Calculer la moyenne en dur\u00e9e d'ann\u00e9e en ignorant les jours, heures, minutes et secondes mean_difference = np.mean(df_diff_mean['Diff\u00e9rence'] / np.timedelta64(1, 'W')) mean_difference = mean_difference/ 52 # Arrondir le r\u00e9sultat au dixi\u00e8me mean_difference_rounded = round(mean_difference, 1)  # Afficher la moyenne en dur\u00e9e d'ann\u00e9e arrondie print(\"Dur\u00e9e moyenne pour reprise d'actions pour actionnaires et ex actionnaires:\", mean_difference_rounded)  <pre>Dur\u00e9e moyenne pour reprise d'actions pour actionnaires et ex actionnaires: 2.8\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : les souscripteurs qui ont au minimum 2 souscriptions en ont repris une en moyenne au bout de 2,4 ans&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : les souscripteurs qui ont au minimum 2 souscriptions en ont repris une en moyenne au bout de 2,4 ans\")) Cl\u00e9 de lecture : les souscripteurs qui ont au minimum 2 souscriptions en ont repris une en moyenne au bout de 2,4 ans In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires\")) Dur\u00e9e moyenne de reprise de souscriptions pour actionnaires In\u00a0[\u00a0]: Copied! <pre>df_actionnaire= df2_copy[df2_copy['Actionnaire ?'] == 1 ].copy()\n</pre> df_actionnaire= df2_copy[df2_copy['Actionnaire ?'] == 1 ].copy() In\u00a0[\u00a0]: Copied! <pre>df_actionnaire[\"Date d'activation\"] = pd.to_datetime(df_actionnaire['Date du Mouvement'], dayfirst=True)\n\n# Trier le dataframe par nom et date\ndf_sorted2 = df_actionnaire.sort_values(by=['ID du contact', 'Date du Mouvement'])\n\n# Calculer la diff\u00e9rence de dates\ndf_sorted2['Diff\u00e9rence'] = df_sorted2.groupby('ID du contact')['Date du Mouvement'].diff()\n\n# Calculer la diff\u00e9rence moyenne par nom, en excluant les valeurs manquantes\ndf_diff_mean2 = df_sorted2.groupby('ID du contact')['Diff\u00e9rence'].mean().dropna().reset_index()\n\n\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean2['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean2['Diff\u00e9rence'])\n\ndf_diff_mean2['Diff\u00e9rence'] = df_diff_mean2['Diff\u00e9rence'].dt.floor('D')\n\n# Calculer la moyenne en dur\u00e9e d'ann\u00e9e en ignorant les jours, heures, minutes et secondes\nmean_difference2 = np.mean(df_diff_mean2['Diff\u00e9rence'] / np.timedelta64(1, 'W'))\nmean_difference2 = mean_difference2/ 52 \n\n# Arrondir le r\u00e9sultat au dixi\u00e8me\nmean_difference_rounded2 = round(mean_difference2, 1)\n\n# Afficher la moyenne en dur\u00e9e d'ann\u00e9e arrondie\nprint(\"Dur\u00e9e moyenne pour reprise d'action pour actionnaires:\", mean_difference_rounded2)\n</pre> df_actionnaire[\"Date d'activation\"] = pd.to_datetime(df_actionnaire['Date du Mouvement'], dayfirst=True)  # Trier le dataframe par nom et date df_sorted2 = df_actionnaire.sort_values(by=['ID du contact', 'Date du Mouvement'])  # Calculer la diff\u00e9rence de dates df_sorted2['Diff\u00e9rence'] = df_sorted2.groupby('ID du contact')['Date du Mouvement'].diff()  # Calculer la diff\u00e9rence moyenne par nom, en excluant les valeurs manquantes df_diff_mean2 = df_sorted2.groupby('ID du contact')['Diff\u00e9rence'].mean().dropna().reset_index()   # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean2['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean2['Diff\u00e9rence'])  df_diff_mean2['Diff\u00e9rence'] = df_diff_mean2['Diff\u00e9rence'].dt.floor('D')  # Calculer la moyenne en dur\u00e9e d'ann\u00e9e en ignorant les jours, heures, minutes et secondes mean_difference2 = np.mean(df_diff_mean2['Diff\u00e9rence'] / np.timedelta64(1, 'W')) mean_difference2 = mean_difference2/ 52   # Arrondir le r\u00e9sultat au dixi\u00e8me mean_difference_rounded2 = round(mean_difference2, 1)  # Afficher la moyenne en dur\u00e9e d'ann\u00e9e arrondie print(\"Dur\u00e9e moyenne pour reprise d'action pour actionnaires:\", mean_difference_rounded2)  <pre>Dur\u00e9e moyenne pour reprise d'action pour actionnaires: 2.8\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions pour multi-casquettes ? &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions pour multi-casquettes ? \")) Dur\u00e9e moyenne de reprise de souscriptions pour multi-casquettes ?  In\u00a0[\u00a0]: Copied! <pre>df2.loc[:, \"multi-casquette ?\"] = df2.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Actionnaire uniquement\", axis=1)\n\ndf_diff_mean3 = df_diff_mean2.merge(df2[['ID du contact', 'multi-casquette ?']], on='ID du contact', how='left')\n\ndf_diff_mean3 = df_diff_mean3.drop_duplicates(subset=\"ID du contact\")\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean3['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean3['Diff\u00e9rence'])\n# Grouper le DataFrame d'origine par 'multi-casquette ?' et compter les occurrences\ncount_per_category = df_diff_mean3.groupby('multi-casquette ?').size().reset_index(name='Nombre de personnes')\ndf_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'].dt.floor('D')\ndf_mean_diff = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].mean().reset_index()\ndf_mean_diff['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff['Diff\u00e9rence'] / pd.Timedelta(days=365)\ndf_mean_diff['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff['Diff\u00e9rence en ann\u00e9es'].round(1)\ndf_mean_diff = df_mean_diff.drop('Diff\u00e9rence', axis=1)\ndf_mean_diff = df_mean_diff.merge(count_per_category, on='multi-casquette ?', how='left')\ndf_mean_diff\n</pre> df2.loc[:, \"multi-casquette ?\"] = df2.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Actionnaire uniquement\", axis=1)  df_diff_mean3 = df_diff_mean2.merge(df2[['ID du contact', 'multi-casquette ?']], on='ID du contact', how='left')  df_diff_mean3 = df_diff_mean3.drop_duplicates(subset=\"ID du contact\") # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean3['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean3['Diff\u00e9rence']) # Grouper le DataFrame d'origine par 'multi-casquette ?' et compter les occurrences count_per_category = df_diff_mean3.groupby('multi-casquette ?').size().reset_index(name='Nombre de personnes') df_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'].dt.floor('D') df_mean_diff = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].mean().reset_index() df_mean_diff['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff['Diff\u00e9rence'] / pd.Timedelta(days=365) df_mean_diff['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff['Diff\u00e9rence en ann\u00e9es'].round(1) df_mean_diff = df_mean_diff.drop('Diff\u00e9rence', axis=1) df_mean_diff = df_mean_diff.merge(count_per_category, on='multi-casquette ?', how='left') df_mean_diff Out[\u00a0]: multi-casquette ? Diff\u00e9rence en ann\u00e9es Nombre de personnes 0 Actionnaire uniquement 2.8 377 1 Actionnaire-adh\u00e9rent 2.9 1245 2 Actionnaire-donateur 2.9 523 3 Triple-engagement 2.7 1369 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'\u00e2ge?  &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'\u00e2ge?  \")) Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'\u00e2ge?   In\u00a0[\u00a0]: Copied! <pre>df_diff_mean4 = df_diff_mean2.merge(df2[['ID du contact', 'cat\u00e9gories \u00e2ge']], on='ID du contact', how='left')\n\ndf_diff_mean4 = df_diff_mean4.drop_duplicates(subset=\"ID du contact\")\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean4['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean4['Diff\u00e9rence'])\ndf_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'].dt.floor('D')\ncount_per_category = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge').size().reset_index(name='Nombre de personnes')\ndf_mean_diff2 = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].mean().reset_index()\ndf_mean_diff2['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff2['Diff\u00e9rence'] / pd.Timedelta(days=365)\ndf_mean_diff2['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff2['Diff\u00e9rence en ann\u00e9es'].round(1)\ndf_mean_diff2 = df_mean_diff2.drop('Diff\u00e9rence', axis=1)\ndf_mean_diff2 = df_mean_diff2.merge(count_per_category, on='cat\u00e9gories \u00e2ge', how='left')\ndf_mean_diff2\n</pre> df_diff_mean4 = df_diff_mean2.merge(df2[['ID du contact', 'cat\u00e9gories \u00e2ge']], on='ID du contact', how='left')  df_diff_mean4 = df_diff_mean4.drop_duplicates(subset=\"ID du contact\") # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean4['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean4['Diff\u00e9rence']) df_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'].dt.floor('D') count_per_category = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge').size().reset_index(name='Nombre de personnes') df_mean_diff2 = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].mean().reset_index() df_mean_diff2['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff2['Diff\u00e9rence'] / pd.Timedelta(days=365) df_mean_diff2['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff2['Diff\u00e9rence en ann\u00e9es'].round(1) df_mean_diff2 = df_mean_diff2.drop('Diff\u00e9rence', axis=1) df_mean_diff2 = df_mean_diff2.merge(count_per_category, on='cat\u00e9gories \u00e2ge', how='left') df_mean_diff2 Out[\u00a0]: cat\u00e9gories \u00e2ge Diff\u00e9rence en ann\u00e9es Nombre de personnes 0 0-25 ans 2.8 957 1 25-40 ans 2.7 590 2 40-60 ans 2.9 761 3 60 ans et plus 2.8 1206 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'anciennet\u00e9 &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'anciennet\u00e9 \")) Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories d'anciennet\u00e9  In\u00a0[\u00a0]: Copied! <pre>df_diff_mean5 = df_diff_mean2.merge(df2[['ID du contact', 'anciennet\u00e9 actionnaires']], on='ID du contact', how='left')\n\ndf_diff_mean5 = df_diff_mean5.drop_duplicates(subset=\"ID du contact\")\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean5['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean5['Diff\u00e9rence'])\ndf_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'].dt.floor('D')\ncount_per_category = df_diff_mean5.groupby('anciennet\u00e9 actionnaires').size().reset_index(name='Nombre de personnes')\ndf_mean_diff3 = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].mean().reset_index()\ndf_mean_diff3['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff3['Diff\u00e9rence'] / pd.Timedelta(days=365)\ndf_mean_diff3['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff3['Diff\u00e9rence en ann\u00e9es'].round(1)\ndf_mean_diff3 = df_mean_diff3.drop('Diff\u00e9rence', axis=1)\n# Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9\ndf_mean_diff3['ordre'] = df_mean_diff3['anciennet\u00e9 actionnaires'].apply(lambda x: ordre_categories_anciennet\u00e9.index(x))\ndf_mean_diff3 = df_mean_diff3.sort_values('ordre')\n# Supprimer la colonne \"ordre\"\ndf_mean_diff3 = df_mean_diff3.drop('ordre', axis=1)\ndf_mean_diff3 = df_mean_diff3.merge(count_per_category, on='anciennet\u00e9 actionnaires', how='left')\ndf_mean_diff3\n</pre> df_diff_mean5 = df_diff_mean2.merge(df2[['ID du contact', 'anciennet\u00e9 actionnaires']], on='ID du contact', how='left')  df_diff_mean5 = df_diff_mean5.drop_duplicates(subset=\"ID du contact\") # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean5['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean5['Diff\u00e9rence']) df_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'].dt.floor('D') count_per_category = df_diff_mean5.groupby('anciennet\u00e9 actionnaires').size().reset_index(name='Nombre de personnes') df_mean_diff3 = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].mean().reset_index() df_mean_diff3['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff3['Diff\u00e9rence'] / pd.Timedelta(days=365) df_mean_diff3['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff3['Diff\u00e9rence en ann\u00e9es'].round(1) df_mean_diff3 = df_mean_diff3.drop('Diff\u00e9rence', axis=1) # Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9 df_mean_diff3['ordre'] = df_mean_diff3['anciennet\u00e9 actionnaires'].apply(lambda x: ordre_categories_anciennet\u00e9.index(x)) df_mean_diff3 = df_mean_diff3.sort_values('ordre') # Supprimer la colonne \"ordre\" df_mean_diff3 = df_mean_diff3.drop('ordre', axis=1) df_mean_diff3 = df_mean_diff3.merge(count_per_category, on='anciennet\u00e9 actionnaires', how='left') df_mean_diff3 Out[\u00a0]: anciennet\u00e9 actionnaires Diff\u00e9rence en ann\u00e9es Nombre de personnes 0 Nouvel actionnaire depuis 2017 ou plus 1.1 1191 1 Nouvel actionnaire entre 2012 \u00e0 2017 2.7 1102 2 Nouvel actionnaire en 2012 ou moins 4.5 1221 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les actionnaires arriv\u00e9s depuis 2017 reprennent plus r\u00e9guli\u00e8rement des souscriptions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les actionnaires arriv\u00e9s depuis 2017 reprennent plus r\u00e9guli\u00e8rement des souscriptions\")) Les actionnaires arriv\u00e9s depuis 2017 reprennent plus r\u00e9guli\u00e8rement des souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories de souscripteurs &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories de souscripteurs \")) Dur\u00e9e moyenne de reprise de souscriptions par cat\u00e9gories de souscripteurs  In\u00a0[\u00a0]: Copied! <pre>df_diff_mean6 = df_diff_mean2.merge(df_MS[['ID du contact', 'Cat\u00e9gories souscripteurs']], on='ID du contact', how='left')\n\ndf_diff_mean6 = df_diff_mean6.drop_duplicates(subset=\"ID du contact\")\n# Convertir la colonne Diff\u00e9rence en timedelta\ndf_diff_mean6['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean6['Diff\u00e9rence'])\ndf_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'].dt.floor('D')\n\ncount_per_category = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs').size().reset_index(name='Nombre de personnes')\n\ndf_mean_diff4 = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].mean().reset_index()\ndf_mean_diff4['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff4['Diff\u00e9rence'] / pd.Timedelta(days=365)\ndf_mean_diff4['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff4['Diff\u00e9rence en ann\u00e9es'].round(1)\ndf_mean_diff4 = df_mean_diff4.drop('Diff\u00e9rence', axis=1)\n# Ordre des cat\u00e9gories souhait\u00e9es\nordre_categories_souscripteurs2 = ['2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\n\n# Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9\ndf_mean_diff4['ordre'] = df_mean_diff4['Cat\u00e9gories souscripteurs'].apply(lambda x: ordre_categories_souscripteurs2.index(x))\n\n# Trier le DataFrame en fonction de la colonne \"ordre\"\ndf_mean_diff4 = df_mean_diff4.sort_values('ordre')\n\n# Supprimer la colonne \"ordre\"\ndf_mean_diff4 = df_mean_diff4.drop('ordre', axis=1)\n\n# R\u00e9initialiser les index\ndf_mean_diff4.reset_index(drop=True, inplace=True)\ndf_mean_diff4 = df_mean_diff4.merge(count_per_category, on='Cat\u00e9gories souscripteurs', how='left')\n\n\ndf_mean_diff4\n</pre> df_diff_mean6 = df_diff_mean2.merge(df_MS[['ID du contact', 'Cat\u00e9gories souscripteurs']], on='ID du contact', how='left')  df_diff_mean6 = df_diff_mean6.drop_duplicates(subset=\"ID du contact\") # Convertir la colonne Diff\u00e9rence en timedelta df_diff_mean6['Diff\u00e9rence'] = pd.to_timedelta(df_diff_mean6['Diff\u00e9rence']) df_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'].dt.floor('D')  count_per_category = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs').size().reset_index(name='Nombre de personnes')  df_mean_diff4 = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].mean().reset_index() df_mean_diff4['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff4['Diff\u00e9rence'] / pd.Timedelta(days=365) df_mean_diff4['Diff\u00e9rence en ann\u00e9es'] = df_mean_diff4['Diff\u00e9rence en ann\u00e9es'].round(1) df_mean_diff4 = df_mean_diff4.drop('Diff\u00e9rence', axis=1) # Ordre des cat\u00e9gories souhait\u00e9es ordre_categories_souscripteurs2 = ['2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']  # Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9 df_mean_diff4['ordre'] = df_mean_diff4['Cat\u00e9gories souscripteurs'].apply(lambda x: ordre_categories_souscripteurs2.index(x))  # Trier le DataFrame en fonction de la colonne \"ordre\" df_mean_diff4 = df_mean_diff4.sort_values('ordre')  # Supprimer la colonne \"ordre\" df_mean_diff4 = df_mean_diff4.drop('ordre', axis=1)  # R\u00e9initialiser les index df_mean_diff4.reset_index(drop=True, inplace=True) df_mean_diff4 = df_mean_diff4.merge(count_per_category, on='Cat\u00e9gories souscripteurs', how='left')   df_mean_diff4 Out[\u00a0]: Cat\u00e9gories souscripteurs Diff\u00e9rence en ann\u00e9es Nombre de personnes 0 2 souscriptions 3.1 2370 1 3 \u00e0 5 souscriptions 2.2 1050 2 6 \u00e0 10 souscriptions 1.0 73 3 10 souscriptions et plus 0.8 21 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les gros souscripteurs reprennent plus r\u00e9guli\u00e8rement des souscriptions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les gros souscripteurs reprennent plus r\u00e9guli\u00e8rement des souscriptions\")) Les gros souscripteurs reprennent plus r\u00e9guli\u00e8rement des souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h2&gt;Notions : pour lecture des boites \u00e0 moustaches ou box plots &lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Notions : pour lecture des boites \u00e0 moustaches ou box plots \")) Notions : pour lecture des boites \u00e0 moustaches ou box plots  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;M\u00e9diane = s\u00e9pare la s\u00e9rie de valeur en 2 parties. 50 % des valeurs sont au-dessous de la m\u00e9diane et 50 % sont au dessus &lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"M\u00e9diane = s\u00e9pare la s\u00e9rie de valeur en 2 parties. 50 % des valeurs sont au-dessous de la m\u00e9diane et 50 % sont au dessus \")) M\u00e9diane = s\u00e9pare la s\u00e9rie de valeur en 2 parties. 50 % des valeurs sont au-dessous de la m\u00e9diane et 50 % sont au dessus  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Premier quartile (Q1) = 25 % des plus petites valeurs de la s\u00e9rie sont compris avant cette valeur&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Premier quartile (Q1) = 25 % des plus petites valeurs de la s\u00e9rie sont compris avant cette valeur\")) Premier quartile (Q1) = 25 % des plus petites valeurs de la s\u00e9rie sont compris avant cette valeur In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Troisi\u00e8me quartile (Q3)= 25 % des plus grandes valeurs de la s\u00e9rie sont compris apres cette valeur soit 75 % des valeurs sont plus petite que cette valeur&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Troisi\u00e8me quartile (Q3)= 25 % des plus grandes valeurs de la s\u00e9rie sont compris apres cette valeur soit 75 % des valeurs sont plus petite que cette valeur\")) Troisi\u00e8me quartile (Q3)= 25 % des plus grandes valeurs de la s\u00e9rie sont compris apres cette valeur soit 75 % des valeurs sont plus petite que cette valeur In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les whiskers ou les bornes extremes des boites \u00e0 moustaches correspondent au Q1 - 1,5*(Q3-Q1) pour la borne inf\u00e9rieure et  au Q3 + 1,5*(Q3-Q1) pour la borne sup\u00e9rieure. Si le max et le min sont inclus dans ces bornes alors se sont leurs valeurs qui seront repr\u00e9sent\u00e9es par les extr\u00e9mit\u00e9s de la boite. S'ils existent des valeurs hors de ces bornes de whiskers alors les bornes des boites \u00e0 moustache repr\u00e9senteront les valeurs de ces whiskers.&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les whiskers ou les bornes extremes des boites \u00e0 moustaches correspondent au Q1 - 1,5*(Q3-Q1) pour la borne inf\u00e9rieure et  au Q3 + 1,5*(Q3-Q1) pour la borne sup\u00e9rieure. Si le max et le min sont inclus dans ces bornes alors se sont leurs valeurs qui seront repr\u00e9sent\u00e9es par les extr\u00e9mit\u00e9s de la boite. S'ils existent des valeurs hors de ces bornes de whiskers alors les bornes des boites \u00e0 moustache repr\u00e9senteront les valeurs de ces whiskers.\")) Les whiskers ou les bornes extremes des boites \u00e0 moustaches correspondent au Q1 - 1,5*(Q3-Q1) pour la borne inf\u00e9rieure et  au Q3 + 1,5*(Q3-Q1) pour la borne sup\u00e9rieure. Si le max et le min sont inclus dans ces bornes alors se sont leurs valeurs qui seront repr\u00e9sent\u00e9es par les extr\u00e9mit\u00e9s de la boite. S'ils existent des valeurs hors de ces bornes de whiskers alors les bornes des boites \u00e0 moustache repr\u00e9senteront les valeurs de ces whiskers. In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les valeurs hors des whiskers sont des valeurs aberrantes ou dites outliers. Ce sont les valeurs qui sont consid\u00e9r\u00e9es comme extr\u00e8mes compar\u00e9 au p\u00e9rim\u00e8tre d\u00e9termni\u00e9 par la majorit\u00e9 des valeurs de la s\u00e9rie&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les valeurs hors des whiskers sont des valeurs aberrantes ou dites outliers. Ce sont les valeurs qui sont consid\u00e9r\u00e9es comme extr\u00e8mes compar\u00e9 au p\u00e9rim\u00e8tre d\u00e9termni\u00e9 par la majorit\u00e9 des valeurs de la s\u00e9rie\")) Les valeurs hors des whiskers sont des valeurs aberrantes ou dites outliers. Ce sont les valeurs qui sont consid\u00e9r\u00e9es comme extr\u00e8mes compar\u00e9 au p\u00e9rim\u00e8tre d\u00e9termni\u00e9 par la majorit\u00e9 des valeurs de la s\u00e9rie In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\ndf_diff_mean['Diff\u00e9rence'] = df_diff_mean['Diff\u00e9rence'].dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_diff_mean[\"Diff\u00e9rence\"] = df_diff_mean[\"Diff\u00e9rence\"].round(1)\n\n# Calculer la m\u00e9diane, Q1 et Q3\nmedian = np.median(df_diff_mean['Diff\u00e9rence'])\nq1 = np.percentile(df_diff_mean['Diff\u00e9rence'], 25)\nq3 = np.percentile(df_diff_mean['Diff\u00e9rence'], 75)\n\n# Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers\niqr = q3 - q1\nlower_whisker = q1 - 1.5 * iqr\nupper_whisker = q3 + 1.5 * iqr\nupper_whisker = upper_whisker.round(1)\n# Cr\u00e9er le box plot horizontalement\nplt.figure(figsize=(8, 6))\nplt.boxplot(df_diff_mean['Diff\u00e9rence'], vert=False)\n\n# Calculer le nombre d'outliers\nwhiskers = plt.boxplot(df_diff_mean['Diff\u00e9rence'], vert=False)['fliers']\nnum_outliers = len(whiskers[0].get_data()[0])\n\n# Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique\nplt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.8, f\"Borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)\n\n# Titre et \u00e9tiquette de l'axe y\nplt.title(\"Box plot de la dur\u00e9e moyenne entre reprise de souscriptions pour ex-actionnaires et actionnaires actuels\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"\")\nplt.yticks([])\n# Afficher le box plot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np df_diff_mean['Diff\u00e9rence'] = df_diff_mean['Diff\u00e9rence'].dt.total_seconds() / (365.25 * 24 * 60 * 60) df_diff_mean[\"Diff\u00e9rence\"] = df_diff_mean[\"Diff\u00e9rence\"].round(1)  # Calculer la m\u00e9diane, Q1 et Q3 median = np.median(df_diff_mean['Diff\u00e9rence']) q1 = np.percentile(df_diff_mean['Diff\u00e9rence'], 25) q3 = np.percentile(df_diff_mean['Diff\u00e9rence'], 75)  # Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers iqr = q3 - q1 lower_whisker = q1 - 1.5 * iqr upper_whisker = q3 + 1.5 * iqr upper_whisker = upper_whisker.round(1) # Cr\u00e9er le box plot horizontalement plt.figure(figsize=(8, 6)) plt.boxplot(df_diff_mean['Diff\u00e9rence'], vert=False)  # Calculer le nombre d'outliers whiskers = plt.boxplot(df_diff_mean['Diff\u00e9rence'], vert=False)['fliers'] num_outliers = len(whiskers[0].get_data()[0])  # Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique plt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes) plt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes) plt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes) plt.text(0.5, 0.8, f\"Borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes) plt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)  # Titre et \u00e9tiquette de l'axe y plt.title(\"Box plot de la dur\u00e9e moyenne entre reprise de souscriptions pour ex-actionnaires et actionnaires actuels\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"\") plt.yticks([]) # Afficher le box plot plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9s de lecture : Il y a 50 % de tous les multi-souscripteurs qui ont repris une souscription au bout de 1,6 an ou moins. Il y a 25 % d'entre eux qui en ont repris une au bout d'un 1 an ou moins(Q1), 25 % en ont repris une au bout de 3 ans ou plus (Q3) soit 75 % qui en ont repris au bout de 3 ans ou moins.&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9s de lecture : Il y a 50 % de tous les multi-souscripteurs qui ont repris une souscription au bout de 1,6 an ou moins. Il y a 25 % d'entre eux qui en ont repris une au bout d'un 1 an ou moins(Q1), 25 % en ont repris une au bout de 3 ans ou plus (Q3) soit 75 % qui en ont repris au bout de 3 ans ou moins.\")) Cl\u00e9s de lecture : Il y a 50 % de tous les multi-souscripteurs qui ont repris une souscription au bout de 1,6 an ou moins. Il y a 25 % d'entre eux qui en ont repris une au bout d'un 1 an ou moins(Q1), 25 % en ont repris une au bout de 3 ans ou plus (Q3) soit 75 % qui en ont repris au bout de 3 ans ou moins. In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il y a 472 personnes qui sont consid\u00e9r\u00e9es comme ayant une dur\u00e9e de reprise de souscriptions jug\u00e9e statistiquement ''hors normes'' car cette dur\u00e9e est 1,5 fois plus grande que celle de 75 % de souscripteurs&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il y a 472 personnes qui sont consid\u00e9r\u00e9es comme ayant une dur\u00e9e de reprise de souscriptions jug\u00e9e statistiquement ''hors normes'' car cette dur\u00e9e est 1,5 fois plus grande que celle de 75 % de souscripteurs\")) Il y a 472 personnes qui sont consid\u00e9r\u00e9es comme ayant une dur\u00e9e de reprise de souscriptions jug\u00e9e statistiquement ''hors normes'' car cette dur\u00e9e est 1,5 fois plus grande que celle de 75 % de souscripteurs In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\ndf_diff_mean2['Diff\u00e9rence'] = df_diff_mean2['Diff\u00e9rence'].dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_diff_mean2[\"Diff\u00e9rence\"] = df_diff_mean2[\"Diff\u00e9rence\"].round(1)\n\n# Calculer la m\u00e9diane, Q1 et Q3\nmedian = np.median(df_diff_mean2['Diff\u00e9rence'])\nq1 = np.percentile(df_diff_mean2['Diff\u00e9rence'], 25)\nq3 = np.percentile(df_diff_mean2['Diff\u00e9rence'], 75)\n\n# Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers\niqr = q3 - q1\nlower_whisker = q1 - 1.5 * iqr\nupper_whisker = q3 + 1.5 * iqr\nupper_whisker = upper_whisker.round(1)\n# Cr\u00e9er le box plot horizontalement\nplt.figure(figsize=(8, 6))\nplt.boxplot(df_diff_mean2['Diff\u00e9rence'], vert=False)\n\n# Calculer le nombre d'outliers\nwhiskers = plt.boxplot(df_diff_mean2['Diff\u00e9rence'], vert=False)['fliers']\nnum_outliers = len(whiskers[0].get_data()[0])\n\n# Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique\nplt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)\n\n# Titre et \u00e9tiquette de l'axe y\nplt.title(\"Box plot de la dur\u00e9e moyenne entre reprise de souscriptions pour les actionnaires actuels\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"\")\nplt.yticks([])\n\n# Afficher le box plot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np df_diff_mean2['Diff\u00e9rence'] = df_diff_mean2['Diff\u00e9rence'].dt.total_seconds() / (365.25 * 24 * 60 * 60) df_diff_mean2[\"Diff\u00e9rence\"] = df_diff_mean2[\"Diff\u00e9rence\"].round(1)  # Calculer la m\u00e9diane, Q1 et Q3 median = np.median(df_diff_mean2['Diff\u00e9rence']) q1 = np.percentile(df_diff_mean2['Diff\u00e9rence'], 25) q3 = np.percentile(df_diff_mean2['Diff\u00e9rence'], 75)  # Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers iqr = q3 - q1 lower_whisker = q1 - 1.5 * iqr upper_whisker = q3 + 1.5 * iqr upper_whisker = upper_whisker.round(1) # Cr\u00e9er le box plot horizontalement plt.figure(figsize=(8, 6)) plt.boxplot(df_diff_mean2['Diff\u00e9rence'], vert=False)  # Calculer le nombre d'outliers whiskers = plt.boxplot(df_diff_mean2['Diff\u00e9rence'], vert=False)['fliers'] num_outliers = len(whiskers[0].get_data()[0])  # Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique plt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes) plt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes) plt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes) plt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes) plt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)  # Titre et \u00e9tiquette de l'axe y plt.title(\"Box plot de la dur\u00e9e moyenne entre reprise de souscriptions pour les actionnaires actuels\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"\") plt.yticks([])  # Afficher le box plot plt.show() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es\ndf_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'] / np.timedelta64(1, 'W')\ndf_diff_mean3 = df_diff_mean3/ 52\ndf_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'].round(1)\n# Cr\u00e9er les groupes pour le boxplot\ngrouped_data = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].apply(list)\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\n# Cr\u00e9er le boxplot\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9\ncategories = grouped_data.index\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende\nfor box, color, category in zip(boxes['boxes'], custom_colors, categories):\n    box.set_facecolor(color)\n    \n# Titre et \u00e9tiquette des axes\nplt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories de multi-engagement\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"cat\u00e9gories de multi-engagement\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es df_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'] / np.timedelta64(1, 'W') df_diff_mean3 = df_diff_mean3/ 52 df_diff_mean3['Diff\u00e9rence'] = df_diff_mean3['Diff\u00e9rence'].round(1) # Cr\u00e9er les groupes pour le boxplot grouped_data = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].apply(list)  # Cr\u00e9er le boxplot en inversant l'ordre des positions # Cr\u00e9er le boxplot plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9 categories = grouped_data.index  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende for box, color, category in zip(boxes['boxes'], custom_colors, categories):     box.set_facecolor(color)      # Titre et \u00e9tiquette des axes plt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories de multi-engagement\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"cat\u00e9gories de multi-engagement\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show()   In\u00a0[\u00a0]: Copied! <pre>#Cr\u00e9er les groupes pour le boxplot\ngrouped_data = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].apply(list)\n\n# Cr\u00e9er le tableau\ndf_retrait_multicasquette = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e conservation': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),\n    \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))\n})).reset_index()\ndf_retrait_multicasquette.rename(columns={'multi-casquette ?': 'cat\u00e9gories de multi-engagement'}, inplace=True)\n# Inverser l'ordre des indices dans le DataFrame\ndf_retrait_multicasquette = df_retrait_multicasquette.iloc[::-1].reset_index(drop=True)\ndf_retrait_multicasquette\n</pre> #Cr\u00e9er les groupes pour le boxplot grouped_data = df_diff_mean3.groupby('multi-casquette ?')['Diff\u00e9rence'].apply(list)  # Cr\u00e9er le tableau df_retrait_multicasquette = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e conservation': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),     \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)))) })).reset_index() df_retrait_multicasquette.rename(columns={'multi-casquette ?': 'cat\u00e9gories de multi-engagement'}, inplace=True) # Inverser l'ordre des indices dans le DataFrame df_retrait_multicasquette = df_retrait_multicasquette.iloc[::-1].reset_index(drop=True) df_retrait_multicasquette  Out[\u00a0]: cat\u00e9gories de multi-engagement M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 Triple-engagement 1.9 0.9 3.9 8.40 54.0 1 Actionnaire-donateur 1.9 0.9 4.2 9.15 26.0 2 Actionnaire-adh\u00e9rent 2.0 0.9 3.9 8.40 80.0 3 Actionnaire uniquement 1.8 0.8 3.7 8.05 24.0 In\u00a0[\u00a0]: Copied! <pre># Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es\ndf_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'] / np.timedelta64(1, 'W')\ndf_diff_mean4 = df_diff_mean4/ 52 \ndf_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'].round(1)\n# Cr\u00e9er les groupes pour le boxplot\ngrouped_data = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].apply(list)\ncustom_order = ['60 ans et plus', '40-60 ans', '25-40 ans', '0-25 ans']\n\n# R\u00e9organiser les indices du groupe grouped_data\ngrouped_data = grouped_data.reindex(custom_order)\n\n# Cr\u00e9er le boxplot\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9\ncategories = grouped_data.index\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende\nfor box, color, category in zip(boxes['boxes'], custom_colors, categories):\n    box.set_facecolor(color)\n    \n# Titre et \u00e9tiquette des axes\nplt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gorie d'age\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"cat\u00e9gories \u00e2ge\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> # Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es df_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'] / np.timedelta64(1, 'W') df_diff_mean4 = df_diff_mean4/ 52  df_diff_mean4['Diff\u00e9rence'] = df_diff_mean4['Diff\u00e9rence'].round(1) # Cr\u00e9er les groupes pour le boxplot grouped_data = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].apply(list) custom_order = ['60 ans et plus', '40-60 ans', '25-40 ans', '0-25 ans']  # R\u00e9organiser les indices du groupe grouped_data grouped_data = grouped_data.reindex(custom_order)  # Cr\u00e9er le boxplot plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9 categories = grouped_data.index  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende for box, color, category in zip(boxes['boxes'], custom_colors, categories):     box.set_facecolor(color)      # Titre et \u00e9tiquette des axes plt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gorie d'age\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"cat\u00e9gories \u00e2ge\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre>custom_order = ['0-25 ans', '25-40 ans', '40-60 ans', '60 ans et plus']\n\n# Cr\u00e9er les groupes pour le boxplot\ngrouped_data = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].apply(list)\ngrouped_data = grouped_data.reindex(custom_order)\n\ndef calculate_outliers(x):\n    return np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))\n\ndf_retraitageage = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e conservation': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),\n    'Nombre d\\'outliers': calculate_outliers(x)\n})).reset_index()\ndf_retraitageage.rename(columns={'cat\u00e9gories \u00e2ge': 'cat\u00e9gories d\\'\u00e2ge'}, inplace=True)\n\ndf_retraitageage\n</pre> custom_order = ['0-25 ans', '25-40 ans', '40-60 ans', '60 ans et plus']  # Cr\u00e9er les groupes pour le boxplot grouped_data = df_diff_mean4.groupby('cat\u00e9gories \u00e2ge')['Diff\u00e9rence'].apply(list) grouped_data = grouped_data.reindex(custom_order)  def calculate_outliers(x):     return np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))  df_retraitageage = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e conservation': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),     'Nombre d\\'outliers': calculate_outliers(x) })).reset_index() df_retraitageage.rename(columns={'cat\u00e9gories \u00e2ge': 'cat\u00e9gories d\\'\u00e2ge'}, inplace=True)  df_retraitageage Out[\u00a0]: cat\u00e9gories d'\u00e2ge M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 0-25 ans 1.9 0.9 3.8 8.15 54.0 1 25-40 ans 1.8 0.8 3.8 8.30 29.0 2 40-60 ans 2.0 0.9 3.9 8.40 49.0 3 60 ans et plus 2.1 0.9 4.0 8.65 56.0 In\u00a0[\u00a0]: Copied! <pre># Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es\ndf_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'] / np.timedelta64(1, 'W')\ndf_diff_mean5 = df_diff_mean5/ 52\ndf_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'].round(1)\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\n\n# Cr\u00e9er les groupes pour le boxplot\ngrouped_data = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].apply(list)\ngrouped_data= grouped_data.reindex(ordre_categories_anciennet\u00e9)\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\n# Cr\u00e9er le boxplot\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9\ncategories = grouped_data.index\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende\nfor box, color, category in zip(boxes['boxes'], custom_colors, categories):\n    box.set_facecolor(color)\n    \n# Titre et \u00e9tiquette des axes\nplt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories d'anciennet\u00e9 des actionnaires\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> # Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es df_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'] / np.timedelta64(1, 'W') df_diff_mean5 = df_diff_mean5/ 52 df_diff_mean5['Diff\u00e9rence'] = df_diff_mean5['Diff\u00e9rence'].round(1) ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']  # Cr\u00e9er les groupes pour le boxplot grouped_data = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].apply(list) grouped_data= grouped_data.reindex(ordre_categories_anciennet\u00e9) # Cr\u00e9er le boxplot en inversant l'ordre des positions # Cr\u00e9er le boxplot plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9 categories = grouped_data.index # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende for box, color, category in zip(boxes['boxes'], custom_colors, categories):     box.set_facecolor(color)      # Titre et \u00e9tiquette des axes plt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories d'anciennet\u00e9 des actionnaires\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Calculer le nombre de personnes par cat\u00e9gorie d'anciennet\u00e9\ndf_retraitanciennet\u00e9actio = df_diff_mean5['anciennet\u00e9 actionnaires'].value_counts().to_frame().reset_index()\ndf_retraitanciennet\u00e9actio.columns = ['anciennet\u00e9 actionnaires', \"Nombre d'individus\"]\n\n# Calculer la m\u00e9diane, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\ndf_stats = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reindex(ordre_categories_anciennet\u00e9).reset_index()\ndf_stats.columns = ['anciennet\u00e9 actionnaires', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']\n\n# Calculer le nombre d'outliers pour chaque cat\u00e9gorie\ndf_outliers = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reindex(ordre_categories_anciennet\u00e9).reset_index()\ndf_outliers.columns = ['anciennet\u00e9 actionnaires', \"Nombre d'outliers\"]\n\n# Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers\ndf_retraitanciennet\u00e9actio = pd.merge(df_retraitanciennet\u00e9actio, df_stats, on='anciennet\u00e9 actionnaires')\ndf_retraitanciennet\u00e9actio= pd.merge(df_retraitanciennet\u00e9actio, df_outliers, on='anciennet\u00e9 actionnaires')\ndf_retraitanciennet\u00e9actio.rename(columns={'M\u00e9diane Dur\u00e9e conservation': 'M\u00e9diane'}, inplace=True)\ndf_retraitanciennet\u00e9actio = df_retraitanciennet\u00e9actio.set_index('anciennet\u00e9 actionnaires').reindex(ordre_categories_anciennet\u00e9).reset_index()\ndf_retraitanciennet\u00e9actio\n</pre> import pandas as pd import numpy as np  # Calculer le nombre de personnes par cat\u00e9gorie d'anciennet\u00e9 df_retraitanciennet\u00e9actio = df_diff_mean5['anciennet\u00e9 actionnaires'].value_counts().to_frame().reset_index() df_retraitanciennet\u00e9actio.columns = ['anciennet\u00e9 actionnaires', \"Nombre d'individus\"]  # Calculer la m\u00e9diane, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] df_stats = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reindex(ordre_categories_anciennet\u00e9).reset_index() df_stats.columns = ['anciennet\u00e9 actionnaires', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']  # Calculer le nombre d'outliers pour chaque cat\u00e9gorie df_outliers = df_diff_mean5.groupby('anciennet\u00e9 actionnaires')['Diff\u00e9rence'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reindex(ordre_categories_anciennet\u00e9).reset_index() df_outliers.columns = ['anciennet\u00e9 actionnaires', \"Nombre d'outliers\"]  # Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers df_retraitanciennet\u00e9actio = pd.merge(df_retraitanciennet\u00e9actio, df_stats, on='anciennet\u00e9 actionnaires') df_retraitanciennet\u00e9actio= pd.merge(df_retraitanciennet\u00e9actio, df_outliers, on='anciennet\u00e9 actionnaires') df_retraitanciennet\u00e9actio.rename(columns={'M\u00e9diane Dur\u00e9e conservation': 'M\u00e9diane'}, inplace=True) df_retraitanciennet\u00e9actio = df_retraitanciennet\u00e9actio.set_index('anciennet\u00e9 actionnaires').reindex(ordre_categories_anciennet\u00e9).reset_index() df_retraitanciennet\u00e9actio Out[\u00a0]: anciennet\u00e9 actionnaires Nombre d'individus M\u00e9diane Q1 Q3 Upper Whiskers Nombre d'outliers 0 Nouvel actionnaire depuis 2017 ou plus 1191 0.9 0.4 1.55 3.275 54 1 Nouvel actionnaire entre 2012 \u00e0 2017 1102 2.3 1.2 3.70 7.450 31 2 Nouvel actionnaire en 2012 ou moins 1221 3.9 2.0 6.30 12.750 20 In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es\ndf_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'] / np.timedelta64(1, 'W')\ndf_diff_mean6 = df_diff_mean6/ 52\ndf_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'].round(1)\n\n# Cr\u00e9er les groupes pour le boxplot et d\u00e9finir l'ordre souhait\u00e9\ncustom_order = [ '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\ngrouped_data = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].apply(list)\ngrouped_data = grouped_data.reindex(custom_order)\n\n# Inverser l'ordre des donn\u00e9es group\u00e9es\ngrouped_data = grouped_data[::-1]\n\n# Cr\u00e9er le boxplot\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9\ncategories = grouped_data.index\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende\nfor box, color, category in zip(boxes['boxes'], custom_colors, categories):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories de souscripteurs\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Convertir la colonne 'Diff\u00e9rence' en ann\u00e9es df_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'] / np.timedelta64(1, 'W') df_diff_mean6 = df_diff_mean6/ 52 df_diff_mean6['Diff\u00e9rence'] = df_diff_mean6['Diff\u00e9rence'].round(1)  # Cr\u00e9er les groupes pour le boxplot et d\u00e9finir l'ordre souhait\u00e9 custom_order = [ '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] grouped_data = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].apply(list) grouped_data = grouped_data.reindex(custom_order)  # Inverser l'ordre des donn\u00e9es group\u00e9es grouped_data = grouped_data[::-1]  # Cr\u00e9er le boxplot plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories dans l'ordre personnalis\u00e9 categories = grouped_data.index  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors =  ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes et cr\u00e9ation de la l\u00e9gende for box, color, category in zip(boxes['boxes'], custom_colors, categories):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Box plots de la dur\u00e9e moyenne entre reprise de souscriptions par cat\u00e9gories de souscripteurs\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show()  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Compter le nombre de personnes par cat\u00e9gorie de souscripteur\ndf_retraitMS = df_diff_mean6['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()\n\n# Renommer les colonnes\ndf_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]\n\n# Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie\ndf_stats = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()\n\n# Renommer les colonnes de statistiques\ndf_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']\n\n# Calculer le nombre d'outliers pour chaque cat\u00e9gorie\ndf_outliers = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index()\ndf_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']\n\n# Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers\ndf_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs')\ndf_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs')\ndf_retraitMS.rename(columns={'M\u00e9diane Dur\u00e9e conservation': 'M\u00e9diane'}, inplace=True)\n\n# Afficher le r\u00e9sultat\ndf_retraitMS\n</pre> import pandas as pd import numpy as np  # Compter le nombre de personnes par cat\u00e9gorie de souscripteur df_retraitMS = df_diff_mean6['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()  # Renommer les colonnes df_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]  # Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie df_stats = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()  # Renommer les colonnes de statistiques df_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']  # Calculer le nombre d'outliers pour chaque cat\u00e9gorie df_outliers = df_diff_mean6.groupby('Cat\u00e9gories souscripteurs')['Diff\u00e9rence'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index() df_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']  # Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers df_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs') df_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs') df_retraitMS.rename(columns={'M\u00e9diane Dur\u00e9e conservation': 'M\u00e9diane'}, inplace=True)  # Afficher le r\u00e9sultat df_retraitMS Out[\u00a0]: Cat\u00e9gories souscripteurs Nombre d'individus M\u00e9diane Q1 Q3 Upper Whiskers Nombre d'outliers 0 2 souscriptions 2370 2.2 0.9 4.6 10.15 89 1 3 \u00e0 5 souscriptions 1050 1.9 1.0 3.2 6.50 18 2 6 \u00e0 10 souscriptions 73 0.9 0.6 1.4 2.60 0 3 10 souscriptions et plus 21 1.0 0.4 1.2 2.40 0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Evolution des intervalles de dur\u00e9e entre les diff\u00e9rents rangs de reprises de souscriptions (en ann\u00e9e)&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, Markdown, HTML  display(HTML('Evolution des intervalles de dur\u00e9e entre les diff\u00e9rents rangs de reprises de souscriptions (en ann\u00e9e)')) Evolution des intervalles de dur\u00e9e entre les diff\u00e9rents rangs de reprises de souscriptions (en ann\u00e9e) In\u00a0[\u00a0]: Copied! <pre>df_var_tps_reprise = df_var_tps_reprise[df_var_tps_reprise[\"Nature du mouvement\"] == \"Souscription\"]\ndf_var_tps_reprise['Date du Mouvement'] = pd.to_datetime(df_var_tps_reprise['Date du Mouvement'])\ndf_var_tps_reprise = df_var_tps_reprise[['ID du contact', 'Date du Mouvement']]\ndf_var_tps_reprise['nb souscriptions'] = df_var_tps_reprise['ID du contact'].map(df_var_tps_reprise ['ID du contact'].value_counts())\ndf_var_tps_reprise = df_var_tps_reprise.sort_values(by=['ID du contact', 'Date du Mouvement'])\ndf_var_tps_reprise = df_var_tps_reprise[(df_var_tps_reprise[\"nb souscriptions\"] &lt;= 10) &amp; (df_var_tps_reprise[\"nb souscriptions\"] &gt; 1)]\ndf_var_tps_reprise = pd.pivot_table(df_var_tps_reprise, index='ID du contact', columns=df_var_tps_reprise.groupby('ID du contact').cumcount() + 1,\nvalues=[\"Date du Mouvement\"],\naggfunc='first')\ndf_var_tps_reprise.columns = [f'{col[0]}_{col[1]}' for col in df_var_tps_reprise.columns]\ndf_var_tps_reprise.reset_index(inplace=True)\n# Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions\nfor i in range(2, 11):\n    df_var_tps_reprise[f'intervalle_souscriptions_{i}_{i-1}'] = df_var_tps_reprise[f'Date du Mouvement_{i}'] - df_var_tps_reprise[f'Date du Mouvement_{i-1}']\n\n# Liste des colonnes d'intervalle \u00e0 convertir\ncolonnes_intervalle = [f'intervalle_souscriptions_{i}_{i-1}' for i in range(2, 11)]\n\n# Convertir les intervalles en ann\u00e9es\nfor colonne in colonnes_intervalle:\n    df_var_tps_reprise[colonne] = df_var_tps_reprise[colonne].apply(lambda x: np.nan if pd.isnull(x) else x.total_seconds() / 31536000)  # 31,536,000 secondes dans une ann\u00e9e\n# Supprimer les colonnes du tableau\n\ncolonnes_a_supprimer = [\n    f\"Date du Mouvement_{i}\" for i in range(1, 11)\n]\n\n# calculer les variations moyenne par colonnes \ndf_var_tps_reprise.drop(colonnes_a_supprimer, axis=1, inplace=True)\nintervalles = df_var_tps_reprise.drop(columns='ID du contact').mean(skipna=True).to_frame()\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es pour l'axe x (colonnes)\ncolonnes = intervalles.index\n\n# Donn\u00e9es pour l'axe y (moyennes)\nmoyennes_values = intervalles.values\n\n# Cr\u00e9er le graphique\nplt.figure(figsize=(10, 6))\nplt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue')\nplt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge\nplt.xlabel('Colonnes')\nplt.ylabel('Variations intervalles entre reprises de souscritpions')\nplt.title('Variations moyennes totale des intervalles  en ann\u00e9e entre ni\u00e8me souscriptions (jusqu\\'\u00e0 10)')\nplt.xticks(rotation=60)\nplt.grid(True)\n\n# Annoter chaque point avec sa valeur\nfor i, txt in enumerate(moyennes_values):\n    plt.text(colonnes[i], txt[0] + 0.2, f'{txt[0]:.2f}', ha='center', va='bottom', color='black', fontweight='normal')\n\n\n# Afficher le graphique\nplt.tight_layout()\nplt.show()\n</pre> df_var_tps_reprise = df_var_tps_reprise[df_var_tps_reprise[\"Nature du mouvement\"] == \"Souscription\"] df_var_tps_reprise['Date du Mouvement'] = pd.to_datetime(df_var_tps_reprise['Date du Mouvement']) df_var_tps_reprise = df_var_tps_reprise[['ID du contact', 'Date du Mouvement']] df_var_tps_reprise['nb souscriptions'] = df_var_tps_reprise['ID du contact'].map(df_var_tps_reprise ['ID du contact'].value_counts()) df_var_tps_reprise = df_var_tps_reprise.sort_values(by=['ID du contact', 'Date du Mouvement']) df_var_tps_reprise = df_var_tps_reprise[(df_var_tps_reprise[\"nb souscriptions\"] &lt;= 10) &amp; (df_var_tps_reprise[\"nb souscriptions\"] &gt; 1)] df_var_tps_reprise = pd.pivot_table(df_var_tps_reprise, index='ID du contact', columns=df_var_tps_reprise.groupby('ID du contact').cumcount() + 1, values=[\"Date du Mouvement\"], aggfunc='first') df_var_tps_reprise.columns = [f'{col[0]}_{col[1]}' for col in df_var_tps_reprise.columns] df_var_tps_reprise.reset_index(inplace=True) # Cr\u00e9er les colonnes de diff\u00e9rences de nombres d'actions for i in range(2, 11):     df_var_tps_reprise[f'intervalle_souscriptions_{i}_{i-1}'] = df_var_tps_reprise[f'Date du Mouvement_{i}'] - df_var_tps_reprise[f'Date du Mouvement_{i-1}']  # Liste des colonnes d'intervalle \u00e0 convertir colonnes_intervalle = [f'intervalle_souscriptions_{i}_{i-1}' for i in range(2, 11)]  # Convertir les intervalles en ann\u00e9es for colonne in colonnes_intervalle:     df_var_tps_reprise[colonne] = df_var_tps_reprise[colonne].apply(lambda x: np.nan if pd.isnull(x) else x.total_seconds() / 31536000)  # 31,536,000 secondes dans une ann\u00e9e # Supprimer les colonnes du tableau  colonnes_a_supprimer = [     f\"Date du Mouvement_{i}\" for i in range(1, 11) ]  # calculer les variations moyenne par colonnes  df_var_tps_reprise.drop(colonnes_a_supprimer, axis=1, inplace=True) intervalles = df_var_tps_reprise.drop(columns='ID du contact').mean(skipna=True).to_frame() import matplotlib.pyplot as plt  # Donn\u00e9es pour l'axe x (colonnes) colonnes = intervalles.index  # Donn\u00e9es pour l'axe y (moyennes) moyennes_values = intervalles.values  # Cr\u00e9er le graphique plt.figure(figsize=(10, 6)) plt.plot(colonnes, moyennes_values, marker='o', linestyle='-', color='darkblue') plt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Ligne du 0 en rouge plt.xlabel('Colonnes') plt.ylabel('Variations intervalles entre reprises de souscritpions') plt.title('Variations moyennes totale des intervalles  en ann\u00e9e entre ni\u00e8me souscriptions (jusqu\\'\u00e0 10)') plt.xticks(rotation=60) plt.grid(True)  # Annoter chaque point avec sa valeur for i, txt in enumerate(moyennes_values):     plt.text(colonnes[i], txt[0] + 0.2, f'{txt[0]:.2f}', ha='center', va='bottom', color='black', fontweight='normal')   # Afficher le graphique plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Part des rachats parmi les cat\u00e9gories de souscripteurs (mono ou multi-souscripteurs)&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, Markdown, HTML display(HTML(\"\"))  display(HTML('Part des rachats parmi les cat\u00e9gories de souscripteurs (mono ou multi-souscripteurs)')) Part des rachats parmi les cat\u00e9gories de souscripteurs (mono ou multi-souscripteurs) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\ndisplay(HTML('&lt;h3&gt;Effectifs crois\u00e9s des personnes ayant fait un rachat parmi les mono et multi-souscripteurs&lt;/h3&gt;'))\n</pre> from IPython.display import display, Markdown, HTML  display(HTML('Effectifs crois\u00e9s des personnes ayant fait un rachat parmi les mono et multi-souscripteurs')) Effectifs crois\u00e9s des personnes ayant fait un rachat parmi les mono et multi-souscripteurs In\u00a0[\u00a0]: Copied! <pre>twenty4_months_ago = datetime.now() - timedelta(days=730)\ndf_partrachat['RFM-Date Dernier Don'] = pd.to_datetime(df_partrachat['RFM-Date Dernier Don'], format='%d/%m/%Y')\ndf_partrachat.loc[:, \"multi-casquette ?\"] = df_partrachat.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Actionnaire uniquement\", axis=1)\n\nconditions = [\n    (df_partrachat['\u00e2ge'] &lt; 25),\n    (df_partrachat['\u00e2ge'] &lt; 40),\n    (df_partrachat['\u00e2ge'] &lt; 60)\n]\n\nchoices = ['0-25 ans', '25-40 ans', '40-60 ans']\n\ndf_partrachat['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus')\n\n\ndf_partrachat['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_partrachat['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)\n\nconditions = [\n    (df_partrachat['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),\n    (df_partrachat['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017'))\n]\n\nchoices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']\n\ndf_partrachat['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus')\ndf_partrachat['RFM-Date Premi\u00e8re Souscription'] = df_partrachat['RFM-Date Premi\u00e8re Souscription'].astype(str)\ndf_partrachatrep = df_partrachat.groupby(['ID du contact', 'Nature du mouvement']).size().reset_index(name='Nombre d\\'interactions')\ndf_partrachatrep['multi-souscripteurs ?'] = df_partrachatrep.groupby('ID du contact')['Nature du mouvement'].transform(lambda x: (x == 'Souscription').any()) &amp; (df_partrachatrep.groupby('ID du contact')['Nombre d\\'interactions'].transform(lambda x: (x &gt; 1).any()))\ndf_partrachatrep['Rachat ?'] = df_partrachatrep.groupby('ID du contact')['Nature du mouvement'].transform(lambda x: (x == 'Rachat').any()) \ndf_partrachatrep = df_partrachatrep.drop_duplicates(subset = \"ID du contact\")\ndf_partrachatrep[\"multi-souscripteurs ?\"] = df_partrachatrep[\"multi-souscripteurs ?\"].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"})\ndf_partrachatrep[\"Rachat ?\"] = df_partrachatrep[\"Rachat ?\"].replace({True: \"Ont fait un rachat\", False: \"Pas de rachat\"})\ndf_partrachatrep = pd.crosstab(index=df_partrachatrep['multi-souscripteurs ?'], columns=df_partrachatrep['Rachat ?'], margins=True, margins_name='Total')\ndf_partrachatrep \n</pre> twenty4_months_ago = datetime.now() - timedelta(days=730) df_partrachat['RFM-Date Dernier Don'] = pd.to_datetime(df_partrachat['RFM-Date Dernier Don'], format='%d/%m/%Y') df_partrachat.loc[:, \"multi-casquette ?\"] = df_partrachat.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Actionnaire uniquement\", axis=1)  conditions = [     (df_partrachat['\u00e2ge'] &lt; 25),     (df_partrachat['\u00e2ge'] &lt; 40),     (df_partrachat['\u00e2ge'] &lt; 60) ]  choices = ['0-25 ans', '25-40 ans', '40-60 ans']  df_partrachat['cat\u00e9gories \u00e2ge'] = np.select(conditions, choices, default='60 ans et plus')   df_partrachat['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_partrachat['RFM-Date Premi\u00e8re Souscription'], dayfirst=True)  conditions = [     (df_partrachat['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2012')),     (df_partrachat['RFM-Date Premi\u00e8re Souscription'] &lt;= pd.to_datetime('2017')) ]  choices = ['Nouvel actionnaire en 2012 ou moins', 'Nouvel actionnaire entre 2012 \u00e0 2017']  df_partrachat['anciennet\u00e9 actionnaires'] = np.select(conditions, choices, default='Nouvel actionnaire depuis 2017 ou plus') df_partrachat['RFM-Date Premi\u00e8re Souscription'] = df_partrachat['RFM-Date Premi\u00e8re Souscription'].astype(str) df_partrachatrep = df_partrachat.groupby(['ID du contact', 'Nature du mouvement']).size().reset_index(name='Nombre d\\'interactions') df_partrachatrep['multi-souscripteurs ?'] = df_partrachatrep.groupby('ID du contact')['Nature du mouvement'].transform(lambda x: (x == 'Souscription').any()) &amp; (df_partrachatrep.groupby('ID du contact')['Nombre d\\'interactions'].transform(lambda x: (x &gt; 1).any())) df_partrachatrep['Rachat ?'] = df_partrachatrep.groupby('ID du contact')['Nature du mouvement'].transform(lambda x: (x == 'Rachat').any())  df_partrachatrep = df_partrachatrep.drop_duplicates(subset = \"ID du contact\") df_partrachatrep[\"multi-souscripteurs ?\"] = df_partrachatrep[\"multi-souscripteurs ?\"].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"}) df_partrachatrep[\"Rachat ?\"] = df_partrachatrep[\"Rachat ?\"].replace({True: \"Ont fait un rachat\", False: \"Pas de rachat\"}) df_partrachatrep = pd.crosstab(index=df_partrachatrep['multi-souscripteurs ?'], columns=df_partrachatrep['Rachat ?'], margins=True, margins_name='Total') df_partrachatrep  Out[\u00a0]: Rachat ? Ont fait un rachat Pas de rachat Total multi-souscripteurs ? Mono-souscripteurs 1717 5831 7548 Multi-souscripteurs 780 3462 4242 Total 2497 9293 11790 In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Supposons que vous avez d\u00e9j\u00e0 cr\u00e9\u00e9 votre table crois\u00e9e df_partrachatrep\n\n# Calculez les pourcentages pour chaque cat\u00e9gorie de \"Rachat ?\"\ndf_percentage = df_partrachatrep.div(df_partrachatrep['Total'], axis=0) * 100\n\n# Cr\u00e9ez un graphique en barres empil\u00e9es \u00e0 100 %\nax = df_percentage.iloc[:-1, :-1].plot(kind='bar', stacked=True, figsize=(10, 6))\n\n# Ajoutez des \u00e9tiquettes et un titre\nplt.xlabel('Multi-souscripteurs / Mono-souscripteurs')\nplt.ylabel('Pourcentage')\nplt.title('Rachat parmi les mono et multi-souscripteurs ')\n\n# Affichez les \u00e9tiquettes de pourcentage pour chaque segment empil\u00e9\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n\n# Affichez la l\u00e9gende\nplt.legend(title='Rachat ?')\n\n# Affichez le graphique\nplt.show()\n</pre> import pandas as pd import matplotlib.pyplot as plt  # Supposons que vous avez d\u00e9j\u00e0 cr\u00e9\u00e9 votre table crois\u00e9e df_partrachatrep  # Calculez les pourcentages pour chaque cat\u00e9gorie de \"Rachat ?\" df_percentage = df_partrachatrep.div(df_partrachatrep['Total'], axis=0) * 100  # Cr\u00e9ez un graphique en barres empil\u00e9es \u00e0 100 % ax = df_percentage.iloc[:-1, :-1].plot(kind='bar', stacked=True, figsize=(10, 6))  # Ajoutez des \u00e9tiquettes et un titre plt.xlabel('Multi-souscripteurs / Mono-souscripteurs') plt.ylabel('Pourcentage') plt.title('Rachat parmi les mono et multi-souscripteurs ')  # Affichez les \u00e9tiquettes de pourcentage pour chaque segment empil\u00e9 for p in ax.patches:     width, height = p.get_width(), p.get_height()     x, y = p.get_xy()      ax.annotate(f'{height:.1f}%', (x + width/2, y + height/2), ha='center', va='center')  # Affichez la l\u00e9gende plt.legend(title='Rachat ?')  # Affichez le graphique plt.show()   In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Dur\u00e9es moyennes entre interactions sur un contrat (concerne les personnes ayant fait des rachats d\\'actions)&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, Markdown, HTML display(HTML(\"\"))  display(HTML('Dur\u00e9es moyennes entre interactions sur un contrat (concerne les personnes ayant fait des rachats d\\'actions)'))  Dur\u00e9es moyennes entre interactions sur un contrat (concerne les personnes ayant fait des rachats d'actions) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;On calcule l'\u00e9cart entre la date de d\u00e9but du contrat et la date de rachat d'actions. On fait ensuite une moyenne individuelle de ces \u00e9carts&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"On calcule l'\u00e9cart entre la date de d\u00e9but du contrat et la date de rachat d'actions. On fait ensuite une moyenne individuelle de ces \u00e9carts\")) On calcule l'\u00e9cart entre la date de d\u00e9but du contrat et la date de rachat d'actions. On fait ensuite une moyenne individuelle de ces \u00e9carts In\u00a0[\u00a0]: Copied! <pre>df.loc[:, \"multi-casquette ?\"] = df.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0\n                                            else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago\n                                            else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)\n                                            else \"Actionnaire uniquement\", axis=1)\ndf_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"] == \"Rachat\"]\ndf_dur\u00e9e_conservtest = df[(df[\"Nature du mouvement\"] == \"Rachat\") &amp; (df[\"multi-casquette ?\"] == \"Actionnaire-adh\u00e9rent\")]\n</pre> df.loc[:, \"multi-casquette ?\"] = df.apply(lambda row: \"Actionnaire-donateur\" if row[\"Actionnaire ?\"] == 1 and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)  and row[\"adh\u00e9rent N\"] == 0 and row['adh\u00e9rent N-1'] == 0                                             else \"Actionnaire-adh\u00e9rent\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and row[\"Donateur N\"] == 0 and row['RFM-Date Dernier Don'] &lt; twenty4_months_ago                                             else \"Triple-engagement\" if row[\"Actionnaire ?\"] == 1 and (row[\"adh\u00e9rent N\"] == 1 or row['adh\u00e9rent N-1'] == 1) and (row[\"Donateur N\"] == 1 or row['RFM-Date Dernier Don'] &gt;= twenty4_months_ago)                                             else \"Actionnaire uniquement\", axis=1) df_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"] == \"Rachat\"] df_dur\u00e9e_conservtest = df[(df[\"Nature du mouvement\"] == \"Rachat\") &amp; (df[\"multi-casquette ?\"] == \"Actionnaire-adh\u00e9rent\")] In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime, timedelta\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.groupby(\"ID du contact\")[\"dur\u00e9e conservation\"].mean().to_frame().reset_index()\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.merge(df2[[\"ID du contact\",'Cat\u00e9gories souscripteurs','multi-souscripteur ?','anciennet\u00e9 actionnaires','cat\u00e9gories \u00e2ge',\"multi-casquette ?\"]], on='ID du contact', how='left')\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop_duplicates(subset = \"ID du contact\")\ndf_dur\u00e9e_conserv['multi-souscripteur ?'] = df_dur\u00e9e_conserv['multi-souscripteur ?'].replace({True: \"multi-souscripteurs\", False: \"souscripteurs uniques\"})\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop(df_dur\u00e9e_conserv[df_dur\u00e9e_conserv[\"dur\u00e9e conservation\"] &lt; timedelta(days=0)].index)\n</pre> from datetime import datetime, timedelta df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.groupby(\"ID du contact\")[\"dur\u00e9e conservation\"].mean().to_frame().reset_index() df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.merge(df2[[\"ID du contact\",'Cat\u00e9gories souscripteurs','multi-souscripteur ?','anciennet\u00e9 actionnaires','cat\u00e9gories \u00e2ge',\"multi-casquette ?\"]], on='ID du contact', how='left') df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop_duplicates(subset = \"ID du contact\") df_dur\u00e9e_conserv['multi-souscripteur ?'] = df_dur\u00e9e_conserv['multi-souscripteur ?'].replace({True: \"multi-souscripteurs\", False: \"souscripteurs uniques\"}) df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop(df_dur\u00e9e_conserv[df_dur\u00e9e_conserv[\"dur\u00e9e conservation\"] &lt; timedelta(days=0)].index) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne totale entre interactions sur un contrats &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne totale entre interactions sur un contrats \")) Dur\u00e9e moyenne totale entre interactions sur un contrats  In\u00a0[\u00a0]: Copied! <pre>moyenne_jours = df_dur\u00e9e_conserv['dur\u00e9e conservation'].mean().days\nmoyenne_annees = moyenne_jours / 365.25\nprint(f\"Moyenne des intervalles entre interractions : {moyenne_annees:.2f} ann\u00e9es\")\n</pre> moyenne_jours = df_dur\u00e9e_conserv['dur\u00e9e conservation'].mean().days moyenne_annees = moyenne_jours / 365.25 print(f\"Moyenne des intervalles entre interractions : {moyenne_annees:.2f} ann\u00e9es\") <pre>Moyenne des intervalles entre interractions : 6.92 ann\u00e9es\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Depuis la date d'activation d'un de leurs contrats de souscription, les souscripteurs ont en moyenne attendu 6, 52 ann\u00e9es avant de racheter des actions sur ces m\u00eames contrats&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Depuis la date d'activation d'un de leurs contrats de souscription, les souscripteurs ont en moyenne attendu 6, 52 ann\u00e9es avant de racheter des actions sur ces m\u00eames contrats\")) Cl\u00e9 de lecture : Depuis la date d'activation d'un de leurs contrats de souscription, les souscripteurs ont en moyenne attendu 6, 52 ann\u00e9es avant de racheter des actions sur ces m\u00eames contrats In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne entre interactions sur un contrats  par cat\u00e9gories du souscripteurs&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne entre interactions sur un contrats  par cat\u00e9gories du souscripteurs\")) Dur\u00e9e moyenne entre interactions sur un contrats  par cat\u00e9gories du souscripteurs In\u00a0[\u00a0]: Copied! <pre>count_per_category = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs').size().reset_index(name='Nombre de personnes')\ndf_dur\u00e9e_conserv_mean_catsous= df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.round(1).to_frame(name=\"Moyenne des intervalles entre interraction  (ann\u00e9es)\")\ndf_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.merge(count_per_category, on='Cat\u00e9gories souscripteurs', how='left')\nordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\ndf_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.set_index('Cat\u00e9gories souscripteurs').loc[ordre_categories_souscripteurs].reset_index()\ndf_dur\u00e9e_conserv_mean_catsous\n</pre>  count_per_category = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs').size().reset_index(name='Nombre de personnes') df_dur\u00e9e_conserv_mean_catsous= df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60) df_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.round(1).to_frame(name=\"Moyenne des intervalles entre interraction  (ann\u00e9es)\") df_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.merge(count_per_category, on='Cat\u00e9gories souscripteurs', how='left') ordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] df_dur\u00e9e_conserv_mean_catsous = df_dur\u00e9e_conserv_mean_catsous.set_index('Cat\u00e9gories souscripteurs').loc[ordre_categories_souscripteurs].reset_index() df_dur\u00e9e_conserv_mean_catsous Out[\u00a0]: Cat\u00e9gories souscripteurs Moyenne des intervalles entre interraction  (ann\u00e9es) Nombre de personnes 0 1 souscription 7.1 656 1 2 souscriptions 6.5 331 2 3 \u00e0 5 souscriptions 6.5 141 3 6 \u00e0 10 souscriptions 6.9 49 4 10 souscriptions et plus 5.5 7 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne entre interactions sur un contrats  par anciennet\u00e9 de l'actionnaire&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne entre interactions sur un contrats  par anciennet\u00e9 de l'actionnaire\")) Dur\u00e9e moyenne entre interactions sur un contrats  par anciennet\u00e9 de l'actionnaire In\u00a0[\u00a0]: Copied! <pre>ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\n\n\ncount_per_category = df_dur\u00e9e_conserv.groupby('anciennet\u00e9 actionnaires').size().reset_index(name='Nombre de personnes')\ndf_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv.groupby(\"anciennet\u00e9 actionnaires\")[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv_mean_anciennet\u00e9.round(1).to_frame(name=\"Moyenne des intervalles entre interractions  (ann\u00e9es)\")\ndf_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv_mean_anciennet\u00e9.merge(count_per_category, on='anciennet\u00e9 actionnaires', how='left')\ndf_dur\u00e9e_conserv_mean_anciennet\u00e9= df_dur\u00e9e_conserv_mean_anciennet\u00e9.reindex(ordre_categories_anciennet\u00e9)\n</pre> ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']   count_per_category = df_dur\u00e9e_conserv.groupby('anciennet\u00e9 actionnaires').size().reset_index(name='Nombre de personnes') df_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv.groupby(\"anciennet\u00e9 actionnaires\")[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60) df_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv_mean_anciennet\u00e9.round(1).to_frame(name=\"Moyenne des intervalles entre interractions  (ann\u00e9es)\") df_dur\u00e9e_conserv_mean_anciennet\u00e9 = df_dur\u00e9e_conserv_mean_anciennet\u00e9.merge(count_per_category, on='anciennet\u00e9 actionnaires', how='left') df_dur\u00e9e_conserv_mean_anciennet\u00e9= df_dur\u00e9e_conserv_mean_anciennet\u00e9.reindex(ordre_categories_anciennet\u00e9)   In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne entre interactions sur un contrat par cat\u00e9gories d'\u00e2ge &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne entre interactions sur un contrat par cat\u00e9gories d'\u00e2ge \")) Dur\u00e9e moyenne entre interactions sur un contrat par cat\u00e9gories d'\u00e2ge  In\u00a0[\u00a0]: Copied! <pre>count_per_category = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge').size().reset_index(name='Nombre de personnes')\ndf_dur\u00e9e_conserv_mean_age= df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_dur\u00e9e_conserv_mean_age = df_dur\u00e9e_conserv_mean_age.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\")\ndf_dur\u00e9e_conserv_mean_age = df_dur\u00e9e_conserv_mean_age.merge(count_per_category, on='cat\u00e9gories \u00e2ge', how='left')\ndf_dur\u00e9e_conserv_mean_age\n</pre> count_per_category = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge').size().reset_index(name='Nombre de personnes') df_dur\u00e9e_conserv_mean_age= df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60) df_dur\u00e9e_conserv_mean_age = df_dur\u00e9e_conserv_mean_age.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\") df_dur\u00e9e_conserv_mean_age = df_dur\u00e9e_conserv_mean_age.merge(count_per_category, on='cat\u00e9gories \u00e2ge', how='left') df_dur\u00e9e_conserv_mean_age Out[\u00a0]: cat\u00e9gories \u00e2ge Moyenne des intervalles entre interactions  (ann\u00e9es) Nombre de personnes 0 0-25 ans 6.9 314 1 25-40 ans 6.7 199 2 40-60 ans 7.0 264 3 60 ans et plus 6.8 407 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne entre interactions sur un contrat par multi-casquettes ? &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne entre interactions sur un contrat par multi-casquettes ? \")) Dur\u00e9e moyenne entre interactions sur un contrat par multi-casquettes ?  In\u00a0[\u00a0]: Copied! <pre>count_per_category = df_dur\u00e9e_conserv.groupby('multi-casquette ?').size().reset_index(name='Nombre de personnes')\ndf_dur\u00e9e_conserv_mean_MC= df_dur\u00e9e_conserv.groupby('multi-casquette ?')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_dur\u00e9e_conserv_mean_MC = df_dur\u00e9e_conserv_mean_MC.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\")\ndf_dur\u00e9e_conserv_mean_MC = df_dur\u00e9e_conserv_mean_MC.merge(count_per_category, on='multi-casquette ?', how='left')\ndf_dur\u00e9e_conserv_mean_MC\n</pre> count_per_category = df_dur\u00e9e_conserv.groupby('multi-casquette ?').size().reset_index(name='Nombre de personnes') df_dur\u00e9e_conserv_mean_MC= df_dur\u00e9e_conserv.groupby('multi-casquette ?')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60) df_dur\u00e9e_conserv_mean_MC = df_dur\u00e9e_conserv_mean_MC.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\") df_dur\u00e9e_conserv_mean_MC = df_dur\u00e9e_conserv_mean_MC.merge(count_per_category, on='multi-casquette ?', how='left') df_dur\u00e9e_conserv_mean_MC Out[\u00a0]: multi-casquette ? Moyenne des intervalles entre interactions  (ann\u00e9es) Nombre de personnes 0 Actionnaire uniquement 7.1 264 1 Actionnaire-adh\u00e9rent 6.7 349 2 Actionnaire-donateur 6.7 156 3 Triple-engagement 6.9 415 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Dur\u00e9e moyenne entre interactions sur un contrat par multi-souscripteurs ? &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Dur\u00e9e moyenne entre interactions sur un contrat par multi-souscripteurs ? \")) Dur\u00e9e moyenne entre interactions sur un contrat par multi-souscripteurs ?  In\u00a0[\u00a0]: Copied! <pre>count_per_category = df_dur\u00e9e_conserv.groupby('multi-souscripteur ?').size().reset_index(name='Nombre de personnes')\ndf_dur\u00e9e_conserv_mean_MS= df_dur\u00e9e_conserv.groupby('multi-souscripteur ?')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60)\ndf_dur\u00e9e_conserv_mean_MS = df_dur\u00e9e_conserv_mean_MS.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\")\ndf_dur\u00e9e_conserv_mean_MS = df_dur\u00e9e_conserv_mean_MS.merge(count_per_category, on='multi-souscripteur ?', how='left')\ndf_dur\u00e9e_conserv_mean_MS\n</pre> count_per_category = df_dur\u00e9e_conserv.groupby('multi-souscripteur ?').size().reset_index(name='Nombre de personnes') df_dur\u00e9e_conserv_mean_MS= df_dur\u00e9e_conserv.groupby('multi-souscripteur ?')[\"dur\u00e9e conservation\"].mean().dt.total_seconds() / (365.25 * 24 * 60 * 60) df_dur\u00e9e_conserv_mean_MS = df_dur\u00e9e_conserv_mean_MS.round(1).to_frame(name=\"Moyenne des intervalles entre interactions  (ann\u00e9es)\") df_dur\u00e9e_conserv_mean_MS = df_dur\u00e9e_conserv_mean_MS.merge(count_per_category, on='multi-souscripteur ?', how='left') df_dur\u00e9e_conserv_mean_MS Out[\u00a0]: multi-souscripteur ? Moyenne des intervalles entre interactions  (ann\u00e9es) Nombre de personnes 0 multi-souscripteurs 6.6 528 1 souscripteurs uniques 7.1 656 In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\ndf_dur\u00e9e_conserv['dur\u00e9e conservation'] = df_dur\u00e9e_conserv['dur\u00e9e conservation'] / np.timedelta64(1, 'W')\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv/ 52\ndf_dur\u00e9e_conserv['dur\u00e9e conservation'] = df_dur\u00e9e_conserv['dur\u00e9e conservation'].round(1)\n# Calculer la m\u00e9diane, Q1 et Q3\nmedian = np.median(df_dur\u00e9e_conserv['dur\u00e9e conservation'])\nq1 = np.percentile(df_dur\u00e9e_conserv['dur\u00e9e conservation'], 25)\nq3 = np.percentile(df_dur\u00e9e_conserv['dur\u00e9e conservation'], 75)\n\n# Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers\niqr = q3 - q1\nlower_whisker = q1 - 1.5 * iqr\nupper_whisker = q3 + 1.5 * iqr\nupper_whisker = upper_whisker.round(1)\n# Cr\u00e9er le box plot horizontalement\nplt.figure(figsize=(8, 6))\nplt.boxplot(df_dur\u00e9e_conserv['dur\u00e9e conservation'], vert=False)\n\n# Calculer le nombre d'outliers\nwhiskers = plt.boxplot(df_dur\u00e9e_conserv['dur\u00e9e conservation'], vert=False)['fliers']\nnum_outliers = len(whiskers[0].get_data()[0])\n\n# Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique\nplt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)\n\n# Titre et \u00e9tiquette de l'axe y\nplt.title(\"Dur\u00e9es moyennes totales entre interactions sur un contrats\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"\")\nplt.yticks([])\n# Afficher le box plot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np df_dur\u00e9e_conserv['dur\u00e9e conservation'] = df_dur\u00e9e_conserv['dur\u00e9e conservation'] / np.timedelta64(1, 'W') df_dur\u00e9e_conserv = df_dur\u00e9e_conserv/ 52 df_dur\u00e9e_conserv['dur\u00e9e conservation'] = df_dur\u00e9e_conserv['dur\u00e9e conservation'].round(1) # Calculer la m\u00e9diane, Q1 et Q3 median = np.median(df_dur\u00e9e_conserv['dur\u00e9e conservation']) q1 = np.percentile(df_dur\u00e9e_conserv['dur\u00e9e conservation'], 25) q3 = np.percentile(df_dur\u00e9e_conserv['dur\u00e9e conservation'], 75)  # Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers iqr = q3 - q1 lower_whisker = q1 - 1.5 * iqr upper_whisker = q3 + 1.5 * iqr upper_whisker = upper_whisker.round(1) # Cr\u00e9er le box plot horizontalement plt.figure(figsize=(8, 6)) plt.boxplot(df_dur\u00e9e_conserv['dur\u00e9e conservation'], vert=False)  # Calculer le nombre d'outliers whiskers = plt.boxplot(df_dur\u00e9e_conserv['dur\u00e9e conservation'], vert=False)['fliers'] num_outliers = len(whiskers[0].get_data()[0])  # Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique plt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes) plt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes) plt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes) plt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes) plt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)  # Titre et \u00e9tiquette de l'axe y plt.title(\"Dur\u00e9es moyennes totales entre interactions sur un contrats\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"\") plt.yticks([]) # Afficher le box plot plt.show() In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].apply(list)\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\ncustom_order = ['10 souscriptions et plus', '6 \u00e0 10 souscriptions', '3 \u00e0 5 souscriptions', '2 souscriptions', '1 souscription']\ngrouped_data = grouped_data.reindex(custom_order)\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = grouped_data.index\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories des souscripteurs\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories des souscripteurs\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre>  # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].apply(list)  # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True) custom_order = ['10 souscriptions et plus', '6 \u00e0 10 souscriptions', '3 \u00e0 5 souscriptions', '2 souscriptions', '1 souscription'] grouped_data = grouped_data.reindex(custom_order) # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = grouped_data.index # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']    # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories des souscripteurs\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories des souscripteurs\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Compter le nombre de personnes par cat\u00e9gorie de souscripteur\ndf_retraitMS = df_dur\u00e9e_conserv['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()\n\n# Renommer les colonnes\ndf_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]\n\n# Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie\ndf_stats = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()\n\n# Renommer les colonnes de statistiques\ndf_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']\n\n# Calculer le nombre d'outliers pour chaque cat\u00e9gorie\ndf_outliers = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index()\ndf_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']\n\n# Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers\ndf_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs')\ndf_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs')\n\n# Afficher le r\u00e9sultat\ndf_retraitMS\n</pre> import pandas as pd import numpy as np  # Compter le nombre de personnes par cat\u00e9gorie de souscripteur df_retraitMS = df_dur\u00e9e_conserv['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()  # Renommer les colonnes df_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]  # Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie df_stats = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()  # Renommer les colonnes de statistiques df_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e conservation', 'Q1', 'Q3', 'Upper Whiskers']  # Calculer le nombre d'outliers pour chaque cat\u00e9gorie df_outliers = df_dur\u00e9e_conserv.groupby('Cat\u00e9gories souscripteurs')['dur\u00e9e conservation'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index() df_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']  # Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers df_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs') df_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs')  # Afficher le r\u00e9sultat df_retraitMS  Out[\u00a0]: Cat\u00e9gories souscripteurs Nombre d'individus M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 1 souscription 656 6.8 3.30 10.80 22.05 0 1 2 souscriptions 331 6.3 3.15 9.65 19.40 0 2 3 \u00e0 5 souscriptions 141 6.2 3.00 9.20 18.50 0 3 6 \u00e0 10 souscriptions 49 6.5 3.40 10.50 21.15 0 4 10 souscriptions et plus 7 5.1 3.10 6.80 12.35 1 In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')['dur\u00e9e conservation'].apply(list)\ncustom_order = ['60 ans et plus', '40-60 ans', '25-40 ans', '0-25 ans']\ngrouped_data = grouped_data.reindex(custom_order)\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = grouped_data.index\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories d'\u00e2ges\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories d'\u00e2ges\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')['dur\u00e9e conservation'].apply(list) custom_order = ['60 ans et plus', '40-60 ans', '25-40 ans', '0-25 ans'] grouped_data = grouped_data.reindex(custom_order) # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)   # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = grouped_data.index  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories d'\u00e2ges\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories d'\u00e2ges\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\n\ncustom_order = ['0-25 ans', '25-40 ans', '40-60 ans', '60 ans et plus']\n\ngrouped_data = grouped_data.reindex(custom_order)\ngrouped_data = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')['dur\u00e9e conservation'].apply(list)\ngrouped_data = grouped_data.reindex(custom_order)\n# Cr\u00e9er le tableau\ndf_interactions_age = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e conservation': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),\n    \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))\n})).reset_index()\ndf_interactions_age.rename(columns={'cat\u00e9gories \u00e2ge': 'Cat\u00e9gories d\\'\u00e2ges'}, inplace=True)\n\ndf_interactions_age\n</pre> # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es  custom_order = ['0-25 ans', '25-40 ans', '40-60 ans', '60 ans et plus']  grouped_data = grouped_data.reindex(custom_order) grouped_data = df_dur\u00e9e_conserv.groupby('cat\u00e9gories \u00e2ge')['dur\u00e9e conservation'].apply(list) grouped_data = grouped_data.reindex(custom_order) # Cr\u00e9er le tableau df_interactions_age = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e conservation': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),     \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)))) })).reset_index() df_interactions_age.rename(columns={'cat\u00e9gories \u00e2ge': 'Cat\u00e9gories d\\'\u00e2ges'}, inplace=True)  df_interactions_age Out[\u00a0]: Cat\u00e9gories d'\u00e2ges M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 0-25 ans 6.3 3.40 10.40 20.900 0.0 1 25-40 ans 6.7 3.15 9.95 20.150 0.0 2 40-60 ans 6.8 3.40 10.40 20.900 0.0 3 60 ans et plus 6.5 3.00 9.95 20.375 0.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;La tranche des 25-40 ans rach\u00e8te plus rapidement leurs actions&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"La tranche des 25-40 ans rach\u00e8te plus rapidement leurs actions\")) La tranche des 25-40 ans rach\u00e8te plus rapidement leurs actions In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_dur\u00e9e_conserv.groupby('anciennet\u00e9 actionnaires')['dur\u00e9e conservation'].apply(list)\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\ngrouped_data = grouped_data.reindex(ordre_categories_anciennet\u00e9)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = grouped_data.index\n\n# Calculer les statistiques pour chaque groupe en inversant l'ordre\nmedians = [np.median(data) for data in grouped_data]\nq1s = [np.percentile(data, 25) for data in grouped_data]\nq3s = [np.percentile(data, 75) for data in grouped_data]\nupper_whiskers = [q3 + 1.5 * (q3 - q1) for q3, q1 in zip(q3s, q1s)]\nupper_whiskers = np.round(upper_whiskers, 1)  # Arrondir les valeurs \u00e0 2 d\u00e9cimales\nnum_outliers = [len(box.get_ydata()) for box in boxes['fliers']]\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories d'anciennet\u00e9 des actionnaires\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n\n# Afficher le boxplot\nplt.show()\n</pre> # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_dur\u00e9e_conserv.groupby('anciennet\u00e9 actionnaires')['dur\u00e9e conservation'].apply(list)  # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True) ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] grouped_data = grouped_data.reindex(ordre_categories_anciennet\u00e9)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = grouped_data.index  # Calculer les statistiques pour chaque groupe en inversant l'ordre medians = [np.median(data) for data in grouped_data] q1s = [np.percentile(data, 25) for data in grouped_data] q3s = [np.percentile(data, 75) for data in grouped_data] upper_whiskers = [q3 + 1.5 * (q3 - q1) for q3, q1 in zip(q3s, q1s)] upper_whiskers = np.round(upper_whiskers, 1)  # Arrondir les valeurs \u00e0 2 d\u00e9cimales num_outliers = [len(box.get_ydata()) for box in boxes['fliers']]  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories d'anciennet\u00e9 des actionnaires\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)   # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre>custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\n\n# R\u00e9organiser les indices du groupe grouped_data\ngrouped_data = grouped_data.reindex(custom_order)\n\n# Cr\u00e9er le tableau\ndf_interaction_anciennet\u00e9 = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e conservation': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5 * (np.percentile(x, 75) - np.percentile(x, 25)),\n    \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5 * (np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5 * (np.percentile(x, 75) - np.percentile(x, 25))))\n})).reset_index()\ndf_interaction_anciennet\u00e9.rename(columns={'anciennet\u00e9 actionnaires': 'Cat\u00e9gories d\\'anciennet\u00e9'}, inplace=True)\n\ndf_interaction_anciennet\u00e9\n</pre> custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']  # R\u00e9organiser les indices du groupe grouped_data grouped_data = grouped_data.reindex(custom_order)  # Cr\u00e9er le tableau df_interaction_anciennet\u00e9 = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e conservation': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5 * (np.percentile(x, 75) - np.percentile(x, 25)),     \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5 * (np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5 * (np.percentile(x, 75) - np.percentile(x, 25)))) })).reset_index() df_interaction_anciennet\u00e9.rename(columns={'anciennet\u00e9 actionnaires': 'Cat\u00e9gories d\\'anciennet\u00e9'}, inplace=True)  df_interaction_anciennet\u00e9 Out[\u00a0]: Cat\u00e9gories d'anciennet\u00e9 M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 Nouvel actionnaire depuis 2017 ou plus 7.6 4.00 11.20 22.0 0.0 1 Nouvel actionnaire entre 2012 \u00e0 2017 6.6 3.05 9.75 19.8 0.0 2 Nouvel actionnaire en 2012 ou moins 5.3 2.50 8.70 18.0 0.0 In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_dur\u00e9e_conserv.groupby('multi-casquette ?')['dur\u00e9e conservation'].apply(list)\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = grouped_data.index\n\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories de multi-engagment\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories de multi-engagement\")\nplt.yticks([])\n\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n\n# Afficher le boxplot\nplt.show()\n</pre> # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_dur\u00e9e_conserv.groupby('multi-casquette ?')['dur\u00e9e conservation'].apply(list)  # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = grouped_data.index  # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)   # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9es moyennes entre interactions sur un contrat par cat\u00e9gories de multi-engagment\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories de multi-engagement\") plt.yticks([])   # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)   # Afficher le boxplot plt.show() In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er le tableau de statistiques\ndf_interaction_multicasquette = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e conservation': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),\n    \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))\n})).reset_index()\ndf_interaction_multicasquette.rename(columns={'multi-casquette ?': 'Cat\u00e9gories de multi-engagement'}, inplace=True)\ndf_interaction_multicasquette = df_interaction_multicasquette.iloc[::-1].reset_index(drop=True)\ndf_interaction_multicasquette\n</pre> # Cr\u00e9er le tableau de statistiques df_interaction_multicasquette = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e conservation': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),     \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)))) })).reset_index() df_interaction_multicasquette.rename(columns={'multi-casquette ?': 'Cat\u00e9gories de multi-engagement'}, inplace=True) df_interaction_multicasquette = df_interaction_multicasquette.iloc[::-1].reset_index(drop=True) df_interaction_multicasquette Out[\u00a0]: Cat\u00e9gories de multi-engagement M\u00e9diane Dur\u00e9e conservation Q1 Q3 Upper Whiskers Nombre d'outliers 0 Triple-engagement 6.7 3.35 10.100 20.2250 0.0 1 Actionnaire-donateur 6.4 3.40 9.800 19.4000 0.0 2 Actionnaire-adh\u00e9rent 6.3 2.70 10.200 21.4500 0.0 3 Actionnaire uniquement 6.6 3.70 10.825 21.5125 0.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Retrait partiel ou total des actions sur un contrat ?&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML display(HTML(\"\"))   # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Retrait partiel ou total des actions sur un contrat ?'))  Retrait partiel ou total des actions sur un contrat ? In\u00a0[\u00a0]: Copied! <pre>df.loc[:, 'multi-souscripteur ?'] = df.duplicated(subset='ID du contact', keep=False)\ndf_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"]== \"Rachat\"]\n</pre> df.loc[:, 'multi-souscripteur ?'] = df.duplicated(subset='ID du contact', keep=False) df_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"]== \"Rachat\"] In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Calculer les valeurs et les \u00e9tiquettes pour le pie chart\ncounts = df['retrait complet ou partiel'].value_counts()\npercentages = counts / counts.sum() * 100\n\n# Cr\u00e9er le pie chart\nplt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\nplt.title(\"Retrait complet ou partiel d'actions pour un contrat\")\n\n\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Calculer les valeurs et les \u00e9tiquettes pour le pie chart counts = df['retrait complet ou partiel'].value_counts() percentages = counts / counts.sum() * 100  # Cr\u00e9er le pie chart plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90) plt.title(\"Retrait complet ou partiel d'actions pour un contrat\")    # Afficher le graphique plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Retrait total ou partiels des actions sur les contrats par multi-souscripteur ?&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Retrait total ou partiels des actions sur les contrats par multi-souscripteur ?\")) Retrait total ou partiels des actions sur les contrats par multi-souscripteur ? In\u00a0[\u00a0]: Copied! <pre>df_retrait_MS = pd.crosstab(index=df_dur\u00e9e_conserv['retrait complet ou partiel'], columns=df_dur\u00e9e_conserv[\"multi-souscripteur ?\"], margins=True, margins_name='Total')\ndf_col_percent = df_retrait_MS.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne\ndf_col_percent = df_col_percent.drop(columns=True)\ndf_col_percent\n</pre> df_retrait_MS = pd.crosstab(index=df_dur\u00e9e_conserv['retrait complet ou partiel'], columns=df_dur\u00e9e_conserv[\"multi-souscripteur ?\"], margins=True, margins_name='Total') df_col_percent = df_retrait_MS.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  # Ajouter la somme des pourcentages dans la derni\u00e8re ligne df_col_percent = df_col_percent.drop(columns=True) df_col_percent Out[\u00a0]: multi-souscripteur ? False Total retrait complet ou partiel retrait complet 82.2 83.5 retrait partiel 17.8 16.5 Total 100.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Lorsqu'ils ont interagi avec un de leurs contrats pour y racheter des actions, les multi-souscripteurs dans 92,7% des cas ont rachet\u00e9 toutes les actions du contrat (retrait complet) et des les 7,3% dans cas restants n'ont pas rachet\u00e9 toutes les actions du contrats (retrait partiel)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Lorsqu'ils ont interagi avec un de leurs contrats pour y racheter des actions, les multi-souscripteurs dans 92,7% des cas ont rachet\u00e9 toutes les actions du contrat (retrait complet) et des les 7,3% dans cas restants n'ont pas rachet\u00e9 toutes les actions du contrats (retrait partiel)\")) Cl\u00e9 de lecture : Lorsqu'ils ont interagi avec un de leurs contrats pour y racheter des actions, les multi-souscripteurs dans 92,7% des cas ont rachet\u00e9 toutes les actions du contrat (retrait complet) et des les 7,3% dans cas restants n'ont pas rachet\u00e9 toutes les actions du contrats (retrait partiel) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\ndisplay(HTML(\"&lt;h2&gt;Part des personnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembours\u00e9 leurs actions rachet\u00e9es&lt;/h2&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  display(HTML(\"\")) display(HTML(\"Part des personnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembours\u00e9 leurs actions rachet\u00e9es\"))  Part des personnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembours\u00e9 leurs actions rachet\u00e9es In\u00a0[\u00a0]: Copied! <pre>dfretraitrepise = dfretraitrepise[[\"ID du contact\", \"Nature du mouvement\",\"Date du Mouvement\"]]\ndfretraitrepise = dfretraitrepise[(dfretraitrepise[\"Nature du mouvement\"] == \"Souscription\") | (dfretraitrepise[\"Nature du mouvement\"] == \"Rachat\")]\ndfretraitrepise[\"Date du Mouvement\"] = pd.to_datetime(dfretraitrepise[\"Date du Mouvement\"], format='%d/%m/%Y')\ndfretraitrepise[\"Date du Mouvement\"] = dfretraitrepise[\"Date du Mouvement\"].dt.year.astype(int)\n# Cr\u00e9ez une liste des ann\u00e9es uniques dans la colonne \"Date du Mouvement\"\nannees_uniques = dfretraitrepise[\"Date du Mouvement\"].unique()\n\n# Cr\u00e9ez une liste des natures de mouvement uniques dans la colonne \"Nature du mouvement\"\nnatures_uniques = dfretraitrepise[\"Nature du mouvement\"].unique()\n\n# Cr\u00e9ez des colonnes de variables binaires pour chaque ann\u00e9e et nature de mouvement\nfor annee in annees_uniques:\n    for nature in natures_uniques:\n        # Cr\u00e9ez une nouvelle colonne avec un nom bas\u00e9 sur l'ann\u00e9e et la nature du mouvement\n        nom_colonne = f\"{nature} {annee}\"\n        \n        # Utilisez np.where pour d\u00e9finir la valeur en fonction de la condition\n        dfretraitrepise[nom_colonne] = np.where((dfretraitrepise[\"Date du Mouvement\"] == annee) &amp; (dfretraitrepise[\"Nature du mouvement\"] == nature), True, False)\n\n# R\u00e9organisez les colonnes pour placer \"ID du contact\", \"Nature du mouvement\" et \"Date du Mouvement\" au d\u00e9but\ncolonnes = [\"ID du contact\", \"Nature du mouvement\", \"Date du Mouvement\"]\ncolonnes += sorted([colonne for colonne in dfretraitrepise.columns if colonne not in colonnes])\n\n# S\u00e9lectionnez et r\u00e9organisez les colonnes dans le DataFrame\ndfretraitrepise = dfretraitrepise[colonnes]\ndfretraitrepise = dfretraitrepise.groupby('ID du contact').max().reset_index()\ndfretraitrepise = dfretraitrepise.drop(columns= [\"Nature du mouvement\", \"Date du Mouvement\"])\ndfretraitrepiseretrait = dfretraitrepise.copy()\n# Initialiser une liste vide pour stocker le nombre de reprises apr\u00e8s rachat\nnombre_de_reprises = []\n\n# Parcourir les lignes du DataFrame\nfor i in range(len(dfretraitrepise)):\n    # Initialisez un compteur pour cette ligne\n    compteur = 0\n    \n    # Parcourir les ann\u00e9es de 2006 \u00e0 2022\n    for annee in range(2006, 2023):\n        # V\u00e9rifier si \"Rachat N\" = True et \"Souscription N+1\" = True\n        rachat_colonne = f\"Rachat {annee}\"\n        souscription_colonne = f\"Souscription {annee + 1}\"\n        \n        if dfretraitrepise[rachat_colonne][i] == True and dfretraitrepise[souscription_colonne][i] == True:\n            compteur += 1\n    \n    # Ajouter le compteur \u00e0 la liste des nombres de reprises apr\u00e8s rachat\n    nombre_de_reprises.append(compteur)\n\n# Ajouter la liste des nombres de reprises apr\u00e8s rachat comme colonne au DataFrame\ndfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] = nombre_de_reprises\n\n\n# Cr\u00e9er la colonne \"a_resouscrit_juste_apres_avoir_rachet\u00e9\" en utilisant la condition\ndfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"] = dfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0\ndfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"]  = dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"].replace({True: \"A re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\", False: \"N'a pas re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\"})\nimport matplotlib.pyplot as plt\n\n# Compter les occurrences de chaque valeur unique\nvalue_counts = dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, (label, count) in enumerate(zip(texts, value_counts)):\n    label.set_text(f\"{label.get_text()} ({count})\")\n\nplt.title(\"\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> dfretraitrepise = dfretraitrepise[[\"ID du contact\", \"Nature du mouvement\",\"Date du Mouvement\"]] dfretraitrepise = dfretraitrepise[(dfretraitrepise[\"Nature du mouvement\"] == \"Souscription\") | (dfretraitrepise[\"Nature du mouvement\"] == \"Rachat\")] dfretraitrepise[\"Date du Mouvement\"] = pd.to_datetime(dfretraitrepise[\"Date du Mouvement\"], format='%d/%m/%Y') dfretraitrepise[\"Date du Mouvement\"] = dfretraitrepise[\"Date du Mouvement\"].dt.year.astype(int) # Cr\u00e9ez une liste des ann\u00e9es uniques dans la colonne \"Date du Mouvement\" annees_uniques = dfretraitrepise[\"Date du Mouvement\"].unique()  # Cr\u00e9ez une liste des natures de mouvement uniques dans la colonne \"Nature du mouvement\" natures_uniques = dfretraitrepise[\"Nature du mouvement\"].unique()  # Cr\u00e9ez des colonnes de variables binaires pour chaque ann\u00e9e et nature de mouvement for annee in annees_uniques:     for nature in natures_uniques:         # Cr\u00e9ez une nouvelle colonne avec un nom bas\u00e9 sur l'ann\u00e9e et la nature du mouvement         nom_colonne = f\"{nature} {annee}\"                  # Utilisez np.where pour d\u00e9finir la valeur en fonction de la condition         dfretraitrepise[nom_colonne] = np.where((dfretraitrepise[\"Date du Mouvement\"] == annee) &amp; (dfretraitrepise[\"Nature du mouvement\"] == nature), True, False)  # R\u00e9organisez les colonnes pour placer \"ID du contact\", \"Nature du mouvement\" et \"Date du Mouvement\" au d\u00e9but colonnes = [\"ID du contact\", \"Nature du mouvement\", \"Date du Mouvement\"] colonnes += sorted([colonne for colonne in dfretraitrepise.columns if colonne not in colonnes])  # S\u00e9lectionnez et r\u00e9organisez les colonnes dans le DataFrame dfretraitrepise = dfretraitrepise[colonnes] dfretraitrepise = dfretraitrepise.groupby('ID du contact').max().reset_index() dfretraitrepise = dfretraitrepise.drop(columns= [\"Nature du mouvement\", \"Date du Mouvement\"]) dfretraitrepiseretrait = dfretraitrepise.copy() # Initialiser une liste vide pour stocker le nombre de reprises apr\u00e8s rachat nombre_de_reprises = []  # Parcourir les lignes du DataFrame for i in range(len(dfretraitrepise)):     # Initialisez un compteur pour cette ligne     compteur = 0          # Parcourir les ann\u00e9es de 2006 \u00e0 2022     for annee in range(2006, 2023):         # V\u00e9rifier si \"Rachat N\" = True et \"Souscription N+1\" = True         rachat_colonne = f\"Rachat {annee}\"         souscription_colonne = f\"Souscription {annee + 1}\"                  if dfretraitrepise[rachat_colonne][i] == True and dfretraitrepise[souscription_colonne][i] == True:             compteur += 1          # Ajouter le compteur \u00e0 la liste des nombres de reprises apr\u00e8s rachat     nombre_de_reprises.append(compteur)  # Ajouter la liste des nombres de reprises apr\u00e8s rachat comme colonne au DataFrame dfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] = nombre_de_reprises   # Cr\u00e9er la colonne \"a_resouscrit_juste_apres_avoir_rachet\u00e9\" en utilisant la condition dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"] = dfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0 dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"]  = dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"].replace({True: \"A re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\", False: \"N'a pas re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\"}) import matplotlib.pyplot as plt  # Compter les occurrences de chaque valeur unique value_counts = dfretraitrepise[\"A resouscrit juste apres avoir rachet\u00e9\"].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, (label, count) in enumerate(zip(texts, value_counts)):     label.set_text(f\"{label.get_text()} ({count})\")  plt.title(\"\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Ici, il s'agit de v\u00e9rifier, lorsque un actionnaire fait un rachat qui est effectif au 31/12/N s'il a re-souscrit l'ann\u00e9e N+1 car se sera fait rembourser ses action le 01/01/N+1&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Ici, il s'agit de v\u00e9rifier, lorsque un actionnaire fait un rachat qui est effectif au 31/12/N s'il a re-souscrit l'ann\u00e9e N+1 car se sera fait rembourser ses action le 01/01/N+1\")) Cl\u00e9 de lecture : Ici, il s'agit de v\u00e9rifier, lorsque un actionnaire fait un rachat qui est effectif au 31/12/N s'il a re-souscrit l'ann\u00e9e N+1 car se sera fait rembourser ses action le 01/01/N+1 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Parmi les personnes ayant effectu\u00e9 un rachat ce sont uniquement 4 % qui ont repris une souscription l'ann\u00e9e qui suivait le rachat&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Parmi les personnes ayant effectu\u00e9 un rachat ce sont uniquement 4 % qui ont repris une souscription l'ann\u00e9e qui suivait le rachat\"))   Parmi les personnes ayant effectu\u00e9 un rachat ce sont uniquement 4 % qui ont repris une souscription l'ann\u00e9e qui suivait le rachat In\u00a0[\u00a0]: Copied! <pre># S\u00e9lectionner les lignes o\u00f9 il y a au moins un \"True\" dans les colonnes \"Rachat {ann\u00e9e}\"\ncolonnes_rachat = [f\"Rachat {annee}\" for annee in range(2006, 2024)]\ndfretraitrepiseretrait_selection = dfretraitrepiseretrait[dfretraitrepiseretrait[colonnes_rachat].any(axis=1)]\n## Initialiser une liste vide pour stocker le nombre de reprises apr\u00e8s rachat\nnombre_de_reprises = []\n\n# Parcourir les lignes du DataFrame avec iterrows()\nfor index, row in dfretraitrepiseretrait_selection.iterrows():\n    # Initialisez un compteur pour cette ligne\n    compteur = 0\n    \n    # Parcourir les ann\u00e9es de 2006 \u00e0 2022\n    for annee in range(2006, 2023):\n        # V\u00e9rifier si \"Rachat N\" = True et \"Souscription N+1\" = True\n        rachat_colonne = f\"Rachat {annee}\"\n        souscription_colonne = f\"Souscription {annee + 1}\"\n        \n        if row[rachat_colonne] == True and row[souscription_colonne] == True:\n            compteur += 1\n    \n    # Ajouter le compteur \u00e0 la liste des nombres de reprises apr\u00e8s rachat\n    nombre_de_reprises.append(compteur)\n\n# Ajouter la liste des nombres de reprises apr\u00e8s rachat comme colonne au DataFrame\ndfretraitrepiseretrait_selection[\"nombre de reprises apr\u00e8s rachat\"] = nombre_de_reprises\n\n\n# Cr\u00e9er la colonne \"a_resouscrit_juste_apres_avoir_rachet\u00e9\" en utilisant la condition\ndfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"] = dfretraitrepiseretrait_selection[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0\ndfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"]  = dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"].replace({True: \"A re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\", False: \"N'a pas re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\"})\nimport matplotlib.pyplot as plt\n\n# Compter les occurrences de chaque valeur unique\nvalue_counts = dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, (label, count) in enumerate(zip(texts, value_counts)):\n    label.set_text(f\"{label.get_text()} ({count})\")\n\nplt.title(\"\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> # S\u00e9lectionner les lignes o\u00f9 il y a au moins un \"True\" dans les colonnes \"Rachat {ann\u00e9e}\" colonnes_rachat = [f\"Rachat {annee}\" for annee in range(2006, 2024)] dfretraitrepiseretrait_selection = dfretraitrepiseretrait[dfretraitrepiseretrait[colonnes_rachat].any(axis=1)] ## Initialiser une liste vide pour stocker le nombre de reprises apr\u00e8s rachat nombre_de_reprises = []  # Parcourir les lignes du DataFrame avec iterrows() for index, row in dfretraitrepiseretrait_selection.iterrows():     # Initialisez un compteur pour cette ligne     compteur = 0          # Parcourir les ann\u00e9es de 2006 \u00e0 2022     for annee in range(2006, 2023):         # V\u00e9rifier si \"Rachat N\" = True et \"Souscription N+1\" = True         rachat_colonne = f\"Rachat {annee}\"         souscription_colonne = f\"Souscription {annee + 1}\"                  if row[rachat_colonne] == True and row[souscription_colonne] == True:             compteur += 1          # Ajouter le compteur \u00e0 la liste des nombres de reprises apr\u00e8s rachat     nombre_de_reprises.append(compteur)  # Ajouter la liste des nombres de reprises apr\u00e8s rachat comme colonne au DataFrame dfretraitrepiseretrait_selection[\"nombre de reprises apr\u00e8s rachat\"] = nombre_de_reprises   # Cr\u00e9er la colonne \"a_resouscrit_juste_apres_avoir_rachet\u00e9\" en utilisant la condition dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"] = dfretraitrepiseretrait_selection[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0 dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"]  = dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"].replace({True: \"A re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\", False: \"N'a pas re-souscrit la m\u00eame ann\u00e9e apres s'\u00eatre fait rembourser les actions rachet\u00e9es\"}) import matplotlib.pyplot as plt  # Compter les occurrences de chaque valeur unique value_counts = dfretraitrepiseretrait_selection[\"A resouscrit juste apres avoir rachet\u00e9\"].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, (label, count) in enumerate(zip(texts, value_counts)):     label.set_text(f\"{label.get_text()} ({count})\")  plt.title(\"\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n\ndisplay(HTML(\"&lt;h3&gt;Parmi les peronnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembourser leurs actions rachet\u00e9es, combien de fois l'ont ils fait au cours de leur parcours d'actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML   display(HTML(\"Parmi les peronnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembourser leurs actions rachet\u00e9es, combien de fois l'ont ils fait au cours de leur parcours d'actionnaires\"))  Parmi les peronnes qui ont re-souscrit la m\u00eame ann\u00e9e apr\u00e8s s'\u00eatre fait rembourser leurs actions rachet\u00e9es, combien de fois l'ont ils fait au cours de leur parcours d'actionnaires In\u00a0[\u00a0]: Copied! <pre>dfretraitrepisetrue = dfretraitrepise[dfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0]\nimport matplotlib.pyplot as plt\n\n# Compter les occurrences de chaque valeur unique\nvalue_counts = dfretraitrepisetrue[\"nombre de reprises apr\u00e8s rachat\"].value_counts()\n\n# Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues\nplt.figure(figsize=(6, 6))\npatches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)\n\n# Ajouter les valeurs absolues aux \u00e9tiquettes\nfor i, (label, count) in enumerate(zip(texts, value_counts)):\n    label.set_text(f\"{label.get_text()} ({count})\")\n\nplt.title(\"\")\nplt.axis('equal')  # Assure que le pie chart est un cercle\n\nplt.show()\n</pre> dfretraitrepisetrue = dfretraitrepise[dfretraitrepise[\"nombre de reprises apr\u00e8s rachat\"] &gt; 0] import matplotlib.pyplot as plt  # Compter les occurrences de chaque valeur unique value_counts = dfretraitrepisetrue[\"nombre de reprises apr\u00e8s rachat\"].value_counts()  # Cr\u00e9er un pie chart avec les pourcentages et les valeurs absolues plt.figure(figsize=(6, 6)) patches, texts, autotexts = plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=30)  # Ajouter les valeurs absolues aux \u00e9tiquettes for i, (label, count) in enumerate(zip(texts, value_counts)):     label.set_text(f\"{label.get_text()} ({count})\")  plt.title(\"\") plt.axis('equal')  # Assure que le pie chart est un cercle  plt.show() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Parmi les 0,3% des actionnaires qui ont re-souscrit l'ann\u00e9e d'apr\u00e8s leur rachat effectif d'ation, il y en a qui l'ont fait plusieurs fois, la majorit\u00e9 la fait qu'une fois&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Parmi les 0,3% des actionnaires qui ont re-souscrit l'ann\u00e9e d'apr\u00e8s leur rachat effectif d'ation, il y en a qui l'ont fait plusieurs fois, la majorit\u00e9 la fait qu'une fois\")) Cl\u00e9 de lecture : Parmi les 0,3% des actionnaires qui ont re-souscrit l'ann\u00e9e d'apr\u00e8s leur rachat effectif d'ation, il y en a qui l'ont fait plusieurs fois, la majorit\u00e9 la fait qu'une fois In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Retrait d\u00e9finitif ou retrait partiel&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML display(HTML(\"\"))   # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Retrait d\u00e9finitif ou retrait partiel'))  Retrait d\u00e9finitif ou retrait partiel In\u00a0[\u00a0]: Copied! <pre>df['Nombre de souscriptions'] = df['ID du contact'].map(df2['ID du contact'].value_counts())\nconditions = [\n     (df['Nombre de souscriptions'] &lt; 2),\n     (df['Nombre de souscriptions'] &lt;3),\n     (df['Nombre de souscriptions'] &lt;=5),\n     (df['Nombre de souscriptions'] &lt;=10)\n]\n\nchoices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]\n\ndf['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')\n</pre> df['Nombre de souscriptions'] = df['ID du contact'].map(df2['ID du contact'].value_counts()) conditions = [      (df['Nombre de souscriptions'] &lt; 2),      (df['Nombre de souscriptions'] &lt;3),      (df['Nombre de souscriptions'] &lt;=5),      (df['Nombre de souscriptions'] &lt;=10) ]  choices = ['1 souscription', \"2 souscriptions\" , \"3 \u00e0 5 souscriptions\",\"6 \u00e0 10 souscriptions\"]  df['Cat\u00e9gories souscripteurs'] = np.select(conditions, choices, default='10 souscriptions et plus')  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\n# Cr\u00e9er une fonction pour v\u00e9rifier les conditions\ndef is_retrait_definitif(row):\n    same_contact_rows = df[df['ID du contact'] == row['ID du contact']]\n    later_rows = same_contact_rows[pd.to_datetime(same_contact_rows['Actions - Date de fin'], format=\"%d/%m/%Y\") &gt; pd.to_datetime(row['Date du Mouvement'])]\n    return (row['Nature du mouvement'] == 'Rachat' and\n            row['retrait complet ou partiel'] == 'retrait complet' and\n            later_rows.empty)\n\n# Appliquer la fonction pour cr\u00e9er la variable conditionnelle\ndf['nature du retrait'] = df.apply(is_retrait_definitif, axis=1).map({True: 'retrait d\u00e9finitif', False: 'retrait partiel'})\n</pre> import pandas as pd  # Cr\u00e9er une fonction pour v\u00e9rifier les conditions def is_retrait_definitif(row):     same_contact_rows = df[df['ID du contact'] == row['ID du contact']]     later_rows = same_contact_rows[pd.to_datetime(same_contact_rows['Actions - Date de fin'], format=\"%d/%m/%Y\") &gt; pd.to_datetime(row['Date du Mouvement'])]     return (row['Nature du mouvement'] == 'Rachat' and             row['retrait complet ou partiel'] == 'retrait complet' and             later_rows.empty)  # Appliquer la fonction pour cr\u00e9er la variable conditionnelle df['nature du retrait'] = df.apply(is_retrait_definitif, axis=1).map({True: 'retrait d\u00e9finitif', False: 'retrait partiel'})  In\u00a0[\u00a0]: Copied! <pre>df_retrait = df[df['Nature du mouvement'] == \"Rachat\"]\ndf_retraitcount = df_retrait['nature du retrait'].value_counts().sort_index().to_frame()\ndf_retraitcount.columns = ['Nombre d\\'individus']\ndf_retraitcount['Pourcentage'] = df_retraitcount['Nombre d\\'individus'].div(df_retraitcount['Nombre d\\'individus'].sum()) * 100\ndf_retraitcount\n</pre> df_retrait = df[df['Nature du mouvement'] == \"Rachat\"] df_retraitcount = df_retrait['nature du retrait'].value_counts().sort_index().to_frame() df_retraitcount.columns = ['Nombre d\\'individus'] df_retraitcount['Pourcentage'] = df_retraitcount['Nombre d\\'individus'].div(df_retraitcount['Nombre d\\'individus'].sum()) * 100 df_retraitcount   Out[\u00a0]: Nombre d'individus Pourcentage nature du retrait retrait d\u00e9finitif 818 29.562703 retrait partiel 1949 70.437297 In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Extraire les donn\u00e9es du DataFrame\nlabels = df_retraitcount.index\nsizes = df_retraitcount['Pourcentage']\n\n# Cr\u00e9er le pie chart\nplt.figure(figsize=(8, 6))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n\n# Ajouter un titre\nplt.title(\"R\u00e9partition des types de retrait\")\n\n# Afficher le pie chart\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Extraire les donn\u00e9es du DataFrame labels = df_retraitcount.index sizes = df_retraitcount['Pourcentage']  # Cr\u00e9er le pie chart plt.figure(figsize=(8, 6)) plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)  # Ajouter un titre plt.title(\"R\u00e9partition des types de retrait\")  # Afficher le pie chart plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Lorsque les souscripteurs ont interagi avec un de leurs contrats pour y racheter TOUTES SES ACTIONS, dans 66,3 % des cas il s'agissait de leur dernier contrat actif. Ainsi lorsque des contrats sont totalement vid\u00e9s de leurs actions, dans 66% des cas cela met fin \u00e0 l'activit\u00e9 d'actionnaire d'une personne (ce sont des ex-actionnaires)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Lorsque les souscripteurs ont interagi avec un de leurs contrats pour y racheter TOUTES SES ACTIONS, dans 66,3 % des cas il s'agissait de leur dernier contrat actif. Ainsi lorsque des contrats sont totalement vid\u00e9s de leurs actions, dans 66% des cas cela met fin \u00e0 l'activit\u00e9 d'actionnaire d'une personne (ce sont des ex-actionnaires)\")) Cl\u00e9 de lecture : Lorsque les souscripteurs ont interagi avec un de leurs contrats pour y racheter TOUTES SES ACTIONS, dans 66,3 % des cas il s'agissait de leur dernier contrat actif. Ainsi lorsque des contrats sont totalement vid\u00e9s de leurs actions, dans 66% des cas cela met fin \u00e0 l'activit\u00e9 d'actionnaire d'une personne (ce sont des ex-actionnaires) In\u00a0[\u00a0]: Copied! <pre>df_retraitdef = df[df[\"nature du retrait\"] == \"retrait d\u00e9finitif\"]\ndf_retraitdef['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_retraitdef['RFM-Date Premi\u00e8re Souscription'], format=\"%Y-%m-%d\")\ndf_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef['Date du Mouvement'] - df_retraitdef[\"RFM-Date Premi\u00e8re Souscription\"]\n</pre> df_retraitdef = df[df[\"nature du retrait\"] == \"retrait d\u00e9finitif\"] df_retraitdef['RFM-Date Premi\u00e8re Souscription'] = pd.to_datetime(df_retraitdef['RFM-Date Premi\u00e8re Souscription'], format=\"%Y-%m-%d\") df_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef['Date du Mouvement'] - df_retraitdef[\"RFM-Date Premi\u00e8re Souscription\"] In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n\n# Supprimer les lignes contenant des NaN dans la colonne \"Dur\u00e9e actionnariat\"\ndf_retraitdef = df_retraitdef.dropna(subset=[\"Dur\u00e9e actionnariat\"])\n\n# R\u00e9initialiser l'index apr\u00e8s la suppression des lignes\ndf_retraitdef = df_retraitdef.reset_index(drop=True)\n\n\n# Diviser par un an en utilisant timedelta\ndf_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef[\"Dur\u00e9e actionnariat\"] / pd.to_timedelta(365, unit='D')\ndf_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef[\"Dur\u00e9e actionnariat\"].round(1)\n\n# Calculer la m\u00e9diane, Q1 et Q3\nmedian = np.median(df_retraitdef[\"Dur\u00e9e actionnariat\"])\nq1 = np.percentile(df_retraitdef[\"Dur\u00e9e actionnariat\"], 25)\nq3 = np.percentile(df_retraitdef[\"Dur\u00e9e actionnariat\"], 75)\n\n# Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers\niqr = q3 - q1\nlower_whisker = q1 - 1.5 * iqr\nupper_whisker = q3 + 1.5 * iqr\nupper_whisker = upper_whisker.round(1)\n\n# Cr\u00e9er le box plot horizontalement\nplt.figure(figsize=(8, 6))\nplt.boxplot(df_retraitdef[\"Dur\u00e9e actionnariat\"], vert=False)\n\n# Calculer le nombre d'outliers\nwhiskers = plt.boxplot(df_retraitdef[\"Dur\u00e9e actionnariat\"], vert=False)['fliers']\nnum_outliers = len(whiskers[0].get_data()[0])\n\n# Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique\nplt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes)\nplt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes)\nplt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)\n\n# Titre et \u00e9tiquette de l'axe y\nplt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premiere souscription au retrait complet d'actions\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"\")\n\n# Afficher le box plot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np   # Supprimer les lignes contenant des NaN dans la colonne \"Dur\u00e9e actionnariat\" df_retraitdef = df_retraitdef.dropna(subset=[\"Dur\u00e9e actionnariat\"])  # R\u00e9initialiser l'index apr\u00e8s la suppression des lignes df_retraitdef = df_retraitdef.reset_index(drop=True)   # Diviser par un an en utilisant timedelta df_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef[\"Dur\u00e9e actionnariat\"] / pd.to_timedelta(365, unit='D') df_retraitdef[\"Dur\u00e9e actionnariat\"] = df_retraitdef[\"Dur\u00e9e actionnariat\"].round(1)  # Calculer la m\u00e9diane, Q1 et Q3 median = np.median(df_retraitdef[\"Dur\u00e9e actionnariat\"]) q1 = np.percentile(df_retraitdef[\"Dur\u00e9e actionnariat\"], 25) q3 = np.percentile(df_retraitdef[\"Dur\u00e9e actionnariat\"], 75)  # Calculer les limites inf\u00e9rieures et sup\u00e9rieures des whiskers iqr = q3 - q1 lower_whisker = q1 - 1.5 * iqr upper_whisker = q3 + 1.5 * iqr upper_whisker = upper_whisker.round(1)  # Cr\u00e9er le box plot horizontalement plt.figure(figsize=(8, 6)) plt.boxplot(df_retraitdef[\"Dur\u00e9e actionnariat\"], vert=False)  # Calculer le nombre d'outliers whiskers = plt.boxplot(df_retraitdef[\"Dur\u00e9e actionnariat\"], vert=False)['fliers'] num_outliers = len(whiskers[0].get_data()[0])  # Ajouter les valeurs de la m\u00e9diane, Q1, Q3, limites des whiskers au graphique plt.text(0.02, 0.9, f\"M\u00e9diane: {median}\", transform=plt.gca().transAxes) plt.text(0.02, 0.8, f\"Q1: {q1}\", transform=plt.gca().transAxes) plt.text(0.02, 0.7, f\"Q3: {q3}\", transform=plt.gca().transAxes) plt.text(0.5, 0.8, f\"borne sup\u00e9rieur du boxplot: {upper_whisker}\", transform=plt.gca().transAxes) plt.text(0.5, 0.9, f\"Outliers: {num_outliers}\", transform=plt.gca().transAxes)  # Titre et \u00e9tiquette de l'axe y plt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premiere souscription au retrait complet d'actions\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"\")  # Afficher le box plot plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Depuis la date de leur entr\u00e9e dans l'actionnariat, 50 % des souscripteurs attendent 7,7 ans ou moins avant de ne plus \u00eatre actionnaire. 25 % attendent 5,8 ans ou moins et 25 % attendent 10 ans ou plus soit 75 % qui ont une dur\u00e9e de vie d'actionnaire de moins de 10 ans, (parmi ceux qui ont quitt\u00e9 l'actionnariat). IL y a 0 personnes qui ont un comportement statistiquement ''hors normes''&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Depuis la date de leur entr\u00e9e dans l'actionnariat, 50 % des souscripteurs attendent 7,7 ans ou moins avant de ne plus \u00eatre actionnaire. 25 % attendent 5,8 ans ou moins et 25 % attendent 10 ans ou plus soit 75 % qui ont une dur\u00e9e de vie d'actionnaire de moins de 10 ans, (parmi ceux qui ont quitt\u00e9 l'actionnariat). IL y a 0 personnes qui ont un comportement statistiquement ''hors normes''\")) Cl\u00e9 de lecture : Depuis la date de leur entr\u00e9e dans l'actionnariat, 50 % des souscripteurs attendent 7,7 ans ou moins avant de ne plus \u00eatre actionnaire. 25 % attendent 5,8 ans ou moins et 25 % attendent 10 ans ou plus soit 75 % qui ont une dur\u00e9e de vie d'actionnaire de moins de 10 ans, (parmi ceux qui ont quitt\u00e9 l'actionnariat). IL y a 0 personnes qui ont un comportement statistiquement ''hors normes'' In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].apply(list)\ncustom_order = [ '1 souscription','2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\ngrouped_data = grouped_data.reindex(custom_order)\n\n\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\ncustom_order = grouped_data.index\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = custom_order\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premi\u00e8re souscription au retrait complet d'actions par cat\u00e9gories de souscripteurs\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories des souscripteurs\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].apply(list) custom_order = [ '1 souscription','2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus'] grouped_data = grouped_data.reindex(custom_order)    # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  custom_order = grouped_data.index  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = custom_order # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premi\u00e8re souscription au retrait complet d'actions par cat\u00e9gories de souscripteurs\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories des souscripteurs\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show()  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Compter le nombre de personnes par cat\u00e9gorie de souscripteur\ndf_retraitMS = df_retraitdef['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()\n\n# Renommer les colonnes\ndf_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]\n\n# Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie\ndf_stats = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()\n\n# Renommer les colonnes de statistiques\ndf_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e actionnariat', 'Q1', 'Q3', 'Upper Whiskers']\n\n# Calculer le nombre d'outliers pour chaque cat\u00e9gorie\ndf_outliers = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index()\ndf_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']\n\n# Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers\ndf_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs')\ndf_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs')\n\n# Classer le tableau par ordre croissant des m\u00e9dianes\ndf_retraitMS = df_retraitMS.sort_values(by='M\u00e9diane Dur\u00e9e actionnariat')\nordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']\n\n# Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9\ndf_retraitMS['ordre'] = df_retraitMS['Cat\u00e9gories souscripteurs'].apply(lambda x: ordre_categories_souscripteurs.index(x))\n\n# Trier le DataFrame en fonction de la colonne \"ordre\"\ndf_retraitMS = df_retraitMS.sort_values('ordre')\n\n# Supprimer la colonne \"ordre\"\ndf_retraitMS = df_retraitMS.drop('ordre', axis=1)\n\n# R\u00e9initialiser les index\ndf_retraitMS.reset_index(drop=True, inplace=True)\n\ndf_retraitMS\n</pre> import pandas as pd import numpy as np  # Compter le nombre de personnes par cat\u00e9gorie de souscripteur df_retraitMS = df_retraitdef['Cat\u00e9gories souscripteurs'].value_counts().to_frame().reset_index()  # Renommer les colonnes df_retraitMS.columns = ['Cat\u00e9gories souscripteurs', \"Nombre d'individus\"]  # Calculer la moyenne, Q1, Q3 et les whiskers de la variable \"Dur\u00e9e actionnariat\" pour chaque cat\u00e9gorie df_stats = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].agg(['median', lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75), lambda x: np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))]).reset_index()  # Renommer les colonnes de statistiques df_stats.columns = ['Cat\u00e9gories souscripteurs', 'M\u00e9diane Dur\u00e9e actionnariat', 'Q1', 'Q3', 'Upper Whiskers']  # Calculer le nombre d'outliers pour chaque cat\u00e9gorie df_outliers = df_retraitdef.groupby('Cat\u00e9gories souscripteurs')['Dur\u00e9e actionnariat'].apply(lambda x: np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))).reset_index() df_outliers.columns = ['Cat\u00e9gories souscripteurs', 'Nombre d\\'outliers']  # Fusionner les DataFrames pour ajouter les statistiques et le nombre d'outliers df_retraitMS = pd.merge(df_retraitMS, df_stats, on='Cat\u00e9gories souscripteurs') df_retraitMS = pd.merge(df_retraitMS, df_outliers, on='Cat\u00e9gories souscripteurs')  # Classer le tableau par ordre croissant des m\u00e9dianes df_retraitMS = df_retraitMS.sort_values(by='M\u00e9diane Dur\u00e9e actionnariat') ordre_categories_souscripteurs = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus']  # Ajouter une colonne pour d\u00e9finir l'ordre souhait\u00e9 df_retraitMS['ordre'] = df_retraitMS['Cat\u00e9gories souscripteurs'].apply(lambda x: ordre_categories_souscripteurs.index(x))  # Trier le DataFrame en fonction de la colonne \"ordre\" df_retraitMS = df_retraitMS.sort_values('ordre')  # Supprimer la colonne \"ordre\" df_retraitMS = df_retraitMS.drop('ordre', axis=1)  # R\u00e9initialiser les index df_retraitMS.reset_index(drop=True, inplace=True)  df_retraitMS Out[\u00a0]: Cat\u00e9gories souscripteurs Nombre d'individus M\u00e9diane Dur\u00e9e actionnariat Q1 Q3 Upper Whiskers Nombre d'outliers 0 1 souscription 84 7.4 5.175 10.45 18.3625 0 1 2 souscriptions 7 6.8 6.250 7.50 9.3750 2 2 10 souscriptions et plus 727 3.7 1.550 7.20 15.6750 3 In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es\ngrouped_data = df_retraitdef.groupby('anciennet\u00e9 actionnaires')['Dur\u00e9e actionnariat'].apply(list)\nordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\ngrouped_data = grouped_data.reindex(ordre_categories_anciennet\u00e9)\n\n# Cr\u00e9er le boxplot en inversant l'ordre des positions\nplt.figure(figsize=(8, 6))\nboxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)\n\ncustom_order = grouped_data.index\n\n# R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories\ncategories = custom_order\n# Couleurs personnalis\u00e9es pour chaque bo\u00eete\ncustom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']\n\n# Attribution des couleurs aux bo\u00eetes\nfor box, color in zip(boxes['boxes'], custom_colors):\n    box.set_facecolor(color)\n\n# Titre et \u00e9tiquette des axes\nplt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premiere souscription au retrait complet d'actions par cat\u00e9gories d'anciennet\u00e9 des actionnaires\")\nplt.xlabel(\"Nombre d'ann\u00e9es\")\nplt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\")\nplt.yticks([])\n\n# Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el)\nlegend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors]\nplt.legend(legend_proxies, categories)\n\n# Afficher le boxplot\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Cr\u00e9er les groupes pour le boxplot et inverser l'ordre des donn\u00e9es grouped_data = df_retraitdef.groupby('anciennet\u00e9 actionnaires')['Dur\u00e9e actionnariat'].apply(list) ordre_categories_anciennet\u00e9 = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] grouped_data = grouped_data.reindex(ordre_categories_anciennet\u00e9)  # Cr\u00e9er le boxplot en inversant l'ordre des positions plt.figure(figsize=(8, 6)) boxes = plt.boxplot(grouped_data, vert=False, patch_artist=True)  custom_order = grouped_data.index  # R\u00e9cup\u00e9rer les \u00e9tiquettes de cat\u00e9gories categories = custom_order # Couleurs personnalis\u00e9es pour chaque bo\u00eete custom_colors = ['powderblue', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'steelblue']  # Attribution des couleurs aux bo\u00eetes for box, color in zip(boxes['boxes'], custom_colors):     box.set_facecolor(color)  # Titre et \u00e9tiquette des axes plt.title(\"Dur\u00e9e de la p\u00e9riode d'actionnariat de la premiere souscription au retrait complet d'actions par cat\u00e9gories d'anciennet\u00e9 des actionnaires\") plt.xlabel(\"Nombre d'ann\u00e9es\") plt.ylabel(\"Cat\u00e9gories d'anciennet\u00e9\") plt.yticks([])  # Cr\u00e9ation de la l\u00e9gende en utilisant des proxies (\u00e9l\u00e9ments de la l\u00e9gende sans affichage r\u00e9el) legend_proxies = [plt.Rectangle((0, 0), 1, 1, color=color) for color in custom_colors] plt.legend(legend_proxies, categories)  # Afficher le boxplot plt.show()  In\u00a0[\u00a0]: Copied! <pre># Cr\u00e9er le tableau de statistiques\ndf_stats = grouped_data.apply(lambda x: pd.Series({\n    'M\u00e9diane Dur\u00e9e actionnariat': np.median(x),\n    'Q1': np.percentile(x, 25),\n    'Q3': np.percentile(x, 75),\n    'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),\n    \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25))))\n})).reset_index()\ndf_stats.rename(columns={'anciennet\u00e9 actionnaires': 'Cat\u00e9gories d\\'anciennet\u00e9'}, inplace=True)\ndf_stats = df_stats.iloc[::-1].reset_index(drop=True)\ndf_stats\n</pre>  # Cr\u00e9er le tableau de statistiques df_stats = grouped_data.apply(lambda x: pd.Series({     'M\u00e9diane Dur\u00e9e actionnariat': np.median(x),     'Q1': np.percentile(x, 25),     'Q3': np.percentile(x, 75),     'Upper Whiskers': np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)),     \"Nombre d'outliers\": np.sum((x &lt; np.percentile(x, 25) - 1.5*(np.percentile(x, 75) - np.percentile(x, 25))) | (x &gt; np.percentile(x, 75) + 1.5*(np.percentile(x, 75) - np.percentile(x, 25)))) })).reset_index() df_stats.rename(columns={'anciennet\u00e9 actionnaires': 'Cat\u00e9gories d\\'anciennet\u00e9'}, inplace=True) df_stats = df_stats.iloc[::-1].reset_index(drop=True) df_stats Out[\u00a0]: Cat\u00e9gories d'anciennet\u00e9 M\u00e9diane Dur\u00e9e actionnariat Q1 Q3 Upper Whiskers Nombre d'outliers 0 Nouvel actionnaire en 2012 ou moins 7.75 3.900 11.2 22.1500 0.0 1 Nouvel actionnaire entre 2012 \u00e0 2017 4.90 2.575 7.3 14.3875 0.0 2 Nouvel actionnaire depuis 2017 ou plus 1.85 0.900 3.2 6.6500 0.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Analyse par d\u00e9ciles d\\'actionnaires&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML display(HTML(\"\"))   # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Analyse par d\u00e9ciles d\\'actionnaires'))  Analyse par d\u00e9ciles d'actionnaires In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Calculer les d\u00e9ciles de la variable \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"\ndf_actionnaire = df[df[\"Actionnaire ?\"] == True]\ndf_actionnaire = df_actionnaire.drop_duplicates(subset=\"ID du contact\")\n#df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'].str.replace(',', '.').astype(float)\n\n# Calculer les d\u00e9ciles avec des intervalles \u00e9gaux\ndeciles = pd.qcut(df_actionnaire[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')\n# En utilisant duplicates='drop'  la fonction supprimera les bornes en double. Cela signifie que si deux valeurs identiques tombent exactement sur une limite d'intervalle, l'une des bornes sera supprim\u00e9e, de sorte que chaque limite d'intervalle est unique. Cela peut entra\u00eener un nombre r\u00e9duit d'intervalles si vos donn\u00e9es ont beaucoup de valeurs identiques.Il faut donc pr\u00e9voir des intervalles en plus pour en sp\u00e9cifier 10  soit utiliser q = 11 au lieu de 10 \n# Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles\ndf_actionnaire['d\u00e9ciles actionnaire'] = deciles\ndf_actionnaire['d\u00e9ciles actionnaire'] = df_actionnaire['d\u00e9ciles actionnaire'].cat.codes + 1\n\n# Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d10\ndf_actionnaire['d\u00e9ciles actionnaires'] = 'd\u00e9cile ' + df_actionnaire['d\u00e9ciles actionnaire'].astype(str)\n</pre> import pandas as pd import numpy as np  # Calculer les d\u00e9ciles de la variable \"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\" df_actionnaire = df[df[\"Actionnaire ?\"] == True] df_actionnaire = df_actionnaire.drop_duplicates(subset=\"ID du contact\") #df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'].str.replace(',', '.').astype(float)  # Calculer les d\u00e9ciles avec des intervalles \u00e9gaux deciles = pd.qcut(df_actionnaire[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop') # En utilisant duplicates='drop'  la fonction supprimera les bornes en double. Cela signifie que si deux valeurs identiques tombent exactement sur une limite d'intervalle, l'une des bornes sera supprim\u00e9e, de sorte que chaque limite d'intervalle est unique. Cela peut entra\u00eener un nombre r\u00e9duit d'intervalles si vos donn\u00e9es ont beaucoup de valeurs identiques.Il faut donc pr\u00e9voir des intervalles en plus pour en sp\u00e9cifier 10  soit utiliser q = 11 au lieu de 10  # Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles df_actionnaire['d\u00e9ciles actionnaire'] = deciles df_actionnaire['d\u00e9ciles actionnaire'] = df_actionnaire['d\u00e9ciles actionnaire'].cat.codes + 1  # Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d10 df_actionnaire['d\u00e9ciles actionnaires'] = 'd\u00e9cile ' + df_actionnaire['d\u00e9ciles actionnaire'].astype(str)  In\u00a0[\u00a0]: Copied! <pre>df_actionnaire['multi-souscripteur ?'] = df_actionnaire['multi-souscripteur ?'].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"})\ndf_actionnaire_MS = df_actionnaire.groupby('d\u00e9ciles actionnaires')['multi-souscripteur ?'].value_counts().unstack().fillna(0)\n</pre> df_actionnaire['multi-souscripteur ?'] = df_actionnaire['multi-souscripteur ?'].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"}) df_actionnaire_MS = df_actionnaire.groupby('d\u00e9ciles actionnaires')['multi-souscripteur ?'].value_counts().unstack().fillna(0)  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Bornes des d\u00e9ciles en fonction du nombre d'actions d\u00e9tenues par actionnaire&lt;/h3&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Bornes des d\u00e9ciles en fonction du nombre d'actions d\u00e9tenues par actionnaire\")) Bornes des d\u00e9ciles en fonction du nombre d'actions d\u00e9tenues par actionnaire In\u00a0[\u00a0]: Copied! <pre># Calculer les d\u00e9ciles avec des intervalles \u00e9gaux\ndeciles = pd.qcut(df_actionnaire[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')\n\n# Obtenir les bornes des d\u00e9ciles\ndecile_bounds = np.unique(deciles)\ndecile_bounds\n</pre> # Calculer les d\u00e9ciles avec des intervalles \u00e9gaux deciles = pd.qcut(df_actionnaire[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')  # Obtenir les bornes des d\u00e9ciles decile_bounds = np.unique(deciles) decile_bounds Out[\u00a0]: <pre>array([Interval(0.999, 12.0, closed='right'),\n       Interval(12.0, 24.0, closed='right'),\n       Interval(24.0, 37.0, closed='right'),\n       Interval(37.0, 49.0, closed='right'),\n       Interval(49.0, 61.0, closed='right'),\n       Interval(61.0, 74.0, closed='right'),\n       Interval(74.0, 85.0, closed='right'),\n       Interval(85.0, 97.0, closed='right'),\n       Interval(97.0, 3373.6, closed='right'),\n       Interval(3373.6, 7979.0, closed='right')], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Premi\u00e8re phrase\ndisplay(HTML(\"&lt;h4&gt;Explications concernant la d\u00e9termination des bornes des d\u00e9ciles : &lt;/h4&gt;\"))\n# Deuxi\u00e8me phrase\ndisplay(HTML(\"&lt;h4&gt;Les bornes des d\u00e9ciles sont calcul\u00e9es en divisant un ensemble de donn\u00e9es tri\u00e9es en dix parties \u00e9gales, de sorte que chaque d\u00e9cile repr\u00e9sente 10 % des observations. Il s'agit d'ordonner les donn\u00e9es en ordre croissant (ici le nombre d'actions poss\u00e9d\u00e9es au total), puis divisez le nombre total d'observations par 10 pour d\u00e9terminer combien d'observations devraient se trouver dans chaque d\u00e9cile. Cependant, il peut arriver que les bornes des d\u00e9ciles ne s\u00e9parent pas parfaitement les donn\u00e9es en parties \u00e9gales lorsque les valeurs sont fortement regroup\u00e9es autour de certaines valeurs (1 action ou 2, par exemple). Dans de tels cas, plusieurs observations peuvent avoir la m\u00eame valeur, ce qui peut entra\u00eener des d\u00e9ciles qui ne contiennent pas exactement 10 % des donn\u00e9es chacun.&lt;/h4&gt;\"))\n\ndisplay(HTML(\"&lt;h4&gt;Pour le deuxi\u00e8me d\u00e9cile par exemple, celui-ci comporte toutes les personnes qui sont inclues dans l'interval 3.0, 5.0, closed='right') autrement \u00e9crit ]3-5]. Il contient alors les personnes poss\u00e9dant au total un nombre d'actions strictement sup\u00e9rieur \u00e0 3 \u00e0 inf\u00e9rieur ou \u00e9gale \u00e0 5&lt;/h4&gt;\"))\n</pre> from IPython.display import display, HTML  # Premi\u00e8re phrase display(HTML(\"Explications concernant la d\u00e9termination des bornes des d\u00e9ciles : \")) # Deuxi\u00e8me phrase display(HTML(\"Les bornes des d\u00e9ciles sont calcul\u00e9es en divisant un ensemble de donn\u00e9es tri\u00e9es en dix parties \u00e9gales, de sorte que chaque d\u00e9cile repr\u00e9sente 10 % des observations. Il s'agit d'ordonner les donn\u00e9es en ordre croissant (ici le nombre d'actions poss\u00e9d\u00e9es au total), puis divisez le nombre total d'observations par 10 pour d\u00e9terminer combien d'observations devraient se trouver dans chaque d\u00e9cile. Cependant, il peut arriver que les bornes des d\u00e9ciles ne s\u00e9parent pas parfaitement les donn\u00e9es en parties \u00e9gales lorsque les valeurs sont fortement regroup\u00e9es autour de certaines valeurs (1 action ou 2, par exemple). Dans de tels cas, plusieurs observations peuvent avoir la m\u00eame valeur, ce qui peut entra\u00eener des d\u00e9ciles qui ne contiennent pas exactement 10 % des donn\u00e9es chacun.\"))  display(HTML(\"Pour le deuxi\u00e8me d\u00e9cile par exemple, celui-ci comporte toutes les personnes qui sont inclues dans l'interval 3.0, 5.0, closed='right') autrement \u00e9crit ]3-5]. Il contient alors les personnes poss\u00e9dant au total un nombre d'actions strictement sup\u00e9rieur \u00e0 3 \u00e0 inf\u00e9rieur ou \u00e9gale \u00e0 5\"))   Explications concernant la d\u00e9termination des bornes des d\u00e9ciles :  Les bornes des d\u00e9ciles sont calcul\u00e9es en divisant un ensemble de donn\u00e9es tri\u00e9es en dix parties \u00e9gales, de sorte que chaque d\u00e9cile repr\u00e9sente 10 % des observations. Il s'agit d'ordonner les donn\u00e9es en ordre croissant (ici le nombre d'actions poss\u00e9d\u00e9es au total), puis divisez le nombre total d'observations par 10 pour d\u00e9terminer combien d'observations devraient se trouver dans chaque d\u00e9cile. Cependant, il peut arriver que les bornes des d\u00e9ciles ne s\u00e9parent pas parfaitement les donn\u00e9es en parties \u00e9gales lorsque les valeurs sont fortement regroup\u00e9es autour de certaines valeurs (1 action ou 2, par exemple). Dans de tels cas, plusieurs observations peuvent avoir la m\u00eame valeur, ce qui peut entra\u00eener des d\u00e9ciles qui ne contiennent pas exactement 10 % des donn\u00e9es chacun. Pour le deuxi\u00e8me d\u00e9cile par exemple, celui-ci comporte toutes les personnes qui sont inclues dans l'interval 3.0, 5.0, closed='right') autrement \u00e9crit ]3-5]. Il contient alors les personnes poss\u00e9dant au total un nombre d'actions strictement sup\u00e9rieur \u00e0 3 \u00e0 inf\u00e9rieur ou \u00e9gale \u00e0 5 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partitions des cat\u00e9gories de souscripteurs au sein des d\u00e9ciles (par multi-souscripteurs ou pas)&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partitions des cat\u00e9gories de souscripteurs au sein des d\u00e9ciles (par multi-souscripteurs ou pas)\")) R\u00e9partitions des cat\u00e9gories de souscripteurs au sein des d\u00e9ciles (par multi-souscripteurs ou pas) In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Supprimez cette ligne si vous n'utilisez pas Jupyter Notebook\n%matplotlib inline\ndf_actionnaire_MS = df_actionnaire_MS.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10'])\n# D\u00e9finir les donn\u00e9es\ndeciles = df_actionnaire_MS.index\nmono_souscripteurs = df_actionnaire_MS['Mono-souscripteurs']\nmulti_souscripteurs = df_actionnaire_MS['Multi-souscripteurs']\n\n# Cr\u00e9er le graphique en barres empil\u00e9es\nfig, ax = plt.subplots()\nbar1 = ax.bar(deciles, mono_souscripteurs, label='Mono-souscripteurs')\nbar2 = ax.bar(deciles, multi_souscripteurs, bottom=mono_souscripteurs, label='Multi-souscripteurs')\n\n# Pivoter les \u00e9tiquettes en x de 45 degr\u00e9s\nplt.xticks(rotation=45)\n\n# Ajouter des valeurs num\u00e9riques au centre de chaque partie des barres\nfor decile, bar_m, bar_multi in zip(deciles, bar1, bar2):\n    height_m = bar_m.get_height()\n    height_multi = bar_multi.get_height()\n    total = height_m + height_multi\n    ax.annotate(f'{height_m}', (decile, height_m/2), ha='center', va='bottom', color='black')\n    ax.annotate(f'{height_multi}', (decile, height_m + height_multi/2), ha='center', va='bottom', color='black')\n\n# Ajouter des labels, un titre et une l\u00e9gende\nplt.xlabel('D\u00e9ciles ')\nplt.ylabel('Nombre d\\'actionnaires')\nplt.title('R\u00e9partition des Multi-souscripteurs par d\u00e9ciles')\nplt.legend()\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Supprimez cette ligne si vous n'utilisez pas Jupyter Notebook %matplotlib inline df_actionnaire_MS = df_actionnaire_MS.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10']) # D\u00e9finir les donn\u00e9es deciles = df_actionnaire_MS.index mono_souscripteurs = df_actionnaire_MS['Mono-souscripteurs'] multi_souscripteurs = df_actionnaire_MS['Multi-souscripteurs']  # Cr\u00e9er le graphique en barres empil\u00e9es fig, ax = plt.subplots() bar1 = ax.bar(deciles, mono_souscripteurs, label='Mono-souscripteurs') bar2 = ax.bar(deciles, multi_souscripteurs, bottom=mono_souscripteurs, label='Multi-souscripteurs')  # Pivoter les \u00e9tiquettes en x de 45 degr\u00e9s plt.xticks(rotation=45)  # Ajouter des valeurs num\u00e9riques au centre de chaque partie des barres for decile, bar_m, bar_multi in zip(deciles, bar1, bar2):     height_m = bar_m.get_height()     height_multi = bar_multi.get_height()     total = height_m + height_multi     ax.annotate(f'{height_m}', (decile, height_m/2), ha='center', va='bottom', color='black')     ax.annotate(f'{height_multi}', (decile, height_m + height_multi/2), ha='center', va='bottom', color='black')  # Ajouter des labels, un titre et une l\u00e9gende plt.xlabel('D\u00e9ciles ') plt.ylabel('Nombre d\\'actionnaires') plt.title('R\u00e9partition des Multi-souscripteurs par d\u00e9ciles') plt.legend()  # Afficher le graphique plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen d'actions par souscriptions entre d\u00e9ciles d'actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen d'actions par souscriptions entre d\u00e9ciles d'actionnaires\")) Nombre moyen d'actions par souscriptions entre d\u00e9ciles d'actionnaires In\u00a0[\u00a0]: Copied! <pre>decile_order = ['d\u00e9cile 1','d\u00e9cile 2','d\u00e9cile 3','d\u00e9cile 4','d\u00e9cile 5','d\u00e9cile 6','d\u00e9cile 7','d\u00e9cile 8','d\u00e9cile 9','d\u00e9cile 10']\n</pre> decile_order = ['d\u00e9cile 1','d\u00e9cile 2','d\u00e9cile 3','d\u00e9cile 4','d\u00e9cile 5','d\u00e9cile 6','d\u00e9cile 7','d\u00e9cile 8','d\u00e9cile 9','d\u00e9cile 10'] In\u00a0[\u00a0]: Copied! <pre>df_decactionsmean = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].mean().to_frame()\ndf_decactionsmean = df_decactionsmean.reindex(index=decile_order)\ndf_decactionsmean\n</pre> df_decactionsmean = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].mean().to_frame() df_decactionsmean = df_decactionsmean.reindex(index=decile_order) df_decactionsmean Out[\u00a0]: Fonci\u00e8re : Nombre d'actions d\u00e9tenues d\u00e9ciles actionnaires d\u00e9cile 1 6.448804 d\u00e9cile 2 18.575442 d\u00e9cile 3 31.300562 d\u00e9cile 4 43.514781 d\u00e9cile 5 55.203441 d\u00e9cile 6 67.965649 d\u00e9cile 7 79.898947 d\u00e9cile 8 91.342209 d\u00e9cile 9 1273.020790 d\u00e9cile 10 5710.822355 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre total d'actions entre d\u00e9ciles d'actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre total d'actions entre d\u00e9ciles d'actionnaires\")) Nombre total d'actions entre d\u00e9ciles d'actionnaires In\u00a0[\u00a0]: Copied! <pre>df_decactionsum = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].sum().to_frame()\ndf_decactionsum = df_decactionsum.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10'])\ndf_decactionsum\n</pre> df_decactionsum = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].sum().to_frame() df_decactionsum = df_decactionsum.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10']) df_decactionsum Out[\u00a0]: Fonci\u00e8re : Nombre d'actions d\u00e9tenues d\u00e9ciles actionnaires d\u00e9cile 1 6739 d\u00e9cile 2 17851 d\u00e9cile 3 33429 d\u00e9cile 4 42688 d\u00e9cile 5 54541 d\u00e9cile 6 71228 d\u00e9cile 7 75904 d\u00e9cile 8 92621 d\u00e9cile 9 1224646 d\u00e9cile 10 5722244 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre moyen de souscriptions entre d\u00e9ciles d'actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre moyen de souscriptions entre d\u00e9ciles d'actionnaires\")) Nombre moyen de souscriptions entre d\u00e9ciles d'actionnaires In\u00a0[\u00a0]: Copied! <pre>df_decsouscriptionmean = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Nombre de souscriptions\"].mean().to_frame()\ndf_decsouscriptionmean = df_decsouscriptionmean.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10'])\ndf_decsouscriptionmean\n</pre> df_decsouscriptionmean = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Nombre de souscriptions\"].mean().to_frame() df_decsouscriptionmean = df_decsouscriptionmean.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10']) df_decsouscriptionmean Out[\u00a0]: Nombre de souscriptions d\u00e9ciles actionnaires d\u00e9cile 1 1.656182 d\u00e9cile 2 1.656361 d\u00e9cile 3 1.624599 d\u00e9cile 4 1.658933 d\u00e9cile 5 1.668192 d\u00e9cile 6 1.560638 d\u00e9cile 7 1.603345 d\u00e9cile 8 1.597520 d\u00e9cile 9 1.627521 d\u00e9cile 10 1.646048 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nombre total de souscriptions entre d\u00e9ciles d'actionnaires&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nombre total de souscriptions entre d\u00e9ciles d'actionnaires\")) Nombre total de souscriptions entre d\u00e9ciles d'actionnaires In\u00a0[\u00a0]: Copied! <pre>df_decsouscriptionsum = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Nombre de souscriptions\"].sum().to_frame()\ndf_decsouscriptionsum = df_decsouscriptionsum.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10'])\ndf_decsouscriptionsum\n</pre> df_decsouscriptionsum = df_actionnaire.groupby(\"d\u00e9ciles actionnaires\")[\"Nombre de souscriptions\"].sum().to_frame() df_decsouscriptionsum = df_decsouscriptionsum.reindex(['d\u00e9cile 1', 'd\u00e9cile 2', 'd\u00e9cile 3', 'd\u00e9cile 4', 'd\u00e9cile 5', 'd\u00e9cile 6', 'd\u00e9cile 7', 'd\u00e9cile 8', 'd\u00e9cile 9', 'd\u00e9cile 10']) df_decsouscriptionsum Out[\u00a0]: Nombre de souscriptions d\u00e9ciles actionnaires d\u00e9cile 1 1527.0 d\u00e9cile 2 1393.0 d\u00e9cile 3 1519.0 d\u00e9cile 4 1430.0 d\u00e9cile 5 1458.0 d\u00e9cile 6 1467.0 d\u00e9cile 7 1342.0 d\u00e9cile 8 1417.0 d\u00e9cile 9 1372.0 d\u00e9cile 10 1437.0 In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n\n# Remplacer les virgules par des points dans la colonne 'Fonci\u00e8re : Capital poss\u00e9d\u00e9'\n#df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] = df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].str.replace(',', '.')\n#df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'].str.replace(',', '.')\n\n# Convertir la colonne 'Fonci\u00e8re : Capital poss\u00e9d\u00e9' en valeurs num\u00e9riques\ndf_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] = pd.to_numeric(df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'], errors='coerce')\ndf_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = pd.to_numeric(df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], errors='coerce')\n\n# Calcul de la part de chaque d\u00e9cile d'actionnaires dans le total\ndf_grouped = df_actionnaire.groupby('d\u00e9ciles actionnaires').agg({\n    'Fonci\u00e8re : Capital poss\u00e9d\u00e9': 'sum',\n    'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)': 'sum'\n})\ntotal_capital = df_grouped['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].sum() #Avec cette ligne et la ligne de dessous on voit qu'on calcul le total avec le capital poss\u00e9d\u00e9 et non la part du capital poss\u00e9d\u00e9 qui inclut les PM\n\ndf_grouped['Part du capital poss\u00e9d\u00e9 (%)'] = df_grouped['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] / total_capital * 100\n\n# Affichage du tableau\ndf_grouped = df_grouped[['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)']]\ndf_grouped.index.name = 'D\u00e9ciles actionnaire'\n\n# Position des barres\nx = np.arange(len(df_grouped))\nwidth = 0.35\n\ndf_grouped = df_grouped.reindex(index=decile_order)\n\n# Cr\u00e9ation du graphique \u00e0 barres\nfig, ax = plt.subplots()\n\n# Barres pour la part du capital poss\u00e9d\u00e9\nbar1 = ax.bar(x, df_grouped['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], width, label='Part du capital poss\u00e9d\u00e9')\n\n# \u00c9tiquettes des axes et du titre\nax.set_xlabel('D\u00e9ciles actionnaire')\nax.set_ylabel('Pourcentage (%)')\nax.set_title(\"R\u00e9partition du capital par d\u00e9ciles d'actionnaires\")\n\n# Positions des \u00e9tiquettes sur l'axe x\nax.set_xticks(x)\nax.set_xticklabels(df_grouped.index, rotation=45, ha='right')  # Inclinaison de 45 degr\u00e9s avec alignement \u00e0 droite\n\n# L\u00e9gende\nax.legend()\n\n# Affichage des valeurs au-dessus des barres\nfor rect in bar1:\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.1f}%', ha='center')\n\n# Affichage du graphique\nplt.tight_layout()  # Ajustement automatique des marges\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np   # Remplacer les virgules par des points dans la colonne 'Fonci\u00e8re : Capital poss\u00e9d\u00e9' #df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] = df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].str.replace(',', '.') #df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'].str.replace(',', '.')  # Convertir la colonne 'Fonci\u00e8re : Capital poss\u00e9d\u00e9' en valeurs num\u00e9riques df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] = pd.to_numeric(df_actionnaire['Fonci\u00e8re : Capital poss\u00e9d\u00e9'], errors='coerce') df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'] = pd.to_numeric(df_actionnaire['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], errors='coerce')  # Calcul de la part de chaque d\u00e9cile d'actionnaires dans le total df_grouped = df_actionnaire.groupby('d\u00e9ciles actionnaires').agg({     'Fonci\u00e8re : Capital poss\u00e9d\u00e9': 'sum',     'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)': 'sum' }) total_capital = df_grouped['Fonci\u00e8re : Capital poss\u00e9d\u00e9'].sum() #Avec cette ligne et la ligne de dessous on voit qu'on calcul le total avec le capital poss\u00e9d\u00e9 et non la part du capital poss\u00e9d\u00e9 qui inclut les PM  df_grouped['Part du capital poss\u00e9d\u00e9 (%)'] = df_grouped['Fonci\u00e8re : Capital poss\u00e9d\u00e9'] / total_capital * 100  # Affichage du tableau df_grouped = df_grouped[['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)']] df_grouped.index.name = 'D\u00e9ciles actionnaire'  # Position des barres x = np.arange(len(df_grouped)) width = 0.35  df_grouped = df_grouped.reindex(index=decile_order)  # Cr\u00e9ation du graphique \u00e0 barres fig, ax = plt.subplots()  # Barres pour la part du capital poss\u00e9d\u00e9 bar1 = ax.bar(x, df_grouped['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], width, label='Part du capital poss\u00e9d\u00e9')  # \u00c9tiquettes des axes et du titre ax.set_xlabel('D\u00e9ciles actionnaire') ax.set_ylabel('Pourcentage (%)') ax.set_title(\"R\u00e9partition du capital par d\u00e9ciles d'actionnaires\")  # Positions des \u00e9tiquettes sur l'axe x ax.set_xticks(x) ax.set_xticklabels(df_grouped.index, rotation=45, ha='right')  # Inclinaison de 45 degr\u00e9s avec alignement \u00e0 droite  # L\u00e9gende ax.legend()  # Affichage des valeurs au-dessus des barres for rect in bar1:     height = rect.get_height()     ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.1f}%', ha='center')  # Affichage du graphique plt.tight_layout()  # Ajustement automatique des marges plt.show()   In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;La structure des donn\u00e9es fait qu'il n'y pas le m\u00eame nombre de personnes dans chaque d\u00e9ciles ce qui peut d\u00e9s\u00e9quilibr\u00e9 les parts (ex : le 2\u00e8me d\u00e9cile poss\u00e8de moins que le premier)&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"La structure des donn\u00e9es fait qu'il n'y pas le m\u00eame nombre de personnes dans chaque d\u00e9ciles ce qui peut d\u00e9s\u00e9quilibr\u00e9 les parts (ex : le 2\u00e8me d\u00e9cile poss\u00e8de moins que le premier)\")) La structure des donn\u00e9es fait qu'il n'y pas le m\u00eame nombre de personnes dans chaque d\u00e9ciles ce qui peut d\u00e9s\u00e9quilibr\u00e9 les parts (ex : le 2\u00e8me d\u00e9cile poss\u00e8de moins que le premier) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Ici lorsqu\\'on parle de part du capital poss\u00e9d\u00e9, il s\\'agit de la part poss\u00e9d\u00e9 sur l\\'ensemble du capital des personnes physiques et morales&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Ici lorsqu\\'on parle de part du capital poss\u00e9d\u00e9, il s\\'agit de la part poss\u00e9d\u00e9 sur l\\'ensemble du capital des personnes physiques et morales\")) Ici lorsqu'on parle de part du capital poss\u00e9d\u00e9, il s'agit de la part poss\u00e9d\u00e9 sur l'ensemble du capital des personnes physiques et morales In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Focus sur le 9\u00e8me d\u00e9cile&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Focus sur le 9\u00e8me d\u00e9cile'))  Focus sur le 9\u00e8me d\u00e9cile In\u00a0[\u00a0]: Copied! <pre>df_actionnaire10 = df_actionnaire[df_actionnaire[\"d\u00e9ciles actionnaires\"] == \"d\u00e9cile 10\"]\n</pre> df_actionnaire10 = df_actionnaire[df_actionnaire[\"d\u00e9ciles actionnaires\"] == \"d\u00e9cile 10\"] In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Nous avons divis\u00e9 le 10 \u00e8me d\u00e9cile de tous les actionnaires en 10 d\u00e9ciles suppl\u00e9mentaires. il s'agit donc de s'int\u00e9resser aux 10 derniers centiles&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Nous avons divis\u00e9 le 10 \u00e8me d\u00e9cile de tous les actionnaires en 10 d\u00e9ciles suppl\u00e9mentaires. il s'agit donc de s'int\u00e9resser aux 10 derniers centiles\")) Nous avons divis\u00e9 le 10 \u00e8me d\u00e9cile de tous les actionnaires en 10 d\u00e9ciles suppl\u00e9mentaires. il s'agit donc de s'int\u00e9resser aux 10 derniers centiles In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;D\u00e9termination des bornes des d\u00e9ciles parmi le 10eme d\u00e9cile de tous les actionnaires, nombre de personnes par d\u00e9cile et nombre d'actions d\u00e9tenues en fonction des d\u00e9ciles &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"D\u00e9termination des bornes des d\u00e9ciles parmi le 10eme d\u00e9cile de tous les actionnaires, nombre de personnes par d\u00e9cile et nombre d'actions d\u00e9tenues en fonction des d\u00e9ciles \")) D\u00e9termination des bornes des d\u00e9ciles parmi le 10eme d\u00e9cile de tous les actionnaires, nombre de personnes par d\u00e9cile et nombre d'actions d\u00e9tenues en fonction des d\u00e9ciles  In\u00a0[\u00a0]: Copied! <pre># Calculer les d\u00e9ciles avec des intervalles \u00e9gaux\ndeciles = pd.qcut(df_actionnaire10[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')\n# Obtenir les bornes des d\u00e9ciles\ndecile_bounds = np.unique(deciles)\ndecile_bounds\n</pre> # Calculer les d\u00e9ciles avec des intervalles \u00e9gaux deciles = pd.qcut(df_actionnaire10[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop') # Obtenir les bornes des d\u00e9ciles decile_bounds = np.unique(deciles) decile_bounds Out[\u00a0]: <pre>array([Interval(3383.999, 3842.8, closed='right'),\n       Interval(3842.8, 4303.2, closed='right'),\n       Interval(4303.2, 4816.9, closed='right'),\n       Interval(4816.9, 5301.6, closed='right'),\n       Interval(5301.6, 5715.5, closed='right'),\n       Interval(5715.5, 6159.6, closed='right'),\n       Interval(6159.6, 6678.5, closed='right'),\n       Interval(6678.5, 7084.0, closed='right'),\n       Interval(7084.0, 7529.7, closed='right'),\n       Interval(7529.7, 7979.0, closed='right')], dtype=object)</pre> In\u00a0[\u00a0]: Copied! <pre>df_actionnaire10 = df_actionnaire10.sort_values(by=\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\")\n\n# Calculer les d\u00e9ciles avec des intervalles \u00e9gaux\ndeciles = pd.qcut(df_actionnaire10[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')\n\n# Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles\ndf_actionnaire10['cat\u00e9gories centiles actionnaires'] = deciles\ndf_actionnaire10['cat\u00e9gories centiles actionnaires'] = df_actionnaire10['cat\u00e9gories centiles actionnaires'].cat.codes + 1\n\n# Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d9\ndf_actionnaire10['cat\u00e9gories centiles actionnaires'] = 'C' + df_actionnaire10['cat\u00e9gories centiles actionnaires'].astype(str)\n</pre> df_actionnaire10 = df_actionnaire10.sort_values(by=\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\")  # Calculer les d\u00e9ciles avec des intervalles \u00e9gaux deciles = pd.qcut(df_actionnaire10[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"], q=10, duplicates='drop')  # Utilisez ces intervalles pour d\u00e9couper les d\u00e9ciles df_actionnaire10['cat\u00e9gories centiles actionnaires'] = deciles df_actionnaire10['cat\u00e9gories centiles actionnaires'] = df_actionnaire10['cat\u00e9gories centiles actionnaires'].cat.codes + 1  # Cr\u00e9er une nouvelle colonne avec la cat\u00e9gorie d1 \u00e0 d9 df_actionnaire10['cat\u00e9gories centiles actionnaires'] = 'C' + df_actionnaire10['cat\u00e9gories centiles actionnaires'].astype(str) In\u00a0[\u00a0]: Copied! <pre> nouveaux_noms = {\n    'C1': 'C90',\n    'C2': 'C91',\n    'C3': 'C92',\n    'C4': 'C93',\n    'C5': 'C94',\n    'C6': 'C95',\n    'C7': 'C96',\n    'C8': 'C97',\n    'C9': 'C98',\n    'C10': 'C99'\n}\n\ndf_actionnaire10['cat\u00e9gories centiles actionnaires'] = df_actionnaire10['cat\u00e9gories centiles actionnaires'].replace(nouveaux_noms)\n</pre>  nouveaux_noms = {     'C1': 'C90',     'C2': 'C91',     'C3': 'C92',     'C4': 'C93',     'C5': 'C94',     'C6': 'C95',     'C7': 'C96',     'C8': 'C97',     'C9': 'C98',     'C10': 'C99' }  df_actionnaire10['cat\u00e9gories centiles actionnaires'] = df_actionnaire10['cat\u00e9gories centiles actionnaires'].replace(nouveaux_noms)  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des cat\u00e9gories de souscripteurs au sein des 10 derniers centiles (par multi-souscripteurs ou pas)&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des cat\u00e9gories de souscripteurs au sein des 10 derniers centiles (par multi-souscripteurs ou pas)\")) R\u00e9partition des cat\u00e9gories de souscripteurs au sein des 10 derniers centiles (par multi-souscripteurs ou pas) In\u00a0[\u00a0]: Copied! <pre>df_actionnaire10['multi-souscripteur ?'] = df_actionnaire10['multi-souscripteur ?'].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"})\ndf_actionnaire_MS10 = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')['multi-souscripteur ?'].value_counts().unstack().fillna(0)\ndf_actionnaire_MS10 = df_actionnaire_MS10.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99'])\ndf_actionnaire_MS10\n</pre> df_actionnaire10['multi-souscripteur ?'] = df_actionnaire10['multi-souscripteur ?'].replace({True: \"Multi-souscripteurs\", False: \"Mono-souscripteurs\"}) df_actionnaire_MS10 = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')['multi-souscripteur ?'].value_counts().unstack().fillna(0) df_actionnaire_MS10 = df_actionnaire_MS10.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99']) df_actionnaire_MS10 Out[\u00a0]: multi-souscripteur ? Mono-souscripteurs Multi-souscripteurs cat\u00e9gories centiles actionnaires C90 53 48 C91 46 54 C92 55 45 C93 48 52 C94 55 45 C95 61 39 C96 54 46 C97 52 49 C98 52 47 C99 56 45 In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Supprimez cette ligne si vous n'utilisez pas Jupyter Notebook\n%matplotlib inline\n\n# D\u00e9finir les donn\u00e9es\ndeciles = df_actionnaire_MS10.index\nmono_souscripteurs = df_actionnaire_MS10['Mono-souscripteurs']\nmulti_souscripteurs = df_actionnaire_MS10['Multi-souscripteurs']\n\n# Cr\u00e9er le graphique en barres empil\u00e9es\nfig, ax = plt.subplots()\nbar1 = ax.bar(deciles, mono_souscripteurs, label='Mono-souscripteurs')\nbar2 = ax.bar(deciles, multi_souscripteurs, bottom=mono_souscripteurs, label='Multi-souscripteurs')\n\n# Pivoter les \u00e9tiquettes en x de 45 degr\u00e9s\nplt.xticks(rotation=45)\n\n# Ajouter des valeurs num\u00e9riques au centre de chaque partie des barres\nfor decile, bar_m, bar_multi in zip(deciles, bar1, bar2):\n    height_m = bar_m.get_height()\n    height_multi = bar_multi.get_height()\n    total = height_m + height_multi\n    ax.annotate(f'{height_m}', (decile, height_m/2), ha='center', va='bottom', color='black')\n    ax.annotate(f'{height_multi}', (decile, height_m + height_multi/2), ha='center', va='bottom', color='black')\n\n# Ajouter des labels, un titre et une l\u00e9gende\nplt.xlabel('Cat\u00e9gories Centiles Actionnaires')\nplt.ylabel('Nombre')\nplt.title('R\u00e9partition des multi-souscripteurs par cat\u00e9gories centiles actionnaires')\nplt.legend()\n\n# Afficher le graphique\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Supprimez cette ligne si vous n'utilisez pas Jupyter Notebook %matplotlib inline  # D\u00e9finir les donn\u00e9es deciles = df_actionnaire_MS10.index mono_souscripteurs = df_actionnaire_MS10['Mono-souscripteurs'] multi_souscripteurs = df_actionnaire_MS10['Multi-souscripteurs']  # Cr\u00e9er le graphique en barres empil\u00e9es fig, ax = plt.subplots() bar1 = ax.bar(deciles, mono_souscripteurs, label='Mono-souscripteurs') bar2 = ax.bar(deciles, multi_souscripteurs, bottom=mono_souscripteurs, label='Multi-souscripteurs')  # Pivoter les \u00e9tiquettes en x de 45 degr\u00e9s plt.xticks(rotation=45)  # Ajouter des valeurs num\u00e9riques au centre de chaque partie des barres for decile, bar_m, bar_multi in zip(deciles, bar1, bar2):     height_m = bar_m.get_height()     height_multi = bar_multi.get_height()     total = height_m + height_multi     ax.annotate(f'{height_m}', (decile, height_m/2), ha='center', va='bottom', color='black')     ax.annotate(f'{height_multi}', (decile, height_m + height_multi/2), ha='center', va='bottom', color='black')  # Ajouter des labels, un titre et une l\u00e9gende plt.xlabel('Cat\u00e9gories Centiles Actionnaires') plt.ylabel('Nombre') plt.title('R\u00e9partition des multi-souscripteurs par cat\u00e9gories centiles actionnaires') plt.legend()  # Afficher le graphique plt.show()  In\u00a0[\u00a0]: Copied! <pre>df_actiond\u00e9cile = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"].sum().to_frame()\ndf_actiond\u00e9cile = df_actiond\u00e9cile.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99'])\ndf_actiond\u00e9cile\n</pre> df_actiond\u00e9cile = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')[\"Fonci\u00e8re : Capital poss\u00e9d\u00e9\"].sum().to_frame() df_actiond\u00e9cile = df_actiond\u00e9cile.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99']) df_actiond\u00e9cile Out[\u00a0]: Fonci\u00e8re : Capital poss\u00e9d\u00e9 cat\u00e9gories centiles actionnaires C90 38319960 C91 42962010 C92 47706855 C93 53470935 C94 57795780 C95 62259750 C96 67156215 C97 73106460 C98 75981990 C99 82075665 In\u00a0[\u00a0]: Copied! <pre>df_actiond\u00e9cile = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].sum().to_frame()\ndf_actiond\u00e9cile = df_actiond\u00e9cile.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99'])\ndf_actiond\u00e9cile\n</pre> df_actiond\u00e9cile = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires')[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"].sum().to_frame() df_actiond\u00e9cile = df_actiond\u00e9cile.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99']) df_actiond\u00e9cile  Out[\u00a0]: Fonci\u00e8re : Nombre d'actions d\u00e9tenues cat\u00e9gories centiles actionnaires C90 364952 C91 409162 C92 454351 C93 509247 C94 550436 C95 592950 C96 639583 C97 696252 C98 723638 C99 781673 In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Supposons que vous avez d\u00e9j\u00e0 cr\u00e9\u00e9 la DataFrame df_actiond\u00e9cile\n\n# Cr\u00e9er le diagramme \u00e0 barres\nplt.figure(figsize=(10, 6))\nbars = plt.bar(df_actiond\u00e9cile.index, df_actiond\u00e9cile[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"])\n\n# Ajouter des \u00e9tiquettes de valeurs sur les barres\nfor bar in bars:\n    height = bar.get_height()\n    plt.annotate(f\"{height:.0f}\", xy=(bar.get_x() + bar.get_width() / 2, height),\n                 xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n\n# Ajouter des titres et des labels\nplt.title(\"Somme des actions d\u00e9tenues par cat\u00e9gories de centiles actionnaires\")\nplt.xlabel(\"Cat\u00e9gories centiles actionnaires\")\nplt.ylabel(\"Somme des actions d\u00e9tenues\")\n\n# Afficher le diagramme\nplt.show()\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt  # Supposons que vous avez d\u00e9j\u00e0 cr\u00e9\u00e9 la DataFrame df_actiond\u00e9cile  # Cr\u00e9er le diagramme \u00e0 barres plt.figure(figsize=(10, 6)) bars = plt.bar(df_actiond\u00e9cile.index, df_actiond\u00e9cile[\"Fonci\u00e8re : Nombre d'actions d\u00e9tenues\"])  # Ajouter des \u00e9tiquettes de valeurs sur les barres for bar in bars:     height = bar.get_height()     plt.annotate(f\"{height:.0f}\", xy=(bar.get_x() + bar.get_width() / 2, height),                  xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')  # Ajouter des titres et des labels plt.title(\"Somme des actions d\u00e9tenues par cat\u00e9gories de centiles actionnaires\") plt.xlabel(\"Cat\u00e9gories centiles actionnaires\") plt.ylabel(\"Somme des actions d\u00e9tenues\")  # Afficher le diagramme plt.show()  In\u00a0[\u00a0]: Copied! <pre># Calcul de la part de chaque d\u00e9cile d'actionnaires dans le total\ndf_grouped = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires').agg({\n    'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)': 'sum'\n})\ndf_grouped = df_grouped.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99'])\n# Affichage du tableau\ndf_grouped = df_grouped[['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)']]\ndf_grouped.index.name = 'D\u00e9ciles actionnaire'\n\n# Position des barres\nx = np.arange(len(df_grouped))\nwidth = 0.35\n\n# Cr\u00e9ation du graphique \u00e0 barres\nfig, ax = plt.subplots()\n\n# Barres pour la part du capital poss\u00e9d\u00e9\nbar1 = ax.bar(x, df_grouped['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], width, label='Part du capital poss\u00e9d\u00e9')\n\n# \u00c9tiquettes des axes et du titre\nax.set_xlabel('D\u00e9ciles actionnaire')\nax.set_ylabel('Pourcentage (%)')\nax.set_title(\"R\u00e9partition du capital parmi les 9 derniers centiles d'actionnaires\", pad=20)  # Augmenter la distance du titre au cadre\n\n# Positions des \u00e9tiquettes sur l'axe x\nax.set_xticks(x)\nax.set_xticklabels(df_grouped.index, rotation=45, ha='right')  # Inclinaison de 45 degr\u00e9s avec alignement \u00e0 droite\n\n# L\u00e9gende\nax.legend()\n\n# Affichage des valeurs au-dessus des barres\nfor rect in bar1:\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.1f}%', ha='center')\n\n# Affichage du graphique\nplt.tight_layout()  # Ajustement automatique des marges\nplt.show()\n</pre>  # Calcul de la part de chaque d\u00e9cile d'actionnaires dans le total df_grouped = df_actionnaire10.groupby('cat\u00e9gories centiles actionnaires').agg({     'Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)': 'sum' }) df_grouped = df_grouped.reindex(['C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99']) # Affichage du tableau df_grouped = df_grouped[['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)']] df_grouped.index.name = 'D\u00e9ciles actionnaire'  # Position des barres x = np.arange(len(df_grouped)) width = 0.35  # Cr\u00e9ation du graphique \u00e0 barres fig, ax = plt.subplots()  # Barres pour la part du capital poss\u00e9d\u00e9 bar1 = ax.bar(x, df_grouped['Fonci\u00e8re : Part du capital poss\u00e9d\u00e9e (%)'], width, label='Part du capital poss\u00e9d\u00e9')  # \u00c9tiquettes des axes et du titre ax.set_xlabel('D\u00e9ciles actionnaire') ax.set_ylabel('Pourcentage (%)') ax.set_title(\"R\u00e9partition du capital parmi les 9 derniers centiles d'actionnaires\", pad=20)  # Augmenter la distance du titre au cadre  # Positions des \u00e9tiquettes sur l'axe x ax.set_xticks(x) ax.set_xticklabels(df_grouped.index, rotation=45, ha='right')  # Inclinaison de 45 degr\u00e9s avec alignement \u00e0 droite  # L\u00e9gende ax.legend()  # Affichage des valeurs au-dessus des barres for rect in bar1:     height = rect.get_height()     ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.1f}%', ha='center')  # Affichage du graphique plt.tight_layout()  # Ajustement automatique des marges plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : 1 % des actionnaires (C99) poss\u00e8dent 238 848 actions soit presque 16,4 % du capital total&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : 1 % des actionnaires (C99) poss\u00e8dent 238 848 actions soit presque 16,4 % du capital total\")) Cl\u00e9 de lecture : 1 % des actionnaires (C99) poss\u00e8dent 238 848 actions soit presque 16,4 % du capital total In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des \u00e2ges parmi les 10 derniers centiles &lt;/h3&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des \u00e2ges parmi les 10 derniers centiles \")) R\u00e9partition des \u00e2ges parmi les 10 derniers centiles  In\u00a0[\u00a0]: Copied! <pre>df_Dage = pd.crosstab(index=df_actionnaire10['cat\u00e9gories \u00e2ge'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total')\ndf_Dage\n</pre> df_Dage = pd.crosstab(index=df_actionnaire10['cat\u00e9gories \u00e2ge'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total') df_Dage Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total cat\u00e9gories \u00e2ge 0-25 ans 32 28 26 27 26 32 23 38 31 28 291 25-40 ans 14 12 19 12 15 15 19 12 13 14 145 40-60 ans 23 30 20 28 24 20 19 19 24 20 227 60 ans et plus 32 30 35 33 35 33 39 32 31 39 339 Total 101 100 100 100 100 100 100 101 99 101 1002 In\u00a0[\u00a0]: Copied! <pre>df_col_percent = df_Dage.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum() \ndf_col_percent\n</pre> df_col_percent = df_Dage.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  df_col_percent  Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total cat\u00e9gories \u00e2ge 0-25 ans 31.7 28.0 26.0 27.0 26.0 32.0 23.0 37.6 31.3 27.7 29.0 25-40 ans 13.9 12.0 19.0 12.0 15.0 15.0 19.0 11.9 13.1 13.9 14.5 40-60 ans 22.8 30.0 20.0 28.0 24.0 20.0 19.0 18.8 24.2 19.8 22.7 60 ans et plus 31.7 30.0 35.0 33.0 35.0 33.0 39.0 31.7 31.3 38.6 33.8 Total 100.1 100.0 100.0 100.0 100.0 100.0 100.0 100.0 99.9 100.0 100.0 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Presque 2/3 des actionnaires du dernier centile ont plus de 60 ans&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Presque 2/3 des actionnaires du dernier centile ont plus de 60 ans\")) Presque 2/3 des actionnaires du dernier centile ont plus de 60 ans In\u00a0[\u00a0]: Copied! <pre>df_row_percent = df_Dage.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1) \ndf_row_percent\n</pre> df_row_percent = df_Dage.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  df_row_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total cat\u00e9gories \u00e2ge 0-25 ans 11.0 9.6 8.9 9.3 8.9 11.0 7.9 13.1 10.7 9.6 100.0 25-40 ans 9.7 8.3 13.1 8.3 10.3 10.3 13.1 8.3 9.0 9.7 100.1 40-60 ans 10.1 13.2 8.8 12.3 10.6 8.8 8.4 8.4 10.6 8.8 100.0 60 ans et plus 9.4 8.8 10.3 9.7 10.3 9.7 11.5 9.4 9.1 11.5 99.7 Total 10.1 10.0 10.0 10.0 10.0 10.0 10.0 10.1 9.9 10.1 100.2 In\u00a0[\u00a0]: Copied! <pre>df_DMS = pd.crosstab(index=df_actionnaire10['Cat\u00e9gories souscripteurs'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total')\ndf_DMC = pd.crosstab(index=df_actionnaire10['multi-casquette ?'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total')\ndf_Danciennet\u00e9 = pd.crosstab(index=df_actionnaire10['anciennet\u00e9 actionnaires'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total')\n</pre> df_DMS = pd.crosstab(index=df_actionnaire10['Cat\u00e9gories souscripteurs'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total') df_DMC = pd.crosstab(index=df_actionnaire10['multi-casquette ?'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total') df_Danciennet\u00e9 = pd.crosstab(index=df_actionnaire10['anciennet\u00e9 actionnaires'], columns=df_actionnaire10['cat\u00e9gories centiles actionnaires'], margins=True, margins_name='Total') In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des nombres de souscriptions au sein du 10eme d\u00e9cile &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des nombres de souscriptions au sein du 10eme d\u00e9cile \")) R\u00e9partition des nombres de souscriptions au sein du 10eme d\u00e9cile  In\u00a0[\u00a0]: Copied! <pre>ordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus', \"Total\"]\ndf_DMS = df_DMS.reindex(ordre_categories)\ndf_DMS\n</pre> ordre_categories = ['1 souscription', '2 souscriptions', '3 \u00e0 5 souscriptions', '6 \u00e0 10 souscriptions', '10 souscriptions et plus', \"Total\"] df_DMS = df_DMS.reindex(ordre_categories) df_DMS Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total Cat\u00e9gories souscripteurs 1 souscription 50 50 52 44 58 57 48 52 53 54 518 2 souscriptions 26 24 25 31 19 20 25 26 23 18 237 3 \u00e0 5 souscriptions 11 12 12 9 12 8 12 10 10 13 109 6 \u00e0 10 souscriptions 1 0 0 1 1 1 0 0 1 1 6 10 souscriptions et plus 13 14 11 15 10 14 15 13 12 15 132 Total 101 100 100 100 100 100 100 101 99 101 1002 In\u00a0[\u00a0]: Copied! <pre>df_col_percent = df_DMS.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum() \ndf_col_percent\n</pre> df_col_percent = df_DMS.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  df_col_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total Cat\u00e9gories souscripteurs 1 souscription 49.5 50.0 52.0 44.0 58.0 57.0 48.0 51.5 53.5 53.5 51.7 2 souscriptions 25.7 24.0 25.0 31.0 19.0 20.0 25.0 25.7 23.2 17.8 23.7 3 \u00e0 5 souscriptions 10.9 12.0 12.0 9.0 12.0 8.0 12.0 9.9 10.1 12.9 10.9 6 \u00e0 10 souscriptions 1.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 1.0 1.0 0.6 10 souscriptions et plus 12.9 14.0 11.0 15.0 10.0 14.0 15.0 12.9 12.1 14.9 13.2 Total 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 99.9 100.1 100.1 In\u00a0[\u00a0]: Copied! <pre>df_row_percent = df_DMS.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1) \ndf_row_percent\n</pre> df_row_percent = df_DMS.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  df_row_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total Cat\u00e9gories souscripteurs 1 souscription 9.7 9.7 10.0 8.5 11.2 11.0 9.3 10.0 10.2 10.4 100.0 2 souscriptions 11.0 10.1 10.5 13.1 8.0 8.4 10.5 11.0 9.7 7.6 99.9 3 \u00e0 5 souscriptions 10.1 11.0 11.0 8.3 11.0 7.3 11.0 9.2 9.2 11.9 100.0 6 \u00e0 10 souscriptions 16.7 0.0 0.0 16.7 16.7 16.7 0.0 0.0 16.7 16.7 100.2 10 souscriptions et plus 9.8 10.6 8.3 11.4 7.6 10.6 11.4 9.8 9.1 11.4 100.0 Total 10.1 10.0 10.0 10.0 10.0 10.0 10.0 10.1 9.9 10.1 100.2 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des types de multi-engagement parmi les 10 derniers centiles &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des types de multi-engagement parmi les 10 derniers centiles \")) R\u00e9partition des types de multi-engagement parmi les 10 derniers centiles  In\u00a0[\u00a0]: Copied! <pre>df_DMC\n</pre> df_DMC Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total multi-casquette ? Actionnaire uniquement 17 10 11 11 15 16 15 10 15 11 131 Actionnaire-adh\u00e9rent 30 43 34 31 29 32 30 42 34 29 334 Actionnaire-donateur 17 14 18 9 16 14 10 6 15 21 140 Triple-engagement 37 33 37 49 40 38 45 43 35 40 397 Total 101 100 100 100 100 100 100 101 99 101 1002 In\u00a0[\u00a0]: Copied! <pre>df_col_percent = df_DMC.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(1)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum() \ndf_col_percent\n</pre> df_col_percent = df_DMC.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(1) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  df_col_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total multi-casquette ? Actionnaire uniquement 16.8 10.0 11.0 11.0 15.0 16.0 15.0 9.9 15.2 10.9 13.1 Actionnaire-adh\u00e9rent 29.7 43.0 34.0 31.0 29.0 32.0 30.0 41.6 34.3 28.7 33.3 Actionnaire-donateur 16.8 14.0 18.0 9.0 16.0 14.0 10.0 5.9 15.2 20.8 14.0 Triple-engagement 36.6 33.0 37.0 49.0 40.0 38.0 45.0 42.6 35.4 39.6 39.6 Total 99.9 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.1 100.0 100.0 In\u00a0[\u00a0]: Copied! <pre>df_row_percent = df_DMC.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1) \ndf_row_percent\n</pre> df_row_percent = df_DMC.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  df_row_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total multi-casquette ? Actionnaire uniquement 13.0 7.6 8.4 8.4 11.5 12.2 11.5 7.6 11.5 8.4 100.1 Actionnaire-adh\u00e9rent 9.0 12.9 10.2 9.3 8.7 9.6 9.0 12.6 10.2 8.7 100.2 Actionnaire-donateur 12.1 10.0 12.9 6.4 11.4 10.0 7.1 4.3 10.7 15.0 99.9 Triple-engagement 9.3 8.3 9.3 12.3 10.1 9.6 11.3 10.8 8.8 10.1 99.9 Total 10.1 10.0 10.0 10.0 10.0 10.0 10.0 10.1 9.9 10.1 100.2 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;R\u00e9partition des aciennet\u00e9s au sein du 10eme d\u00e9cile &lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"R\u00e9partition des aciennet\u00e9s au sein du 10eme d\u00e9cile \")) R\u00e9partition des aciennet\u00e9s au sein du 10eme d\u00e9cile  In\u00a0[\u00a0]: Copied! <pre>custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins', \"Total\"]\ndf_Danciennet\u00e9 = df_Danciennet\u00e9.reindex(custom_order)\ndf_Danciennet\u00e9\n</pre> custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins', \"Total\"] df_Danciennet\u00e9 = df_Danciennet\u00e9.reindex(custom_order) df_Danciennet\u00e9 Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 36 31 33 40 31 35 29 32 47 33 347 Nouvel actionnaire entre 2012 \u00e0 2017 31 31 33 26 29 36 38 31 22 28 305 Nouvel actionnaire en 2012 ou moins 34 38 34 34 40 29 33 38 30 40 350 Total 101 100 100 100 100 100 100 101 99 101 1002 In\u00a0[\u00a0]: Copied! <pre>df_Danciennet\u00e9\n</pre> df_Danciennet\u00e9 Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 36 31 33 40 31 35 29 32 47 33 347 Nouvel actionnaire entre 2012 \u00e0 2017 31 31 33 26 29 36 38 31 22 28 305 Nouvel actionnaire en 2012 ou moins 34 38 34 34 40 29 33 38 30 40 350 Total 101 100 100 100 100 100 100 101 99 101 1002 In\u00a0[\u00a0]: Copied! <pre>df_col_percent = df_Danciennet\u00e9.copy()\ndf_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100\ndf_col_percent = df_col_percent.round(0)\ndf_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum() \ndf_col_percent\n</pre> df_col_percent = df_Danciennet\u00e9.copy() df_col_percent = df_col_percent.div(df_col_percent.loc['Total']) * 100 df_col_percent = df_col_percent.round(0) df_col_percent.iloc[-1] = df_col_percent.iloc[:-1].sum()  df_col_percent Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 36.0 31.0 33.0 40.0 31.0 35.0 29.0 32.0 47.0 33.0 35.0 Nouvel actionnaire entre 2012 \u00e0 2017 31.0 31.0 33.0 26.0 29.0 36.0 38.0 31.0 22.0 28.0 30.0 Nouvel actionnaire en 2012 ou moins 34.0 38.0 34.0 34.0 40.0 29.0 33.0 38.0 30.0 40.0 35.0 Total 101.0 100.0 100.0 100.0 100.0 100.0 100.0 101.0 99.0 101.0 100.0 In\u00a0[\u00a0]: Copied! <pre>custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins']\ndf_row_percent = df_Danciennet\u00e9.copy()\ndf_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100\ndf_row_percent = df_row_percent.round(1)\ndf_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1) \ndf_row_percent \n</pre> custom_order = ['Nouvel actionnaire depuis 2017 ou plus', 'Nouvel actionnaire entre 2012 \u00e0 2017', 'Nouvel actionnaire en 2012 ou moins'] df_row_percent = df_Danciennet\u00e9.copy() df_row_percent.iloc[:, :-1] = df_row_percent.iloc[:, :-1].div(df_row_percent['Total'], axis=0) * 100 df_row_percent = df_row_percent.round(1) df_row_percent['Total'] = df_row_percent.iloc[:, :-1].sum(axis=1)  df_row_percent  Out[\u00a0]: cat\u00e9gories centiles actionnaires C90 C91 C92 C93 C94 C95 C96 C97 C98 C99 Total anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus 10.4 8.9 9.5 11.5 8.9 10.1 8.4 9.2 13.5 9.5 99.9 Nouvel actionnaire entre 2012 \u00e0 2017 10.2 10.2 10.8 8.5 9.5 11.8 12.5 10.2 7.2 9.2 100.1 Nouvel actionnaire en 2012 ou moins 9.7 10.9 9.7 9.7 11.4 8.3 9.4 10.9 8.6 11.4 100.0 Total 10.1 10.0 10.0 10.0 10.0 10.0 10.0 10.1 9.9 10.1 100.2 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;&lt;u&gt;Analyse sur les dons d\\'actions&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  display(HTML(\"\"))   # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Analyse sur les dons d\\'actions'))  Analyse sur les dons d'actions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Ne concerne que les personnes ayant fait des dons&lt;/h3&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Ne concerne que les personnes ayant fait des dons\")) Ne concerne que les personnes ayant fait des dons In\u00a0[\u00a0]: Copied! <pre>df_nbaction = df2.groupby(\"ID du contact\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame().reset_index()\ndf_don = df[df[\"Nature du mouvement\"] ==\"Don TDL\"]\ndf_don = df_don.groupby(\"ID du contact\")[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().to_frame().reset_index()\ndf_don = pd.merge(df_don, df_nbaction[['ID du contact', 'Nombre d\\'actions \u00e0 l\\'acquisition']], on='ID du contact')\ndf_don[\"pourcentage donn\u00e9\"] = df_don[\"Nombre d'actions \u00e9chang\u00e9es\"]/df_don[\"Nombre d'actions \u00e0 l'acquisition\"] * 100\n</pre> df_nbaction = df2.groupby(\"ID du contact\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame().reset_index() df_don = df[df[\"Nature du mouvement\"] ==\"Don TDL\"] df_don = df_don.groupby(\"ID du contact\")[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().to_frame().reset_index() df_don = pd.merge(df_don, df_nbaction[['ID du contact', 'Nombre d\\'actions \u00e0 l\\'acquisition']], on='ID du contact') df_don[\"pourcentage donn\u00e9\"] = df_don[\"Nombre d'actions \u00e9chang\u00e9es\"]/df_don[\"Nombre d'actions \u00e0 l'acquisition\"] * 100 In\u00a0[\u00a0]: Copied! <pre>conditions = [\n    (df_don[\"pourcentage donn\u00e9\"] &lt; 20),\n    (df_don[\"pourcentage donn\u00e9\"] &lt; 40),\n    (df_don[\"pourcentage donn\u00e9\"] &lt; 60),\n    (df_don['pourcentage donn\u00e9'] &lt; 80),\n    (df_don['pourcentage donn\u00e9'] &lt; 100)\n]\n\nchoices = [\n    \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\"\n]\n\ndf_don[\"cat\u00e9gories des doneurs d'actions\"] = np.select(conditions, choices, default=\"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\")\n</pre> conditions = [     (df_don[\"pourcentage donn\u00e9\"] &lt; 20),     (df_don[\"pourcentage donn\u00e9\"] &lt; 40),     (df_don[\"pourcentage donn\u00e9\"] &lt; 60),     (df_don['pourcentage donn\u00e9'] &lt; 80),     (df_don['pourcentage donn\u00e9'] &lt; 100) ]  choices = [     \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\" ]  df_don[\"cat\u00e9gories des doneurs d'actions\"] = np.select(conditions, choices, default=\"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\") In\u00a0[\u00a0]: Copied! <pre>value_counts = df_don[\"cat\u00e9gories des doneurs d'actions\"].value_counts().reset_index()\nvalue_counts.columns = [\"cat\u00e9gories des doneurs d'actions\", \"Nombre d'individus\"]\ncategories_order = [ \n     \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\"]\n# Cr\u00e9er un DataFrame contenant toutes les cat\u00e9gories dans l'ordre sp\u00e9cifi\u00e9\ncategories_df = pd.DataFrame({\"cat\u00e9gories des doneurs d'actions\": categories_order})\n\n# Fusionner les donn\u00e9es avec la r\u00e9indexation\nvalue_counts_sorted = categories_df.merge(value_counts, how=\"left\")\n\nvalue_counts[\"cat\u00e9gories des doneurs d'actions\"] = value_counts[\"cat\u00e9gories des doneurs d'actions\"].astype(str)\n\n# Fusionner les donn\u00e9es avec la r\u00e9indexation\nvalue_counts_sorted = categories_df.merge(value_counts, how=\"left\")\n</pre> value_counts = df_don[\"cat\u00e9gories des doneurs d'actions\"].value_counts().reset_index() value_counts.columns = [\"cat\u00e9gories des doneurs d'actions\", \"Nombre d'individus\"] categories_order = [       \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\"] # Cr\u00e9er un DataFrame contenant toutes les cat\u00e9gories dans l'ordre sp\u00e9cifi\u00e9 categories_df = pd.DataFrame({\"cat\u00e9gories des doneurs d'actions\": categories_order})  # Fusionner les donn\u00e9es avec la r\u00e9indexation value_counts_sorted = categories_df.merge(value_counts, how=\"left\")  value_counts[\"cat\u00e9gories des doneurs d'actions\"] = value_counts[\"cat\u00e9gories des doneurs d'actions\"].astype(str)  # Fusionner les donn\u00e9es avec la r\u00e9indexation value_counts_sorted = categories_df.merge(value_counts, how=\"left\")  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Donn\u00e9es pour l'histogramme\ncategories = value_counts_sorted[\"cat\u00e9gories des doneurs d'actions\"]\ncounts = value_counts_sorted[\"Nombre d'individus\"]\n\n# Cr\u00e9er le graphique\nplt.figure(figsize=(8, 6))\nbars = plt.bar(categories, counts)\n\n# Incliner les noms des cat\u00e9gories et espacer les barres\nplt.xticks(rotation=45, ha='right')\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre d'individus appartenant aux diff\u00e9rentes cat\u00e9gories des donateurs d'actions \")\nplt.xlabel(\"\")\nplt.ylabel(\"Nombre d'individus\")\n\n# Ajouter les valeurs au-dessus de chaque barre\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, height, height, ha='center', va='bottom')\n\n# Afficher l'histogramme\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Donn\u00e9es pour l'histogramme categories = value_counts_sorted[\"cat\u00e9gories des doneurs d'actions\"] counts = value_counts_sorted[\"Nombre d'individus\"]  # Cr\u00e9er le graphique plt.figure(figsize=(8, 6)) bars = plt.bar(categories, counts)  # Incliner les noms des cat\u00e9gories et espacer les barres plt.xticks(rotation=45, ha='right')  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre d'individus appartenant aux diff\u00e9rentes cat\u00e9gories des donateurs d'actions \") plt.xlabel(\"\") plt.ylabel(\"Nombre d'individus\")  # Ajouter les valeurs au-dessus de chaque barre for bar in bars:     height = bar.get_height()     plt.text(bar.get_x() + bar.get_width() / 2, height, height, ha='center', va='bottom')  # Afficher l'histogramme plt.show()  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Parmi les souscripteurs qui ont fait des dons d'actions, il y en avait 309 qui ont donn\u00e9 toutes les actions qu'ils avaient achet\u00e9es et 13 personnes ont donn\u00e9 80 \u00e0 99 % de toutes les actions qu'ils poss\u00e9daient ([80 - 100[ % d'actions donn\u00e9es)&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Parmi les souscripteurs qui ont fait des dons d'actions, il y en avait 309 qui ont donn\u00e9 toutes les actions qu'ils avaient achet\u00e9es et 13 personnes ont donn\u00e9 80 \u00e0 99 % de toutes les actions qu'ils poss\u00e9daient ([80 - 100[ % d'actions donn\u00e9es)\")) Cl\u00e9 de lecture : Parmi les souscripteurs qui ont fait des dons d'actions, il y en avait 309 qui ont donn\u00e9 toutes les actions qu'ils avaient achet\u00e9es et 13 personnes ont donn\u00e9 80 \u00e0 99 % de toutes les actions qu'ils poss\u00e9daient ([80 - 100[ % d'actions donn\u00e9es) In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# R\u00e9cup\u00e9rer les donn\u00e9es pour le diagramme\ncategories = value_counts_sorted[\"cat\u00e9gories des doneurs d'actions\"]\ncounts = value_counts_sorted[\"Nombre d'individus\"]\n\n# Cr\u00e9er une figure et des axes\nfig, ax = plt.subplots()\n\n# D\u00e9finir l'angle de d\u00e9part du premier secteur (en degr\u00e9s)\nstartangle = 260\n\n# G\u00e9n\u00e9rer le diagramme en secteurs avec angle de d\u00e9part sp\u00e9cifi\u00e9\npie = ax.pie(counts, labels=categories, autopct='%1.1f%%', startangle=startangle)\n\n# Tourner le cercle\nax.set_aspect('equal')\n\n# Ajouter un titre\nax.set_title(\"R\u00e9partition des donateurs d'actions par cat\u00e9gorie\")\n\n# Afficher le diagramme\nplt.show()\n</pre> import matplotlib.pyplot as plt  # R\u00e9cup\u00e9rer les donn\u00e9es pour le diagramme categories = value_counts_sorted[\"cat\u00e9gories des doneurs d'actions\"] counts = value_counts_sorted[\"Nombre d'individus\"]  # Cr\u00e9er une figure et des axes fig, ax = plt.subplots()  # D\u00e9finir l'angle de d\u00e9part du premier secteur (en degr\u00e9s) startangle = 260  # G\u00e9n\u00e9rer le diagramme en secteurs avec angle de d\u00e9part sp\u00e9cifi\u00e9 pie = ax.pie(counts, labels=categories, autopct='%1.1f%%', startangle=startangle)  # Tourner le cercle ax.set_aspect('equal')  # Ajouter un titre ax.set_title(\"R\u00e9partition des donateurs d'actions par cat\u00e9gorie\")  # Afficher le diagramme plt.show()  In\u00a0[\u00a0]: Copied! <pre>df_don = df_don.merge(df[[\"Cat\u00e9gories souscripteurs\",\"multi-casquette ?\",\"anciennet\u00e9 actionnaires\",\"cat\u00e9gories \u00e2ge\", \"ID du contact\"]], on='ID du contact', how='left')\ndf_don= df_don.drop_duplicates(subset=\"ID du contact\")\n# D\u00e9finir les conditions pour les cat\u00e9gories d'actions poss\u00e9d\u00e9es\nconditions = [\n    (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 10),\n    (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50),\n    (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 200)\n]\n\n# D\u00e9finir les valeurs correspondantes pour chaque condition\nvalues = ['1 \u00e0 10 actions poss\u00e9d\u00e9es', '11 \u00e0 50 actions poss\u00e9d\u00e9es', '51 \u00e0 200 actions poss\u00e9d\u00e9es']\n\n# Appliquer les conditions et attribuer les valeurs correspondantes \u00e0 la nouvelle colonne\ndf_don[\"cat\u00e9gorie actionnaire par nombre d'actions\"] = np.select(conditions, values, default='Plus de 200 actions poss\u00e9d\u00e9es')\n</pre> df_don = df_don.merge(df[[\"Cat\u00e9gories souscripteurs\",\"multi-casquette ?\",\"anciennet\u00e9 actionnaires\",\"cat\u00e9gories \u00e2ge\", \"ID du contact\"]], on='ID du contact', how='left') df_don= df_don.drop_duplicates(subset=\"ID du contact\") # D\u00e9finir les conditions pour les cat\u00e9gories d'actions poss\u00e9d\u00e9es conditions = [     (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 10),     (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50),     (df_don[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 200) ]  # D\u00e9finir les valeurs correspondantes pour chaque condition values = ['1 \u00e0 10 actions poss\u00e9d\u00e9es', '11 \u00e0 50 actions poss\u00e9d\u00e9es', '51 \u00e0 200 actions poss\u00e9d\u00e9es']  # Appliquer les conditions et attribuer les valeurs correspondantes \u00e0 la nouvelle colonne df_don[\"cat\u00e9gorie actionnaire par nombre d'actions\"] = np.select(conditions, values, default='Plus de 200 actions poss\u00e9d\u00e9es') In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Croisement entre les caract\u00e9risitiques des donateurs et le pourcentage des leurs actions donn\u00e9es&lt;/h3&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Croisement entre les caract\u00e9risitiques des donateurs et le pourcentage des leurs actions donn\u00e9es\")) Croisement entre les caract\u00e9risitiques des donateurs et le pourcentage des leurs actions donn\u00e9es In\u00a0[\u00a0]: Copied! <pre>categories_order = [ \n     \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",\n    \"Total\"]\n</pre> categories_order = [       \"]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"[80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es\",     \"Total\"] In\u00a0[\u00a0]: Copied! <pre>df_donage = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"cat\u00e9gories \u00e2ge\"], margins=True, margins_name='Total')\ndf_donage = df_donage.reindex(categories_order)\ndf_donage\n</pre> df_donage = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"cat\u00e9gories \u00e2ge\"], margins=True, margins_name='Total') df_donage = df_donage.reindex(categories_order) df_donage Out[\u00a0]: cat\u00e9gories \u00e2ge 0-25 ans 25-40 ans 40-60 ans 60 ans et plus Total cat\u00e9gories des doneurs d'actions ]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 82 45 75 112 314 [20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 31 18 22 25 96 [40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 16 12 7 18 53 [60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 15 11 13 17 56 [80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 4 2 3 8 17 100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 87 66 66 125 344 Total 235 154 186 305 880 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les actionnaires qui donnent leurs actions ont globalement plus de 60 ans&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les actionnaires qui donnent leurs actions ont globalement plus de 60 ans\")) Les actionnaires qui donnent leurs actions ont globalement plus de 60 ans In\u00a0[\u00a0]: Copied! <pre>df_donancienet\u00e9 = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"anciennet\u00e9 actionnaires\"], margins=True, margins_name='Total')\ndf_donancienet\u00e9.reindex(categories_order)\n</pre> df_donancienet\u00e9 = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"anciennet\u00e9 actionnaires\"], margins=True, margins_name='Total') df_donancienet\u00e9.reindex(categories_order) Out[\u00a0]: anciennet\u00e9 actionnaires Nouvel actionnaire depuis 2017 ou plus Nouvel actionnaire en 2012 ou moins Nouvel actionnaire entre 2012 \u00e0 2017 Total cat\u00e9gories des doneurs d'actions ]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 112 107 95 314 [20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 44 32 20 96 [40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 17 22 14 53 [60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 16 18 22 56 [80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 6 10 1 17 100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 110 136 98 344 Total 305 325 250 880 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;Les actionnaires qui donnent leurs actions sont globalement anciens&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les actionnaires qui donnent leurs actions sont globalement anciens\")) Les actionnaires qui donnent leurs actions sont globalement anciens In\u00a0[\u00a0]: Copied! <pre>df_donMC = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"multi-casquette ?\"], margins=True, margins_name='Total')\ndf_donMC.reindex(categories_order)\n</pre> df_donMC = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"multi-casquette ?\"], margins=True, margins_name='Total') df_donMC.reindex(categories_order) Out[\u00a0]: multi-casquette ? Actionnaire uniquement Actionnaire-adh\u00e9rent Actionnaire-donateur Triple-engagement Total cat\u00e9gories des doneurs d'actions ]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 88 98 35 93 314 [20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 20 21 14 41 96 [40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 11 16 6 20 53 [60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 18 8 5 25 56 [80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 1 8 2 6 17 100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 84 104 37 119 344 Total 222 255 99 304 880 In\u00a0[\u00a0]: Copied! <pre>df_donMS = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"Cat\u00e9gories souscripteurs\"], margins=True, margins_name='Total')\ndf_donMS.reindex(categories_order)\n</pre> df_donMS = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"Cat\u00e9gories souscripteurs\"], margins=True, margins_name='Total') df_donMS.reindex(categories_order) Out[\u00a0]: Cat\u00e9gories souscripteurs 1 souscription 10 souscriptions et plus 2 souscriptions 3 \u00e0 5 souscriptions 6 \u00e0 10 souscriptions Total cat\u00e9gories des doneurs d'actions ]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 131 7 86 57 33 314 [20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 51 1 22 14 8 96 [40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 33 0 14 4 2 53 [60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 32 1 18 4 1 56 [80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 11 0 3 2 1 17 100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 271 0 56 12 5 344 Total 529 9 199 93 50 880 In\u00a0[\u00a0]: Copied! <pre>df_donnbactions = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"cat\u00e9gorie actionnaire par nombre d'actions\"], margins=True, margins_name='Total')\ndf_donnbactions.reindex(categories_order)\n</pre> df_donnbactions = pd.crosstab(index=df_don[\"cat\u00e9gories des doneurs d'actions\"], columns=df_don[\"cat\u00e9gorie actionnaire par nombre d'actions\"], margins=True, margins_name='Total') df_donnbactions.reindex(categories_order) Out[\u00a0]: cat\u00e9gorie actionnaire par nombre d'actions 1 \u00e0 10 actions poss\u00e9d\u00e9es 11 \u00e0 50 actions poss\u00e9d\u00e9es 51 \u00e0 200 actions poss\u00e9d\u00e9es Plus de 200 actions poss\u00e9d\u00e9es Total cat\u00e9gories des doneurs d'actions ]0-20[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 16 56 113 129 314 [20 - 40[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 20 38 25 13 96 [40 - 60[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 12 19 20 2 53 [60 - 80[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 19 11 21 5 56 [80 - 100[ % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 7 5 5 0 17 100 % d'actions donn\u00e9es sur le total d'actions poss\u00e9d\u00e9es 217 80 36 11 344 Total 291 209 220 160 880 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h3&gt;50% de ceux qui donnent totalement leurs actions en ont peu&lt;/h3&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"50% de ceux qui donnent totalement leurs actions en ont peu\")) 50% de ceux qui donnent totalement leurs actions en ont peu In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;u&gt;&lt;h2&gt;Analyses statistiques&lt;/u&gt;&lt;/h2&gt;&lt;/center&gt;')) \n</pre> from IPython.display import display, HTML  display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Analyses statistiques'))   Analyses statistiques In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;Les commentaires sous les analyses statistiques peuvent ne pas \u00eatre valables. Les donn\u00e9es \u00e9tant cr\u00e9ees al\u00e9atoirement \u00e0 chaque fois que le code est ex\u00e9cut\u00e9, les r\u00e9sultats des analyses sont diff\u00e9rent \u00e0 chaque fois. Laisser les commentaires permet d\\'\u00e9clairer sur les m\u00e9thodes de lecture et de compr\u00e9hension des analyses plut\u00f4t que s\\'int\u00e9resser \u00e0 leurs r\u00e9sultats m\u00eames&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  display(HTML(\"\"))  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Les commentaires sous les analyses statistiques peuvent ne pas \u00eatre valables. Les donn\u00e9es \u00e9tant cr\u00e9ees al\u00e9atoirement \u00e0 chaque fois que le code est ex\u00e9cut\u00e9, les r\u00e9sultats des analyses sont diff\u00e9rent \u00e0 chaque fois. Laisser les commentaires permet d\\'\u00e9clairer sur les m\u00e9thodes de lecture et de compr\u00e9hension des analyses plut\u00f4t que s\\'int\u00e9resser \u00e0 leurs r\u00e9sultats m\u00eames')) Les commentaires sous les analyses statistiques peuvent ne pas \u00eatre valables. Les donn\u00e9es \u00e9tant cr\u00e9ees al\u00e9atoirement \u00e0 chaque fois que le code est ex\u00e9cut\u00e9, les r\u00e9sultats des analyses sont diff\u00e9rent \u00e0 chaque fois. Laisser les commentaires permet d'\u00e9clairer sur les m\u00e9thodes de lecture et de compr\u00e9hension des analyses plut\u00f4t que s'int\u00e9resser \u00e0 leurs r\u00e9sultats m\u00eames In\u00a0[\u00a0]: Copied! <pre>df_nbaction = df2.groupby(\"ID du contact\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame().reset_index()\n</pre> df_nbaction = df2.groupby(\"ID du contact\")[\"Nombre d'actions \u00e0 l'acquisition\"].sum().to_frame().reset_index() In\u00a0[\u00a0]: Copied! <pre>df_nbaction= df_nbaction.merge(df[['ID du contact',\"Nombre de souscriptions\"]], on='ID du contact', how='left')\ndf_nbaction = df_nbaction.drop_duplicates(subset=\"ID du contact\")\n</pre> df_nbaction= df_nbaction.merge(df[['ID du contact',\"Nombre de souscriptions\"]], on='ID du contact', how='left') df_nbaction = df_nbaction.drop_duplicates(subset=\"ID du contact\") In\u00a0[\u00a0]: Copied! <pre>df_diff_mean = df_diff_mean.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\",\"Nombre de souscriptions\"]], on='ID du contact', how='left')\ndf_diff_mean = df_diff_mean.drop_duplicates(subset=\"ID du contact\")\ndf_diff_mean[\"Nombre moyen d'action par souscription\"] = df_diff_mean[\"Nombre d'actions \u00e0 l'acquisition\"]/df_diff_mean[\"Nombre de souscriptions\"]\n</pre> df_diff_mean = df_diff_mean.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\",\"Nombre de souscriptions\"]], on='ID du contact', how='left') df_diff_mean = df_diff_mean.drop_duplicates(subset=\"ID du contact\") df_diff_mean[\"Nombre moyen d'action par souscription\"] = df_diff_mean[\"Nombre d'actions \u00e0 l'acquisition\"]/df_diff_mean[\"Nombre de souscriptions\"] In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS)\ndfa = df_diff_mean.copy()\n\n# Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300\ndfa = dfa.drop(dfa[dfa[\"Nombre moyen d'action par souscription\"] &gt; 300].index)\n\n# Supprimer les lignes avec des valeurs manquantes pour la variable 'Moyenne temps pour nouvelle resouscription'\ndfa = dfa.dropna(subset=['Diff\u00e9rence'])\n\n# V\u00e9rifier le nombre de lignes apr\u00e8s la suppression des valeurs manquantes\nprint(\"Nombre de lignes apr\u00e8s suppression des valeurs manquantes :\", len(dfa))\n\n\n# D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x)\ny = dfa[\"Diff\u00e9rence\"]\nx = dfa[\"Nombre moyen d'action par souscription\"]\n\n# Ajouter une constante \u00e0 la variable ind\u00e9pendante\nx = sm.add_constant(x)\n\n# Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3)\nmodel = sm.OLS(y, x)\nresults = model.fit(cov_type='HC3')\n\n# Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste\nprint(results.summary())\n\n# Plot des donn\u00e9es avec la ligne de r\u00e9gression\nplt.scatter(dfa[\"Nombre moyen d'action par souscription\"], dfa[\"Diff\u00e9rence\"])\nplt.plot(dfa[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2)\nplt.xlabel(\"Nombre moyen d'action par souscription\")\nplt.ylabel(\"Moyenne temps pour nouvelle resouscription\")\nplt.title(\"R\u00e9gression lin\u00e9aire du temps moyen pour nouvelle resouscription par rapport au nombre moyen d'actions par souscription\")\nplt.show()\n</pre> import pandas as pd import statsmodels.api as sm import matplotlib.pyplot as plt  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS) dfa = df_diff_mean.copy()  # Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300 dfa = dfa.drop(dfa[dfa[\"Nombre moyen d'action par souscription\"] &gt; 300].index)  # Supprimer les lignes avec des valeurs manquantes pour la variable 'Moyenne temps pour nouvelle resouscription' dfa = dfa.dropna(subset=['Diff\u00e9rence'])  # V\u00e9rifier le nombre de lignes apr\u00e8s la suppression des valeurs manquantes print(\"Nombre de lignes apr\u00e8s suppression des valeurs manquantes :\", len(dfa))   # D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x) y = dfa[\"Diff\u00e9rence\"] x = dfa[\"Nombre moyen d'action par souscription\"]  # Ajouter une constante \u00e0 la variable ind\u00e9pendante x = sm.add_constant(x)  # Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3) model = sm.OLS(y, x) results = model.fit(cov_type='HC3')  # Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste print(results.summary())  # Plot des donn\u00e9es avec la ligne de r\u00e9gression plt.scatter(dfa[\"Nombre moyen d'action par souscription\"], dfa[\"Diff\u00e9rence\"]) plt.plot(dfa[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2) plt.xlabel(\"Nombre moyen d'action par souscription\") plt.ylabel(\"Moyenne temps pour nouvelle resouscription\") plt.title(\"R\u00e9gression lin\u00e9aire du temps moyen pour nouvelle resouscription par rapport au nombre moyen d'actions par souscription\") plt.show()    <pre>Nombre de lignes apr\u00e8s suppression des valeurs manquantes : 4125\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             Diff\u00e9rence   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.3046\nDate:                Thu, 28 Sep 2023   Prob (F-statistic):              0.581\nTime:                        14:13:29   Log-Likelihood:                -9888.6\nNo. Observations:                4125   AIC:                         1.978e+04\nDf Residuals:                    4123   BIC:                         1.979e+04\nDf Model:                           1                                         \nCovariance Type:                  HC3                                         \n==========================================================================================================\n                                             coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------------\nconst                                      2.8386      0.056     51.019      0.000       2.730       2.948\nNombre moyen d'action par souscription    -0.0004      0.001     -0.552      0.581      -0.002       0.001\n==============================================================================\nOmnibus:                     1173.394   Durbin-Watson:                   1.994\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             2839.260\nSkew:                           1.579   Prob(JB):                         0.00\nKurtosis:                       5.560   Cond. No.                         104.\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Il y a peu de lien entre le laps de temps pour reprendre une souscription et le nombre moyen d'actions prises par souscription. On remarque que la ligne rouge est presque horizontale. Alors que plus cette derni\u00e8re est verticale plus il y a une corr\u00e9lation forte entre les 2 variables. De plus si la ligne monte vers le ciel, il y a une corr\u00e9lation positive et inversement. Ici on remarque que la ligne plonge. On remarque que les personnes qui ont pris beaucoup d'actions par souscription en moyenne ont tendance \u00e0 reprendre des souscriptions de mani\u00e8re moins espac\u00e9e. Le fait d'avoir une moyenne d'actions par souscription avec une unit\u00e9 en moins diminurait 0.0020 fois le laps de temps pour reprendre une souscription&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Il y a peu de lien entre le laps de temps pour reprendre une souscription et le nombre moyen d'actions prises par souscription. On remarque que la ligne rouge est presque horizontale. Alors que plus cette derni\u00e8re est verticale plus il y a une corr\u00e9lation forte entre les 2 variables. De plus si la ligne monte vers le ciel, il y a une corr\u00e9lation positive et inversement. Ici on remarque que la ligne plonge. On remarque que les personnes qui ont pris beaucoup d'actions par souscription en moyenne ont tendance \u00e0 reprendre des souscriptions de mani\u00e8re moins espac\u00e9e. Le fait d'avoir une moyenne d'actions par souscription avec une unit\u00e9 en moins diminurait 0.0020 fois le laps de temps pour reprendre une souscription\")) Cl\u00e9 de lecture : Il y a peu de lien entre le laps de temps pour reprendre une souscription et le nombre moyen d'actions prises par souscription. On remarque que la ligne rouge est presque horizontale. Alors que plus cette derni\u00e8re est verticale plus il y a une corr\u00e9lation forte entre les 2 variables. De plus si la ligne monte vers le ciel, il y a une corr\u00e9lation positive et inversement. Ici on remarque que la ligne plonge. On remarque que les personnes qui ont pris beaucoup d'actions par souscription en moyenne ont tendance \u00e0 reprendre des souscriptions de mani\u00e8re moins espac\u00e9e. Le fait d'avoir une moyenne d'actions par souscription avec une unit\u00e9 en moins diminurait 0.0020 fois le laps de temps pour reprendre une souscription In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime, timedelta\ndf_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"] == \"Rachat\"]\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.groupby(\"ID du contact\")[\"dur\u00e9e conservation\"].mean().to_frame().reset_index()\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop(df_dur\u00e9e_conserv[df_dur\u00e9e_conserv[\"dur\u00e9e conservation\"] &lt; timedelta(days=0)].index)\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\",\"Nombre de souscriptions\"]], on='ID du contact', how='left')\ndf_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop_duplicates(subset=\"ID du contact\")\ndf_dur\u00e9e_conserv[\"Nombre moyen d'action par souscription\"] = df_dur\u00e9e_conserv[\"Nombre d'actions \u00e0 l'acquisition\"]/df_dur\u00e9e_conserv[\"Nombre de souscriptions\"]\n</pre> from datetime import datetime, timedelta df_dur\u00e9e_conserv = df[df[\"Nature du mouvement\"] == \"Rachat\"] df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.groupby(\"ID du contact\")[\"dur\u00e9e conservation\"].mean().to_frame().reset_index() df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop(df_dur\u00e9e_conserv[df_dur\u00e9e_conserv[\"dur\u00e9e conservation\"] &lt; timedelta(days=0)].index) df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\",\"Nombre de souscriptions\"]], on='ID du contact', how='left') df_dur\u00e9e_conserv = df_dur\u00e9e_conserv.drop_duplicates(subset=\"ID du contact\") df_dur\u00e9e_conserv[\"Nombre moyen d'action par souscription\"] = df_dur\u00e9e_conserv[\"Nombre d'actions \u00e0 l'acquisition\"]/df_dur\u00e9e_conserv[\"Nombre de souscriptions\"]  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS)\ndfb = df_dur\u00e9e_conserv.copy()\n\n# Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300\ndfb = dfb.drop(dfb[dfb[\"Nombre moyen d'action par souscription\"] &gt; 300].index)\n\n# Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es\ndfb = dfb.dropna(subset=['dur\u00e9e conservation', \"Nombre moyen d'action par souscription\"])\n\n# Convertir la variable \"Moyenne temps pour nouvelle resouscription\" en ann\u00e9es (num\u00e9rique)\ndfb[\"dur\u00e9e conservation\"] = dfb[\"dur\u00e9e conservation\"] / pd.Timedelta(days=365)\n\n# D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x)\ny = dfb[\"dur\u00e9e conservation\"]\nx = dfb[\"Nombre moyen d'action par souscription\"]\n\n# Ajouter une constante \u00e0 la variable ind\u00e9pendante\nx = sm.add_constant(x)\n\n# Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3)\nmodel = sm.OLS(y, x)\nresults = model.fit(cov_type='HC3')\n\n# Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste\nprint(results.summary())\n\n# Plot des donn\u00e9es avec la ligne de r\u00e9gression\nplt.scatter(dfb[\"Nombre moyen d'action par souscription\"], dfb[\"dur\u00e9e conservation\"])\nplt.plot(dfb[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2)\nplt.xlabel(\"Nombre moyen d'action par souscription\")\nplt.ylabel(\"intervalle moyen entre interaction avec un contrat\")\nplt.title(\"R\u00e9gression lin\u00e9aire de l'intervalle moyen  (en ann\u00e9e) entre interaction avec un contrat par rapport au nombre moyen d'actions par souscription\")\nplt.show()\n</pre> import pandas as pd import statsmodels.api as sm  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS) dfb = df_dur\u00e9e_conserv.copy()  # Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300 dfb = dfb.drop(dfb[dfb[\"Nombre moyen d'action par souscription\"] &gt; 300].index)  # Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es dfb = dfb.dropna(subset=['dur\u00e9e conservation', \"Nombre moyen d'action par souscription\"])  # Convertir la variable \"Moyenne temps pour nouvelle resouscription\" en ann\u00e9es (num\u00e9rique) dfb[\"dur\u00e9e conservation\"] = dfb[\"dur\u00e9e conservation\"] / pd.Timedelta(days=365)  # D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x) y = dfb[\"dur\u00e9e conservation\"] x = dfb[\"Nombre moyen d'action par souscription\"]  # Ajouter une constante \u00e0 la variable ind\u00e9pendante x = sm.add_constant(x)  # Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3) model = sm.OLS(y, x) results = model.fit(cov_type='HC3')  # Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste print(results.summary())  # Plot des donn\u00e9es avec la ligne de r\u00e9gression plt.scatter(dfb[\"Nombre moyen d'action par souscription\"], dfb[\"dur\u00e9e conservation\"]) plt.plot(dfb[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2) plt.xlabel(\"Nombre moyen d'action par souscription\") plt.ylabel(\"intervalle moyen entre interaction avec un contrat\") plt.title(\"R\u00e9gression lin\u00e9aire de l'intervalle moyen  (en ann\u00e9e) entre interaction avec un contrat par rapport au nombre moyen d'actions par souscription\") plt.show()  <pre>                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     dur\u00e9e conservation   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                 4.345e-05\nDate:                Thu, 28 Sep 2023   Prob (F-statistic):              0.995\nTime:                        14:13:29   Log-Likelihood:                -3307.6\nNo. Observations:                1151   AIC:                             6619.\nDf Residuals:                    1149   BIC:                             6629.\nDf Model:                           1                                         \nCovariance Type:                  HC3                                         \n==========================================================================================================\n                                             coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------------\nconst                                      6.8504      0.159     43.110      0.000       6.539       7.162\nNombre moyen d'action par souscription -1.534e-05      0.002     -0.007      0.995      -0.005       0.005\n==============================================================================\nOmnibus:                      178.372   Durbin-Watson:                   1.979\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               55.879\nSkew:                           0.285   Prob(JB):                     7.35e-13\nKurtosis:                       2.084   Cond. No.                         89.8\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : Pour le test pr\u00e9cent, dans le tableau ''OLS Regression Results'', on observe que pour la variable ''Nombre moyen d'actions par souscription'' une valeur P&gt;|z| a \u00e9t\u00e9 calcul\u00e9e \u00e0 0.096 soit 9,6 % de chances de se tromper en affirmant qu'il puisse avoir une corr\u00e9lation entre le nombre moyen d'actions par souscription par personne et le fait que cette personne ait pris plus ou moins de temps avant de faire un rachat d'actions sur un de ses contrats. Il est pr\u00e9f\u00e9rable que la valeur ''P&gt;|z|' calcul\u00e9e soit inf\u00e9rieure \u00e0 0,05 pour pouvoir affirmer qu'il y ait un lien entre 2 variables. En plus de ne rien pouvoir affirmer sur le lien entre les 2 variables prises en compte, on voit que la relation entre ces derni\u00e8res est potentiellement tr\u00e8s faible. Une unit\u00e9 en plus du nombre moyen d'actions par souscriptions diminuerait de 0.0025 fois le laps de temps pour un rachat d'actions&lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : Pour le test pr\u00e9cent, dans le tableau ''OLS Regression Results'', on observe que pour la variable ''Nombre moyen d'actions par souscription'' une valeur P&gt;|z| a \u00e9t\u00e9 calcul\u00e9e \u00e0 0.096 soit 9,6 % de chances de se tromper en affirmant qu'il puisse avoir une corr\u00e9lation entre le nombre moyen d'actions par souscription par personne et le fait que cette personne ait pris plus ou moins de temps avant de faire un rachat d'actions sur un de ses contrats. Il est pr\u00e9f\u00e9rable que la valeur ''P&gt;|z|' calcul\u00e9e soit inf\u00e9rieure \u00e0 0,05 pour pouvoir affirmer qu'il y ait un lien entre 2 variables. En plus de ne rien pouvoir affirmer sur le lien entre les 2 variables prises en compte, on voit que la relation entre ces derni\u00e8res est potentiellement tr\u00e8s faible. Une unit\u00e9 en plus du nombre moyen d'actions par souscriptions diminuerait de 0.0025 fois le laps de temps pour un rachat d'actions\")) Cl\u00e9 de lecture : Pour le test pr\u00e9cent, dans le tableau ''OLS Regression Results'', on observe que pour la variable ''Nombre moyen d'actions par souscription'' une valeur P&gt;|z| a \u00e9t\u00e9 calcul\u00e9e \u00e0 0.096 soit 9,6 % de chances de se tromper en affirmant qu'il puisse avoir une corr\u00e9lation entre le nombre moyen d'actions par souscription par personne et le fait que cette personne ait pris plus ou moins de temps avant de faire un rachat d'actions sur un de ses contrats. Il est pr\u00e9f\u00e9rable que la valeur ''P&gt;|z|' calcul\u00e9e soit inf\u00e9rieure \u00e0 0,05 pour pouvoir affirmer qu'il y ait un lien entre 2 variables. En plus de ne rien pouvoir affirmer sur le lien entre les 2 variables prises en compte, on voit que la relation entre ces derni\u00e8res est potentiellement tr\u00e8s faible. Une unit\u00e9 en plus du nombre moyen d'actions par souscriptions diminuerait de 0.0025 fois le laps de temps pour un rachat d'actions In\u00a0[\u00a0]: Copied! <pre>df_retraitdef =  df_retraitdef.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\"]], on='ID du contact', how='left')\ndf_retraitdef =  df_retraitdef.drop_duplicates(subset=\"ID du contact\")\n</pre> df_retraitdef =  df_retraitdef.merge(df_nbaction[[\"ID du contact\",\"Nombre d'actions \u00e0 l'acquisition\"]], on='ID du contact', how='left') df_retraitdef =  df_retraitdef.drop_duplicates(subset=\"ID du contact\") In\u00a0[\u00a0]: Copied! <pre>df_retraitdef[\"Nombre moyen d'action par souscription\"] = df_retraitdef[\"Nombre d'actions \u00e0 l'acquisition_y\"]/df_retraitdef[\"Nombre de souscriptions\"]\n</pre> df_retraitdef[\"Nombre moyen d'action par souscription\"] = df_retraitdef[\"Nombre d'actions \u00e0 l'acquisition_y\"]/df_retraitdef[\"Nombre de souscriptions\"] In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS)\ndfc = df_retraitdef.copy()\n\n# Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300\ndfc = dfc.drop(dfc[dfc[\"Nombre moyen d'action par souscription\"] &gt; 300].index)\n\n# Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es\ndfc = dfc.dropna(subset=['Dur\u00e9e actionnariat', \"Nombre moyen d'action par souscription\"])\n\n\n# D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x)\ny = dfc[\"Dur\u00e9e actionnariat\"]\nx = dfc[\"Nombre moyen d'action par souscription\"]\n\n# Ajouter une constante \u00e0 la variable ind\u00e9pendante\nx = sm.add_constant(x)\n\n# Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3)\nmodel = sm.OLS(y, x)\nresults = model.fit(cov_type='HC3')\n\n# Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste\nprint(results.summary())\n\n# Plot des donn\u00e9es avec la ligne de r\u00e9gression\nplt.scatter(dfc[\"Nombre moyen d'action par souscription\"], dfc[\"Dur\u00e9e actionnariat\"])\nplt.plot(dfc[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2)\nplt.xlabel(\"Nombre moyen d'action par souscription\")\nplt.ylabel(\"Moyenne dur\u00e9e actionnariat\")\nplt.title(\"R\u00e9gression lin\u00e9aire de la dur\u00e9e de vie d'actionnaire par rapport au nombre moyen d'actions par souscription\")\nplt.show()\n</pre> import pandas as pd import statsmodels.api as sm  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (merged_dffinalMS) dfc = df_retraitdef.copy()  # Supprimer les lignes o\u00f9 la variable \"Nombre moyen d'action par souscription\" d\u00e9passe 300 dfc = dfc.drop(dfc[dfc[\"Nombre moyen d'action par souscription\"] &gt; 300].index)  # Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es dfc = dfc.dropna(subset=['Dur\u00e9e actionnariat', \"Nombre moyen d'action par souscription\"])   # D\u00e9finir les variables d\u00e9pendante (y) et ind\u00e9pendante (x) y = dfc[\"Dur\u00e9e actionnariat\"] x = dfc[\"Nombre moyen d'action par souscription\"]  # Ajouter une constante \u00e0 la variable ind\u00e9pendante x = sm.add_constant(x)  # Cr\u00e9er un mod\u00e8le de r\u00e9gression lin\u00e9aire et ajuster aux donn\u00e9es avec covariance robuste (HC3) model = sm.OLS(y, x) results = model.fit(cov_type='HC3')  # Afficher les r\u00e9sultats de la r\u00e9gression avec covariance robuste print(results.summary())  # Plot des donn\u00e9es avec la ligne de r\u00e9gression plt.scatter(dfc[\"Nombre moyen d'action par souscription\"], dfc[\"Dur\u00e9e actionnariat\"]) plt.plot(dfc[\"Nombre moyen d'action par souscription\"], results.fittedvalues, color='red', linewidth=2) plt.xlabel(\"Nombre moyen d'action par souscription\") plt.ylabel(\"Moyenne dur\u00e9e actionnariat\") plt.title(\"R\u00e9gression lin\u00e9aire de la dur\u00e9e de vie d'actionnaire par rapport au nombre moyen d'actions par souscription\") plt.show() <pre>                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     Dur\u00e9e actionnariat   R-squared:                       0.001\nModel:                            OLS   Adj. R-squared:                 -0.011\nMethod:                 Least Squares   F-statistic:                    0.1019\nDate:                Thu, 28 Sep 2023   Prob (F-statistic):              0.750\nTime:                        14:13:30   Log-Likelihood:                -240.34\nNo. Observations:                  86   AIC:                             484.7\nDf Residuals:                      84   BIC:                             489.6\nDf Model:                           1                                         \nCovariance Type:                  HC3                                         \n==========================================================================================================\n                                             coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------------\nconst                                      7.8337      0.547     14.324      0.000       6.762       8.906\nNombre moyen d'action par souscription     0.0025      0.008      0.319      0.750      -0.013       0.018\n==============================================================================\nOmnibus:                        2.710   Durbin-Watson:                   1.695\nProb(Omnibus):                  0.258   Jarque-Bera (JB):                1.906\nSkew:                           0.170   Prob(JB):                        0.386\nKurtosis:                       2.355   Cond. No.                         73.3\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA des nombres de souscriptions en fonction des retraits partiels ou non d'actions sur un contrat&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA des nombres de souscriptions en fonction des retraits partiels ou non d'actions sur un contrat\")) ANOVA des nombres de souscriptions en fonction des retraits partiels ou non d'actions sur un contrat In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_actionnaireretrait)\ndf = df_retrait\n# Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es\ndf = df.dropna(subset=[\"Nombre de souscriptions\", \"retrait complet ou partiel\"])\n# Effectuer l'ANOVA\nmodel = ols('df[\"Nombre de souscriptions\"] ~ C(df[\"retrait complet ou partiel\"])', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"Nombre de souscriptions\"], df['retrait complet ou partiel'])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_actionnaireretrait) df = df_retrait # Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es df = df.dropna(subset=[\"Nombre de souscriptions\", \"retrait complet ou partiel\"]) # Effectuer l'ANOVA model = ols('df[\"Nombre de souscriptions\"] ~ C(df[\"retrait complet ou partiel\"])', data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"Nombre de souscriptions\"], df['retrait complet ou partiel'])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc) <pre>                                          sum_sq      df         F    PR(&gt;F)\nC(df[\"retrait complet ou partiel\"])     6.609192     1.0  1.562966  0.211398\nResidual                             7446.602379  1761.0       NaN       NaN\n         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n=====================================================================\n     group1          group2     meandiff p-adj   lower  upper  reject\n---------------------------------------------------------------------\nretrait complet retrait partiel   0.1666 0.2114 -0.0947 0.4278  False\n---------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Cl\u00e9 de lecture : On peut affirmer qu'il y a un lien entre le fait de vider compl\u00e8tement ou pas un contrat de ses actions et le fait d'avoir plus ou moins pris de souscriptions. On remarque que la valeur ''p-adj'' (un \u00e9quivalent de la valeur P&gt;|z|) est \u00e9gale \u00e0 0.009. On a 0,9 % de chance de se tromper en affirmant cela. Cependant cette relation est minime. Les personnes ayant vid\u00e9 partiellement un de leurs contrats en faisant un rachat d'actions (retrait partiel) avaient en moyenne 0,65 souscription de moins que ceux qui ont vid\u00e9 compl\u00e8tement leurs contrats. De plus la v\u00e9rification du lien entre ces variables est un peu biais\u00e9e dans le sens ou une m\u00eame personne aura pu faire des retraits partiels et des retraits complets \u00e0 la fois  &lt;/h4&gt;\"))\n</pre>  from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Cl\u00e9 de lecture : On peut affirmer qu'il y a un lien entre le fait de vider compl\u00e8tement ou pas un contrat de ses actions et le fait d'avoir plus ou moins pris de souscriptions. On remarque que la valeur ''p-adj'' (un \u00e9quivalent de la valeur P&gt;|z|) est \u00e9gale \u00e0 0.009. On a 0,9 % de chance de se tromper en affirmant cela. Cependant cette relation est minime. Les personnes ayant vid\u00e9 partiellement un de leurs contrats en faisant un rachat d'actions (retrait partiel) avaient en moyenne 0,65 souscription de moins que ceux qui ont vid\u00e9 compl\u00e8tement leurs contrats. De plus la v\u00e9rification du lien entre ces variables est un peu biais\u00e9e dans le sens ou une m\u00eame personne aura pu faire des retraits partiels et des retraits complets \u00e0 la fois  \")) Cl\u00e9 de lecture : On peut affirmer qu'il y a un lien entre le fait de vider compl\u00e8tement ou pas un contrat de ses actions et le fait d'avoir plus ou moins pris de souscriptions. On remarque que la valeur ''p-adj'' (un \u00e9quivalent de la valeur P&gt;|z|) est \u00e9gale \u00e0 0.009. On a 0,9 % de chance de se tromper en affirmant cela. Cependant cette relation est minime. Les personnes ayant vid\u00e9 partiellement un de leurs contrats en faisant un rachat d'actions (retrait partiel) avaient en moyenne 0,65 souscription de moins que ceux qui ont vid\u00e9 compl\u00e8tement leurs contrats. De plus la v\u00e9rification du lien entre ces variables est un peu biais\u00e9e dans le sens ou une m\u00eame personne aura pu faire des retraits partiels et des retraits complets \u00e0 la fois   In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA moyenne des nombres de souscriptions en fonction des retraits d\u00e9finitifs ou non de ses actions&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA moyenne des nombres de souscriptions en fonction des retraits d\u00e9finitifs ou non de ses actions\")) ANOVA moyenne des nombres de souscriptions en fonction des retraits d\u00e9finitifs ou non de ses actions In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_actionnaireretrait)\ndf = df_retrait\n# Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es\ndf = df.dropna(subset=[\"Nombre de souscriptions\", \"nature du retrait\"])\n# Effectuer l'ANOVA\nmodel = ols('df[\"Nombre de souscriptions\"] ~ C(df[\"nature du retrait\"])', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"Nombre de souscriptions\"], df['nature du retrait'])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_actionnaireretrait) df = df_retrait # Supprimer les lignes avec des valeurs manquantes pour les variables concern\u00e9es df = df.dropna(subset=[\"Nombre de souscriptions\", \"nature du retrait\"]) # Effectuer l'ANOVA model = ols('df[\"Nombre de souscriptions\"] ~ C(df[\"nature du retrait\"])', data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"Nombre de souscriptions\"], df['nature du retrait'])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc)  <pre>                                 sum_sq      df         F        PR(&gt;F)\nC(df[\"nature du retrait\"])   101.068215     1.0  24.20806  9.453356e-07\nResidual                    7352.143357  1761.0       NaN           NaN\n         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n=====================================================================\n      group1           group2     meandiff p-adj lower  upper  reject\n---------------------------------------------------------------------\nretrait d\u00e9finitif retrait partiel   1.0822   0.0 0.6508 1.5135   True\n---------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Ceux qui n'ont pas fait de retrait d\u00e9finitif ont en moyenne 3 souscriptions de plus que ceux qui l'ont fait &lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Ceux qui n'ont pas fait de retrait d\u00e9finitif ont en moyenne 3 souscriptions de plus que ceux qui l'ont fait \")) Ceux qui n'ont pas fait de retrait d\u00e9finitif ont en moyenne 3 souscriptions de plus que ceux qui l'ont fait  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA nombre d'actions des contrats en fonction du retrait total ou pas des actions par contrat &lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA nombre d'actions des contrats en fonction du retrait total ou pas des actions par contrat \")) ANOVA nombre d'actions des contrats en fonction du retrait total ou pas des actions par contrat  In\u00a0[\u00a0]: Copied! <pre>df_retrait = df_retrait.merge(df_nbaction[[\"Nombre d\\'actions \u00e0 l\\'acquisition\", \"ID du contact\"]], on='ID du contact', how='left')\ndf_retrait = df_retrait.drop_duplicates(subset=\"Mouvement de titre Name\")\ndf_retrait[\"Nombre moyen action par souscription\"] = df_retrait[\"Nombre d\\'actions \u00e0 l\\'acquisition_y\"]/df_retrait[\"Nombre de souscriptions\"]\n</pre> df_retrait = df_retrait.merge(df_nbaction[[\"Nombre d\\'actions \u00e0 l\\'acquisition\", \"ID du contact\"]], on='ID du contact', how='left') df_retrait = df_retrait.drop_duplicates(subset=\"Mouvement de titre Name\") df_retrait[\"Nombre moyen action par souscription\"] = df_retrait[\"Nombre d\\'actions \u00e0 l\\'acquisition_y\"]/df_retrait[\"Nombre de souscriptions\"] In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_retrait\ndf = df.dropna(subset=[\"Nombre d'actions \u00e0 l'acquisition_x\", 'retrait complet ou partiel'])\n\n# Effectuer l'ANOVA\nmodel = ols(\"df[\\\"Nombre d'actions \u00e0 l'acquisition_x\\\"] ~ C(df['retrait complet ou partiel'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"Nombre d'actions \u00e0 l'acquisition_x\"], df['retrait complet ou partiel'])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_retrait df = df.dropna(subset=[\"Nombre d'actions \u00e0 l'acquisition_x\", 'retrait complet ou partiel'])  # Effectuer l'ANOVA model = ols(\"df[\\\"Nombre d'actions \u00e0 l'acquisition_x\\\"] ~ C(df['retrait complet ou partiel'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"Nombre d'actions \u00e0 l'acquisition_x\"], df['retrait complet ou partiel'])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc)  <pre>                                           sum_sq      df          F    PR(&gt;F)\nC(df['retrait complet ou partiel'])  1.306261e+05     1.0  14.333277  0.000156\nResidual                             2.515321e+07  2760.0        NaN       NaN\n         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n=====================================================================\n     group1          group2     meandiff p-adj  lower   upper  reject\n---------------------------------------------------------------------\nretrait complet retrait partiel  18.5395 0.0002 8.9374 28.1415   True\n---------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les contrats qui sont vid\u00e9s compl\u00e8tement ont beaucoup moins d'actions initialement \u00e0 leur activation&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les contrats qui sont vid\u00e9s compl\u00e8tement ont beaucoup moins d'actions initialement \u00e0 leur activation\")) Les contrats qui sont vid\u00e9s compl\u00e8tement ont beaucoup moins d'actions initialement \u00e0 leur activation In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA moyenne des nombres d'actions par souscription par personne en fonction du retrait total ou pas des actions par contrat &lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA moyenne des nombres d'actions par souscription par personne en fonction du retrait total ou pas des actions par contrat \")) ANOVA moyenne des nombres d'actions par souscription par personne en fonction du retrait total ou pas des actions par contrat  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_retrait\ndf = df.dropna(subset=['Nombre moyen action par souscription', 'retrait complet ou partiel'])\n# Effectuer l'ANOVA\nmodel = ols(\"df['Nombre moyen action par souscription'] ~ C(df['retrait complet ou partiel'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df['Nombre moyen action par souscription'], df['retrait complet ou partiel'])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_retrait df = df.dropna(subset=['Nombre moyen action par souscription', 'retrait complet ou partiel']) # Effectuer l'ANOVA model = ols(\"df['Nombre moyen action par souscription'] ~ C(df['retrait complet ou partiel'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df['Nombre moyen action par souscription'], df['retrait complet ou partiel'])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc)  <pre>                                           sum_sq      df         F    PR(&gt;F)\nC(df['retrait complet ou partiel'])  1.552296e+02     1.0  0.025288  0.873669\nResidual                             1.077901e+07  1756.0       NaN       NaN\n         Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n======================================================================\n     group1          group2     meandiff p-adj   lower   upper  reject\n----------------------------------------------------------------------\nretrait complet retrait partiel  -0.8086 0.8737 -10.7808 9.1637  False\n----------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt; Ce sont les plus petits actionnaires qui vident les contrats compl\u00e8tement&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\" Ce sont les plus petits actionnaires qui vident les contrats compl\u00e8tement\"))  Ce sont les plus petits actionnaires qui vident les contrats compl\u00e8tement In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA moyenne des nombres d'actions en fonction du retrait d\u00e9finitif ou pas des actions &lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA moyenne des nombres d'actions en fonction du retrait d\u00e9finitif ou pas des actions \")) ANOVA moyenne des nombres d'actions en fonction du retrait d\u00e9finitif ou pas des actions  In\u00a0[\u00a0]: Copied! <pre>df_retrait.rename(columns={\"Nombre d'actions \u00e0 l'acquisition_y\": \"nombre_action_totale\"}, inplace=True)\n</pre> df_retrait.rename(columns={\"Nombre d'actions \u00e0 l'acquisition_y\": \"nombre_action_totale\"}, inplace=True)  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_retrait.copy()\ndf = df.dropna(subset=[\"nombre_action_totale\", 'nature du retrait'])\n\n# Effectuer l'ANOVA\nmodel = ols(\"df['nombre_action_totale'] ~ C(df['nature du retrait'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"nombre_action_totale\"], df['nature du retrait'])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_retrait.copy() df = df.dropna(subset=[\"nombre_action_totale\", 'nature du retrait'])  # Effectuer l'ANOVA model = ols(\"df['nombre_action_totale'] ~ C(df['nature du retrait'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"nombre_action_totale\"], df['nature du retrait'])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc)   <pre>                                  sum_sq      df         F    PR(&gt;F)\nC(df['nature du retrait'])  2.898909e+05     1.0  9.347905  0.002266\nResidual                    5.445589e+07  1756.0       NaN       NaN\n          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n=======================================================================\n      group1           group2     meandiff p-adj   lower  upper  reject\n-----------------------------------------------------------------------\nretrait d\u00e9finitif retrait partiel  57.9613 0.0023 20.7797 95.143   True\n-----------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt; Les personnes qui font des retraits d\u00e9fintifs ont g\u00e9n\u00e9ralement moins d'actions (221 en moins en moyenne)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\" Les personnes qui font des retraits d\u00e9fintifs ont g\u00e9n\u00e9ralement moins d'actions (221 en moins en moyenne)\"))  Les personnes qui font des retraits d\u00e9fintifs ont g\u00e9n\u00e9ralement moins d'actions (221 en moins en moyenne) In\u00a0[\u00a0]: Copied! <pre>df_RFsous = df2.copy()\ndf_RFsous= df_RFsous[df_RFsous[\"Nature du mouvement\"]== \"Souscription\"]\n\ndf_RFsous[\"cat\u00e9gorie souscription\"] = df_RFsous.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5\n                                          else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50\n                                          else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100\n                                          else \"Souscriptions de plus de 100 actions\",\n                                          axis = 1) \n</pre> df_RFsous = df2.copy() df_RFsous= df_RFsous[df_RFsous[\"Nature du mouvement\"]== \"Souscription\"]  df_RFsous[\"cat\u00e9gorie souscription\"] = df_RFsous.apply( lambda row : \"Souscription de 5 actions ou moins\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;=5                                           else \"Souscription de 6 \u00e0 50 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 50                                           else \"Souscriptions de 51 \u00e0 100 actions\" if row[\"Nombre d'actions \u00e0 l'acquisition\"] &lt;= 100                                           else \"Souscriptions de plus de 100 actions\",                                           axis = 1)  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;Test Chi-2 pour tester la relation entre les cat\u00e9gories de souscriptions (diff\u00e9rentes cat\u00e9gories de nombres d'actions par souscription) avec le fait de demander un re\u00e7us fiscal&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Test Chi-2 pour tester la relation entre les cat\u00e9gories de souscriptions (diff\u00e9rentes cat\u00e9gories de nombres d'actions par souscription) avec le fait de demander un re\u00e7us fiscal\")) Test Chi-2 pour tester la relation entre les cat\u00e9gories de souscriptions (diff\u00e9rentes cat\u00e9gories de nombres d'actions par souscription) avec le fait de demander un re\u00e7us fiscal In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom scipy.stats import chi2_contingency\n\n# Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles\ntable = pd.crosstab(df_RFsous[\"cat\u00e9gorie souscription\"], df_RFsous[\"A fait l'objet d'un re\u00e7u fiscal_1\"])\n\n# Effectuer le test du chi-carr\u00e9\nchi2, p_value, dof, expected = chi2_contingency(table)\n\n# Afficher les r\u00e9sultats\nprint(\"Test du chi-carr\u00e9\")\nprint(\"Valeur de chi2 :\", chi2)\nprint(\"P-valeur :\", p_value)\nprint(\"Degr\u00e9s de libert\u00e9 :\", dof)\n</pre> import pandas as pd from scipy.stats import chi2_contingency  # Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles table = pd.crosstab(df_RFsous[\"cat\u00e9gorie souscription\"], df_RFsous[\"A fait l'objet d'un re\u00e7u fiscal_1\"])  # Effectuer le test du chi-carr\u00e9 chi2, p_value, dof, expected = chi2_contingency(table)  # Afficher les r\u00e9sultats print(\"Test du chi-carr\u00e9\") print(\"Valeur de chi2 :\", chi2) print(\"P-valeur :\", p_value) print(\"Degr\u00e9s de libert\u00e9 :\", dof)  <pre>Test du chi-carr\u00e9\nValeur de chi2 : 1.5037293365068827\nP-valeur : 0.6814098692768409\nDegr\u00e9s de libert\u00e9 : 3\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il n'y a aucun lien : regarder la P-valeur, elle est bien sup\u00e9rieure \u00e0 0,05 &lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il n'y a aucun lien : regarder la P-valeur, elle est bien sup\u00e9rieure \u00e0 0,05 \")) Il n'y a aucun lien : regarder la P-valeur, elle est bien sup\u00e9rieure \u00e0 0,05  In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA  pour tester la relation entre le nombre d'actions d'une souscription avec le fait de demander un re\u00e7u fiscal&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA  pour tester la relation entre le nombre d'actions d'une souscription avec le fait de demander un re\u00e7u fiscal\")) ANOVA  pour tester la relation entre le nombre d'actions d'une souscription avec le fait de demander un re\u00e7u fiscal In\u00a0[\u00a0]: Copied! <pre>df_RFsous.columns\ndf_RFsous.rename(columns={\"Nombre d'actions \u00e0 l'acquisition\": \"nombre_actions\"}, inplace=True)\ndf_RFsous.rename(columns={\"A fait l'objet d'un re\u00e7u fiscal\": \"RF\"}, inplace=True)\n</pre> df_RFsous.columns df_RFsous.rename(columns={\"Nombre d'actions \u00e0 l'acquisition\": \"nombre_actions\"}, inplace=True) df_RFsous.rename(columns={\"A fait l'objet d'un re\u00e7u fiscal\": \"RF\"}, inplace=True) In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_RFsous.copy()\ndf = df.dropna(subset=[\"RF\", \"nombre_actions\"])\n\n# Effectuer l'ANOVA\nmodel = ols(\"df['nombre_actions'] ~ C(df['RF'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"nombre_actions\"], df[\"RF\"])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_RFsous.copy() df = df.dropna(subset=[\"RF\", \"nombre_actions\"])  # Effectuer l'ANOVA model = ols(\"df['nombre_actions'] ~ C(df['RF'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"nombre_actions\"], df[\"RF\"])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc) <pre>                   sum_sq       df         F    PR(&gt;F)\nC(df['RF'])  1.238011e+04      1.0  1.344316  0.246291\nResidual     1.554978e+08  16885.0       NaN       NaN\nMultiple Comparison of Means - Tukey HSD, FWER=0.05\n===================================================\ngroup1 group2 meandiff p-adj   lower  upper  reject\n---------------------------------------------------\n     0      1  -2.0308 0.2463 -5.4638 1.4023  False\n---------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il n'y a aucun lien entre le nombre de d'actions par souscription et le fait de demander un re\u00e7u fiscal pour cette souscription (diff\u00e9rence du nombre d'actions trop minime)&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il n'y a aucun lien entre le nombre de d'actions par souscription et le fait de demander un re\u00e7u fiscal pour cette souscription (diff\u00e9rence du nombre d'actions trop minime)\")) Il n'y a aucun lien entre le nombre de d'actions par souscription et le fait de demander un re\u00e7u fiscal pour cette souscription (diff\u00e9rence du nombre d'actions trop minime) In\u00a0[\u00a0]: Copied! <pre>df_affecsous = df2.copy()\n</pre> df_affecsous = df2.copy() In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;Test du lien entre le type d'affectation des actions de la souscription et le nombre d'actions de la souscription&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Test du lien entre le type d'affectation des actions de la souscription et le nombre d'actions de la souscription\")) Test du lien entre le type d'affectation des actions de la souscription et le nombre d'actions de la souscription In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom scipy.stats import chi2_contingency\n\n# Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles\ntable = pd.crosstab(df_affecsous [\"cat\u00e9gorie souscription\"], df_affecsous [\"Type affectation\"])\n\n# Effectuer le test du chi-carr\u00e9\nchi2, p_value, dof, expected = chi2_contingency(table)\n\n# Afficher les r\u00e9sultats\nprint(\"Test du chi-carr\u00e9\")\nprint(\"Valeur de chi2 :\", chi2)\nprint(\"P-valeur :\", p_value)\nprint(\"Degr\u00e9s de libert\u00e9 :\", dof)\n</pre> import pandas as pd from scipy.stats import chi2_contingency  # Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles table = pd.crosstab(df_affecsous [\"cat\u00e9gorie souscription\"], df_affecsous [\"Type affectation\"])  # Effectuer le test du chi-carr\u00e9 chi2, p_value, dof, expected = chi2_contingency(table)  # Afficher les r\u00e9sultats print(\"Test du chi-carr\u00e9\") print(\"Valeur de chi2 :\", chi2) print(\"P-valeur :\", p_value) print(\"Degr\u00e9s de libert\u00e9 :\", dof) <pre>Test du chi-carr\u00e9\nValeur de chi2 : 5.444360222968541\nP-valeur : 0.48820687336541335\nDegr\u00e9s de libert\u00e9 : 6\n</pre> In\u00a0[\u00a0]: Copied! <pre>df_affecsous.rename(columns={\"Nombre d'actions \u00e0 l'acquisition\": \"nombre_actions\"}, inplace=True)\n</pre> df_affecsous.rename(columns={\"Nombre d'actions \u00e0 l'acquisition\": \"nombre_actions\"}, inplace=True) In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_affecsous.copy()\ndf = df.dropna(subset=[\"nombre_actions\", \"Type affectation\"])\n\n# Effectuer l'ANOVA\nmodel = ols(\"df['nombre_actions'] ~ C(df['Type affectation'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"nombre_actions\"], df[\"Type affectation\"])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_affecsous.copy() df = df.dropna(subset=[\"nombre_actions\", \"Type affectation\"])  # Effectuer l'ANOVA model = ols(\"df['nombre_actions'] ~ C(df['Type affectation'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"nombre_actions\"], df[\"Type affectation\"])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc) <pre>                                 sum_sq       df         F    PR(&gt;F)\nC(df['Type affectation'])  9.028781e+03      2.0  0.490163  0.612535\nResidual                   1.555012e+08  16884.0       NaN       NaN\n      Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n===============================================================\n   group1       group2    meandiff p-adj   lower  upper  reject\n---------------------------------------------------------------\nd\u00e9di\u00e9 projet d\u00e9di\u00e9 r\u00e9gion   1.7424 0.5968 -2.4745 5.9592  False\nd\u00e9di\u00e9 projet   non d\u00e9di\u00e9    0.5327 0.9532 -3.7033 4.7686  False\nd\u00e9di\u00e9 r\u00e9gion   non d\u00e9di\u00e9   -1.2097 0.7844 -5.4796 3.0602  False\n---------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>df_affecsousct = df_affecsous.groupby(\"Type affectation\")[\"nombre_actions\"].mean().to_frame()\ndf_affecsousct\n</pre> df_affecsousct = df_affecsous.groupby(\"Type affectation\")[\"nombre_actions\"].mean().to_frame() df_affecsousct Out[\u00a0]: nombre_actions Type affectation d\u00e9di\u00e9 projet 52.055488 d\u00e9di\u00e9 r\u00e9gion 53.797857 non d\u00e9di\u00e9 52.588150 In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Les souscriptions avec le moins d'actions voient leur capital le plus souvent allou\u00e9 \u00e0 des projets, puis celles qui ont un peu plus d'actions (18 actions de plus en moyenne que les souscriptions d\u00e9di\u00e9es projets) sont allou\u00e9es aux r\u00e9gions, puis les soucriptions avec le plus d'actions sont souvent non-d\u00e9di\u00e9es&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Les souscriptions avec le moins d'actions voient leur capital le plus souvent allou\u00e9 \u00e0 des projets, puis celles qui ont un peu plus d'actions (18 actions de plus en moyenne que les souscriptions d\u00e9di\u00e9es projets) sont allou\u00e9es aux r\u00e9gions, puis les soucriptions avec le plus d'actions sont souvent non-d\u00e9di\u00e9es\")) Les souscriptions avec le moins d'actions voient leur capital le plus souvent allou\u00e9 \u00e0 des projets, puis celles qui ont un peu plus d'actions (18 actions de plus en moyenne que les souscriptions d\u00e9di\u00e9es projets) sont allou\u00e9es aux r\u00e9gions, puis les soucriptions avec le plus d'actions sont souvent non-d\u00e9di\u00e9es In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;ANOVA testant le lien entre la cat\u00e9gorie d'engagement et la  variation du nombre d'actions prises entre la 2eme et 1ere souscription.&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"ANOVA testant le lien entre la cat\u00e9gorie d'engagement et la  variation du nombre d'actions prises entre la 2eme et 1ere souscription.\")) ANOVA testant le lien entre la cat\u00e9gorie d'engagement et la  variation du nombre d'actions prises entre la 2eme et 1ere souscription. In\u00a0[\u00a0]: Copied! <pre>df_variationactions10 = df_variationactions10.merge(df_MS[[\"multi-casquette ?\", \"ID du contact\"]], on = \"ID du contact\", how = 'left')\ndf_variationactions10 = df_variationactions10[[\"multi-casquette ?\", \"ID du contact\", \"diff_actions_souscriptions_2_1\"]]\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait)\ndf = df_variationactions10.copy()\ndf = df.dropna(subset=[\"diff_actions_souscriptions_2_1\", \"multi-casquette ?\"])\n\n# Effectuer l'ANOVA\nmodel = ols(\"df['diff_actions_souscriptions_2_1'] ~ C(df['multi-casquette ?'])\", data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Effectuer les comparaisons post hoc (m\u00e9thode de Tukey)\nposthoc = pairwise_tukeyhsd(df[\"diff_actions_souscriptions_2_1\"], df[\"multi-casquette ?\"])\n\n# Afficher la table ANOVA\nprint(anova_table)\n\n# Afficher les comparaisons post hoc\nprint(posthoc)\n</pre> df_variationactions10 = df_variationactions10.merge(df_MS[[\"multi-casquette ?\", \"ID du contact\"]], on = \"ID du contact\", how = 'left') df_variationactions10 = df_variationactions10[[\"multi-casquette ?\", \"ID du contact\", \"diff_actions_souscriptions_2_1\"]]   import pandas as pd import statsmodels.api as sm from statsmodels.formula.api import ols from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Charger les donn\u00e9es \u00e0 partir du DataFrame donn\u00e9 (df_retrait) df = df_variationactions10.copy() df = df.dropna(subset=[\"diff_actions_souscriptions_2_1\", \"multi-casquette ?\"])  # Effectuer l'ANOVA model = ols(\"df['diff_actions_souscriptions_2_1'] ~ C(df['multi-casquette ?'])\", data=df).fit() anova_table = sm.stats.anova_lm(model, typ=2)  # Effectuer les comparaisons post hoc (m\u00e9thode de Tukey) posthoc = pairwise_tukeyhsd(df[\"diff_actions_souscriptions_2_1\"], df[\"multi-casquette ?\"])  # Afficher la table ANOVA print(anova_table)  # Afficher les comparaisons post hoc print(posthoc) <pre>                                  sum_sq      df         F   PR(&gt;F)\nC(df['multi-casquette ?'])  4.214267e+03     3.0  0.074983  0.97346\nResidual                    6.536385e+07  3489.0       NaN      NaN\n                Multiple Comparison of Means - Tukey HSD, FWER=0.05                \n===================================================================================\n        group1                group2        meandiff p-adj   lower    upper  reject\n-----------------------------------------------------------------------------------\nActionnaire uniquement Actionnaire-adh\u00e9rent   2.7392 0.9866 -18.0381 23.5166  False\nActionnaire uniquement Actionnaire-donateur   4.3205 0.9666 -19.5503 28.1913  False\nActionnaire uniquement    Triple-engagement   3.0473 0.9812 -17.5134  23.608  False\n  Actionnaire-adh\u00e9rent Actionnaire-donateur   1.5812 0.9962 -16.8008 19.9632  False\n  Actionnaire-adh\u00e9rent    Triple-engagement    0.308 0.9999  -13.506  14.122  False\n  Actionnaire-donateur    Triple-engagement  -1.2732 0.9979   -19.41 16.8636  False\n-----------------------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il n'y a aucun lien entre la cat\u00e9gorie d'engagement de l'actionnaire (multi-engagemenet, etc) et le nombre d'actions qu'il reprend lors de sa deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re.&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il n'y a aucun lien entre la cat\u00e9gorie d'engagement de l'actionnaire (multi-engagemenet, etc) et le nombre d'actions qu'il reprend lors de sa deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re.\")) Il n'y a aucun lien entre la cat\u00e9gorie d'engagement de l'actionnaire (multi-engagemenet, etc) et le nombre d'actions qu'il reprend lors de sa deuxi\u00e8me souscription par rapport \u00e0 la premi\u00e8re. In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h2&gt;Test Chi-carr\u00e9 testant le lien entre la cat\u00e9gorie d'engagement et la cat\u00e9gorie de variation du nombre d'actions prises entre la 2eme et 1ere souscription.&lt;/h2&gt;&lt;/center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Test Chi-carr\u00e9 testant le lien entre la cat\u00e9gorie d'engagement et la cat\u00e9gorie de variation du nombre d'actions prises entre la 2eme et 1ere souscription.\")) Test Chi-carr\u00e9 testant le lien entre la cat\u00e9gorie d'engagement et la cat\u00e9gorie de variation du nombre d'actions prises entre la 2eme et 1ere souscription. In\u00a0[\u00a0]: Copied! <pre>conditions = [\n    (df_variationactions10[\"diff_actions_souscriptions_2_1\"] &gt; 0),\n    (df_variationactions10[\"diff_actions_souscriptions_2_1\"] == 0),\n    (df_variationactions10[\"diff_actions_souscriptions_2_1\"] &lt; 0)\n]\n\nchoices = ['augmentation', 'stagnation', 'diminution']\n\ndf_variationactions10['Cat\u00e9gories variation'] = np.select(conditions, choices, default='diminution')\n\nimport pandas as pd\nfrom scipy.stats import chi2_contingency\n\n# Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles\ntable = pd.crosstab(df_variationactions10['Cat\u00e9gories variation'], df_variationactions10[\"multi-casquette ?\"])\n\n# Effectuer le test du chi-carr\u00e9\nchi2, p_value, dof, expected = chi2_contingency(table)\n\n# Afficher les r\u00e9sultats\nprint(\"Test du chi-carr\u00e9\")\nprint(\"Valeur de chi2 :\", chi2)\nprint(\"P-valeur :\", p_value)\nprint(\"Degr\u00e9s de libert\u00e9 :\", dof)\n</pre> conditions = [     (df_variationactions10[\"diff_actions_souscriptions_2_1\"] &gt; 0),     (df_variationactions10[\"diff_actions_souscriptions_2_1\"] == 0),     (df_variationactions10[\"diff_actions_souscriptions_2_1\"] &lt; 0) ]  choices = ['augmentation', 'stagnation', 'diminution']  df_variationactions10['Cat\u00e9gories variation'] = np.select(conditions, choices, default='diminution')  import pandas as pd from scipy.stats import chi2_contingency  # Cr\u00e9er un tableau de contingence \u00e0 partir des deux variables cat\u00e9gorielles table = pd.crosstab(df_variationactions10['Cat\u00e9gories variation'], df_variationactions10[\"multi-casquette ?\"])  # Effectuer le test du chi-carr\u00e9 chi2, p_value, dof, expected = chi2_contingency(table)  # Afficher les r\u00e9sultats print(\"Test du chi-carr\u00e9\") print(\"Valeur de chi2 :\", chi2) print(\"P-valeur :\", p_value) print(\"Degr\u00e9s de libert\u00e9 :\", dof) <pre>Test du chi-carr\u00e9\nValeur de chi2 : 13.14554323291345\nP-valeur : 0.04078205664946092\nDegr\u00e9s de libert\u00e9 : 6\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;h4&gt;Il n'y a \u00e9galement aucun lien entre le fait de faire augmenter, diminuer ou stagner le nombre d'actions prises lors de la 2eme souscription par rapport \u00e0 la premi\u00e8re et le fait d'avoir diff\u00e9rents types de multi-engagement&lt;/h4&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML  # Afficher un titre avec une taille de police plus grande display(HTML(\"Il n'y a \u00e9galement aucun lien entre le fait de faire augmenter, diminuer ou stagner le nombre d'actions prises lors de la 2eme souscription par rapport \u00e0 la premi\u00e8re et le fait d'avoir diff\u00e9rents types de multi-engagement\")) Il n'y a \u00e9galement aucun lien entre le fait de faire augmenter, diminuer ou stagner le nombre d'actions prises lors de la 2eme souscription par rapport \u00e0 la premi\u00e8re et le fait d'avoir diff\u00e9rents types de multi-engagement In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\n\n\n# Ins\u00e9rer un saut de page\ndisplay(HTML(\"&lt;div style='page-break-before: always;'&gt;&lt;/div&gt;\"))\n# Afficher un titre avec une taille de police plus grande\ndisplay(HTML(\"&lt;center&gt;&lt;h1&gt;Annexes&lt;/h1&gt;&lt;center&gt;\"))\n</pre> from IPython.display import display, Markdown, HTML   # Ins\u00e9rer un saut de page display(HTML(\"\")) # Afficher un titre avec une taille de police plus grande display(HTML(\"Annexes\")) Annexes In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;center&gt;&lt;h2&gt;Focus annuel sur le nombre  d\\'actions et de souscriptions&lt;/h2&gt;&lt;/center&gt;'))\n</pre> from IPython.display import display, HTML  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Focus annuel sur le nombre  d\\'actions et de souscriptions')) Focus annuel sur le nombre  d'actions et de souscriptions In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\n# Afficher un titre centr\u00e9 avec une taille de police plus grande\ndisplay(HTML('&lt;h3&gt;Pour les graphiques qui suivent nous avons consid\u00e9r\u00e9 la \"date effective du mouvement\" sur l\\'objet \"mouvements de titres\" qui est rattach\u00e9 \u00e0 l\\'objet \"contrat\"&lt;/h3&gt;'))\n</pre> from IPython.display import display, HTML  # Afficher un titre centr\u00e9 avec une taille de police plus grande display(HTML('Pour les graphiques qui suivent nous avons consid\u00e9r\u00e9 la \"date effective du mouvement\" sur l\\'objet \"mouvements de titres\" qui est rattach\u00e9 \u00e0 l\\'objet \"contrat\"')) Pour les graphiques qui suivent nous avons consid\u00e9r\u00e9 la \"date effective du mouvement\" sur l'objet \"mouvements de titres\" qui est rattach\u00e9 \u00e0 l'objet \"contrat\" In\u00a0[\u00a0]: Copied! <pre>df_souscription_an = df2[\"r\u00e9partition ann\u00e9e\"].value_counts().to_frame()\ndf_souscription_an = df_souscription_an.sort_values(by=\"r\u00e9partition ann\u00e9e\")\n\nimport matplotlib.pyplot as plt\n\n# Data\nannee_souscription = df_souscription_an.index\nnombre_souscriptions = df_souscription_an['count']\n\n# Create the bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(annee_souscription, nombre_souscriptions, color='skyblue')\n\n# Add data labels above each bar\nfor i, v in enumerate(nombre_souscriptions):\n    plt.text(annee_souscription[i], v, str(v), ha='center', va='bottom', fontsize=10)\n\n# Title and labels for axes\nplt.title(\"Nombre de souscriptions par ann\u00e9e\")\nplt.xlabel(\"Ann\u00e9es de souscription\")\nplt.ylabel(\"Nombre de souscriptions\")\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n</pre> df_souscription_an = df2[\"r\u00e9partition ann\u00e9e\"].value_counts().to_frame() df_souscription_an = df_souscription_an.sort_values(by=\"r\u00e9partition ann\u00e9e\")  import matplotlib.pyplot as plt  # Data annee_souscription = df_souscription_an.index nombre_souscriptions = df_souscription_an['count']  # Create the bar plot plt.figure(figsize=(10, 6)) plt.bar(annee_souscription, nombre_souscriptions, color='skyblue')  # Add data labels above each bar for i, v in enumerate(nombre_souscriptions):     plt.text(annee_souscription[i], v, str(v), ha='center', va='bottom', fontsize=10)  # Title and labels for axes plt.title(\"Nombre de souscriptions par ann\u00e9e\") plt.xlabel(\"Ann\u00e9es de souscription\") plt.ylabel(\"Nombre de souscriptions\")  # Rotate x-axis labels for better readability plt.xticks(rotation=45)  # Display the plot plt.tight_layout() plt.show()   In\u00a0[\u00a0]: Copied! <pre>df_action_an = df2.groupby('r\u00e9partition ann\u00e9e')[\"Nombre d'actions \u00e0 l'acquisition\"].sum().reset_index()\n\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es\nannee_rachat = df_action_an['r\u00e9partition ann\u00e9e']\nnombre_actions = df_action_an[\"Nombre d'actions \u00e0 l'acquisition\"]\n\n# Cr\u00e9er le diagramme en b\u00e2tons\nplt.figure(figsize=(10, 6))\nplt.bar(annee_rachat, nombre_actions, width=0.8, color='skyblue')  # Increase the width parameter for wider bars\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre total d'actions prises par ann\u00e9e\")\nplt.xlabel(\"Ann\u00e9es\")\nplt.ylabel(\"Nombre total d'actions \u00e0 l'acquisition\")\n\n# Afficher les valeurs au-dessus de chaque barre\nfor i, v in enumerate(nombre_actions):\n    plt.text(annee_rachat[i], v + 100, str(int(v)), ha='center', va='bottom', fontsize=8)\n\n# Faire pivoter les \u00e9tiquettes de l'axe des x pour une meilleure lisibilit\u00e9\nplt.xticks(rotation=45)\n\n# Afficher le diagramme en b\u00e2tons\nplt.tight_layout()\nplt.show()\n</pre> df_action_an = df2.groupby('r\u00e9partition ann\u00e9e')[\"Nombre d'actions \u00e0 l'acquisition\"].sum().reset_index()  import matplotlib.pyplot as plt  # Donn\u00e9es annee_rachat = df_action_an['r\u00e9partition ann\u00e9e'] nombre_actions = df_action_an[\"Nombre d'actions \u00e0 l'acquisition\"]  # Cr\u00e9er le diagramme en b\u00e2tons plt.figure(figsize=(10, 6)) plt.bar(annee_rachat, nombre_actions, width=0.8, color='skyblue')  # Increase the width parameter for wider bars  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre total d'actions prises par ann\u00e9e\") plt.xlabel(\"Ann\u00e9es\") plt.ylabel(\"Nombre total d'actions \u00e0 l'acquisition\")  # Afficher les valeurs au-dessus de chaque barre for i, v in enumerate(nombre_actions):     plt.text(annee_rachat[i], v + 100, str(int(v)), ha='center', va='bottom', fontsize=8)  # Faire pivoter les \u00e9tiquettes de l'axe des x pour une meilleure lisibilit\u00e9 plt.xticks(rotation=45)  # Afficher le diagramme en b\u00e2tons plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>df_actionmean_an = df2.groupby('r\u00e9partition ann\u00e9e')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().reset_index()\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es du tableau\nannee_acquisition = df_actionmean_an['r\u00e9partition ann\u00e9e']\nnombre_actions_acquisition = df_actionmean_an[\"Nombre d'actions \u00e0 l'acquisition\"]\n\n# Cr\u00e9er le diagramme en b\u00e2tons\nplt.bar(annee_acquisition, nombre_actions_acquisition)\n\n# Ajouter les \u00e9tiquettes de valeurs sur chaque barre\nfor i in range(len(annee_acquisition)):\n    plt.text(annee_acquisition[i], nombre_actions_acquisition[i], str(int(nombre_actions_acquisition[i])),\n             ha='center', va='bottom')\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre moyen d'actions par souscription par ann\u00e9e\")\nplt.xlabel(\"Ann\u00e9e d'acquisition\")\nplt.ylabel(\"Nombre moyen d'actions \u00e0 l'acquisition\")\n\n# Incliner les ann\u00e9es sur l'axe des abscisses\nplt.xticks(rotation=45)\n# Afficher le diagramme\nplt.tight_layout()\nplt.show()\n</pre> df_actionmean_an = df2.groupby('r\u00e9partition ann\u00e9e')[\"Nombre d'actions \u00e0 l'acquisition\"].mean().reset_index() import matplotlib.pyplot as plt  # Donn\u00e9es du tableau annee_acquisition = df_actionmean_an['r\u00e9partition ann\u00e9e'] nombre_actions_acquisition = df_actionmean_an[\"Nombre d'actions \u00e0 l'acquisition\"]  # Cr\u00e9er le diagramme en b\u00e2tons plt.bar(annee_acquisition, nombre_actions_acquisition)  # Ajouter les \u00e9tiquettes de valeurs sur chaque barre for i in range(len(annee_acquisition)):     plt.text(annee_acquisition[i], nombre_actions_acquisition[i], str(int(nombre_actions_acquisition[i])),              ha='center', va='bottom')  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre moyen d'actions par souscription par ann\u00e9e\") plt.xlabel(\"Ann\u00e9e d'acquisition\") plt.ylabel(\"Nombre moyen d'actions \u00e0 l'acquisition\")  # Incliner les ann\u00e9es sur l'axe des abscisses plt.xticks(rotation=45) # Afficher le diagramme plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>df_perteaction_an = df_rachat.groupby('ann\u00e9e rachat')[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().reset_index()\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es\nannee_rachat = df_perteaction_an['ann\u00e9e rachat']\nnombre_actions = df_perteaction_an['Nombre d\\'actions \u00e9chang\u00e9es']\n\n# Cr\u00e9er le diagramme en b\u00e2tons\nplt.figure(figsize=(10, 6))\nplt.bar(annee_rachat, nombre_actions, color='skyblue')\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre d'actions retir\u00e9es par ann\u00e9e de rachat\")\nplt.xlabel(\"Ann\u00e9es de rachat\")\nplt.ylabel(\"Nombre d'actions retir\u00e9es\")\n\n# Afficher les valeurs au-dessus de chaque barre\nfor i, v in enumerate(nombre_actions):\n    plt.text(annee_rachat[i], v + 100, str(int(v)), ha='center', va='bottom', fontsize=8)\n\n# Faire pivoter les \u00e9tiquettes de l'axe des x pour une meilleure lisibilit\u00e9\nplt.xticks(rotation=45)\n\n# Afficher le diagramme en b\u00e2tons\nplt.tight_layout()\nplt.show()\n</pre>  df_perteaction_an = df_rachat.groupby('ann\u00e9e rachat')[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().reset_index() import matplotlib.pyplot as plt  # Donn\u00e9es annee_rachat = df_perteaction_an['ann\u00e9e rachat'] nombre_actions = df_perteaction_an['Nombre d\\'actions \u00e9chang\u00e9es']  # Cr\u00e9er le diagramme en b\u00e2tons plt.figure(figsize=(10, 6)) plt.bar(annee_rachat, nombre_actions, color='skyblue')  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre d'actions retir\u00e9es par ann\u00e9e de rachat\") plt.xlabel(\"Ann\u00e9es de rachat\") plt.ylabel(\"Nombre d'actions retir\u00e9es\")  # Afficher les valeurs au-dessus de chaque barre for i, v in enumerate(nombre_actions):     plt.text(annee_rachat[i], v + 100, str(int(v)), ha='center', va='bottom', fontsize=8)  # Faire pivoter les \u00e9tiquettes de l'axe des x pour une meilleure lisibilit\u00e9 plt.xticks(rotation=45)  # Afficher le diagramme en b\u00e2tons plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>df_donaction_an = df_dongraph.groupby('ann\u00e9e rachat')[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().reset_index()\n\nimport matplotlib.pyplot as plt\n\n# Donn\u00e9es du tableau\nannee_rachat = df_donaction_an['ann\u00e9e rachat']\nnombre_actions = df_donaction_an['Nombre d\\'actions \u00e9chang\u00e9es']\n\n# Cr\u00e9er le diagramme en b\u00e2tons\nplt.bar(annee_rachat, nombre_actions)\n\n# Ajouter les \u00e9tiquettes de valeur au-dessus des barres\nfor x, y in zip(annee_rachat, nombre_actions):\n    plt.text(x, y, str(int(y)), ha='center', va='bottom')\n\n# Titre et \u00e9tiquettes des axes\nplt.title(\"Nombre d'actions donn\u00e9es par ann\u00e9e (Don TDL)\")\nplt.xlabel(\"Ann\u00e9es\")\nplt.ylabel(\"Nombre d'actions donn\u00e9es\")\n\n# Afficher le diagramme\nplt.tight_layout()\nplt.show()\n</pre>  df_donaction_an = df_dongraph.groupby('ann\u00e9e rachat')[\"Nombre d'actions \u00e9chang\u00e9es\"].sum().reset_index()  import matplotlib.pyplot as plt  # Donn\u00e9es du tableau annee_rachat = df_donaction_an['ann\u00e9e rachat'] nombre_actions = df_donaction_an['Nombre d\\'actions \u00e9chang\u00e9es']  # Cr\u00e9er le diagramme en b\u00e2tons plt.bar(annee_rachat, nombre_actions)  # Ajouter les \u00e9tiquettes de valeur au-dessus des barres for x, y in zip(annee_rachat, nombre_actions):     plt.text(x, y, str(int(y)), ha='center', va='bottom')  # Titre et \u00e9tiquettes des axes plt.title(\"Nombre d'actions donn\u00e9es par ann\u00e9e (Don TDL)\") plt.xlabel(\"Ann\u00e9es\") plt.ylabel(\"Nombre d'actions donn\u00e9es\")  # Afficher le diagramme plt.tight_layout() plt.show()"},{"location":"projets/","title":"Projets","text":"<ul> <li> NLP \u2014 Classification de plaintes financi\u00e8res</li> </ul> <p>Objectif : cat\u00e9goriser 66 699 plaintes clients par type de service bancaire (recouvrement, rapports de cr\u00e9dit, pr\u00eat \u00e9tudiant, pr\u00eat sur salaire).</p> <p>Stack : Python (PyTorch, <code>torch.nn</code>, <code>torchtext</code>), pr\u00e9traitement (spaCy/NTLK, tokenisation, lemmatisation, stopwords), LSTM bi-directionnel, gestion du d\u00e9s\u00e9quilibre (class weights), \u00e9valuation (<code>scikit-learn</code>: m\u00e9triques/ROC).</p> <p>D\u00e9tails \u2192</p> <ul> <li> Vision \u2014 Application Streamlit d\u2019imagerie m\u00e9dicale</li> </ul> <p>Objectif : classifier des images (cerveau, poumon, autre) via un CNN et proposer une d\u00e9mo web (Streamlit) d'outil de classification.</p> <p>Stack : Python (scikit-image, TensorFlow/Keras, \u00e9ventuellement OpenCV), data viz (Matplotlib/Seaborn/Plotly), d\u00e9ploiement Streamlit.</p> <p>D\u00e9tails \u2192</p> <ul> <li> Analyse \u2014 Syst\u00e8me d\u2019actionnariat (Terre de Liens)</li> </ul> <p>Objectif : profiler les actionnaires, suivre souscriptions/rachats, analyser la stabilit\u00e9 et les comportements d\u2019investissement.</p> <p>Stack : Python (Pandas, NumPy, SciPy, Statsmodels), data viz (Matplotlib, Seaborn, Plotly), tests/statistiques descriptives, export rapport.</p> <p>D\u00e9tails \u2192</p> <ul> <li> Clustering &amp; ACP \u2014 Criminalit\u00e9 aux \u00c9tats-Unis</li> </ul> <p>Objectif : regrouper les 50 \u00c9tats par profils de criminalit\u00e9 et r\u00e9duire la dimension (ACP) pour interpr\u00e9tation.</p> <p>Stack : <code>scikit-learn</code> (KMeans, PCA), Pandas/NumPy, data viz (Seaborn, Matplotlib), crit\u00e8res d\u2019aide au choix (coude/inertie, silhouette si besoin).</p> <p>D\u00e9tails \u2192</p> <ul> <li> AFC \u2014 \u00c9lections pr\u00e9sidentielles 2022 (\u00cele-de-France)</li> </ul> <p>Objectif : analyser les correspondances d\u00e9partements \u00d7 candidats et visualiser proximit\u00e9s/contrastes.</p> <p>Stack : Python (Pandas, NumPy), Correspondence Analysis avec <code>prince</code> (ou <code>mca</code>), data viz (Matplotlib/Seaborn/Plotly), tableaux de contingence.</p> <p>D\u00e9tails \u2192</p> <ul> <li> R (panel) \u2014 Prix h\u00e9doniques, immobilier lyonnais</li> </ul> <p>Objectif : estimer l\u2019impact de la localisation et des attributs des biens sur les prix (donn\u00e9es DVF).</p> <p>Stack : R (tidyverse : <code>dplyr</code>, <code>readr</code>, <code>tidyr</code>, dataviz : <code>ggplot2</code>/Plotly), mod\u00e8les panel avec <code>plm</code>, <code>broom</code>, <code>car</code>, reporting (<code>stargazer</code>/<code>texreg</code>).</p> <p>D\u00e9tails \u2192</p> <ul> <li> R (panel) \u2014 D\u00e9terminants des salaires aux \u00c9tats-Unis</li> </ul> <p>Objectif : identifier les effets (\u00e9ducation, exp\u00e9rience, caract\u00e9ristiques individuelles) via mod\u00e8les panel (Within/Between, Hausman-Taylor).</p> <p>Stack : R (tidyverse, <code>plm</code>), diagnostics (<code>lmtest</code>, <code>sandwich</code>), dataviz (<code>ggplot2</code>/Plotly), mise en forme (<code>broom</code>, <code>stargazer</code>).</p> <p>D\u00e9tails \u2192</p> <ul> <li> Certifications</li> </ul> <p>Objectif : pr\u00e9senter les certificats cl\u00e9s (SQL, ML supervis\u00e9/non supervis\u00e9, Excel).</p> <p>Stack : pages statiques (Markdown) + scans/exports PDF/PNG.</p> <p>D\u00e9tails \u2192</p>"},{"location":"projets/certifications/","title":"Certifications data","text":""},{"location":"projets/certifications/#certification-sql","title":"Certification SQL","text":"<p>Th\u00e8mes abord\u00e9s par la certification : joining data, data manipulation, PostgreSQL summary stats and window functions, functions for manipuation data in PostgreSQL, data analysis in SQL</p> <p></p>"},{"location":"projets/certifications/#certification-machine-learning-with-python-supervised-learning-with-scikit-learn","title":"Certification Machine Learning with Python: supervised learning with scikit-learn","text":"<p>Th\u00e8mes abord\u00e9s par la certification : using supervised techniques to build predictive models (for regression and classification problems), cross-validation, best parameters searching (Gridseach), model performance evaluation, hyper-parameter tuning, using pipelines.</p> <p></p>"},{"location":"projets/certifications/#certification-machine-learning-with-python-unsupervised-learning-with-python-scikit-learn","title":"Certification Machine Learning with Python: unsupervised learning with Python (Scikit-Learn)","text":"<p>Th\u00e8mes abord\u00e9s par la certification : clustering with K-means algorithm, data viz  with hierarchical clustering and t-SNE, dimensions reducition regarding principal component analysis (PCA), non-negative matrix factorization (NMF), building recommender systems with NMF</p> <p></p>"},{"location":"projets/certifications/#certification-data-preparation-with-excel","title":"Certification Data preparation with Excel","text":"<p>Th\u00e8mes abord\u00e9s par la certification : Functions for Data Preparation, conditional formulas, Lookups and data transformation.</p> <p></p>"},{"location":"projets/certifications/#certification-data-analytics-with-excel","title":"Certification Data analytics with Excel","text":"<p>Th\u00e8mes abord\u00e9s par la certification : PivotTables, Logical functions, What-if analysis, Forcasting.</p> <p></p>"},{"location":"projets/crime-usa/","title":"2. Clustering, et Analyse en Composantes Principales en Python  sur la criminalit\u00e9 aux Etats-Unis","text":""},{"location":"projets/crime-usa/#presentation-du-contexte-de-lanalyse-de-donnees","title":"Pr\u00e9sentation du contexte de l'analyse de donn\u00e9es","text":"<p>Ce travail a \u00e9t\u00e9 effectu\u00e9 dans le cadre d'une auto formation grace aux supports de Formasys.La base de donn\u00e9es \u00e9tudi\u00e9e comporte des observations pour les 50 \u00e9tats des USA concernant 4 variables d'int\u00e9ret.</p> <p>\"Murder\" repr\u00e9sente le taux de meurtre pour 100 000 habitants dans chaque \u00c9tat. \"Assault\" correspond au nombre d'agressions pour 100 000 habitants. \"UrbanPop\" indique le pourcentage de la population r\u00e9sidant dans des zones urbaines. \"Rape\" repr\u00e9sente le taux de viols pour 100 000 habitants.</p> <p>L'enjeux du travail consistait dans un premier temps \u00e0 utiliser l'agorithme kmeans dans le but de regrouper les \u00e9tats au sein d'un nombre de cluster optimal ou le plus pertinent possible. Le nombre de clusters optimal a \u00e9t\u00e9 d\u00e9terminer \u00e0 hauteur de 4.</p> <p>Une fois le clustering effectu\u00e9, il s'agissait d'effectuer une r\u00e9duction de dimensions des donn\u00e9es gr\u00e2ce \u00e0 une ACP afin de pouvoir visualiser la r\u00e9partition relative des \u00e9tats entre eux. Autrement dit il s'agissait de savoir sur quelles caract\u00e9ristiques il \u00e9tait possible de rapprocher ou distinguer les \u00e9tats et de savoir sur quels crit\u00e8res les clusters avaient \u00e9t\u00e9 \u00e9tablis. Notons que l'application d'un ACP se fait uniquement avec des donn\u00e9es quantitatives</p>"},{"location":"projets/crime-usa/#code-et-quelques-elements-de-data-vizualisation","title":"Code et quelques \u00e9l\u00e9ments de data vizualisation","text":"<p>La base de donn\u00e9es est \u00e0 retrouver ici. Le code qui a permi la r\u00e9alisation du travail est \u00e0 retrouver sous forme de jupyter notebook via ce lien.  </p> <p>Analyse des variables</p> <p></p> <p>D\u00e9termination du nombre de clusters optimal</p> <p></p> <p>Ici on voit que le gain d'inertie ne devient plus significatif une fois atteint 4 clusters.</p> <p>Premi\u00e8re visualisation des clusters sur diff\u00e9rents plans relatifs \u00e0 diff\u00e9rentes combinaisons de 2 variables</p> <p></p> <p>Nombre de composantes principales \u00e0 garder pour la r\u00e9duction de dimensions des donn\u00e9es en fonction de la variabilit\u00e9 qu'elles expliquent pour ces-derni\u00e8res</p> <p></p> <p>On observe qu'en conservant 2 composantes qui sont une combinaison lin\u00e9aire des diff\u00e9rents variables, on captures d\u00e9j\u00e0 pr\u00e8s de 87 % de la variabilit\u00e9 des donn\u00e9es. </p> <p>Visualisation des individus et clusters suite \u00e0 la r\u00e9duction de dimension superpos\u00e9e au cercle de corr\u00e9lation de l'ACP</p> <p></p> <p>Gr\u00e2ce \u00e0 cette r\u00e9duction de dimension il est ainsi possible de voir comment rapprocher ou distinguer les \u00e9tats et sur quels crit\u00e8res ces comparaisons peuvent \u00eatre effectu\u00e9es. </p>"},{"location":"projets/elections-afc/","title":"3. Analyse factorielle des correspondances (AFC): elections pr\u00e9sidentielles 2022, focus sur l'Ile de France.","text":"<p>Ce travail a \u00e9t\u00e9 effectu\u00e9 dans le cadre d'une auto-formation gr\u00e2ce aux supports de cours de LeCoinstat. Gr\u00e2ce \u00e0 des donn\u00e9es retra\u00e7ant le nombre de votes pour les diff\u00e9rents candidats en liste pour les \u00e9lections pr\u00e9sidentielles de 2022 au seins des diff\u00e9rents d\u00e9partements d'Ile de France, il s'agissait de mettre en place une analyse factorielle des correspondances entre diff\u00e9rents candidats et diff\u00e9rents d\u00e9partements. Il s'agissait ici d'effectuer \u00e9galement une r\u00e9duction de dimensions des donn\u00e9es, faisant face \u00e0 des variables cat\u00e9gorielles (candidats et d\u00e9partements), une AFC s'imposait plut\u00f4t qu'une ACP. </p> <p>L'objectif de ce travail \u00e9tait alors de pouvoir rapprocher des candidats et des d\u00e9partements entre eux en fonction de la typologie des votes. </p>"},{"location":"projets/elections-afc/#code-et-quelques-elements-de-data-vizualisation","title":"Code et quelques \u00e9l\u00e9ments de data vizualisation","text":"<p>La base de donn\u00e9es est \u00e0 retrouver ici. Le code qui a permi la r\u00e9alisation du travail est \u00e0 retrouver sous forme de jupyter notebook via ce lien. </p> <p>Tableau de contingence entre les diff\u00e9rentes variables</p> <p></p> <p>Classements des candidats par nombre de votes</p> <p></p> <p>Qualit\u00e9 de la repr\u00e9sentativit\u00e9 des variables parmi les composants</p> <p>Apr\u00e8s avoir d\u00e9termin\u00e9 qu'il faille garder composants pour cette analyse car explicants \u00e0 eux deux une assez forte variabilit\u00e9 des donn\u00e9es, il s'agissait de regarder si les diff\u00e9rentes variables \u00e9taient bien repr\u00e9sent\u00e9es parmi les composants. Pour cela il faut s'in\u00e9t\u00e9resser au cos2 qui  mesurent l'association entre chaque variable et chaque axe factoriel sur un plan form\u00e9 par nos 2 composantes principales. Ainsi il a \u00e9t\u00e9 possible de s'int\u00e9resser aux profils lignes (les d\u00e9partements) et aux profils colonnes(les candidats). Il sera possible d'interpr\u00e9ter les positionnements relatifs des d\u00e9partements et des candidats uniquement si leur cosinus carr\u00e9 est sup\u00e9rieur \u00e0 0,5 en consid\u00e9rant les axes factoriels 1 et 2 (composantes 1 et 2). </p> <p></p> <p>Factor maps superpos\u00e9es des analyses de profils lignes et colonnes</p> <p>En obtenant une factor map il est possible de rapprocher ou distinguer certains candidats en fonction de leur points communs en termes de votes parmi les diff\u00e9rents d\u00e9partements, et il est egalement possible de rapprocher ou distinguer des d\u00e9partements en fonction des votes qu'ils ont comptabilis\u00e9 pour diff\u00e9rents candidats. Comme pr\u00e9cis\u00e9 pr\u00e9c\u00e9demment, il sera possible de tirer des conclusions concernant la position relative des candidats et des d\u00e9partement entre eux uniquement si ces derniers ont une assez bonne repr\u00e9sentativit\u00e9 dans la d\u00e9termination des composants s\u00e9lectionn\u00e9s. </p> <p></p>"},{"location":"projets/imagerie-medicale/","title":"Application web de computer vision : R\u00e9seau de neuronnes convultif et classification d'imageries m\u00e9dicales","text":""},{"location":"projets/imagerie-medicale/#presentation-de-lapplication-streamlit-et-strucutre-du-modele-cnn","title":"Pr\u00e9sentation de l'application streamlit et strucutre du mod\u00e8le CNN","text":"<p>L'enjeu de ce projet \u00e9tait de cr\u00e9er une application web streamlit qui permet d'ins\u00e9rer une image, le mod\u00e8le pr\u00e9dit ensuite s'il s'agit d'une imagerie m\u00e9dicale du cerveau, des poumons ou la classe autres qui signifie qu'il ne s'agit d'aucune de ces classes pr\u00e9c\u00e9dentes. L'application est accessible ici.</p> <p>Les pr\u00e9dictions se basent sur un mod\u00e8le de neuronnes convultif simple. Il aura \u00e9t\u00e9 entrain\u00e9 sur 18 777 images repr\u00e9sentant des imageries m\u00e9dicales de cerveaux, de poumons et d'autres photos random (visages, paysages, animaux, monuments, figures abstraites) en libre acc\u00e8s sur des base de donn\u00e9es Kaggle. La validation a \u00e9t\u00e9 faite sur 4 217 images par la suite. Le notebook qui a permis de r\u00e9aliser ce mod\u00e8le est accessible ici.</p> <p>La r\u00e9seaux de neuronnes a \u00e9t\u00e9 consrtuit selon les param\u00e8tres suivants : </p> <ul> <li> <p>Normalisation de la taille des images </p> </li> <li> <p>Diff\u00e9rentes couches de convolution 2D avec 128, 64, 32, et 16 filtres de taile 4X4 </p> </li> <li> <p>Rajout de couche de maxpooling \u00e0 chaque fois pour r\u00e9sumer les features maps obtenue par les couches de concolutions</p> </li> <li> <p>Rajout d'une couche  Flatten qui r\u00e9duit la dimension des features maps en un vecteur pour simplification d'apprentissage</p> </li> <li> <p>Rajout de couche dense avec 64 neuronnes pour apprentissage des informations tir\u00e9es des couhces de convultion, de pooling et de la couche Flatten.</p> </li> <li> <p>Derni\u00e8re couche \u00e0 3 neuronnes retournant la probabilit\u00e9 qu'une image appartienne \u00e0 une classe ou aux autres. </p> </li> <li> <p>Entrainement du mod\u00e8e sur 3 \u00e9poques</p> </li> </ul> <p>Il se r\u00e9sume alors de la sorte :  </p> <p> </p> <p>Les performances du mod\u00e8le sont tr\u00e8s \u00e9lev\u00e9es, ce qui pourrait laisser penser qu'il y a eu du sur apprentissage. En r\u00e9alit\u00e9 ceci est du au manque de diversit\u00e9 entre les images du set d'apprentissage et du set d'entra\u00eenement. En effet m\u00eame si les images n'\u00e9taient pas les m\u00eames elles se ressemblaient tout de m\u00eame (Les IRM du cerveau se ressemblant toutes par exemple). </p>"},{"location":"projets/imagerie-medicale/#limites-du-modele","title":"Limites du mod\u00e8le","text":"<p>Ce mod\u00e8le est un mod\u00e8le simple, le set d'apprentissage est tout de m\u00eame r\u00e9duit et la diversit\u00e9 des images y \u00e9tant inclues reste \u00e0 relativiser. En effet face \u00e0 des contraintes d'acc\u00e8s \u00e0 des images assez diversifi\u00e9es et face \u00e0 une capacit\u00e9 de gestion de donn\u00e9es r\u00e9duite, le mod\u00e8le peut avoir du mal a reconnaitre une image qui contiendrait tout de m\u00eame une imagerie m\u00e9dicale de cerveau ou de poumons mais \u00e9tant peu \"conventionnel\".</p>"},{"location":"projets/imagerie-medicale/#retour-du-modele-via-lapplication-streamlit","title":"Retour du mod\u00e8le via l'application streamlit","text":""},{"location":"projets/nlp-lstm/","title":"IA &amp; NLP :  Model LSTM pour  la pr\u00e9diction du type de sujet conernant les r\u00e9clamations et pleintes \u00e0 l'encontre de services financiers","text":""},{"location":"projets/nlp-lstm/#presentation-du-probleme","title":"Pr\u00e9sentation du probl\u00e8me :","text":"<p>Dans ce projet de traitement automatique du langage naturel (NLP), j\u2019ai d\u00e9velopp\u00e9 un mod\u00e8le bas\u00e9 sur une architecture Bidirectional LSTM (Long Short-Term Memory) afin de classer des plaintes clients issues du secteur des services financiers. La base de donn\u00e9es comprenait 66 699 plaintes textuelles, chacune d\u00e9crivant un probl\u00e8me rencontr\u00e9 par un client avec sa banque , ici : Recouvrement de dettes, Rapports de cr\u00e9dit, Pr\u00eat \u00e9tudiant, Pr\u00eat sur salaire. Le notebook du travail est disponible ici. La base de donn\u00e9es sur laquelle le travail a \u00e9t\u00e9 fait ici : </p>"},{"location":"projets/nlp-lstm/#modele-lstm","title":"Mod\u00e8le LSTM","text":"<p>Un LSTM (Long Short-Term Memory) est une variante des r\u00e9seaux de neurones r\u00e9currents (RNN) con\u00e7ue pour mieux g\u00e9rer les d\u00e9pendances \u00e0 long terme dans des s\u00e9quences. Il est compos\u00e9 de cellules qui utilisent trois types de portes :</p> <ul> <li>Porte d\u2019entr\u00e9e (input gate) : contr\u00f4le quelles nouvelles informations sont ajout\u00e9es \u00e0 la m\u00e9moire.</li> <li>Porte d\u2019oubli (forget gate) : d\u00e9cide quelles informations pass\u00e9es sont conserv\u00e9es ou supprim\u00e9es.</li> <li>Porte de sortie (output gate) : d\u00e9termine quelles informations de la m\u00e9moire sont utilis\u00e9es pour produire la sortie actuelle.</li> <li>Cette structure permet au LSTM de retenir le contexte pertinent sur de longues s\u00e9quences, \u00e9vitant le probl\u00e8me du vanishing gradient que rencontrent les RNN classiques.</li> </ul> <p>Cette architecture rend le LSTM particuli\u00e8rement adapt\u00e9 pour l\u2019interpr\u00e9tation des s\u00e9quences verbales complexes issues de ce type de donn\u00e9es clients.</p> <p></p>"},{"location":"projets/nlp-lstm/#enjeux-du-travail","title":"Enjeux du travail","text":"<ul> <li>Un point crucial de ce projet a \u00e9t\u00e9 la pr\u00e9paration des donn\u00e9es, notamment la tokenisation et le padding des s\u00e9quences textuelles pour normaliser leur longueur avant l\u2019apprentissage : Ainsi il aura fallu pr\u00e9-traiter permis de nettoyer et homog\u00e9n\u00e9iser les textes. Apr\u00e8s suppression des URLs, nombres et ponctuation, puis tokenisation, lemmatisation et suppression des stopwords, le nombre de tokens par plainte a nettement diminu\u00e9 et les s\u00e9quences sont devenues plus compactes. Ce travail pr\u00e9pare efficacement les donn\u00e9es pour l\u2019apprentissage du mod\u00e8le LSTM. Voila l'\u00e9volution du format d'input avec le pr\u00e9traitement :</li> </ul> <ul> <li>Un autre d\u00e9fi a r\u00e9sid\u00e9 dans la gestion des classes d\u00e9s\u00e9quilibr\u00e9es (class imbalance), qui a n\u00e9cessit\u00e9 des ajustements tels que la pond\u00e9ration des classes et des techniques de sur/sous-\u00e9chantillonnage pour \u00e9viter un biais du mod\u00e8le vers les classes majoritaires.</li> </ul>"},{"location":"projets/nlp-lstm/#architecture-retenue","title":"Architecture retenue :","text":"<p>Apr\u00e8s avoir tester la sensibilit\u00e9 des performances du mod\u00e8le avec diff\u00e9rentes architectures, l'architecture suivante aura \u00e9t\u00e9 s\u00e9lectionn\u00e9e : </p> <ul> <li>Une couche d\u2019embedding transforme chaque mot en un vecteur de 300 dimensions pour repr\u00e9senter son sens.</li> <li>Deux couches LSTM bidirectionnelles analysent le texte dans les deux sens pour mieux comprendre le contexte des phrases.</li> <li>Une couche dense affine les informations extraites avant la pr\u00e9diction.</li> <li>Une couche de sortie pr\u00e9dit la cat\u00e9gorie de plainte parmi les quatre disponibles.</li> <li>Des techniques de r\u00e9gularisation comme le dropout sont utilis\u00e9es pour \u00e9viter le surapprentissage et am\u00e9liorer les performances du mod\u00e8le. Egalement de la pond\u00e9ration de classe pour g\u00e9rer les class inbalance.</li> </ul> <p></p>"},{"location":"projets/nlp-lstm/#resultats","title":"R\u00e9sultats :","text":"<p>Les performances du mod\u00e8le optimal retenu ont \u00e9t\u00e9 les suivantes : </p> <p> </p>"},{"location":"projets/prix-hedoniques-lyon/","title":"4.Mod\u00e9lisation statistique en donn\u00e9es de panel en R : application de la m\u00e9thode des prix h\u00e9doniques au march\u00e9 immobilier Lyonnais","text":""},{"location":"projets/prix-hedoniques-lyon/#presentation-du-contexte-de-la-modelisation-statistique-portant-sur-lapplication-de-la-methode-des-prix-hedoniques-au-marche-immobilier-lyonnaise","title":"Pr\u00e9sentation du contexte de la mod\u00e9lisation statistique portant sur l\u2019application de la m\u00e9thode des prix h\u00e9doniques au march\u00e9 immobilier lyonnaise","text":"<p>Le travail de mod\u00e9lisation statistique s\u2019est fait \u00e0 partir de 6 bases de donn\u00e9es diff\u00e9rentes comportant des informations sur des biens immobiliers mises \u00e0 la vente sur Lyon et sur leur valeur fonci\u00e8re. Ce sont des bases de donn\u00e9es open source \u00e0 retrouver sur https://app.dvf.etalab.gouv.fr/. Il s\u2019agissait avant tout pour ce travail de tester l\u2019effet de l\u2019\u00e9loignement au centre ville sur la d\u00e9termination des prix des caract\u00e9ristiques des biens (nombre de chambre, pi\u00e8ces, types de bien,etc). Il aura fallu s\u2019int\u00e9resser aux valeurs fonci\u00e8res de biens de 2 quartiers \u00e0 chaque fois, un loin du centre et un autre pr\u00e8s du centre pour 2 arrondissements diff\u00e9rents de Lyon (ayant plus ou moins la m\u00eame r\u00e9putation) et 2 quartiers (loin et pr\u00e8s) de Villeurbanne (commune frontali\u00e8re de Lyon). Les bases de donn\u00e9es sont \u00e0 retrouver dans le document suivant.</p>"},{"location":"projets/prix-hedoniques-lyon/#code-et-quelques-elements-de-data-vizualisation","title":"Code et quelques \u00e9l\u00e9ments de data vizualisation","text":"<p>Le code qui aura permis de r\u00e9aliser l'analyse de donn\u00e9es et ensuite de sp\u00e9cifier un mod\u00e8le statistique est disponible ici. Le code a \u00e9t\u00e9 \u00e9crit en language R et \u00e9crit sous Rstudio en markdown</p> <p>Voici quelques statistiques descriptives ainsi qu'un des mod\u00e8les sp\u00e9cifi\u00e9s tir\u00e9s du projet</p> <p>Statisitiques descrives portant sur les valeurs d'int\u00e9rets de la base de donn\u00e9es utilis\u00e9e</p> <p></p> <p>Box plot des valeurs fonci\u00e8res d\u00e9pendant des cat\u00e9gories de biens regroup\u00e9s par nombre de pi\u00e8ces dont ils disposent</p> <p></p> <p>Mod\u00e8le statististique permettant de tester l'effet l'\u00e9loignement au centre sur le prix des biens en isolant les effets de \"prestige des arrondissements\"</p> <p></p>"},{"location":"projets/salaires-panel-us/","title":"Mod\u00e9lisation statistique en donn\u00e9es de panel en R : analyse des d\u00e9terminants des salaires aux Etats-Unis","text":""},{"location":"projets/salaires-panel-us/#presentation-du-contexte-de-la-modelisation-statistique","title":"Pr\u00e9sentation du contexte de la mod\u00e9lisation statistique","text":"<p>Le travail de mod\u00e9lisation statistique s\u2019est fait \u00e0 partir de la base de donn\u00e9es : wagepan disponible en open source dans le package wooldridge disponible avec R. Wooldridge. Elle contient des informations sur les salaires et les caract\u00e9ristiques des travailleurs aux \u00c9tats-Unis. Il s\u2019agit de donn\u00e9es de panel donc ayant une dimension transversale et temporelle. L\u2019enjeu principal du travail r\u00e9sidait dans le choix d\u2019un estimateur adapt\u00e9 au contexte de l\u2019\u00e9tude (entre estimateur Within, Between, D1, Pooling) ainsi que dans le choix d\u2019une sp\u00e9cification de mod\u00e8le statistique le plus appropri\u00e9 permettant de comprendre la d\u00e9termination des salaires aux Etats-Unis en vue des variables d\u2019\u00e9tudes \u00e0 disposition.</p> <p>Ainsi il s\u2019agissait de savoir s\u2019il \u00e9tait pr\u00e9f\u00e9rable de sp\u00e9cifier un mod\u00e8le consid\u00e9rant des effets individuels ou non (\u00e0 savoir si les variables explicatives ont les m\u00eames effets pour chaque individu), si les caract\u00e9ristiques individuelles inobserv\u00e9es \u00e9taient \u00e0 consid\u00e9rer de mani\u00e8res fixe ou al\u00e9atoire ( \u00e0 savoir si les caract\u00e9ristiques intrins\u00e8ques de chaque individu \u00e9taient corr\u00e9l\u00e9es aux variables explicatives, ex : motivation et poursuite de longues \u00e9tudes). Apr\u00e8s la sp\u00e9cification d\u2019un mod\u00e8le \u00e0 effets individuels fixes donc gr\u00e2ce \u00e0 un estimateur within, l\u2019enjeu \u00e9tait de d\u00e9terminer les effets des caract\u00e9ristiques constantes dans le temps (effet de la couleur de peau sur les salaires) qui sont par nature neutralis\u00e9s par l\u2019estimation within. La solution pr\u00e9conis\u00e9e face \u00e0 ce probl\u00e8me aura \u00e9t\u00e9 de sp\u00e9cifier un mod\u00e8le dynamique qu\u2019est celui d'Haussmann-Taylor.</p> <p>Les r\u00e9sultats de cette analyse statistique auront permis de quantifier l\u2019impact de diff\u00e9rentes caract\u00e9ristiques de personnes qu\u2019elles soient constantes ou non dans le temps (origine ethnique, ann\u00e9es d\u2018\u00e9ducation vs exp\u00e9rience) sur la d\u00e9termination des salaires d\u2019Etats-uniens. </p>"},{"location":"projets/salaires-panel-us/#code-et-quelques-elements-de-data-vizualisation","title":"Code et quelques \u00e9l\u00e9ments de data vizualisation","text":"<p>Le code qui a \u00e9t\u00e9 produit pour ce projet d'analyse de donn\u00e9es et de mod\u00e9lisation statistique est disponible ici. Le code a \u00e9t\u00e9 \u00e9crit en language R et \u00e9crit sous Rstudio en markdown</p> <p>Voici quelques statistiques descriptives ainsi qu'un des mod\u00e8les sp\u00e9cifi\u00e9s tir\u00e9s du projet</p> <p>Distribution des salaires disponibles dans la base</p> <p></p> <p>Box Plots des moyennes des salaires sur la p\u00e9riode \u00e9tudi\u00e9e en fonction des cat\u00e9gories de m\u00e9tiers des individus pr\u00e9sents dans la base</p> <p></p> <p>Evolution des salaires moyens par secteurs d'activit\u00e9s sur la p\u00e9riode \u00e9tudi\u00e9e</p> <p></p> <p>Tableau des r\u00e9sultats de la sp\u00e9cification d'un mod\u00e8le Haussmann Taylor permettant d'attester des effets de r\u00e9gresseurs constants dans le temps dans le cadre d'une estimation within \u00e0 effet fixe</p> <p></p>"},{"location":"projets/terre-de-liens/","title":"Projet  analyse de donn\u00e9es en Python: syst\u00e8me d'actionnariat chez Terre de Liens","text":""},{"location":"projets/terre-de-liens/#presentation-du-contexte-de-lanalyse-de-donnees","title":"Pr\u00e9sentation du contexte de l'analyse de donn\u00e9es","text":"<p>Lors d'un stage effectu\u00e9 chez Terre de Liens, j'ai \u00e9t\u00e9 missionn\u00e9 pour la r\u00e9alisation d'une analyse de donn\u00e9es sur le syst\u00e8me d'actionnariat mis en place par la structure. Resituons dans un premier temps le syst\u00e8me d\u2019actionnariat mis en place par Terre de Liens. Ce dernier permet \u00e0 tout individu d\u2019acheter des actions aupr\u00e8s de sa soci\u00e9t\u00e9 fonci\u00e8re afin d\u2019augmenter le capital lui permettant d\u2019acheter des terres agricoles et d\u2019y installer des personnes ayant des projets d\u2019installation agricole.</p> <p>Il est donc possible de souscrire \u00e0 la Fonci\u00e8re Terre de liens en achetant une ou plusieurs actions et d\u2019affecter ce montant \u00e0 3 post diff\u00e9rents (\u00e0 une ferme ou terre agricole en particulier, \u00e0 la Fondation Terre de liens ou \u00e0 une association r\u00e9gionale Terre de Liens.</p> <p>Ayant la volont\u00e9 de mieux conna\u00eetre et comprendre la stabilit\u00e9 de ce syst\u00e8me, de le p\u00e9renniser et d\u2019augmenter le capital de la fonci\u00e8re, Terre de Liens m\u2019a missionn\u00e9 pour produire une analyse de ce syst\u00e8me d\u2019actionnariat. Il s\u2019agissait de comprendre avant tout sur quels types d\u2019actionnaires reposait ce syst\u00e8me (en termes de profils et de montants investis), ainsi que d\u2019identifier leurs comportements vis-\u00e0-vis de la soci\u00e9t\u00e9 fonci\u00e8re (volume d\u2019achat d\u2019actions et de rachats, intervalles en reprises d\u2019actions, rachats d\u2019actions, etc).</p> <p>Il \u00e9tait ensuite possible de proc\u00e9der \u00e0 diff\u00e9rents tests statistiques pour mettre en lumi\u00e8re de potentielles corr\u00e9lations ou pas entre diff\u00e9rents profils d\u2019actionnaires et diff\u00e9rents comportements.</p> <p>La base de donn\u00e9es utilis\u00e9e pour ce travail comportait dans sa version brute 39 476 lignes et 25 champs d\u2019int\u00e9r\u00eat \u00e0 extraire sur le cloud Salesforce de la strucutre. Dans un souci de protection des donn\u00e9es, une base fictive a \u00e9t\u00e9 recr\u00e9e pour transmettre la m\u00e9thodologie employ\u00e9e lors de ce chantier. Cette base fictive reproduit la structure de donn\u00e9es initialement utilis\u00e9es. Elle est aliment\u00e9e al\u00e9atoirement par de nouvelles donn\u00e9es \u00e0 chaque fois que le code qui permet l\u2019analyse est ex\u00e9cut\u00e9.</p>"},{"location":"projets/terre-de-liens/#code-et-quelques-elements-de-data-vizualisation","title":"Code et quelques \u00e9l\u00e9ments de data vizualisation","text":"<p>Le code de ce chantier d'analyse est disponible via ce lien. Il s'agit d'un code en python r\u00e9alis\u00e9 en Jupyter Notebook sous VS Code</p> <p>Voici quelques indicateurs extraits de l'analyse :</p> <p>Analyse de la variation moyenne du nombre d'actions souscrites entre chaque rang de souscriptions prises</p> <p></p> <p>Distribution des types de variations du nombre d'actions prises entre la septi\u00e8me et sixi\u00e8me  et entre la huiti\u00e8me et septi\u00e8me souscription</p> <p></p> <p>Box plot des dur\u00e9e entre reprises de souscription en fonction des diff\u00e9rents types d'actionnaires</p> <p></p> <p>R\u00e9partition des parts du capital poss\u00e9d\u00e9 parmi les 9 derniers centiles des actionnaires les plus riches</p> <p></p> <p>Test Chi-2 et test post ANOVA pour d\u00e9finir la relation entre l'affectation des diff\u00e9rentes souscriptions et le nombre moyens d'actions par souscription</p> <p>. </p>"}]}